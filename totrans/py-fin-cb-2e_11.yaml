- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asset Allocation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Asset allocation is the most important decision that any investor needs to face,
    and there is no one-size-fits-all solution that can work for each and every investor.
    By asset allocation, we mean spreading the investor’s total investment amount
    over certain assets (be it stocks, options, bonds, or any other financial instruments).
    When considering the allocation, the investor wants to balance the risk and the
    potential reward. At the same time, the allocation is dependent on factors such
    as the individual goals (expected return), risk tolerance (how much risk the investor
    is willing to accept), or the investment horizon (short-or long-term investment).
  prefs: []
  type: TYPE_NORMAL
- en: The key framework in asset allocation is the **modern portfolio theory** (**MPT**,
    also known as **mean-variance analysis**). It was introduced by the Nobel recipient
    Harry Markowitz and describes how risk-averse investors can construct portfolios
    to maximize their expected returns (profits) for a given level of risk. The main
    insight from MPT is that investors should not evaluate an asset’s performance
    alone (by metrics such as expected return or volatility), but instead, investigate
    how it would impact the performance of their portfolio of assets.
  prefs: []
  type: TYPE_NORMAL
- en: MPT is closely related to the concept of diversification, which simply means
    that owning different kinds of assets reduces risk, as the loss or gain of a particular
    security has less impact on the overall portfolio’s performance. Another key concept
    to be aware of is that while the portfolio return is the weighted average of the
    individual asset returns, this is not true for the risk (volatility). That is
    because the volatility is also dependent on the correlations between the assets.
    What is interesting is that thanks to optimized asset allocation, it is possible
    to have a portfolio with lower volatility than the lowest individual volatility
    of the assets in the portfolio. In principle, the lower the correlation between
    the assets we hold, the better it is for diversification. With a perfect negative
    correlation, we could diversify all the risk.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main assumptions of modern portfolio theory are:'
  prefs: []
  type: TYPE_NORMAL
- en: Investors are rational and aim to maximize their returns while avoiding risks
    whenever possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investors share the goal to maximize their expected returns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All investors have the same level of information about potential investments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Commissions, taxes, and transaction costs are not taken into account.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investors can borrow and lend money (without limits) at a risk-free rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we start with the most basic asset allocation strategy, and
    on its basis, learn how to evaluate the performance of portfolios (also applicable
    to individual assets). Later on, we show three different approaches to obtaining
    the efficient frontier, while also relaxing some of the assumptions of MPT. One
    of the main benefits of learning how to approach optimization problems is that
    they can be easily refactored, for example, by optimizing a different objective
    function or adding specific constraints on the weights. This requires only slight
    modifications to the code, while the majority of the framework stays the same.
    At the very end, we explore a novel approach to asset allocation based on the
    combination of graph theory and machine learning—Hierarchical Risk Parity.
  prefs: []
  type: TYPE_NORMAL
- en: 'We cover the following recipes in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Evaluating an equally-weighted portfolio’s performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the efficient frontier using Monte Carlo simulations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the efficient frontier using optimization with `SciPy`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the efficient frontier using convex optimization with `CVXPY`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the optimal portfolio with Hierarchical Risk Parity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating an equally-weighted portfolio’s performance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We begin with inspecting the most basic asset allocation strategy: the **equally-weighted**
    (**1/n**) **portfolio**. The idea is to assign equal weights to all the considered
    assets, thus diversifying the portfolio. As simple as that might sound, DeMiguel,
    Garlappi, and Uppal (2007) show that it can be difficult to beat the performance
    of the *1/n* portfolio by using more advanced asset allocation strategies.'
  prefs: []
  type: TYPE_NORMAL
- en: The goal of the recipe is to show how to create a *1/n* portfolio of the FAANG
    companies (Facebook/Meta, Amazon, Apple, Netflix, and Google/Alphabet), calculate
    its returns, and then use the `quantstats` library to quickly obtain all relevant
    portfolio evaluation metrics in the form of a tear sheet. Historically, a tear
    sheet is a concise (usually one-page) document summarizing important information
    about public companies.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Execute the following steps to create and evaluate the *1/n* portfolio:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the considered assets and download their prices from Yahoo Finance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate individual asset returns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the portfolio returns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Generate basic performance evaluation plots:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Executing the snippet generates the following figure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_01.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 11.1: Selected evaluation metrics of the 1/n portfolio'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The created snapshot consists of cumulative portfolio returns, the underwater
    plot depicting the drawdown periods (we will explain it in the *How it works…*
    section), and daily returns.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Calculate the basic portfolio evaluation metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Executing the snippet returns the following metrics for our portfolio and the
    benchmark:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: Performance evaluation metrics of the 1/n portfolio and the S&P
    500 benchmark'
  prefs: []
  type: TYPE_NORMAL
- en: We describe some of the metrics presented in *Figure 11.2* in the following
    section.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Steps 1* to *3*, we followed the already established approach—imported the
    libraries, set up the parameters, downloaded stock prices of the FAANG companies
    from the years 2020 to 2021, and calculated simple returns using the adjusted
    close prices.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 4*, we created a list of weights, each one equal to `1/n_assets`, where
    `n_assets` is the number of assets we want to have in our portfolio. Next, we
    calculated the portfolio returns as a matrix multiplication (also known as the
    dot product) of the portfolio weights and a transposed matrix of asset returns.
    To transpose the matrix, we used the `T` method of a `pandas` DataFrame. Then,
    we stored the portfolio returns as a `pandas` Series object, because that is the
    input for the ensuing step.
  prefs: []
  type: TYPE_NORMAL
- en: In the first edition of the book, we explored the performance of the *1/n* portfolio
    using the `pyfolio` library. However, since that time, the company that was responsible
    for the library (Quantopian) was closed, and the library is not actively maintained
    anymore. The library can still be used, as we show in the additional notebook
    available in the book’s GitHub repository. Alternatively, you can use `pyfolio-reloaded`,
    which is a fork of the original library maintained by Stefan Jansen, the author
    of *Machine Learning for Algorithmic Trading*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Step 6*, we generated a figure containing basic portfolio evaluation plots
    using the `quantstats` library. While we are already familiar with the plot depicting
    the daily returns, the other two are new:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cumulative returns plot**: It presents the evolution of the portfolio’s worth
    over time.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Underwater plot**:This plot presents the investment from a pessimistic point
    of view, as it focuses on losses. It plots all the drawdown periods and how long
    they lasted, that is, until the value rebounded to a new high. One of the insights
    we can draw from this is how long the periods of losses lasted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lastly, we generated portfolio evaluation metrics. While doing so, we also provided
    a benchmark. We chose the SPY, which is an **exchange-traded fund** (**ETF**)
    designed to follow the S&P 500 index. We could provide the benchmark as either
    the ticker or a `pandas` DataFrame/Series containing the prices/returns. The library
    can handle both options and we can indicate if we want to calculate the returns
    from prices using the `prepare_returns` argument.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most important metrics that we saw in *Figure 11.2* are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sharpe ratio**: One of the most popular performance evaluation metrics, it
    measures the excess return (over the risk-free rate) per unit of standard deviation.
    When no risk-free rate is provided, the default assumption is that it is equal
    to 0%. The greater the Sharpe ratio, the better the portfolio’s risk-adjusted
    performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sortino ratio**: A modified version of the Sharpe ratio, where the standard
    deviation in the denominator is replaced with downside deviation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Omega ratio**: The probability-weighted ratio of gains over losses for a
    determined return target threshold (default set to 0). Its main advantage over
    the Sharpe ratio is that the Omega ratio—by construction—considers all moments
    of the returns distribution, while the former only considers the first two (mean
    and variance).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max drawdown**: A metric of the downside risk of a portfolio, it measures
    the largest peak-to-valley loss (expressed as a percentage) during the course
    of the investment. The lower the maximum drawdown, the better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tail** **ratio**: The ratio (absolute) between the 95th and 5th percentile
    of the daily returns. A tail ratio of ~0.8 means that losses are ~1.25 times as
    bad as profits.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Downside deviation is similar to standard deviation; however, it only considers
    negative returns—it discards all positive changes from the series. It also allows
    us to define different levels of minimum acceptable returns (dependent on the
    investor) and returns below that threshold are used to calculate the downside
    deviation.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have mostly generated only the basic selection of plots and metrics
    available in the `quantstats` library. However, the library has much more to offer.
  prefs: []
  type: TYPE_NORMAL
- en: Full tear sheets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`quantstats` allows us to generate a complete HTML report containing all of
    the available plots and metrics (including a comparison to the benchmark). We
    can create such a report using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Executing it generates an HTML file containing the exhaustive tear sheet of
    our equally-weighted portfolio, compared to the SPY. Please refer to the `EW portfolio
    evaluation.html` file on GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s explain some of the new, yet relevant metrics visible in the generated
    report:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Calmar ratio**: The ratio is defined as the average annual compounded rate
    of return divided by the maximum drawdown for that same time period. The higher
    the ratio, the better.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Skew**: Skewness measures the degree of asymmetry, that is, how much is the
    given distribution (here, of portfolio returns) more skewed than the Normal distribution.
    Negative skewness (left-skewed distributions) means that large negative returns
    occur more frequently than large positive ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kurtosis**: It measures extreme values in either of the tails. Distributions
    with large kurtosis exhibit tail data exceeding the tails of the Gaussian distribution,
    meaning that large and small returns occur more frequently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alpha**:It describes a strategy’s ability to beat the market. In other words,
    it is the portfolio excess returns above the benchmark return.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Beta**:It measures the overall systematic risk of a portfolio of investments.
    In other words, it is a measure of portfolio volatility compared to the systematic
    risk of the entire market. A portfolio’s beta is equal to the weighted average
    of the beta coefficients of all the individual assets in a portfolio.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The metrics also include the 10 worst drawdowns. That is, they show how bad
    each of the drawdowns was, the recovery date, and the drawdowns’ duration. This
    information complements the analysis of the underwater plot we mentioned before.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: The 10 worst drawdowns during the evaluation period'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the report also contains some new plots, which we explain below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rolling Sharpe ratio**: Instead of reporting one number over time, it is
    also interesting to see how stable the Sharpe ratio was. That is why the following
    plot presents this metric calculated on a rolling basis, using 6 months’ worth
    of data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Rolling (6 months) Sharpe ratio'
  prefs: []
  type: TYPE_NORMAL
- en: The five worst drawdown periods are also visualized on a separate plot. For
    exact dates when the drawdowns started and ended, please refer to *Figure 11.3*.
    One thing worth mentioning is that the drawdown periods are superimposed on the
    cumulative returns plot. This way, we can clearly confirm the definition of the
    drawdown, that is, how much our portfolio is down from the peak before it recovers
    back to the peak level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Five worst drawdown periods during the evaluation period'
  prefs: []
  type: TYPE_NORMAL
- en: A histogram depicting the distribution of the monthly returns, including a **kernel
    density estimate** (**KDE**) and the average value. It’s helpful in analyzing
    the distribution of the returns. In the plot, we can see that the average monthly
    returns over the evaluation period were positive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: Distribution of the monthly returns (histogram + KDE)'
  prefs: []
  type: TYPE_NORMAL
- en: A heatmap serving as a summary of what the returns were over certain months/years.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: A heatmap presenting the monthly returns over the years'
  prefs: []
  type: TYPE_NORMAL
- en: A quantile plot showing the distribution of the returns aggregated to different
    frequencies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: Quantile plot aggregating the returns to different frequencies'
  prefs: []
  type: TYPE_NORMAL
- en: Before creating the comprehensive HTML report, we generated the basic plots
    and metrics using the `qs.reports.plots` and `qs.reports.metrics` functions. We
    can also use those functions to get the very same metrics/plots as we have obtained
    in the report by appropriately specifying the `mode` argument. To get all the
    metrics, we should pass `"full"` instead of `"basic"` (which is also the default
    value).
  prefs: []
  type: TYPE_NORMAL
- en: Enriching the pandas DataFrames/Series with new methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another interesting feature of the `quantstats` library is that it can enrich
    the `pandas` DataFrame or Series with new methods, used for calculating all the
    metrics available in the library. To do so, we first need to execute the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can access the methods straight from the DataFrame containing the
    return series. For example, we can quickly calculate the Sharpe and Sortino ratios
    using the following snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Which returns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The values are a match to what we calculated earlier using the `qs.reports.metrics`
    function. For a complete list of the available methods, you can run the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Additional resources are available here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'DeMiguel, V., Garlappi, L., & Uppal, R. 2007, “Optimal versus naive diversification:
    how inefficient is the 1/N portfolio strategy?” *The Review of Financial Studies*,
    22(5): 1915-1953: [https://doi.org/10.1093/rfs/hhm075](https://doi.org/10.1093/rfs/hhm075)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the efficient frontier using Monte Carlo simulations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'According to the Modern Portfolio Theory, the **efficient frontier** is a set
    of optimal portfolios in the risk-return spectrum. This means that the portfolios
    on the frontier:'
  prefs: []
  type: TYPE_NORMAL
- en: Offer the highest expected return for a given level of risk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offer the lowest level of risk for a given level of expected returns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All portfolios located under the efficient frontier curve are considered sub-optimal,
    so it is always better to choose the ones on the frontier instead.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we show how to find the efficient frontier using Monte Carlo
    simulations. Before showing more elegant approaches based on optimization, we
    employ a brute force approach in which we build thousands of portfolios using
    randomly assigned weights. Then, we can calculate the portfolios’ performance
    (expected returns/volatility) and use those values to determine the efficient
    frontier. For this exercise, we use the returns of four US tech companies from
    2021.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Execute the following steps to find the efficient frontier using Monte Carlo
    simulations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up the parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the stock prices from Yahoo Finance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the annualized average returns and the corresponding standard deviation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Simulate random portfolio weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the portfolio metrics:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a DataFrame containing all the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The DataFrame looks as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_09.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 11.9: Selected metrics of each of the generated portfolios'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Locate the points creating the efficient frontier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the efficient frontier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Executing the snippet generates the plot with all the randomly created portfolios,
    four points indicating the individual assets, and the efficient frontier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.10: The efficient frontier identified using Monte Carlo simulations'
  prefs: []
  type: TYPE_NORMAL
- en: In *Figure 11.10*, we see the typical, bullet-like shape of the efficient frontier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some insights we could draw from analyzing the efficient frontier:'
  prefs: []
  type: TYPE_NORMAL
- en: Anything to the left of the efficient frontier’s line is not achievable, as
    we cannot get that level of expected return for such a level of volatility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of a portfolio consisting only of Microsoft’s stock lies very
    close to the efficient frontier.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideally, we should search for a portfolio offering exceptional returns but with
    a combined standard deviation that is lower than the standard deviations of the
    individual assets. For example, we should not consider a portfolio consisting
    only of Meta’s stock (it is not efficient), but the one that lies on the frontier
    directly above. That is because the latter offers a much better expected return
    for the same level of expected volatility.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In *Step 2*, we defined the parameters used for this recipe, such as the considered
    timeframe, the assets we wanted to use for building the portfolio, and the number
    of simulations. An important thing to note here is that we also ran `ASSETS.sort()`
    to sort the list alphabetically. This matters when interpreting the results, as
    when downloading data from Yahoo Finance using the `yfinance` library, the obtained
    prices are ordered alphabetically, not as specified in the provided list. Having
    downloaded the stock prices, we calculated simple returns using the `pct_change`
    method, and dropped the first row containing NaNs.
  prefs: []
  type: TYPE_NORMAL
- en: For evaluating the potential portfolios, we needed the average (expected) annual
    return and the corresponding covariance matrix. We obtained them by using the
    `mean` and `cov` methods of the DataFrame. We also annualized both metrics by
    multiplying them by 252 (the average number of trading days in a year).
  prefs: []
  type: TYPE_NORMAL
- en: We needed the covariance matrix, as for calculating the portfolio volatility,
    we also needed to account for the correlation between the assets. To benefit from
    significant diversification, the assets should have low positive or negative correlations.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 5*, we calculated the random portfolio weights. Following the assumptions
    of the modern portfolio theory (refer to the chapter introduction for reference),
    the weights needed to be positive and sum up to 1\. To achieve this, we first
    generated a matrix of random numbers (between 0 and 1) using `np.random.random`.
    The matrix was of size `N_SIMULATIONS` by `n_assets`. To make sure the weights
    summed up to 1, we divided each row of the matrix by its sum.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Step 6*, we calculated the portfolio metrics—returns, standard deviation,
    and the Sharpe ratio. To calculate the expected annual portfolio returns, we had
    to multiply the weights by the previously calculated annual averages. For the
    standard deviations, we had to use the following formula: ![](../Images/B18112_11_001.png),
    where ![](../Images/B18112_11_002.png) is the vector of weights and ![](../Images/B18112_11_003.png)
    is the historical covariance matrix. We iterated over all the simulated portfolios
    using a `for` loop.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the `for` loop implementation is actually faster than the vectorized
    matrix equivalent: `np.diag(np.sqrt(np.dot(weights,` `np.dot(cov_mat, weights.T))))`.
    The reason for that is the quickly increasing number of off-diagonal elements
    to be calculated, which does not matter for the metrics of interest. This approach
    is faster than the `for` loop for only a relatively small number of simulations
    (~100).'
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we assumed that the risk-free rate was 0%, so the Sharpe ratio
    of the portfolio could be calculated as portfolio returns divided by the portfolio’s
    volatility. Another possible approach would be to calculate the average annual
    risk-free rate over 2021 and to use the portfolio excess returns for calculating
    the ratio.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to keep in mind while finding the optimal asset allocation and evaluating
    its performance is that we are optimizing historically. We use the past performance
    to select the allocation that should work best, provided the market conditions
    do not change. As we know very well, that is rarely the case, thus past performance
    is not always indicative of future performance.
  prefs: []
  type: TYPE_NORMAL
- en: The last three steps led to visualizing the results. First, we put all the relevant
    metrics into a `pandas` DataFrame. Second, we identified the points of the efficient
    frontier. To do so, we created an array of expected returns from the sample. We
    used `np.linspace`, with the min and max values coming from the calculated portfolio
    returns. We rounded the numbers to two decimals to make the calculations smoother.
    For each expected return, we found the minimum observed volatility. In cases where
    there was no match, as can happen with equally spread points on the linear space,
    we skipped that point.
  prefs: []
  type: TYPE_NORMAL
- en: In the very last step, we plotted the simulated portfolios, the individual assets,
    and the approximated efficient frontier in one plot. The shape of the frontier
    was a bit jagged, which can be expected when using only simulated values that
    are not that frequent in some extreme areas. Additionally, we colored the dots
    representing the simulated portfolios by the value of the Sharpe ratio. Following
    the ratio’s definition, the upper-left part of the plot shows a sweet spot with
    the highest expected returns per expected volatility.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the available colormaps in `matplotlib` documentation. Depending
    on the problem at hand, a different colormap might be more suitable (sequential,
    diverging, qualitative, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having simulated 100,000 random portfolios, we can also investigate which one
    has the highest Sharpe ratio (maximum expected return per unit of risk, also known
    as the **tangency portfolio**) or minimum volatility. To locate these portfolios
    among the simulated ones, we use the `np.argmin` and `np.argmax` functions, which
    return the index of the minimum/maximum value in the array.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: We can also investigate the constituents of these portfolios, together with
    the expected performance. Here, we only focus on the results, but the code used
    for generating the summaries is available in the book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'The maximum Sharpe ratio portfolio allocates the majority of the resources
    (~95%) to Microsoft and virtually nothing to Twitter. That is because Twitter’s
    annualized average returns for 2021 were negative:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The minimum volatility portfolio assigns ~78% of the weight to Microsoft, as
    it is the stock with the lowest volatility (this can be inspected by viewing the
    covariance matrix):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we mark these two portfolios on the efficient frontier plot. To do so,
    we add two extra scatterplots, each with one point corresponding to the selected
    portfolio. We then define the marker shape with the `marker` argument and the
    marker size with the `s` argument. We increase the size of the markers to make
    the portfolios more visible among all other points.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the snippet generates the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.11: Efficient frontier with the Global Minimum Volatility and Max
    Sharpe Ratio portfolios'
  prefs: []
  type: TYPE_NORMAL
- en: We did not plot the individual assets and the efficient frontier’s line to avoid
    the plot becoming too cluttered. The plot aligns with the intuition we have built
    while analyzing *Figure 11.10*. First, the Minimum Volatility portfolio lies on
    the leftmost part of the frontier, which corresponds to the lowest expected volatility.
    Second, the Max Sharpe Ratio portfolio lies in the upper-left part of the plot,
    where the ratio of the expected returns to volatility is the highest.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the efficient frontier using optimization with SciPy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, *Finding the efficient frontier using Monte Carlo simulations*,
    we used a brute force approach based on Monte Carlo simulations to visualize the
    efficient frontier. In this recipe, we use a more refined method to find the frontier.
  prefs: []
  type: TYPE_NORMAL
- en: From its definition, the efficient frontier is formed by a set of portfolios
    offering the highest expected portfolio return for certain volatility, or offering
    the lowest risk (volatility) for a certain level of expected returns. We can leverage
    this fact, and use it in numerical optimization.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of optimization is to find the best (optimal) value of the objective
    function by adjusting the target variables and taking into account some boundaries
    and constraints (which have an impact on the target variables). In this case,
    the objective function is a function returning portfolio volatility, and the target
    variables are portfolio weights.
  prefs: []
  type: TYPE_NORMAL
- en: 'Mathematically, the problem can be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_004.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/B18112_11_005.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/B18112_11_006.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/B18112_11_007.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](../Images/B18112_11_008.png) is a vector of weights, ![](../Images/B18112_11_009.png)
    is the covariance matrix, ![](../Images/B18112_11_010.png) is a vector of returns,
    and ![](../Images/B18112_11_011.png)is the expected portfolio return.
  prefs: []
  type: TYPE_NORMAL
- en: To find the efficient frontier, we iterate the optimization routine used for
    finding the optimal portfolio weights over a range of expected portfolio returns.
  prefs: []
  type: TYPE_NORMAL
- en: In this recipe, we work with the same dataset as in the previous one in order
    to show that the results obtained by both approaches are similar.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This recipe requires running all the code from the *Finding the efficient frontier
    using Monte Carlo simulations* recipe.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Execute the following steps to find the efficient frontier using optimization
    with `SciPy`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define functions for calculating portfolio returns and volatility:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the function calculating the efficient frontier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the considered range of expected portfolio returns:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the efficient frontier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract the volatilities of the efficient portfolios:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the calculated efficient frontier, together with the simulated portfolios:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following figure presents a graph of the efficient frontier, calculated
    using numerical optimization:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_12.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 11.12: Efficient frontier identified using numerical optimization together
    with the previously generated random portfolios'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We see that the efficient frontier has a very similar shape to the one obtained
    using Monte Carlo simulations. The only difference is that the line is smoother.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Identify the minimum volatility portfolio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the performance summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running the snippet results in the following summary:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The minimum volatility portfolio is achieved by investing mostly in Microsoft
    and Meta, while not investing in Tesla at all.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned in the introduction, we continued the example from the previous
    recipe. That is why we had to run *Steps 1* to *4* from there (not shown here
    for brevity), to have all the required data. As an extra prerequisite, we had
    to import the optimization module from `SciPy`.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 2*, we defined two functions, which return the expected portfolio return
    and volatility, given historical data and the portfolio weights. We had to define
    these functions instead of calculating these metrics directly as we use them later
    on in the optimization procedure. The algorithm iteratively tries different weights
    and needs to be able to use the current values of the target variables (weights)
    to arrive at the metric it tries to optimize.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Step 3*, we defined a function called `get_efficient_frontier`. Its goal
    is to return a list containing the efficient portfolios, given historical metrics
    and the considered range of expected portfolio returns. This was the most important
    step of the recipe and contained a lot of nuances. We describe the logic of the
    function sequentially:'
  prefs: []
  type: TYPE_NORMAL
- en: The outline of the function is that it runs the optimization procedure for each
    expected portfolio return in the considered range, and stores the resulting optimal
    portfolio in a list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Outside of the `for` loop, we defined a couple of objects that we pass into
    the optimizer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The arguments that are passed to the objective function. In this case, these
    are the historical average returns and the covariance matrix. The function that
    we optimize must accept the arguments as inputs. That is why we pass the returns
    to the `get_portf_vol` function (defined in *Step 2*), even though they are not
    necessary for calculations and are not used within the function.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bounds` (a nested tuple)—for each target variable (weight), we provide a tuple
    containing the boundary values, that is, the minimum and maximum allowable values.
    In this case, the values span the range from 0 to 1 (no negative weights, as per
    the MPT).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initial_guess`, which is the initial guess of the target variables. The goal
    of using the initial guess is to make the optimization run faster and more efficiently.
    In this case, the guess is the equally-weighted allocation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Inside the `for` loop, we defined the last element used for the optimization—the
    constraints. We defined two constraints:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The expected portfolio return must be equal to the provided value.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The sum of the weights must be equal to 1.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The first constraint is the reason why the constraint’s tuple is defined within
    the loop. That is because the loop passes over the considered range of expected
    portfolio returns, and for each value, we find the optimal risk level.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We run the optimizer with the **Sequential Least-Squares Programming** (**SLSQP**)
    algorithm, which is frequently used for generic minimization problems. For the
    function to be minimized, we pass the previously defined `get_portfolio_vol` function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The optimizer sets the equality (`eq`) constraint to 0\. That is why the intended
    constraint, `np.sum(weights) == 1`, is expressed as `np.sum(weights) - 1 == 0`.
  prefs: []
  type: TYPE_NORMAL
- en: In *Steps 4* and *5*, we defined the range of expected portfolio returns (based
    on the range we empirically observed in the previous recipe) and ran the optimization
    function.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 6*, we iterated over the list of efficient portfolios and extracted
    the optimal volatilities. We extracted the volatility from the `scipy.optimize.OptimizeResult`
    object by accessing the `fun` element. This stands for the optimized objective
    function which is, in this case, the portfolio volatility.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 7*, we added the calculated efficient frontier on top of the plot from
    the previous recipe, *Finding the efficient frontier using Monte Carlo simulations*.
    All the simulated portfolios lie on or below the efficient frontier, which is
    what we expected to happen.
  prefs: []
  type: TYPE_NORMAL
- en: In *Steps 8* and *9*, we identified the minimum volatility portfolio, printed
    the performance metrics, and showed the portfolio’s weights (extracted from the
    efficient frontier).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now compare the two minimum volatility portfolios: the one obtained
    using Monte Carlo simulations, and the one we received from optimization. The
    prevailing pattern in the allocation is the same—allocate the majority of the
    available resources to Meta and Microsoft. We can also see that the volatility
    of the optimized strategy is slightly lower. This means that among the 100,000
    portfolios, we have not simulated the actual minimum volatility portfolio (for
    the considered range of expected portfolio returns).'
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We can also use the optimization approach to find the weights that generate
    a portfolio with the highest expected Sharpe ratio, that is, the tangency portfolio.
    To do so, we first need to redefine the objective function, which now will be
    the negative of the Sharpe ratio. The reason why we use the negative is that optimization
    algorithms run minimization problems. We can easily approach maximization problems
    by changing the sign of the objective function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the new objective function (negative Sharpe ratio):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The second step is very similar to what we have already done with the efficient
    frontier, this time without the `for` loop, as we are only searching for one set
    of weights. We include the risk-free rate in the arguments (though we assume it
    is 0%, for simplicity) and only use one constraint—the sum of the target variables
    must be equal to 1.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the optimized portfolio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Extract information about the maximum Sharpe ratio portfolio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the performance summary:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running the snippet prints the following summary of the portfolio maximizing
    the Sharpe ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: To achieve the maximum Sharpe ratio, the investor should invest mostly in Microsoft
    (>96% allocation), with a 0% allocation to Meta and Twitter.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Markowitz, H., 1952\. “Portfolio Selection,” *The Journal of Finance*, 7(1):
    77–91'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding the efficient frontier using convex optimization with CVXPY
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous recipe, *Finding the efficient frontier using optimization with*
    *SciPy*, we found the efficient frontier using numerical optimization with the
    `SciPy` library. We used portfolio volatility as the metric we wanted to minimize.
    However, it is also possible to state the same problem a bit differently and use
    convex optimization to find the efficient frontier.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can reframe the mean-variance optimization problem into a risk-aversion
    framework, in which the investor wants to maximize the risk-adjusted return:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_012.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/B18112_11_013.png)'
  prefs: []
  type: TYPE_IMG
- en: '![](../Images/B18112_11_006.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, ![](../Images/B18112_11_015.png) is the risk-aversion parameter, and the
    constraints specify that the weights must sum up to 1, and short-selling is not
    allowed. The higher the value of ![](../Images/B18112_11_016.png), the more risk-averse
    the investor is.
  prefs: []
  type: TYPE_NORMAL
- en: Short-selling assumes borrowing an asset and selling it on the open market.
    Then, we purchase the asset later at a lower price. Our gain is the difference
    after repaying the initial loan. In this recipe, we use the same data as in the
    previous two recipes, to make sure the results are comparable.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This recipe requires running all the code from the previous recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Finding the efficient frontier using Monte Carlo simulations*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Finding the efficient frontier using optimization with SciPy*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Execute the following steps to find the efficient frontier using convex optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Convert the annualized average returns and the covariance matrix to `numpy`
    arrays:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up the optimization problem:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the efficient frontier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Plot the allocation for different values of the risk-aversion parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In *Figure 11.13*, we can see the asset allocation for the considered range
    of risk-aversion parameters (![](../Images/B18112_11_017.png)):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_13.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 11.13: Asset allocation per various levels of risk-aversion'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In *Figure 11.13*, we can see that for very small values of ![](../Images/B18112_11_0161.png),
    the investor would allocate 100% of their resources to Tesla. As we increased
    the risk aversion, the allocation to Tesla grew smaller, and more weight was allocated
    to Microsoft and the other assets. At the other end of the considered values for
    the parameter, the investor would allocate 0% to Tesla.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Plot the efficient frontier, together with the individual assets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Figure *11.14* presents the efficient frontier, generated by solving the convex
    optimization problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.14: Efficient frontier identified by solving the convex optimization
    problem'
  prefs: []
  type: TYPE_NORMAL
- en: The generated frontier is similar to the one in *Figure 11.10* (generated using
    Monte Carlo simulations). Back then, we established that a portfolio consisting
    of only Microsoft’s stocks lies very close to the efficient frontier. Now we can
    say the same about the portfolio comprised entirely of Tesla’s stocks. When using
    Monte Carlo simulations, we did not have enough observations generated in that
    part of the returns/volatility plane to draw the efficient frontier line around
    that portfolio. In the *There’s more...* section, we also compare this frontier
    to the one obtained in the previous recipe, in which we used the `SciPy` library.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned in the introduction, we continued the example from the previous
    two recipes. That is why we had to run *Steps 1* to *4* from the *Finding the
    efficient frontier using Monte Carlo simulations* recipe (not shown here for brevity)
    to have all the required data. As an extra step, we had to import the `cvxpy`
    convex optimization library. We additionally converted the historical average
    returns and the covariance matrix into `numpy` arrays.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 3*, we set up the optimization problem. We started by defining the
    target variables (`weights`), the risk-aversion parameter (`gamma_par`, where
    “par” is added to highlight that it is a parameter of the optimization routine),
    the portfolio returns and volatility (both using the previously defined `weights`
    object), and lastly, the objective function—the risk-adjusted returns we want
    to maximize. Then, we created the `cp.Problem` object and passed the objective
    function and a list of constraints as arguments.
  prefs: []
  type: TYPE_NORMAL
- en: 'We used `cp.quad_form(x, y)` to express the following multiplication: *x*^T*yx*.'
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 4*, we found the efficient frontier by solving the convex optimization
    problem for multiple values of the risk-aversion parameter. To define the considered
    values, we used the `np.logspace` function to get 25 values of ![](../Images/B18112_11_0161.png).
    For each value of the parameter, we found the optimal solution by running `problem.solve()`.
    We stored the values of interest in dedicated lists.
  prefs: []
  type: TYPE_NORMAL
- en: '`np.logspace` is similar to `np.linspace`; the difference is that the former
    finds numbers evenly spread on a log scale instead of a linear scale.'
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 5*, we plotted the asset allocation per various levels of risk aversion.
    Lastly, we plotted the efficient frontier, together with the individual assets.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Comparing the results from two formulations of the asset allocation problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We can also plot the two efficient frontiers for comparison—the one calculated
    by minimizing the volatility per expected level of return, and the other one using
    convex optimization and maximizing the risk-adjusted return:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing the snippet generates the following plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_15.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.15: Comparison of efficient frontiers generated by minimizing volatility
    per expected level of return (left) and by maximizing the risk-adjusted return
    (right)'
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the generated efficient frontiers are very similar, with some
    minor differences. First, the one obtained using minimization is smoother, as
    we used more points to calculate the frontier. Second, the right one is defined
    for a slightly larger range of possible volatility/returns pairs.
  prefs: []
  type: TYPE_NORMAL
- en: Allowing for leverage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another interesting concept we can incorporate into the analysis is the maximum
    allowable leverage. We replace the non-negativity constraints on the weights with
    a max leverage constraint, using the norm of a vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following snippet, we only show what was added on top of the things
    we defined in *Step 3*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: In the next snippet, we modify the code, this time to include two loops—one
    over potential values of the risk-aversion parameter, and the other one indicating
    the maximum allowable leverage. Max leverage equal to 1 (meaning no leverage)
    results in a case similar to the previous optimization problem (only this time,
    there is no non-negativity constraint).
  prefs: []
  type: TYPE_NORMAL
- en: We also redefine the placeholder objects (used for storing the results) to be
    either 2D matrices (`np.ndarrays`) or including the third dimension, in the case
    of weights.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: In the following snippet, we plot the efficient frontiers for different maximum
    leverages. We can clearly see that higher leverage increases returns and, at the
    same time, allows for greater volatility.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Executing the code generates the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_16.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.16: Efficient frontier for different values of maximum leverage'
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we also recreate the plot showing weight allocation per varying risk-aversion
    levels. With a maximum leverage of 1, there is no short selling.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Executing the snippet generates the following figure.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.17: Asset allocation per different levels of risk aversion and maximum
    leverage'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can spot a clear pattern: with an increase in risk aversion, investors stop
    using leverage altogether and converge to a similar allocation for all levels
    of the maximum permitted leverage.'
  prefs: []
  type: TYPE_NORMAL
- en: Finding the optimal portfolio with Hierarchical Risk Parity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: De Prado (2018) explains that quadratic optimizers tend to deliver unreliable
    solutions, due to their instability, concentration, and underperformance. The
    main reason for all those troubles is the need to invert the covariance matrix,
    which is prone to cause large errors when the matrix is numerically ill-conditioned.
    He also refers to **Markowitz’s curse**, which implies that the more correlated
    the investments are, the greater the need for diversification, which in turn leads
    to bigger estimation errors in the portfolio weights.
  prefs: []
  type: TYPE_NORMAL
- en: A potential solution is to introduce a hierarchical structure, which means that
    small estimation errors will no longer lead to entirely different allocations.
    That is possible because the quadratic optimizers have complete freedom to fully
    reshuffle the weights to their liking (unless some explicit constraints are enforced).
  prefs: []
  type: TYPE_NORMAL
- en: '**Hierarchical Risk Parity** (**HRP**) is a novel portfolio optimization method
    that combines graph theory and machine learning techniques in order to build a
    diversified portfolio based on the information available in the covariance matrix.
    At a very high level, the algorithm works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Calculate a distance matrix based on the correlation of the assets (covariance
    matrix).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cluster the assets into a tree structure with hierarchical clustering (based
    on the distance matrix).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the minimum variance portfolio within each branch of the tree.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterate over the levels of the tree and combine the portfolios at each node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a more detailed description of the algorithm, please refer to De Prado (2018).
  prefs: []
  type: TYPE_NORMAL
- en: 'We also mention some of the advantages of the HRP approach:'
  prefs: []
  type: TYPE_NORMAL
- en: It fully utilizes the information from the covariance matrix and does not require
    inverting it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It treats clustered assets as complements, rather than substitutes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The weights produced by the algorithm are more stable and robust.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The solution can be intuitively understood with the help of visualizations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can include additional constraints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Literature suggests that the method outperforms the classical mean-variance
    approaches out-of-sample.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this recipe, we apply the Hierarchical Risk Parity algorithm to form a portfolio
    from the stocks of the 10 biggest US tech companies.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Execute the following steps to find the optimal asset allocation using the
    HRP:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Download the stock prices of the 10 biggest US tech companies:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the returns from prices:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Find the optimal allocation using Hierarchical Risk Parity:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Display the (cleaned) weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This returns the following portfolio weights:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the portfolio performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'which returns the following evaluation metrics:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Visualize the hierarchical clustering used for finding the portfolio weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running the snippet generates the following plot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_18.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 11.18: Dendrogram visualizing the process of cluster formation'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In *Figure 11.18*, we can see that companies such as Visa and MasterCard were
    clustered together. In the plot, the y-axis represents the distance between the
    two leaves that are to be merged.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This makes sense, as if we wanted to invest in a publicly traded US credit card
    company like Visa, we might consider adding or reducing the allocation to another
    very similar company, such as MasterCard. Similarly in the case of Google and
    Microsoft, although the difference between those two companies is larger. This
    is the very idea of applying the hierarchy structure to the correlation between
    the assets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find the number of stocks to buy using 50,000 USD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running the snippet prints the following dictionary of the suggested number
    of stocks to purchase and the leftover cash:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After importing the libraries, we downloaded the stock prices of the 10 largest
    US tech companies for the year 2021\. In *Step 3*, we created a DataFrame containing
    the daily stock returns using the `returns_from_prices` function.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 4*, we instantiated the `HRPOpt` object and passed in the stock returns
    as input. Then, we used the `optimize` method to find the optimal weights. An
    inquisitive reader might notice that when describing the algorithm, we mentioned
    that it is based on the covariance matrix, while we used the return series as
    input. Under the hood, when we pass in the `returns` argument, the class computes
    the covariance matrix for us. Alternatively, we can pass in the covariance matrix
    directly using the `cov_matrix` argument.
  prefs: []
  type: TYPE_NORMAL
- en: When passing the covariance matrix directly, we can benefit from using alternative
    formulations of the covariance matrix, rather than the sample covariance. For
    example, we could use the Ledoit-Wolf shrinkage or the **oracle approximating
    shrinkage** (**OAS**). You can find references for those methods in the *See also*
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we displayed the cleaned weights using the `clean_weights` method. It
    is a helper method that rounds the weights to 5 decimals (can be adjusted) and
    cuts off any weights below a certain threshold to 0\. In *Step 6*, we calculated
    the portfolio’s expected performance using the `portfolio_performance` method.
    While doing so, we changed the default risk-free rate to 0%.
  prefs: []
  type: TYPE_NORMAL
- en: In *Step 7*, we plotted the results of the hierarchical clustering using the
    `plot_dendogram` function. The figure produced by this function is very useful
    for getting an understanding of how the algorithm works and which assets were
    clustered together.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Step 8*, we performed a discrete allocation based on the calculated weights.
    We assumed we had 50,000 USD and wanted to allocate as much as possible using
    the HRP weights. First, we recovered the latest prices from the downloaded prices,
    so the ones from 2021-12-30\. Then, we instantiated an object of the `DiscreteAllocation`
    class by providing the weights, latest prices, and our budget. Lastly, we used
    the `lp_portfolio` method to use linear programming to find the number of stocks
    we should buy, while keeping in mind our budget. We obtained two objects as the
    output: a dictionary containing the pairs of assets and the corresponding number
    of stocks, and the remaining money.'
  prefs: []
  type: TYPE_NORMAL
- en: An alternative approach to linear programming would be to employ the greedy
    iterative search, available under the `greedy_portfolios` method.
  prefs: []
  type: TYPE_NORMAL
- en: There’s more...
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`PyPortfolioOpt` has much more to offer than we have covered. For example,
    it greatly simplifies obtaining the efficient frontier. We can calculate it using
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Import the libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the expected returns and the covariance matrix:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As we have already established multiple times in this chapter, mean-variance
    optimization requires two components: the expected returns of the assets and their
    covariance matrix. `PyPortfolioOpt` offers multiple possibilities for calculating
    both of them. While we have already mentioned alternatives to the covariance matrix,
    you can use the following for the expected returns: historical mean return, exponentially
    weighted mean historical return, and CAPM estimate of returns. Here, we calculated
    the historical mean and the Ledoit-Wolf shrinkage estimate of the covariance matrix.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Find and plot the efficient frontier:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Running the snippet generates the following figure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![](../Images/B18112_11_19.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 11.19: Efficient frontier obtained using the Ledoit-Wolf shrinkage estimate
    of the covariance matrix'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Identify the tangency portfolio:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This returns the following portfolio weights:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `EfficientFrontier` class allows for identifying more than just the tangency
    portfolio. We can also use the following methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`min_volatility`: Finds the portfolio with minimum volatility.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_quadratic_utility`: Finds the portfolio that maximizes the quadratic utility,
    given a level of risk aversion. This is the same approach as the one we have covered
    in the previous recipe.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`efficient_risk`: Finds a portfolio that maximizes the return for a given target
    risk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`efficient_return`: Finds a portfolio that minimizes the risk for a given target
    return.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the last two options, we can generate market neutral portfolios, that is,
    portfolios with weights summing up to zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we have mentioned before, the functionalities we showed are just the proverbial
    tip of the iceberg. Using the library, we can also explore the following:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Incorporate sector constraints: Let’s assume you want to have a portfolio of
    stocks from various sectors, while keeping some conditions, for example, having
    at least 20% in tech.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Optimize for transaction costs: In a case when we already have a portfolio
    and want to rebalance, it might be quite expensive to completely rebalance the
    portfolio (and as we have discussed before, the instability of the portfolio weights
    can be a big disadvantage of the mean-variance optimization). In such a case,
    we can add an additional objective to rebalance the portfolio while keeping the
    transaction costs as low as possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the L2 regularization while optimizing the portfolio: By using the regularization
    we counter the behavior of many weights dropping to zero. We can experiment with
    different values of the gamma parameter to find the allocation that works best
    for us. You might already be familiar with the L2 regularization thanks to the
    famous Ridge Regression algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the Black-Litterman model to get a more stable model of the expected returns
    than just by using the historical mean returns. It is a Bayesian approach to asset
    allocation, which combines a prior estimate of returns with views on certain assets
    to arrive at a posterior estimate of expected returns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the notebook on GitHub, you can also find short examples of finding the efficient
    frontier while allowing for short-selling or using L2 regularization.
  prefs: []
  type: TYPE_NORMAL
- en: You can also experiment with not using the expected returns. Literature suggests
    that due to the difficulties in getting an accurate estimate of expected returns,
    minimum variance portfolios consistently outperform the maximum Sharpe ratio portfolios
    out-of-sample.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Additional resources concerning the approaches mentioned in the recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Black, F; & Litterman, R. 1991\. “ Combining investor views with market equilibrium,”
    *The Journal of Fixed Income*, 1, (2): 7-18: https://doi.org/10.3905/jfi.1991.408013'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Black, F., & Litterman, R. 1992\. “Global portfolio optimization,” *Financial
    Analysts Journal*, *48(5):* 28-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen, Y., Wiesel, A., Eldar, Y. C., & Hero, A. O. 2010\. “Shrinkage Algorithms
    for MMSE Covariance Estimation,” IEEE Transactions on Signal Processing, 58(10):
    5016-5029: [https://doi.org/10.1109/TSP.2010.2053029](https://doi.org/10.1109/TSP.2010.2053029)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'De Prado, M. L. 2016\. “Building diversified portfolios that outperform out
    of sample,” *The Journal of Portfolio Management*, *42*(4): 59-69: https://doi.org/10.3905/jpm.2016.42.4.059.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: De Prado, M. L. 2018\. *Advances in Financial Machine Learning*. John Wiley
    & Sons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ledoit, O., & Wolf, M. 2003 “Improved estimation of the covariance matrix of
    stock returns with an application to portfolio selection,” *Journal of Empirical
    Finance*, *10*(5): 603-621'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ledoit, O., & Wolf, M. 2004\. “Honey, I shrunk the sample covariance matrix,”
    *The Journal of Portfolio Management*, *30*(4): 110-119: https://doi.org/10.3905/jpm.2004.110'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have learned about asset allocation. We started with the
    simplest equally-weighted portfolio, which was proven to be quite difficult to
    outperform, even with advanced optimization techniques. Then, we explored various
    approaches to calculating the efficient frontier using mean-variance optimization.
    Lastly, we also touched upon some of the recent developments in asset allocation,
    that is, the Hierarchical Risk Parity algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'You might find the following references interesting for learning more about
    approaching asset allocation with Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Riskfolio-Lib` ([https://github.com/dcajasn/Riskfolio-Lib](https://github.com/dcajasn/Riskfolio-Lib)):
    Another popular portfolio optimization library containing a wide selection of
    algorithms and evaluation metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`deepdow` ([https://github.com/jankrepl/deepdow](https://github.com/jankrepl/deepdow)):
    A Python library connecting portfolio optimization and deep learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next chapter, we cover various methods of backtesting trading and asset
    allocation strategies.
  prefs: []
  type: TYPE_NORMAL
