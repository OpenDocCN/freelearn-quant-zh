- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Linear Models – From Risk Factors to Return Forecasts
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性模型 - 从风险因素到回报预测
- en: The family of linear models represents one of the most useful hypothesis classes.
    Many learning algorithms that are widely applied in algorithmic trading rely on
    linear predictors because they can be efficiently trained, are relatively robust
    to noisy financial data, and have strong links to the theory of finance. Linear
    predictors are also intuitive, easy to interpret, and often fit the data reasonably
    well or at least provide a good baseline.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型家族代表了最有用的假设类之一。许多在算法交易中广泛应用的学习算法依赖于线性预测器，因为它们可以被有效地训练，相对而言对嘈杂的金融数据具有较强的鲁棒性，并且与金融理论有着紧密的联系。线性预测器也直观易懂，容易解释，并且通常能很好地拟合数据，或者至少提供一个良好的基准。
- en: 'Linear regression has been known for over 200 years, since Legendre and Gauss
    applied it to  astronomy and began to analyze its statistical properties. Numerous
    extensions have since adapted the linear regression model and the baseline **ordinary
    least squares** (**OLS**) method to learn its parameters:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归已经被人们所知超过200年，自从Legendre和Gauss将其应用于天文学并开始分析其统计属性以来。自那时起，许多扩展都已适应了线性回归模型和基线**普通最小二乘法**（**OLS**）方法来学习其参数：
- en: '**Generalized linear models** (**GLM**) expand the scope of applications by
    allowing for response variables that imply an error distribution other than the
    normal distribution. GLMs include the probit or logistic models for **categorical
    response variables** that appear in classification problems.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义线性模型**（**GLM**）通过允许响应变量表示除正态分布以外的误差分布来扩展应用范围。 GLM 包括针对分类问题中出现的**分类响应变量**的
    probit 或 logistic 模型。'
- en: More **robust estimation methods** enable statistical inference where the data
    violates baseline assumptions due to, for example, correlation over time or across
    observations. This is often the case with panel data that contains repeated observations
    on the same units, such as historical returns on a universe of assets.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多**稳健的估计方法**使得在数据违反基线假设的情况下进行统计推断成为可能，例如，随时间或观察之间的相关性。这在包含对同一单位进行重复观察的面板数据中经常发生，例如，一组资产的历史回报。
- en: '**Shrinkage methods** aim to improve the predictive performance of linear models.
    They use a complexity penalty that biases the coefficients learned by the model,
    with the goal of reducing the model''s variance and improving out-of-sample predictive
    performance.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收缩方法**旨在改善线性模型的预测性能。它们使用复杂性惩罚来偏置模型学习的系数，目的是减少模型的方差并提高样本外的预测性能。'
- en: In practice, linear models are applied to regression and classification problems
    with the goals of inference and prediction. Numerous asset pricing models have
    been developed by academic and industry researchers that leverage linear regression.
    Applications include the identification of significant factors that drive asset
    returns for better risk and performance management, as well as the prediction
    of returns over various time horizons. Classification problems, on the other hand,
    include directional price forecasts.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，线性模型被应用于回归和分类问题，其目标是推断和预测。学术界和工业界的研究人员已经开发了许多利用线性回归的资产定价模型。应用包括确定驱动资产回报的重要因素，以实现更好的风险和绩效管理，以及在各种时间范围内预测回报。另一方面，分类问题包括方向性价格预测。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: How linear regression works and which assumptions it makes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归是如何工作的以及它做出了什么样的假设
- en: Training and diagnosing linear regression models
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和诊断线性回归模型
- en: Using linear regression to predict stock returns
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归预测股票回报
- en: Use regularization to improve predictive performance
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则化来提高预测性能
- en: How logistic regression works
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归的工作原理
- en: Converting a regression into a classification problem
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将回归问题转化为分类问题
- en: You can find the code samples for this chapter and links to additional resources
    in the corresponding directory of the GitHub repository. The notebooks include
    color versions of the images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub存储库的相应目录中找到本章的代码示例和额外资源的链接。笔记本包括彩色版本的图像。
- en: From inference to prediction
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从推断到预测
- en: As the name suggests, linear regression models assume that the output is the
    result of a linear combination of the inputs. The model also assumes a random
    error that allows for each observation to deviate from the expected linear relationship.
    The reasons that the model does not perfectly describe the relationship between
    inputs and output in a deterministic way include, for example, missing variables,
    measurement, or data collection issues.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，线性回归模型假设输出是输入的线性组合的结果。该模型还假设存在随机误差，使得每个观测值都可以偏离预期的线性关系。导致模型不能完美地以确定的方式描述输入和输出之间关系的原因包括，例如，缺少变量、测量或数据收集问题。
- en: If we want to draw statistical conclusions about the true (but not observed)
    linear relationship in the population based on the regression parameters estimated
    from the sample, we need to add assumptions about the statistical nature of these
    errors. The baseline regression model makes the strong assumption that the distribution
    of the errors is identical across observations. It also assumes that errors are
    independent of each other—in other words, knowing one error does not help to forecast
    the next error. The assumption of **independent and identically distributed**
    (**IID**) errors implies that their covariance matrix is the identity matrix multiplied
    by a constant representing the error variance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要基于从样本估计的回归参数对人口中的真实（但未观察到的）线性关系进行统计结论，我们需要增加关于这些误差的统计性质的假设。基线回归模型做出了一个强大的假设，即误差的分布在观察中是相同的。它还假设错误相互独立——换句话说，知道一个错误不会帮助预测下一个错误。**独立同分布**（IID）误差的假设意味着它们的协方差矩阵是身份矩阵乘以代表误差方差的常数。
- en: These assumptions guarantee that the OLS method delivers estimates that are
    not only unbiased but also efficient, which means that OLS estimates achieve the
    lowest sampling error among all linear learning algorithms. However, these assumptions
    are rarely met in practice.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设保证了OLS方法提供的估计不仅是无偏的，而且是有效的，这意味着OLS估计在所有线性学习算法中获得最低的抽样误差。然而，这些假设在实践中很少得到满足。
- en: In finance, we often encounter panel data with repeated observations on a given
    cross section. The attempt to estimate the systematic exposure of a universe of
    assets to a set of risk factors over time typically reveals correlation along
    the time axis, in the cross-sectional dimension, or both. Hence, alternative learning
    algorithms have emerged that assume error covariance matrices that are more complex
    than multiples of the identity matrix.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，我们经常遇到具有给定横截面上重复观测的面板数据。尝试估计资产组合对一组风险因素随时间的系统性暴露通常会在时间轴上显示相关性，在横截面维度上也会如此。因此，出现了一些替代学习算法，假设误差协方差矩阵比身份矩阵的倍数更复杂。
- en: On the other hand, methods that learn biased parameters for a linear model may
    yield estimates with lower variance and, hence, improve their predictive performance.
    Shrinkage methods reduce the model's complexity by applying regularization, which
    adds a penalty term to the linear objective function.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，学习线性模型的有偏参数的方法可能会产生方差较低的估计值，从而提高其预测性能。收缩方法通过应用正则化来降低模型的复杂性，这会向线性目标函数添加惩罚项。
- en: This penalty is positively related to the absolute size of the coefficients
    so that they are shrunk relative to the baseline case. Larger coefficients imply
    a more complex model that reacts more strongly to variations in the inputs. When
    properly calibrated, the penalty can limit the growth of the model's coefficients
    beyond what is optimal from a bias-variance perspective.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这个惩罚项与系数的绝对大小正相关，因此相对于基线情况，它们会被收缩。较大的系数意味着更复杂的模型，它对输入变化的反应更强烈。当正确校准时，惩罚可以限制模型系数的增长，使其不超过从偏差-方差角度看到的最优值。
- en: First, we will introduce the baseline techniques for cross-section and panel
    data for linear models, as well as important enhancements that produce accurate
    estimates when key assumptions are violated. We will then illustrate these methods
    by estimating factor models that are ubiquitous in the development of algorithmic
    trading strategies. Finally, we will turn our attention to how shrinkage methods
    apply regularization and demonstrate how to use them to predict asset returns
    and generate trading signals.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍交叉和面板数据的线性模型的基线技术，以及在关键假设被违反时产生准确估计的重要增强方法。然后，我们将通过估计在算法交易策略开发中普遍存在的因子模型来说明这些方法。最后，我们将转向收缩方法如何应用正则化，并演示如何使用它们来预测资产回报并生成交易信号。
- en: The baseline model – multiple linear regression
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基线模型 - 多重线性回归
- en: We will begin with the model's specification and objective function, the methods
    we can use to learn its parameters, and the statistical assumptions that allow
    the inference and diagnostics of these assumptions. Then, we will present extensions
    that we can use to adapt the model to situations that violate these assumptions.
    Useful references for additional background include *Wooldridge* (*2002* and *2008*).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从模型的规范和目标函数开始，以及我们可以用来学习其参数的方法，以及允许推断和诊断这些假设的统计假设。然后，我们将介绍扩展内容，用于适应违反这些假设的情况。用于额外背景的有用参考资料包括*Wooldridge*（*2002*和*2008*）。
- en: How to formulate the model
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何制定模型
- en: The multiple regression model defines a linear functional relationship between
    one continuous outcome variable and *p* input variables that can be of any type
    but may require preprocessing. Multivariate regression, in contrast, refers to
    the regression of multiple outputs on multiple input variables.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 多重回归模型定义了一个连续结果变量和*p*个输入变量之间的线性功能关系，这些输入变量可以是任何类型，但可能需要预处理。相比之下，多元回归是指多个输出变量对多个输入变量的回归。
- en: 'In the population, the linear regression model has the following form for a
    single instance of the output *y*, an input vector ![](img/B15439_07_001.png),
    and the error ![](img/B15439_07_002.png):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在总体中，线性回归模型对于输出*y*的单个实例，输入向量![](img/B15439_07_001.png)，和误差项![](img/B15439_07_002.png)具有以下形式：
- en: '![](img/B15439_07_003.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_003.png)'
- en: 'The interpretation of the coefficients is straightforward: the value of a coefficient
    ![](img/B15439_07_093.png) is the partial, average effect of the variable *x*[i]
    on the output, holding all other variables constant.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的解释很简单：系数的值![](img/B15439_07_093.png)是变量*x*[i]对输出的部分平均效应，保持所有其他变量恒定。
- en: 'We can also write the model more compactly in matrix form. In this case, *y*
    is a vector of *N* output observations, *X* is the design matrix with *N* rows
    of observations on the *p* variables plus a column of 1s for the intercept, and
    ![](img/B15439_07_004.png) is the vector containing the *P* = *p*+1 coefficients:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以以矩阵形式更紧凑地写出模型。在这种情况下，*y*是一个由*N*个输出观测值组成的向量，*X*是设计矩阵，有*N*行观测值和*p*个变量的列，另外还有一列用于截距，![](img/B15439_07_004.png)是包含*P*
    = *p*+1个系数的向量：
- en: '![](img/B15439_07_005.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_005.png)'
- en: The model is linear in its *p* +1 parameters but can represent nonlinear relationships
    if we choose or transform variables accordingly, for example, by including a polynomial
    basis expansion or logarithmic terms. You can also use categorical variables with
    dummy encoding, and include interactions between variables by creating new inputs
    of the form *x*[i]*x*[j].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在其*p* +1个参数中是线性的，但如果我们选择或相应地转换变量，例如，通过包含多项式基函数扩展或对数项，它可以表示非线性关系。您还可以使用带有虚拟编码的分类变量，并通过创建形式为*x*[i]*x*[j]的新输入来包含变量之间的交互作用。
- en: To complete the formulation of the model from a statistical point of view so
    that we can test hypotheses about its parameters, we need to make specific assumptions
    about the error term. We'll do this after introducing the most important methods
    to learn the parameters.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从统计学角度完成模型的制定，以便我们可以测试关于其参数的假设，我们需要对误差项进行具体的假设。在介绍了学习参数的最重要方法后，我们将这样做。
- en: How to train the model
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何训练模型
- en: 'There are several methods we can use to learn the model parameters from the
    data: **ordinary least squares** (**OLS**), **maximum likelihood estimation**
    (**MLE**), and **stochastic gradient descent** (**SGD**). We will present each
    method in turn.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以从数据中学习模型参数：**普通最小二乘法**（**OLS**），**最大似然估计**（**MLE**），和**随机梯度下降**（**SGD**）。我们将依次介绍每种方法。
- en: Ordinary least squares – how to fit a hyperplane to the data
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 普通最小二乘法 - 如何将超平面拟合到数据
- en: The method of least squares is the original method that learns the parameters
    of the hyperplane that best approximates the output from the input data. As the
    name suggests, it takes the best approximation to minimize the sum of the squared
    distances between the output value and the hyperplane represented by the model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法是学习最佳逼近输出与输入数据之间关系的超平面的原始方法。顾名思义，它采用最佳逼近以最小化模型表示的输出值与超平面之间的距离的平方和。
- en: 'The difference between the model''s prediction and the actual outcome for a
    given data point is the **residual** (whereas the deviation of the true model
    from the true output in the population is called **error**). Hence, in formal
    terms, the least-squares estimation method chooses the coefficient vector to minimize
    the **residual sum of squares** (**RSS**):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定数据点，模型预测与实际结果之间的差异是**残差**（而真实模型与人口真实输出之间的偏差被称为**误差**）。因此，形式上，最小二乘估计方法选择系数向量以最小化**残差平方和**（**RSS**）：
- en: '![](img/B15439_07_006.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_006.png)'
- en: 'Thus, the least-squares coefficients ![](img/B15439_07_007.png) are computed
    as:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最小二乘系数 ![](img/B15439_07_007.png) 计算如下：
- en: '![](img/B15439_07_008.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_008.png)'
- en: 'The optimal parameter vector that minimizes the RSS results from setting the
    derivatives with respect to ![](img/B15439_07_009.png) of the preceding expression
    to zero. Assuming *X* has full column rank, which requires that the input variables
    are not linearly dependent, it is thus invertible, and we obtain a unique solution,
    as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化 RSS 的最优参数向量结果是将上述表达式对 ![](img/B15439_07_009.png) 的导数设置为零。假设 *X* 具有满列秩，这要求输入变量不是线性相关的，因此可逆，我们得到一个唯一解，如下所示：
- en: '![](img/B15439_07_010.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_010.png)'
- en: When *y* and *X* have means of zero, which can be achieved by subtracting their
    respective means, ![](img/B15439_07_009.png) represents the ratio of the covariance
    between the inputs and the outputs ![](img/B15439_07_012.png) and the output variance
    ![](img/B15439_07_013.png)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *y* 和 *X* 的均值为零时，可以通过减去它们的各自均值来实现，![](img/B15439_07_009.png) 表示输入与输出的协方差之比
    ![](img/B15439_07_012.png) 和输出方差 ![](img/B15439_07_013.png) ：
- en: 'There is also a geometric interpretation: the coefficients that minimize RSS
    ensure that the vector of residuals ![](img/B15439_07_014.png) is orthogonal to
    the subspace of ![](img/B15439_07_015.png) spanned by the *P* columns of *X*,
    and the estimates ![](img/B15439_07_016.png) are orthogonal projections into that
    subspace.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种几何解释：最小化 RSS 的系数确保残差向量 ![](img/B15439_07_014.png) 垂直于由 *X* 的 *P* 列张成的子空间，而估计值
    ![](img/B15439_07_016.png) 是该子空间的正交投影。
- en: Maximum likelihood estimation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: MLE is an important general method used to estimate the parameters of a statistical
    model. It relies on the likelihood function, which computes how likely it is to
    observe the sample of outputs when given the input data as a function of the model
    parameters. The likelihood differs from probabilities in that it is not normalized
    to a range from 0 to 1.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: MLE 是用于估计统计模型参数的重要一般方法。它依赖于似然函数，该函数计算了在给定输入数据的情况下观察到输出样本的可能性，作为模型参数的函数。似然性不同于概率，因为它没有归一化为0到1的范围。
- en: 'We can set up the likelihood function for the multiple linear regression example
    by assuming a distribution for the error term, such as the standard normal distribution:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过假设错误项的分布，如标准正态分布，我们可以为多元线性回归示例设置似然函数：
- en: '![](img/B15439_07_017.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_017.png)'
- en: 'This allows us to compute the conditional probability of observing a given
    output *y*[i] given the corresponding input vector *x*[i] and the parameters ![](img/B15439_07_009.png),
    ![](img/B15439_07_019.png):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够计算出在给定输入向量 *x*[i] 和参数 ![](img/B15439_07_009.png), ![](img/B15439_07_019.png)
    时观察到给定输出 *y*[i] 的条件概率：
- en: '![](img/B15439_07_020.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_020.png)'
- en: 'Assuming the output values are conditionally independent, given the inputs,
    the likelihood of the sample is proportional to the product of the conditional
    probabilities of the individual output data points. Since it is easier to work
    with sums than with products, we apply the logarithm to obtain the **log-likelihood
    function**:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输出值在给定输入的条件下是条件独立的，样本的似然性与各个输出数据点的条件概率的乘积成比例。由于处理总和比处理乘积更容易，我们对其应用对数以获得**对数似然函数**：
- en: '![](img/B15439_07_021.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_021.png)'
- en: 'The goal of MLE is to choose the model parameters that maximize the probability
    of the observed output sample, taking the inputs as given. Hence, the MLE parameter
    estimate results from maximizing the log-likelihood function:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: MLE的目标是选择最大化观察输出样本的概率的模型参数，假定输入是给定的。因此，MLE参数估计的结果来自于最大化对数似然函数：
- en: '![](img/B15439_07_022.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_022.png)'
- en: Due to the assumption of normally distributed errors, maximizing the log-likelihood
    function produces the same parameter solution as least squares. This is because
    the only expression that depends on the parameters is the squared residual in
    the exponent.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于假设误差正态分布，最大化对数似然函数产生与最小二乘相同的参数解。这是因为唯一依赖于参数的表达式是指数中的平方残差。
- en: For other distributional assumptions and models, MLE will produce different
    results, as we will see in the last section on binary classification, where the
    outcome follows a Bernoulli distribution. Furthermore, MLE is a more general estimation
    method because, in many cases, the least-squares method is not applicable, as
    we will see later for logistic regression.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他分布假设和模型，MLE将产生不同的结果，就像我们将在最后一节关于二元分类中看到的那样，其中结果遵循伯努利分布。此外，MLE是一种更一般的估计方法，因为在许多情况下，最小二乘法是不适用的，正如我们稍后将看到的逻辑回归一样。
- en: Gradient descent
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降
- en: Gradient descent is a general-purpose optimization algorithm that will find
    stationary points of smooth functions. The solution will be a global optimum if
    the objective function is convex. Variations of gradient descent are widely used
    in training complex neural networks, but also to compute solutions for MLE problems.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种通用的优化算法，将找到平滑函数的驻点。如果目标函数是凸函数，则解将是全局最优解。梯度下降的变体广泛用于训练复杂的神经网络，还用于计算MLE问题的解决方案。
- en: The algorithm uses the gradient of the objective function. The gradient contains
    the partial derivatives of the objective with respect to the parameters. These
    derivatives indicate how much the objective changes for an infinitesimal (infinitely
    small) step in the direction of the corresponding parameters. It turns out that
    the maximal change of the function value results from a step in the direction
    of the gradient itself.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法使用目标函数的梯度。梯度包含了关于参数的偏导数。这些导数表示了在对应参数的方向上进行微小（无穷小）步骤时，目标的变化量。事实证明，函数值的最大变化来自于沿着梯度方向的步骤。
- en: '*Figure 7.1* sketches the process for a single variable *x* and a convex function
    *f(x)*, where we are looking for the minimum, *x*[0] . Where the function has
    a negative slope, gradient descent increases the target value for *x*[0], and
    decreases the values otherwise:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.1*描绘了对于单变量*x*和凸函数*f(x)*的过程，其中我们正在寻找最小值，*x*[0]。当函数具有负斜率时，梯度下降增加*x*[0]的目标值，否则减少值：'
- en: '![](img/B15439_07_01.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_01.png)'
- en: 'Figure 7.1: Gradient descent'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：梯度下降
- en: When we minimize a function that describes, for example, the cost of a prediction
    error, the algorithm computes the gradient for the current parameter values using
    the training data. Then, it modifies each parameter in proportion to the negative
    value of its corresponding gradient component. As a result, the objective function
    will assume a lower value and move the parameters closer to the solution. The
    optimization stops when the gradient becomes small, and the parameter values change
    very little.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们最小化描述例如预测误差成本的函数时，算法使用训练数据计算当前参数值的梯度。然后，它根据其相应梯度分量的负值，按比例修改每个参数。结果，目标函数将取得较低的值，并将参数移动到解决方案附近。优化停止时，梯度变得很小，参数值变化很少。
- en: The size of these steps is determined by the learning rate, which is a critical
    parameter that may require tuning. Many implementations include the option for
    this learning rate to gradually decrease with the number of iterations. Depending
    on the size of the data, the algorithm may iterate many times over the entire
    dataset. Each such iteration is called an **epoch**. The number of epochs and
    the tolerance used to stop further iterations are additional hyperparameters you
    can tune.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤的大小由学习率确定，学习率是一个关键参数，可能需要调整。许多实现包括此学习率随迭代次数逐渐减小的选项。根据数据的大小，算法可能会多次迭代整个数据集。每个这样的迭代被称为一个**epoch**。你可以调整的其他超参数包括迭代的数量和用于停止进一步迭代的容差。
- en: Stochastic gradient descent randomly selects a data point and computes the gradient
    for this data point, as opposed to an average over a larger sample to achieve
    a speedup. There are also batch versions that use a certain number of data points
    for each step.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降（Stochastic gradient descent）随机选择一个数据点，并为该数据点计算梯度，而不是对较大样本进行平均以实现加速。还有一些批处理版本，每一步使用一定数量的数据点。
- en: The Gauss–Markov theorem
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯-马尔可夫定理
- en: To assess the statistical properties of the model and run inference, we need
    to make assumptions about the residuals that represent the part of the input data
    the model is unable to correctly fit or "explain."
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估模型的统计特性并进行推断，我们需要对残差做出假设，这些残差代表了模型无法正确拟合或“解释”的输入数据的部分。
- en: The **Gauss–Markov theorem** (**GMT**) defines the assumptions required for
    OLS to produce unbiased estimates of the model parameters ![](img/B15439_07_023.png),
    and for these estimates to have the lowest standard error among all linear models
    for cross-sectional data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯-马尔可夫定理**（**GMT**）定义了 OLS 产生模型参数 ![](img/B15439_07_023.png) 无偏估计所需的假设，以及这些估计在横截面数据的所有线性模型中具有最低标准误差。'
- en: 'The baseline multiple regression model makes the following GMT assumptions
    (*Wooldridge 2008*):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 基线多元回归模型对以下 GMT 做出如下假设（*Wooldridge 2008*）：
- en: In the population, linearity holds so that ![](img/B15439_07_024.png), where
    ![](img/B15439_07_025.png) are unknown but constant and ![](img/B15439_07_026.png)
    is a random error.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在总体中，线性成立，因此 ![](img/B15439_07_024.png)，其中 ![](img/B15439_07_025.png) 未知但恒定，![](img/B15439_07_026.png)
    是随机误差。
- en: The data for the input variables ![](img/B15439_07_027.png) is a random sample
    from the population.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入变量 ![](img/B15439_07_027.png) 的数据是来自总体的随机样本。
- en: No perfect collinearity—there are no exact linear relationships among the input
    variables.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无完全共线性—输入变量之间不存在精确的线性关系。
- en: 'The error ![](img/B15439_07_026.png) has a conditional mean of zero given any
    of the inputs: ![](img/B15439_07_029.png).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 误差 ![](img/B15439_07_026.png) 在给定任何输入时的条件均值为零：![](img/B15439_07_029.png)。
- en: 'Homoskedasticity—the error term ![](img/B15439_07_030.png) has constant variance
    given the inputs: ![](img/B15439_07_031.png)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同方差性（Homoskedasticity）—误差项 ![](img/B15439_07_030.png) 在给定输入的情况下具有恒定方差：![](img/B15439_07_031.png)
- en: The fourth assumption implies that no missing variable exists that is correlated
    with any of the input variables.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个假设暗示不存在与任何输入变量相关的缺失变量。
- en: Under the first four assumptions (GMT 1-4), the OLS method delivers unbiased
    estimates. Including an irrelevant variable does not bias the intercept and slope
    estimates, but omitting a relevant variable will result in biased parameter estimates.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在前四个假设（GMT 1-4）下，OLS 方法提供无偏估计。包括一个无关变量不会使截距和斜率估计出现偏差，但省略一个相关变量将导致参数估计偏差。
- en: 'Under GMT 1-4, OLS is then also consistent: as the sample size increases, the
    estimates converge to the true value as the standard errors become arbitrary.
    The converse is, unfortunately, also true: if the conditional expectation of the
    error is not zero because the model misses a relevant variable or the functional
    form is wrong (for example, quadratic or log terms are missing), then all parameter
    estimates are biased. If the error is correlated with any of the input variables,
    then OLS is also not consistent and adding more data will not remove the bias.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GMT 1-4 下，OLS 也是一致的：随着样本大小的增加，估计值收敛于真实值，标准误差变得任意。反之亦然：如果误差的条件期望不为零，因为模型遗漏了一个相关变量或函数形式错误（例如，遗漏了二次项或对数项），那么所有参数估计都是有偏的。如果误差与任何输入变量相关，则
    OLS 也不一致，增加更多数据也不会消除偏差。
- en: If we add the fifth assumption, then OLS also produces the **best linear unbiased
    estimates** (**BLUE**). Best means that the estimates have the lowest standard
    error among all linear estimators. Hence, if the five assumptions hold and the
    goal is statistical inference, then the OLS estimates are the way to go. If the
    goal, however, is to predict, then we will see that other estimators exist that
    trade some bias for a lower variance to achieve superior predictive performance
    in many settings.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们加上第五个假设，那么 OLS 也会产生**最佳线性无偏估计**（**BLUE**）。最佳意味着估计在所有线性估计器中具有最低的标准误差。因此，如果五个假设成立且目标是统计推断，则
    OLS 估计是正确的选择。然而，如果目标是预测，那么我们将看到其他估计器存在，它们在许多情况下通过牺牲一些偏差以获得更低的方差来实现更优的预测性能。
- en: Now that we have introduced the basic OLS assumptions, we can take a look at
    inference in small and large samples.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了基本的OLS假设，我们可以来看看小样本和大样本中的推断。
- en: How to conduct statistical inference
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何进行统计推断
- en: Inference in the linear regression context aims to draw conclusions from the
    sample data about the true relationship in the population. This includes testing
    hypotheses about the significance of the overall relationship or the values of
    particular coefficients, as well as estimates of confidence intervals.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归背景下的推断旨在从样本数据中推断出人口中的真实关系。这包括测试关于总体关系或特定系数值的假设，以及置信区间的估计。
- en: 'The key ingredient for statistical inference is a test statistic with a known
    distribution, typically computed from a quantity of interest like a regression
    coefficient. We can formulate a null hypothesis about this statistic and compute
    the probability of observing the actual value for this statistic, given the sample
    under the assumption that the hypothesis is correct. This probability is commonly
    referred to as the **p-value**: if it drops below a significance threshold (typically
    5 percent), then we reject the hypothesis because it makes the value that we observed
    for the test statistic in the sample very unlikely. On the flip side, the p-value
    reflects the probability that we are wrong in rejecting what is, in fact, a correct
    hypothesis.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 统计推断的关键要素是具有已知分布的检验统计量，通常是从感兴趣的数量（如回归系数）计算得出的。我们可以针对该统计量制定一个关于零假设，并计算在假设正确的情况下，在样本中观察到该统计量的实际值的概率。这个概率通常被称为**p值**：如果它降低到显著性阈值以下（通常为5%），那么我们会拒绝假设，因为它使我们在样本中观察到的检验统计量的值非常不太可能。另一方面，p值反映了我们在拒绝实际上是正确假设时可能出错的概率。
- en: In addition to the five GMT assumptions, the **classical linear model** assumes
    **normality**—that the population error is normally distributed and independent
    of the input variables. This strong assumption implies that the output variable
    is normally distributed, conditional on the input variables. It allows for the
    derivation of the exact distribution of the coefficients, which, in turn, implies
    exact distributions of the test statistics that are needed for exact hypotheses
    tests in small samples. This assumption often fails in practice—asset returns,
    for instance, are not normally distributed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除了五个GMT假设之外，**经典线性模型**还假设**正态性**——即人口误差服从正态分布，并且与输入变量独立。这个强假设意味着在给定输入变量的情况下，输出变量服从正态分布。它允许推导出系数的精确分布，进而意味着在小样本中进行精确假设检验所需的测试统计量的精确分布。在实践中，这个假设通常是不成立的——例如，资产回报并不服从正态分布。
- en: 'Fortunately, however, the test statistics used under normality are also approximately
    valid when normality does not hold. More specifically, the following distributional
    characteristics of the test statistics hold approximately under GMT assumptions
    1–5 and exactly when normality holds:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，幸运的是，即使在正态性不成立时，正态性下使用的检验统计量也近似有效。更具体地说，测试统计量的以下分布特征在GMT假设1-5下大致成立，在正态性成立时完全成立：
- en: 'The parameter estimates follow a multivariate normal distribution: ![](img/B15439_07_032.png).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数估计值遵循多元正态分布：![](img/B15439_07_032.png)。
- en: Under GMT 1–5, the parameter estimates are unbiased, and we can get an unbiased
    estimate of ![](img/B15439_07_033.png), the constant error variance, using ![](img/B15439_07_034.png).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GMT 1-5下，参数估计值是无偏的，并且我们可以使用 ![](img/B15439_07_034.png) 得到![](img/B15439_07_033.png)
    的无偏估计，即常数误差方差。
- en: The **t-statistic for a hypothesis test about an individual coefficient** ![](img/B15439_07_035.png)
    is ![](img/B15439_07_036.png) and follows a *t* distribution with *N*-*p*-1 degrees
    of freedom, where ![](img/B15439_07_037.png) is the *j*'s element of the diagonal
    of ![](img/B15439_07_038.png).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于个别系数的假设检验的**t统计量** ![](img/B15439_07_035.png) 是 ![](img/B15439_07_036.png)，并且遵循具有
    *N*-*p*-1 自由度的*t*分布，其中 ![](img/B15439_07_037.png) 是![](img/B15439_07_038.png)
    的对角线的第 *j* 个元素。
- en: The *t* distribution converges to the normal distribution. Since the 97.5 quantile
    of the normal distribution is about 1.96, a useful rule of thumb for a **95 percent
    confidence interval around a parameter estimate** is ![](img/B15439_07_039.png),
    where *se* means **standard error**. An interval that includes zero implies that
    we can't reject the null hypothesis that the true parameter is zero and, hence,
    irrelevant for the model.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t*分布收敛于正态分布。由于正态分布的97.5分位数约为1.96，因此**95%置信区间**的一个有用的经验法则是，其公式为![](img/B15439_07_039.png)，其中*se*表示**标准误差**。包含零的区间意味着我们无法拒绝真参数为零的零假设，因此对模型无关。'
- en: The F-statistic allows for tests of restrictions on several parameters, including
    whether the entire regression is significant. It measures the change (reduction)
    in the RSS that results from additional variables.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F统计量允许对多个参数的限制进行测试，包括整个回归是否显著。它衡量了由额外变量导致的RSS的变化（减少）。
- en: Finally, the **Lagrange multiplier** (**LM**) test is an alternative to the
    F-test for testing multiple restrictions.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，**拉格朗日乘数**（**LM**）检验是测试多重约束的F检验的替代方法。
- en: How to diagnose and remedy problems
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何诊断和解决问题
- en: Diagnostics validate the model assumptions and help us prevent wrong conclusions
    when interpreting the result and conducting statistical inference. They include
    goodness of fit measures and various tests of the assumptions about the error
    term, including how closely the residuals match a normal distribution.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断验证模型假设，并帮助我们在解释结果和进行统计推断时防止错误结论。它们包括拟合优度指标和有关误差项假设的各种测试，包括残差与正态分布的拟合程度
- en: Furthermore, diagnostics evaluate whether the residual variance is indeed constant
    or exhibits heteroskedasticity (covered later in this section). They also test
    if the errors are conditionally uncorrelated or exhibit serial correlation, that
    is, if knowing one error helps to predict consecutive errors.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，诊断评估残差方差是否确实恒定或是否表现出异方差性（稍后在本节中介绍）。它们还测试错误是否条件不相关或是否表现出串行相关性，即，如果知道一个错误有助于预测连续的错误。
- en: In addition to conducting the following diagnostic tests, you should always
    visually inspect the residuals. This helps to detect whether they reflect systematic
    patterns, as opposed to random noise that suggests the model is missing one or
    more factors that drive the outcome.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了进行以下诊断测试之外，您还应该始终直观地检查残差。这有助于检测它们是否反映了系统模式，而不是表明模型缺少一个或多个驱动结果的因素的随机噪声。
- en: Goodness of fit
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拟合优度
- en: '**Goodness-of-fit measures** assess how well a model explains the variation
    in the outcome. They help to evaluate the quality of the model specification,
    for instance, when selecting among different model designs.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**拟合优度指标**评估模型解释结果变异的能力。它们有助于评估模型规范的质量，例如在选择不同的模型设计时。'
- en: Goodness-of-fit metrics differ in how they measure the fit. Here, we will focus
    on in-sample metrics; we will use out-of-sample testing and cross-validation when
    we focus on predictive models in the next section.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合优度指标在衡量拟合程度时存在差异。在这里，我们将重点关注样本内指标；当我们关注预测模型时，我们将使用样本外测试和交叉验证。
- en: 'Prominent goodness-of-fit measures include the **(adjusted) R2**, which should
    be maximized and is based on the least-squares estimate:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 杰出的拟合优度指标包括（调整后的）R²，应最大化，并且基于最小二乘估计：
- en: R² measures the share of the variation in the outcome data explained by the
    model and is computed as ![](img/B15439_07_040.png), where TSS is the sum of squared
    deviations of the outcome from its mean. It also corresponds to the squared correlation
    coefficient between the actual outcome values and those estimated by the model.
    The implicit goal is to maximize R². However, it never decreases as we add more
    variables. One of the shortcomings of R², therefore, is that it encourages overfitting.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R²衡量模型解释结果数据变异的份额，并计算为![](img/B15439_07_040.png)，其中TSS是结果与其均值之间的平方偏差的和。它还对应于实际结果值与模型估计值之间的平方相关系数。隐含的目标是最大化R²。但是，随着添加更多变量，它永远不会减少。因此，R²的一个缺点是它鼓励过度拟合。
- en: The adjusted R² penalizes R² for adding more variables; each additional variable
    needs to reduce the RSS significantly to produce better goodness of fit.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整后的R²对R²进行惩罚以添加更多变量；每个额外变量都需要显著降低RSS才能产生更好的拟合优度。
- en: 'Alternatively, the **Akaike information criterion** (**AIC**) and the **Bayesian
    information criterion** (**BIC**) are to be minimized and are based on the maximum-likelihood
    estimate:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，要最小化的是**赤池信息准则**（**AIC**）和**贝叶斯信息准则**（**BIC**），它们基于最大似然估计：
- en: '![](img/B15439_07_041.png), where ![](img/B15439_07_042.png) is the value of
    the maximized likelihood function and *k* is the number of parameters.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/B15439_07_041.png)，其中![](img/B15439_07_042.png)是最大化似然函数的值，*k*是参数的数量。'
- en: '![](img/B15439_07_043.png), where *N* is the sample size.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/B15439_07_043.png)，其中 *N* 是样本量。'
- en: Both metrics penalize for complexity. BIC imposes a higher penalty, so it might
    underfit relative to AIC and vice versa.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种度量都对复杂性进行了惩罚。BIC施加了更高的惩罚，因此相对于AIC可能欠拟合，反之亦然。
- en: Conceptually, AIC aims to find the model that best describes an unknown data-generating
    process, whereas BIC tries to find the best model among the set of candidates.
    In practice, both criteria can be used jointly to guide model selection when the
    goal is an in-sample fit; otherwise, cross-validation and selection based on estimates
    of generalization error are preferable.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在概念上，AIC旨在找到最佳描述未知数据生成过程的模型，而BIC试图在候选模型集合中找到最佳模型。在实践中，当目标是样本内拟合时，可以同时使用这两个标准来指导模型选择；否则，交叉验证和基于泛化误差估计的选择更可取。
- en: Heteroskedasticity
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异方差性
- en: GMT assumption 5 requires the residual covariance to take the shape ![](img/B15439_07_044.png),
    that is, a diagonal matrix with entries equal to the constant variance of the
    error term. **Heteroskedasticity** occurs when the residual variance is not constant
    but differs across observations. If the residual variance is positively correlated
    with an input variable, that is, when errors are larger for input values that
    are far from their mean, then OLS standard error estimates will be too low; consequently,
    the t-statistic will be inflated, leading to false discoveries of relationships
    where none actually exist.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: GMT假设5要求残差协方差采用形状![](img/B15439_07_044.png)，即对角矩阵，其条目等于误差项的恒定方差。**异方差性**发生在残差方差不恒定，而是在观察之间不同的情况下。如果残差方差与输入变量呈正相关，即当误差较大时，与其均值相距较远的输入值，那么OLS标准误差估计将过低；因此，t统计量将被膨胀，导致在实际上不存在关系的情况下发现了假阳性关系。
- en: Diagnostics starts with a visual inspection of the residuals. Systematic patterns
    in the (supposedly random) residuals suggest statistical tests of the null hypothesis
    that errors are homoscedastic against various alternatives. These tests include
    the Breusch–Pagan and White tests.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断从对残差的可视检查开始。在（假定为随机的）残差中出现系统性模式表明对错误是同方差的零假设进行统计检验，而不同的备择假设。这些检验包括Breusch-Pagan和White检验。
- en: 'There are several ways to correct OLS estimates for heteroskedasticity:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以校正OLS估计的异方差性：
- en: '**Robust standard errors** (sometimes called *White standard errors*) take
    heteroskedasticity into account when computing the error variance using a so-called
    **sandwich estimator**.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稳健标准误差**（有时称为*White标准误差*）在计算误差方差时考虑了异方差性，使用所谓的**夹心估计量**。'
- en: '**Clustered standard errors** assume that there are distinct groups in your
    data that are homoscedastic, but the error variance differs between groups. These
    groups could be different asset classes or equities from different industries.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类标准误差**假定数据中存在不同的组，这些组是同方差的，但是组间的误差方差不同。这些组可以是不同的资产类别或来自不同行业的股票。'
- en: 'Several alternatives to OLS estimate the error covariance matrix using different
    assumptions when ![](img/B15439_07_045.png). The following are available in `statsmodels`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种替代OLS的方法，它们使用不同的假设来估计误差协方差矩阵，当![](img/B15439_07_045.png)时。以下是`statsmodels`中可用的选项：
- en: '**Weighted least squares (WLS)**: For heteroskedastic errors where the covariance
    matrix has only diagonal entries, as for OLS, but now the entries are allowed
    to vary.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权最小二乘法（WLS）**：用于异方差误差，其中协方差矩阵仅具有对角项，与OLS相同，但现在允许这些项变化。'
- en: '**Feasible generalized least squares (GLSAR)**: For autocorrelated errors that
    follow an autoregressive AR(*p*) process (see *Chapter 9*, *Time-Series Models
    for Volatility Forecasts and Statistical Arbitrage*).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可行广义最小二乘法（GLSAR）**：适用于自相关误差遵循自回归 AR(*p*) 过程（见 *第 9 章*，*波动率预测和统计套利的时间序列模型*）的情况。'
- en: '**Generalized least squares (GLS)**: For arbitrary covariance matrix structure;
    yields efficient and unbiased estimates in the presence of heteroskedasticity
    or serial correlation.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义最小二乘（GLS）**：适用于任意协方差矩阵结构；在异方差性或序列相关存在时产生高效且无偏的估计值。'
- en: Serial correlation
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 序列相关
- en: Serial correlation means that consecutive residuals produced by linear regression
    are correlated, which violates the fourth GMT assumption. Positive serial correlation
    implies that the standard errors are underestimated and that the t-statistics
    will be inflated, leading to false discoveries if ignored. However, there are
    procedures to correct for serial correlation when calculating standard errors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 序列相关意味着线性回归产生的连续残差是相关的，这违反了第四个GMT假设。正序列相关意味着标准误差被低估，并且t统计量将被夸大，如果忽略这一点，可能导致错误发现。但是，在计算标准误差时有纠正序列相关的程序。
- en: The **Durbin–Watson statistic** diagnoses serial correlation. It tests the hypothesis
    that the OLS residuals are not autocorrelated against the alternative that they
    follow an autoregressive process (which we will explore in the next chapter).
    The test statistic ranges from 0 to 4; values near 2 indicate non-autocorrelation,
    lower values suggest positive autocorrelation, and higher values indicate negative
    autocorrelation. The exact threshold values depend on the number of parameters
    and observations and need to be looked up in tables.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**杜宾-沃森统计量**用于诊断序列相关性。它检验普通最小二乘法残差不具有自相关性的假设，假设它们遵循自回归过程（我们将在下一章中探讨）。检验统计量的范围从0到4；接近2的值表示非自相关性，较低的值暗示着正自相关，而较高的值则表示负自相关。确切的阈值取决于参数和观测值的数量，并且需要在表中查找。'
- en: Multicollinearity
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多重共线性
- en: '**Multicollinearity** occurs when two or more independent variables are highly
    correlated. This poses several challenges:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**多重共线性**是指两个或更多个自变量高度相关时发生的情况。这带来了几个挑战：'
- en: It is difficult to determine which factors influence the dependent variable.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难确定哪些因素影响因变量。
- en: The individual p-values can be misleading—a p-value can be high, even if the
    variable is, in fact, important.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个p值可能会误导——即使变量实际上很重要，p值也可能很高。
- en: The confidence intervals for the regression coefficients will be too wide, possibly
    even including zero. This complicates the determination of an independent variable's
    effect on the outcome.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归系数的置信区间将会过宽，甚至可能包含零。这使得确定一个独立变量对结果的影响变得复杂。
- en: There is no formal or theory-based solution that corrects for multicollinearity.
    Instead, try to remove one or more of the correlated input variables, or increase
    the sample size.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正式的或基于理论的解决方案可以纠正多重共线性。相反，请尝试删除一个或多个相关的输入变量，或增加样本量。
- en: How to run linear regression in practice
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在实践中如何运行线性回归
- en: 'The accompanying notebook, `linear_regression_intro.ipynb`, illustrates a simple
    and then a multiple linear regression, the latter using both OLS and gradient
    descent. For the multiple regression, we generate two random input variables *x*[1]
    and *x*[2] that range from -50 to +50, and an outcome variable that''s calculated
    as a linear combination of the inputs, plus random Gaussian noise, to meet the
    normality assumption GMT 6:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 附带的笔记本`linear_regression_intro.ipynb`演示了简单线性回归和多元线性回归，后者同时使用OLS和梯度下降。对于多元回归，我们生成两个范围从-50到+50的随机输入变量*x*[1]和*x*[2]，以及一个作为输入的线性组合加上随机高斯噪声的结果变量，以满足正态性假设
    GMT 6：
- en: '![](img/B15439_07_046.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_046.png)'
- en: OLS with statsmodels
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 statsmodels 进行 OLS
- en: 'We use `statsmodels` to estimate a multiple regression model that accurately
    reflects the data-generating process, as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`statsmodels`来估计一个准确反映数据生成过程的多元回归模型，如下所示：
- en: '[PRE0]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This yields the following OLS Regression Results summary:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下普通最小二乘回归结果摘要：
- en: '![](img/B15439_07_02.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_02.png)'
- en: 'Figure 7.2: OLS Regression Results summary'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：OLS回归结果摘要
- en: 'The upper part of the summary displays the dataset characteristics—namely,
    the estimation method and the number of observations and parameters—and indicates
    that standard error estimates do not account for heteroskedasticity. The middle
    panel shows the coefficient values that closely reflect the artificial data-generating
    process. We can confirm that the estimates displayed in the middle of the summary
    result can be obtained using the OLS formula derived previously:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要的上半部分显示了数据集的特征——即估计方法和观测值和参数的数量，并指出标准误差估计不考虑异方差性。中间面板显示了系数值，这些值与人工数据生成过程密切相关。我们可以确认，在摘要结果中间显示的估计值可以使用先前导出的OLS公式获得：
- en: '[PRE1]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following code visualizes how the model fitted by the model to the randomly
    generated data points:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可视化了模型对随机生成数据点的拟合情况：
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Figure 7.3* displays the resulting hyperplane and original data points:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.3*显示了结果超平面和原始数据点：'
- en: '![](img/B15439_07_03.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_03.png)'
- en: 'Figure 7.3: Regression hyperplane'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：回归超平面
- en: The upper right part of the panel displays the goodness-of-fit measures we just
    discussed, alongside the F-test, which rejects the hypothesis that all coefficients
    are zero and irrelevant. Similarly, the t-statistics indicate that intercept and
    both slope coefficients are, unsurprisingly, highly significant.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 面板的右上部分显示了我们刚刚讨论过的拟合优度度量，以及F检验，它拒绝了所有系数为零且无关的假设。类似地，t统计量表明截距和两个斜率系数显然是高度显著的。
- en: The bottom part of the summary contains the residual diagnostics. The left panel
    displays skew and kurtosis, which are used to test the normality hypothesis. Both
    the Omnibus and the Jarque–Bera tests fail to reject the null hypothesis that
    the residuals are normally distributed. The Durbin–Watson statistic tests for
    serial correlation in the residuals and has a value near 2, which, given two parameters
    and 625 observations, fails to reject the hypothesis of no serial correlation,
    as outlined in the previous section on this topic.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要的底部包含了残差诊断。左侧面板显示了偏度和峰度，用于检验正态性假设。Omnibus和Jarque–Bera测试都未能拒绝残差服从正态分布的原假设。Durbin–Watson统计量测试残差的序列相关性，并且具有接近2的值，考虑到两个参数和625个观测值，未能拒绝有关此主题的前一节中概述的无序列相关假设。
- en: 'Lastly, the condition number provides evidence about multicollinearity: it
    is the ratio of the square roots of the largest and the smallest eigenvalue of
    the design matrix that contains the input data. A value above 30 suggests that
    the regression may have significant multicollinearity.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，条件数提供了关于多重共线性的证据：它是包含输入数据的设计矩阵的最大特征值和最小特征值的平方根之比。30以上的值表明回归可能存在显著的多重共线性。
- en: '`statsmodels` includes additional diagnostic tests that are linked in the notebook.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels`包含了与笔记本链接的额外诊断测试。'
- en: Stochastic gradient descent with sklearn
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用sklearn的随机梯度下降
- en: The sklearn library includes an `SGDRegressor` model in its `linear_models`
    module. To learn the parameters for the same model using this method, we need
    to standardize the data because the gradient is sensitive to the scale.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn库在其`linear_models`模块中包括一个`SGDRegressor`模型。为了使用该方法学习相同模型的参数，我们需要对数据进行标准化，因为梯度对尺度很敏感。
- en: 'We use the `StandardScaler()` for this purpose: it computes the mean and the
    standard deviation for each input variable during the fit step, and then subtracts
    the mean and divides by the standard deviation during the transform step, which
    we can conveniently conduct in a single `fit_transform()` command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`StandardScaler()`来实现这个目的：它在拟合步骤期间计算每个输入变量的平均值和标准差，然后在转换步骤期间减去平均值并除以标准差，我们可以方便地在单个`fit_transform()`命令中进行：
- en: '[PRE3]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we instantiate `SGDRegressor` using the default values except for a `random_state`
    setting to facilitate replication:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用默认值实例化`SGDRegressor`，除了设置一个`random_state`以便复制：
- en: '[PRE4]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we can fit the `sgd` model, create the in-sample predictions for both
    the OLS and the `sgd` models, and compute the root mean squared error for each:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以拟合`sgd`模型，为OLS模型和`sgd`模型创建样本内预测，并计算每个模型的均方根误差：
- en: '[PRE5]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As expected, both models yield the same result. We will now take on a more ambitious
    project using linear regression to estimate a multi-factor asset pricing model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，两个模型产生相同的结果。我们现在将承担一个更有雄心的项目，使用线性回归来估计多因素资产定价模型。
- en: How to build a linear factor model
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建线性因子模型
- en: Algorithmic trading strategies use factor models to quantify the relationship
    between the return of an asset and the sources of risk that are the main drivers
    of these returns. Each factor risk carries a premium, and the total asset return
    can be expected to correspond to a weighted average of these risk premia.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 算法交易策略使用因素模型来量化资产回报与风险来源之间的关系，这些风险是这些回报的主要驱动因素。每个因素风险都带有溢价，而总资产回报预计将对应于这些风险溢价的加权平均。
- en: 'There are several practical applications of factor models across the portfolio
    management process, from construction and asset selection to risk management and
    performance evaluation. The importance of factor models continues to grow as common
    risk factors are now tradeable:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 因素模型在组合管理流程的各个方面都有几个实际应用，从构建和资产选择到风险管理和绩效评估。随着共同的风险因素现在可交易，因素模型的重要性不断增长：
- en: A summary of the returns of many assets, by a much smaller number of factors,
    reduces the amount of data required to estimate the covariance matrix when optimizing
    a portfolio.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过少数因素总结许多资产的回报，可减少在优化组合时估计协方差矩阵所需的数据量。
- en: An estimate of the exposure of an asset or a portfolio to these factors allows
    for the management of the resulting risk, for instance, by entering suitable hedges
    when risk factors are themselves traded or can be proxied.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于资产或投资组合对这些因素的暴露的估计允许管理产生的风险，例如当风险因素本身可交易或可被替代时采取合适的对冲措施。
- en: A factor model also permits the assessment of the incremental signal content
    of new alpha factors.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因素模型还允许评估新α因素的增量信号内容。
- en: A factor model can also help assess whether a manager's performance, relative
    to a benchmark, is indeed due to skillful asset selection and market timing, or
    if the performance can instead be explained by portfolio tilts toward known return
    drivers. These drivers can, today, be replicated as low-cost, passively managed
    funds that do not incur active management fees.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因素模型还有助于评估管理人员相对于基准的表现是否确实是由于熟练的资产选择和市场择时，还是表现可以解释为对已知回报驱动因素的组合倾向。今天，这些驱动因素可以通过低成本、被动管理基金来复制，而不需要支付主动管理费用。
- en: The following examples apply to equities, but risk factors have been identified
    for all asset classes (Ang 2014).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于股票，但对于所有资产类别都已识别出风险因素（Ang 2014）。
- en: From the CAPM to the Fama–French factor models
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从CAPM到法玛-法国因素模型
- en: 'Risk factors have been a key ingredient to quantitative models since the **capital
    asset pricing model** (**CAPM**) explained the expected returns of all *N* assets
    ![](img/B15439_07_047.png) using their respective exposure ![](img/B15439_07_048.png)
    to a single factor, the expected excess return of the overall market over the
    risk-free rate ![](img/B15439_07_049.png). The CAPM model takes the following
    linear form:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 风险因素自**资本资产定价模型**（**CAPM**）解释了所有 *N* 资产的预期回报 ![](img/B15439_07_047.png) ，即它们各自对单一因素的暴露
    ![](img/B15439_07_048.png) 与总体市场超过无风险利率的预期超额回报 ![](img/B15439_07_049.png) ，成为量化模型的关键因素。CAPM
    模型采取以下线性形式：
- en: '![](img/B15439_07_050.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_050.png)'
- en: This differs from the classic fundamental analysis, à la Dodd and Graham, where
    returns depend on firm characteristics. The rationale is that, in the aggregate,
    investors cannot eliminate this so-called systematic risk through diversification.
    Hence, in equilibrium, they require compensation for holding an asset commensurate
    with its systematic risk. The model implies that, given efficient markets where
    prices immediately reflect all public information, there should be no superior
    risk-adjusted returns. In other words, the value of ![](img/B15439_07_051.png)
    should be zero.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这与经典的基本面分析不同，如道德和格雷厄姆，其中回报取决于公司特征。理论基础是，总体上，投资者不能通过分散化消除所谓的系统风险。因此，在均衡状态下，他们要求持有资产的补偿与其系统风险相称。该模型暗示，鉴于市场高效，价格立即反映所有公开信息，不应该有优越的风险调整回报。换句话说，![](img/B15439_07_051.png)
    的价值应为零。
- en: Empirical tests of the model use linear regression and have consistently failed,
    for example, by identifying anomalies in the form of superior risk-adjusted returns
    that do not depend on overall market exposure, such as higher returns for smaller
    firms (Goyal 2012).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的实证检验使用线性回归，一直持续失败，例如通过识别异常，即不依赖于整体市场暴露的优越风险调整回报，例如更小型公司的较高回报（Goyal 2012）。
- en: 'These failures have prompted a lively debate about whether the efficient markets
    or the single factor aspect of the joint hypothesis is to blame. It turns out
    that both premises are probably wrong:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些失败引发了关于是市场有效还是联合假设的单一因素方面出了问题的热烈辩论。结果表明，这两个前提都可能是错误的：
- en: 'Joseph Stiglitz earned the 2001 Nobel Prize in economics in part for showing
    that markets are generally not perfectly efficient: if markets are efficient,
    there is no value in collecting data because this information is already reflected
    in prices. However, if there is no incentive to gather information, it is hard
    to see how it should be already reflected in prices.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约瑟夫·斯蒂格利茨部分因表明市场通常不是完全有效的而获得了2001年诺贝尔经济学奖：如果市场是有效的，那么收集数据就没有价值，因为这些信息已经反映在价格中。然而，如果没有动力来收集信息，很难看到它如何已经反映在价格中。
- en: On the other hand, theoretical and empirical improvements of the CAPM suggest
    that additional factors help explain some of the anomalies mentioned previously,
    which result in various multi-factor models.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，对CAPM的理论和实证改进表明，额外因素有助于解释先前提到的一些异常情况，这导致了各种多因素模型。
- en: Stephen Ross proposed the **arbitrage pricing theory** (**APT**) in 1976 as
    an alternative that allows for several risk factors while eschewing market efficiency.
    In contrast to the CAPM, it assumes that opportunities for superior returns due
    to mispricing may exist but will quickly be arbitraged away. The theory does not
    specify the factors, but research suggests that the most important are changes
    in inflation and industrial production, as well as changes in risk premia or the
    term structure of interest rates.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 斯蒂芬·罗斯于1976年提出了**套利定价理论**（**APT**）作为另一种选择，它允许多个风险因素，同时避开市场效率。与CAPM相反，它假设由于错定价而获得优越回报的机会可能存在，但会很快被套利掉。该理论不指定因素，但研究表明最重要的因素可能是通胀和工业生产的变化，以及风险溢价或利率期限结构的变化。
- en: Kenneth French and Eugene Fama (who won the 2013 Nobel Prize) identified additional
    risk factors that depend on firm characteristics and are widely used today. In
    1993, the Fama–French three-factor model added the relative size and value of
    firms to the single CAPM source of risk. In 2015, the five-factor model further
    expanded the set to include firm profitability and level of investment, which
    had been shown to be significant in the intervening years. In addition, many factor
    models include a price momentum factor.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 肯尼斯·弗伦奇和尤金·法玛（2013年诺贝尔奖得主）确定了依赖于公司特征并且今天被广泛使用的额外风险因素。 1993年，法玛-法国三因子模型将相对规模和公司价值添加到了单一CAPM风险来源中。2015年，五因子模型进一步扩展了集合，包括公司盈利能力和投资水平，这些在介入的几年中被证明是显著的。此外，许多因子模型包括价格动量因子。
- en: 'The Fama–French risk factors are computed as the return difference on diversified
    portfolios with high or low values, according to metrics that reflect a given
    risk factor. These returns are obtained by sorting stocks according to these metrics
    and then going long stocks above a certain percentile, while shorting stocks below
    a certain percentile. The metrics associated with the risk factors are defined
    as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛-法国风险因素是根据反映特定风险因素的度量标准计算出高值或低值多元化投资组合的回报差异。通过根据这些度量标准对股票进行排序，然后做多某个百分位以上的股票，同时做空某个百分位以下的股票来获得这些回报。与风险因素相关的度量标准定义如下：
- en: '**Size**: **Market equity** (**ME**)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模**：**市值**（**ME**）'
- en: '**Value**: **Book value of equity** (**BE**) divided by ME'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值**：**股本账面价值**（**BE**）除以ME'
- en: '**Operating profitability (OP)**: Revenue minus cost of goods sold/assets'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**经营盈利能力（OP）**：收入减去销售成本/资产'
- en: '**Investment**: Investment/assets'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资**：投资/资产'
- en: There are also unsupervised learning techniques for the data-driven discovery
    of risk factors that use factors and principal component analysis. We will explore
    this in *Chapter 13*, *Data-Driven Risk Factors and Asset Allocation with Unsupervised
    Learning*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 还有无监督学习技术用于基于数据发现风险因素，该技术使用因素和主成分分析。我们将在*第13章*《基于数据的风险因素和无监督学习的资产配置》中探讨这一点。
- en: Obtaining the risk factors
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取风险因素
- en: Fama and French make updated risk factors and research portfolio data available
    through their website, and you can use the `pandas_datareader` library to obtain
    the data. For this application, refer to the `fama_macbeth.ipynb` notebook for
    the following code examples and additional detail.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和法伦奇通过他们的网站提供了更新的风险因素和研究投资组合数据，您可以使用 `pandas_datareader` 库来获取数据。对于这个应用程序，请参考
    `fama_macbeth.ipynb` 笔记本以获取以下代码示例和额外细节。
- en: 'In particular, we will be using the five Fama–French factors that result from
    sorting stocks, first into three size groups and then into two, for each of the
    remaining three firm-specific factors. Hence, the factors involve three sets of
    value-weighted portfolios formed as ![](img/B15439_07_052.png) sorts on size and
    book-to-market, size and operating profitability, and size and investment. The
    risk factor values computed as the average returns of the **portfolios** (**PF**)
    are outlined in the following table:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将使用法玛-法伦奇因子中的五个因子，这些因子是根据股票排序而得出的，首先分为三个大小组，然后分为两个，每个剩余的三个特定公司因子。因此，这些因子涉及三组以![](img/B15439_07_052.png)大小和账面市值排序的加权组合，大小和经营盈利能力排序，以及大小和投资排序。计算的风险因素值作为**投资组合**（**PF**）的平均回报在下表中概述：
- en: '| Concept | Label | Name | Risk factor calculation |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 概念 | 标签 | 名称 | 风险因素计算 |'
- en: '| Size | SMB | Small minus big | Nine small stock PF minus nine large stock
    PF. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 规模 | SMB | 小减大 | 九个小股票 PF 减去九个大股票 PF。 |'
- en: '| Value | HML | High minus low | Two value PF minus two growth (with low BE/ME
    value) PF. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 价值 | HML | 高减低 | 两个价值 PF 减去两个成长（具有低 BE/ME 价值）PF。 |'
- en: '| Profitability | RMW | Robust minus weak | Two robust OP PF minus two weak
    OP PF. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 盈利能力 | RMW | 强大减弱小 | 两个强大的 OP PF 减去两个弱小的 OP PF。 |'
- en: '| Investment | CMA | Conservative minus aggressive | Two conservative investment
    portfolios, minus two aggressive investment portfolios. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 投资 | CMA | 保守减激进 | 两个保守投资组合减去两个激进投资组合。 |'
- en: '| Market | Rm-Rf | Excess return on the market | Value-weight return of all
    firms incorporated in and listed on major US exchanges with good data, minus the
    one-month Treasury bill rate. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 市场 | Rm-Rf | 市场的超额回报 | 所有在美国主要交易所上市并上市的公司的加权回报减去一个月期的国债利率。 |'
- en: 'We will use returns at a monthly frequency that we will obtain for the period
    2010–2017, as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 2010 年至 2017 年的时期获得的每月频率的回报，如下所示：
- en: '[PRE6]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Fama and French also made numerous portfolios available that we can use to
    illustrate the estimation of the factor exposures, as well as the value of the
    risk premia available in the market for a given time period. We will use a panel
    of the 17 industry portfolios at a monthly frequency. We will subtract the risk-free
    rate from the returns because the factor model works with excess returns:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和法伦奇还提供了许多投资组合，我们可以用来说明因子暴露度的估计，以及市场上某个特定时期可用的风险溢价的价值。我们将使用每月频率的 17 个行业投资组合的面板。我们会从回报中减去无风险利率，因为因子模型使用超额回报：
- en: '[PRE7]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will now build a linear factor model based on this panel data using a method
    that addresses the failure of some basic linear regression assumptions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将基于这些面板数据构建一个线性因子模型，使用一种方法来解决一些基本线性回归假设的失败。
- en: Fama–Macbeth regression
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 法玛-麦克贝斯回归
- en: Given data on risk factors and portfolio returns, it is useful to estimate the
    portfolio's exposure to these returns to learn how much they drive the portfolio's
    returns. It is also of interest to understand the premium that the market pays
    for the exposure to a given factor, that is, how much taking this risk is worth.
    The risk premium then permits to estimate the return for any portfolio provide
    we know or can assume its factor exposure.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于风险因素和投资组合回报的数据，估计投资组合对这些回报的暴露度是有用的，以了解它们对投资组合回报的推动程度。了解市场为暴露于给定因素的回报支付的溢价也很有趣，即，承担这种风险有多值得。风险溢价然后允许估计任何投资组合的回报，只要我们知道或可以假设其因子暴露。
- en: More formally, we will have *i*=1, ..., *N* asset or portfolio returns over
    *t*=1, ..., *T* periods, and each asset's excess period return will be denoted.
    The goal is to test whether the *j*=1, ..., *M* factors explain the excess returns
    and the risk premium associated with each factor. In our case, we have *N*=17
    portfolios and *M*=5 factors, each with 96 periods of data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，我们将有 *i*=1, ..., *N* 个资产或投资组合在 *t*=1, ..., *T* 个时期的回报，每个资产的超额时期回报将被标记。目标是测试
    *j*=1, ..., *M* 个因素是否解释了超额回报以及与每个因素相关的风险溢价。在我们的情况下，我们有 *N*=17 个投资组合和 *M*=5 个因素，每个因素有
    96 个时期的数据。
- en: Factor models are estimated for many stocks in a given period. Inference problems
    will likely arise in such cross-sectional regressions because the fundamental
    assumptions of classical linear regression may not hold. Potential violations
    include measurement errors, covariation of residuals due to heteroskedasticity
    and serial correlation, and multicollinearity (Fama and MacBeth 1973).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'To address the inference problem caused by the correlation of the residuals,
    Fama and MacBeth proposed a two-step methodology for a cross-sectional regression
    of returns on factors. The two-stage Fama–Macbeth regression is designed to estimate
    the premium rewarded for the exposure to a particular risk factor by the market.
    The two stages consist of:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: 'First stage: *N* time-series regression, one for each asset or portfolio, of
    its excess returns on the factors to estimate the factor loadings. In matrix form,
    for each asset:![](img/B15439_07_053.png)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Second stage: *T* cross-sectional regression, one for each time period, to
    estimate the risk premium. In matrix form, we obtain a vector of risk premia for
    each period:![](img/B15439_07_054.png)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we can compute the factor risk premia as the time average and get a t-statistic
    to assess their individual significance, using the assumption that the risk premia
    estimates are independent over time:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15439_07_055.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: If we had a very large and representative data sample on traded risk factors,
    we could use the sample mean as a risk premium estimate. However, we typically
    do not have a sufficiently long history to, and the margin of error around the
    sample mean could be quite large. The Fama–Macbeth methodology leverages the covariance
    of the factors with other assets to determine the factor premia.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: The second moment of asset returns is easier to estimate than the first moment,
    and obtaining more granular data improves estimation considerably, which is not
    true of mean estimation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'We can implement the first stage to obtain the 17 factor loading estimates
    as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'For the second stage, we run 96 regressions of the period returns for the cross
    section of portfolios on the factor loadings:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we compute the average for the 96 periods to obtain our factor risk
    premium estimates:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The linearmodels library extends `statsmodels` with various models for panel
    data and also implements the two-stage Fama–MacBeth procedure:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This provides us with the same result:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15439_07_04.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.4: LinearFactorModel estimation summary'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: The accompanying notebook illustrates the use of categorical variables by using
    industry dummies when estimating risk premia for a larger panel of individual
    stocks.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: Regularizing linear regression using shrinkage
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The least-squares method to train a linear regression model will produce the
    best linear and unbiased coefficient estimates when the Gauss–Markov assumptions
    are met. Variations like GLS fare similarly well, even when OLS assumptions about
    the error covariance matrix are violated. However, there are estimators that produce
    biased coefficients to reduce the variance and achieve a lower generalization
    error overall (Hastie, Tibshirani, and Friedman 2009).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最小二乘法训练线性回归模型将在满足高斯-马尔科夫假设时产生最佳的线性和无偏的系数估计。即使OLS关于误差协方差矩阵的假设被违反，类似GLS的变体也能表现出色。然而，有些估计器会产生偏差系数以减小方差并在整体上实现更低的泛化误差（Hastie，Tibshirani
    和 Friedman 2009）。
- en: When a linear regression model contains many correlated variables, their coefficients
    will be poorly determined. This is because the effect of a large positive coefficient
    on the RSS can be canceled by a similarly large negative coefficient on a correlated
    variable. As a result, the risk of prediction errors due to high variance increases
    because this wiggle room for the coefficients makes the model more likely to overfit
    to the sample.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当线性回归模型包含许多相关变量时，它们的系数将被较差地确定。这是因为大正系数对RSS的影响可以被相关变量上的同样大的负系数抵消。因此，由于系数的这种摆动空间使得模型更有可能对样本过拟合，导致了因高方差而产生预测误差的风险增加。
- en: How to hedge against overfitting
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何对冲过拟合
- en: One popular technique to control overfitting is that of **regularization**,
    which involves the addition of a penalty term to the error function to discourage
    the coefficients from reaching large values. In other words, size constraints
    on the coefficients can alleviate the potentially negative impact on out-of-sample
    predictions. We will encounter regularization methods for all models since overfitting
    is such a pervasive problem.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 控制过拟合的一种流行技术是**正则化**，它涉及向误差函数添加惩罚项，以阻止系数达到较大的值。换句话说，对系数的大小施加约束可以缓解系数对样本外预测可能产生的负面影响。由于过拟合是一个普遍存在的问题，因此我们将遇到所有模型的正则化方法。
- en: 'In this section, we will introduce shrinkage methods that address two motivations
    to improve on the approaches to linear models discussed so far:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍缩小方法，以解决迄今为止讨论的线性模型的两个改进动机：
- en: '**Prediction accuracy**: The low bias but high variance of least-squares estimates
    suggests that the generalization error could be reduced by shrinking or setting
    some coefficients to zero, thereby trading off a slightly higher bias for a reduction
    in the variance of the model.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测准确度**：最小二乘估计的低偏差但高方差表明，通过缩小或将某些系数设为零，可以减小泛化误差，从而以稍高的偏差换取模型方差的减小。'
- en: '**Interpretation**: A large number of predictors may complicate the interpretation
    or communication of the big picture of the results. It may be preferable to sacrifice
    some detail to limit the model to a smaller subset of parameters with the strongest
    effects.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释**：大量的预测变量可能会复杂化结果的解释或传达整体结果的信息。牺牲一些细节以限制模型到具有最强效应的更小的参数子集可能更可取。'
- en: Shrinkage models restrict the regression coefficients by imposing a penalty
    on their size. They achieve this goal by adding a term ![](img/B15439_07_056.png)
    to the objective function. This term implies that the coefficients of a shrinkage
    model minimize the RSS, plus a penalty that is positively related to the (absolute)
    size of the coefficients.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 缩小模型通过对系数施加惩罚来限制回归系数的大小。它们通过向目标函数添加一个项 ![](img/B15439_07_056.png) 来实现这一目标。这一项意味着缩小模型的系数将最小化RSS，加上一个与系数的（绝对）大小正相关的惩罚。
- en: 'The added penalty thus turns the linear regression coefficients into the solution
    to a constrained minimization problem that, in general, takes the following Lagrangian
    form:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 添加的惩罚因此将线性回归系数转换为受约束的最小化问题的解，一般情况下，采用以下的拉格朗日形式：
- en: '![](img/B15439_07_057.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_057.png)'
- en: The regularization parameter ![](img/B15439_07_058.png) determines the size
    of the penalty effect, that is, the strength of the regularization. As soon as
    ![](img/B15439_07_059.png) is positive, the coefficients will differ from the
    unconstrained least squared parameters, which implies a biased estimate. You should
    choose hyperparameter ![](img/B15439_07_059.png) adaptively via cross-validation
    to minimize an estimate of the expected prediction error. We will illustrate how
    to do so in the next section.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化参数 ![](img/B15439_07_058.png) 确定惩罚效应的大小，即正则化的强度。一旦 ![](img/B15439_07_059.png)
    是正的，系数将与无约束的最小二乘参数不同，这意味着偏估计。您应该通过交叉验证自适应地选择超参数 ![](img/B15439_07_059.png) 来最小化预期预测误差的估计。我们将在下一节中说明如何做到这一点。
- en: Shrinkage models differ by how they calculate the penalty, that is, the functional
    form of *S*. The most common versions are the **ridge regression**, which uses
    the sum of the squared coefficients, and the **lasso model**, which bases the
    penalty on the sum of the absolute values of the coefficients.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型通过如何计算惩罚来区分，即* S *的函数形式。最常见的版本是**岭回归**，它使用平方系数的总和，以及**套索模型**，它将惩罚基于系数的绝对值的总和。
- en: '**Elastic net regression**, which is not explicitly covered here, uses a combination
    of both. Scikit-learn includes an implementation that works very similarly to
    the examples we will demonstrate here.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**弹性网络回归**在这里没有明确涵盖，它使用两者的组合。Scikit-learn包含一个实现，其工作方式与我们将在这里演示的示例非常相似。'
- en: How ridge regression works
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 岭回归的工作原理
- en: 'Ridge regression shrinks the regression coefficients by adding a penalty to
    the objective function that equals the sum of the squared coefficients, which
    in turn corresponds to the L2 norm of the coefficient vector (Hoerl and Kennard
    1970):'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归通过将惩罚添加到等于系数平方和的目标函数来收缩回归系数，这反过来对应于系数向量的L2范数（Hoerl和Kennard 1970）：
- en: '![](img/B15439_07_061.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_061.png)'
- en: 'Hence, the ridge coefficients are defined as:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，岭系数被定义为：
- en: '![](img/B15439_07_062.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_062.png)'
- en: The intercept ![](img/B15439_07_063.png) has been excluded from the penalty
    to make the procedure independent of the origin chosen for the output variable—otherwise,
    adding a constant to all output values would change all slope parameters, as opposed
    to a parallel shift.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 截距 ![](img/B15439_07_063.png) 已从惩罚中排除，以使该过程与所选的输出变量的原点无关—否则，向所有输出值添加常数将改变所有斜率参数，而不是平行移位。
- en: 'It is important to standardize the inputs by subtracting from each input the
    corresponding mean and dividing the result by the input''s standard deviation.
    This is because the ridge solution is sensitive to the scale of the inputs. There
    is also a closed solution for the ridge estimator that resembles the OLS case:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化输入很重要，通过从每个输入中减去相应的平均值并将结果除以输入的标准差来实现。这是因为岭回归解对输入的尺度敏感。对于岭估计器，也有一个类似OLS案例的封闭解决方案：
- en: '![](img/B15439_07_064.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_064.png)'
- en: The solution adds the scaled identity matrix ![](img/B15439_07_065.png) to *X*^T*X*
    before inversion, which guarantees that the problem is non-singular, even if *X*^T*X*
    does not have full rank. This was one of the motivations for using this estimator
    when it was originally introduced.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在求逆之前，解决方案在 *X*^T*X* 之前添加了缩放的单位矩阵 ![](img/B15439_07_065.png)，这确保了即使 *X*^T*X*
    不具有完全秩，问题也是非奇异的。这是最初引入此估计器时的动机之一。
- en: 'The ridge penalty results in the proportional shrinkage of all parameters.
    In the case of orthonormal inputs, the ridge estimates are just a scaled version
    of the least-squares estimates, that is:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚导致所有参数的按比例缩小。对于正交输入的情况，岭估计仅是最小二乘估计的缩放版本，即：
- en: '![](img/B15439_07_066.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_066.png)'
- en: Using the **singular value decomposition** (**SVD**) of the input matrix *X*,
    we can gain insight into how the shrinkage affects inputs in the more common case
    where they are not orthonormal. The SVD of a centered matrix represents the principal
    components of a matrix (see *Chapter 13*, *Data-Driven Risk Factors and Asset
    Allocation with Unsupervised Learning*) that capture uncorrelated directions in
    the column space of the data in descending order of variance.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 利用输入矩阵 *X* 的**奇异值分解** (**SVD**)，我们可以深入了解收缩如何影响输入，在更常见的情况下，即它们不是正交的情况下。中心矩阵的奇异值分解代表了矩阵的主成分（见*第13章*，*使用无监督学习的数据驱动风险因素和资产配置*），以方差递减的顺序捕获数据列空间中的不相关方向。
- en: Ridge regression shrinks the coefficients relative to the alignment of input
    variables with the directions in the data that exhibit most variance. More specifically,
    it shrinks those coefficients the most that represent inputs aligned with the
    principal components that capture less variance. Hence, the assumption that's
    implicit in ridge regression is that the directions in the data that vary the
    most will be most influential or most reliable when predicting the output.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: How lasso regression works
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The lasso (Hastie, Tibshirani, and Wainwright 2015), known as basis pursuit
    in signal processing, also shrinks the coefficients by adding a penalty to the
    sum of squares of the residuals, but the lasso penalty has a slightly different
    effect. The lasso penalty is the sum of the absolute values of the coefficient
    vector, which corresponds to its L1 norm. Hence, the lasso estimate is defined
    by:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B15439_07_067.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
- en: Similar to ridge regression, the inputs need to be standardized. The lasso penalty
    makes the solution nonlinear, and there is no closed-form expression for the coefficients,
    as in ridge regression. Instead, the lasso solution is a quadratic programming
    problem, and there are efficient algorithms that compute the entire path of coefficients,
    which results in different values of ![](img/B15439_07_059.png) with the same
    computational cost as ridge regression.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: The lasso penalty had the effect of gradually reducing some coefficients to
    zero as the regularization increases. For this reason, the lasso can be used for
    the continuous selection of a subset of features.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: Let's now move on and put the various linear regression models to practical
    use and generate predictive stock trading signals.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: How to predict returns with linear regression
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will use linear regression with and without shrinkage to
    predict returns and generate trading signals.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to create the model inputs and outputs. To this end, we'll create
    features along the lines we discussed in *Chapter 4*, *Financial Feature Engineering
    – How to Research Alpha Factors*, as well as forward returns for various time
    horizons, which we will use as outcomes for the models.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Then, we will apply the linear regression models discussed in the previous section
    to illustrate their usage with `statsmodels` and sklearn and evaluate their predictive
    performance. In the next chapter, we will use the results to develop a trading
    strategy and demonstrate the end-to-end process of backtesting a strategy driven
    by a machine learning model.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Preparing model features and forward returns
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To prepare the data for our predictive model, we need to:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Select a universe of equities and a time horizon
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build and transform alpha factors that we will use as features
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calculate forward returns that we aim to predict
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And (potentially) clean our data
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The notebook `preparing_the_model_data.ipynb` contains the code examples for
    this section.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Creating the investment universe
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will use daily equity data from the Quandl Wiki US Stock Prices dataset for
    the years 2013 to 2017\. See the instructions in the `data` directory in the root
    folder of the GitHub repository for this book on how to obtain the data.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自Quandl Wiki US Stock Prices数据集的每日股票数据，时间为2013年至2017年。请参阅此书GitHub存储库的根文件夹中的`data`目录中的说明，了解如何获取数据。
- en: 'We start by loading the daily (adjusted) **open, high, low, close, and volume**
    (**OHLCV**) prices and metadata, which includes sector information. Use the path
    to `DATA_STORE`, where you originally saved the Quandl Wiki data:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载每日（调整后的）**开盘价、最高价、最低价、收盘价和成交量**（**OHLCV**）价格和元数据，其中包括部门信息。使用您最初保存Quandl
    Wiki数据的`DATA_STORE`路径：
- en: '[PRE12]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We remove tickers that do not have at least 2 years of data:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除没有至少2年数据的股票：
- en: '[PRE13]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, we clean up the sector names and ensure that we only use equities with
    both price and sector information:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们清理部门名称，并确保我们仅使用具有价格和部门信息的权益：
- en: '[PRE14]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For now, we are left with 2,265 tickers with daily price data for at least
    2 years. First, there''s the `prices` DataFrame:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们还剩下2,265个具有至少2年每日价格数据的股票。首先，是`prices` DataFrame：
- en: '[PRE15]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, there''s the `stocks` DataFrame:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是`stocks` DataFrame：
- en: '[PRE16]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We will use a 21-day rolling average of the (adjusted) dollar volume traded
    to select the most liquid stocks for our model. Limiting the number of stocks
    also has the benefit of reducing training and backtesting time; excluding stocks
    with low dollar volumes can also reduce the noise of price data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用21天滚动平均的（调整后的）美元交易量来选择我们模型中最流动的股票。限制股票数量还有减少训练和回测时间的好处；排除低美元交易量股票也可以减少价格数据的噪音。
- en: 'The computation requires us to multiply the daily close price with the corresponding
    volume and then apply a rolling mean to each ticker using `.groupby()`, as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 计算要求我们将每日收盘价与相应的成交量相乘，然后对每个股票使用`.groupby()`应用滚动平均，如下所示：
- en: '[PRE17]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We then use this value to rank stocks for each date so that we can select,
    for example, the 100 most-traded stocks for a given date:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用此值对每个日期的股票进行排名，以便我们可以选择，例如，给定日期的前100个最活跃的股票：
- en: '[PRE18]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Selecting and computing alpha factors using TA-Lib
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用TA-Lib选择和计算阿尔法因子
- en: We will create a few momentum and volatility factors using TA-Lib, as described
    in *Chapter 4*, *Financial Feature Engineering – How to Research Alpha Factors*.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用TA-Lib创建一些动量和波动性因子，如*第4章*，*金融特征工程-如何研究阿尔法因子*中所述。
- en: 'First, we add the **relative strength index** (**RSI**), as follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们添加**相对强度指数**（**RSI**），如下所示：
- en: '[PRE19]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'A quick evaluation shows that, for the 100 most-traded stocks, the mean and
    median 5-day forward returns are indeed decreasing in the RSI values, grouped
    to reflect the commonly 30/70 buy/sell thresholds:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速的评估显示，对于最活跃的100只股票，5天期的平均和中位数正向回报确实随着RSI值的减少而减少，分组反映了通常的30/70买入/卖出阈值：
- en: '[PRE20]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '| rsi_signal | count | Mean | std | min | 25% | 50% | 75% | max |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| rsi_signal | count | Mean | std | min | 25% | 50% | 75% | max |'
- en: '| (0, 30] | 4,154 | 0.12% | 1.01% | -5.45% | -0.34% | 0.11% | 0.62% | 4.61%
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| (0, 30] | 4,154 | 0.12% | 1.01% | -5.45% | -0.34% | 0.11% | 0.62% | 4.61%
    |'
- en: '| (30, 70] | 107,329 | 0.05% | 0.76% | -16.48% | -0.30% | 0.06% | 0.42% | 7.57%
    |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| (30, 70] | 107,329 | 0.05% | 0.76% | -16.48% | -0.30% | 0.06% | 0.42% | 7.57%
    |'
- en: '| (70, 100] | 10,598 | 0.00% | 0.63% | -8.79% | -0.28% | 0.01% | 0.31% | 5.86%
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| (70, 100] | 10,598 | 0.00% | 0.63% | -8.79% | -0.28% | 0.01% | 0.31% | 5.86%
    |'
- en: 'Then, we compute **Bollinger Bands**. The TA-Lib `BBANDS` function returns
    three values so that we set up a function that returns a `DataFrame` with the
    higher and lower bands for use with `groupby()` and `apply()`:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算**布林带**。TA-Lib的`BBANDS`函数返回三个值，因此我们设置一个函数，返回一个用于`groupby()`和`apply()`的`DataFrame`中的上下轨带：
- en: '[PRE21]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We take the percentage difference between the stock price and the upper or
    lower Bollinger Band and take logs to compress the distribution. The goal is to
    reflect the current value, relative to the recent volatility trend:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们取股票价格与上下布林带之间的百分比差异，并取对数来压缩分布。目标是反映当前值与最近波动趋势的相对值：
- en: '[PRE22]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, we compute the **average true range** (**ATR**), which takes three inputs,
    namely, the high, low, and close prices. We standardize the result to make the
    metric more comparable across stocks:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算**平均真实范围**（**ATR**），它需要三个输入，即最高、最低和收盘价格。我们标准化结果，以使指标在股票之间更具可比性：
- en: '[PRE23]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we generate the **moving average convergence/divergence** (**MACD**)
    indicator, which reflects the difference between a shorter and a longer-term exponential
    moving average:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们生成**移动平均收敛/发散**（**MACD**）指标，反映了较短和较长期指数移动平均之间的差异：
- en: '[PRE24]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Adding lagged returns
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加滞后回报
- en: 'To capture the price trend for various historical lags, we compute the corresponding
    returns and transform the result into the daily geometric mean. We''ll use lags
    for 1 day; 1 and 1 weeks; and 1, 2, and 3 months. We''ll also winsorize the returns
    by clipping the values at the 0.01st and 99.99th percentile:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉各种历史滞后的价格趋势，我们计算相应的回报并将结果转换为日几何平均值。我们将使用1天的滞后；1周和1周；以及1、2和3个月。我们还将通过在0.01和99.99分位数处剪切值来修剪回报的
    winsorize 值：
- en: '[PRE25]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We then shift the daily, (bi-)weekly, and monthly returns to use them as features
    for the current observations. In other words, in addition to the latest returns
    for these periods, we also use the prior five results. For example, we shift the
    weekly returns for the prior 5 weeks so that they align with the current observations
    and can be used to predict the current forward return:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将每日、（双周）和每月的回报向后移动，以便将其用作当前观察的特征。换句话说，除了这些时期的最新回报外，我们还使用前五个结果。例如，我们将前5周的周回报向后移动，以使其与当前观察对齐，并可用于预测当前的前瞻回报：
- en: '[PRE26]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Generating target forward returns
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成目标前瞻回报
- en: We will test predictions for various lookahead periods. The goal is to identify
    the holding period that produces the best predictive accuracy, as measured by
    the **information coefficient** (**IC**).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测试各种前瞻期的预测。目标是确定产生最佳预测准确度的持有期，衡量标准是**信息系数**（**IC**）。
- en: 'More specifically, we shift returns for time horizon *t* back by *t* days to
    use them as forward returns. For instance, we shift the 5-day return from *t*[0]
    to *t*[5] back by 5 days so that this value becomes the model target for *t*[0].
    We can generate daily, (bi-)weekly, and monthly forward returns as follows:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们将时间段 *t* 的回报向前移动 *t* 天，以便将其用作前瞻回报。例如，我们将 *t*[0] 的5天回报向后移动5天，这样该值就成为
    *t*[0] 的模型目标。我们可以生成每日、（双周）和每月的前瞻回报如下：
- en: '[PRE27]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Dummy encoding of categorical variables
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 类别变量的虚拟编码
- en: 'We need to convert any categorical variable into a numeric format so that the
    linear regression can process it. For this purpose, we will use a dummy encoding
    that creates individual columns for each category level and flags the presence
    of this level in the original categorical column with an entry of 1, and 0 otherwise.
    The pandas function `get_dummies()` automates dummy encoding. It detects and properly
    converts columns of type objects, as illustrated here. If you need dummy variables
    for columns containing integers, for instance, you can identify them using the
    keyword columns:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将任何分类变量转换为数值格式，以便线性回归可以处理它。为此，我们将使用一种虚拟编码，为每个类别级别创建单独的列，并在原始分类列中标记该级别的存在，输入为1，否则为0。pandas
    函数 `get_dummies()` 自动化了虚拟编码。它检测并正确转换类型为对象的列，如此处所示。如果您需要对包含整数的列进行虚拟变量处理，例如，您可以使用关键字
    columns 进行识别：
- en: '[PRE28]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'When converting all categories into dummy variables and estimating the model
    with an intercept (as you typically would), you inadvertently create multicollinearity:
    the matrix now contains redundant information, no longer has full rank, and instead
    becomes singular.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 当将所有类别转换为虚拟变量并估计带有截距的模型（通常会这样做）时，您无意中创建了多重共线性：矩阵现在包含冗余信息，不再具有完整秩，而是变得奇异。
- en: It is simple to avoid this by removing one of the new indicator columns. The
    coefficient on the missing category level will now be captured by the intercept
    (which is always 1, including when every remaining category dummy is 0).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 通过移除其中一列新的指示器列，可以简单地避免这个问题。缺失类别级别的系数现在将被截距捕获（即使每个剩余类别虚拟变量都为0时，截距始终为1）。
- en: 'Use the `drop_first` keyword to correct the dummy variables accordingly:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `drop_first` 关键字来正确调整虚拟变量：
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To capture seasonal effects and changing market conditions, we create time
    indictor variables for the year and month:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉季节效应和不断变化的市场情况，我们为年份和月份创建时间指示变量：
- en: '[PRE30]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, we combine our price data with the sector information and create dummy
    variables for the time and sector categories:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将我们的价格数据与部门信息结合，并为时间和部门类别创建虚拟变量：
- en: '[PRE31]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We obtain some 50 features as a result that we can now use with the various
    regression models discussed in the previous section.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了大约50个特征，现在我们可以将其与前一节讨论的各种回归模型一起使用。
- en: Linear OLS regression using statsmodels
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 statsmodels 进行线性最小二乘回归
- en: In this section, we will demonstrate how to run statistical inference with stock
    return data using `statsmodels` and interpret the results. The notebook `04_statistical_inference_of_stock_returns_with_statsmodels.ipynb`
    contains the code examples for this section.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将演示如何使用 `statsmodels` 运行股票回报数据的统计推断并解释结果。笔记本 `04_statistical_inference_of_stock_returns_with_statsmodels.ipynb`
    包含此部分的代码示例。
- en: Selecting the relevant universe
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择相关的股票池
- en: 'Based on our ranked rolling average of the dollar volume, we select the top
    100 stocks for any given trading day in our sample:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们的美元交易量的排名滚动平均值，我们选择样本中任何给定交易日的前100只股票：
- en: '[PRE32]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We then create our outcome variables and features, as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建我们的结果变量和特征，如下所示：
- en: '[PRE33]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Estimating the vanilla OLS regression
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 估计普通最小二乘回归
- en: 'We can estimate a linear regression model using OLS with `statsmodels`, as
    demonstrated previously. We select a forward return, for example, for a 5-day
    holding period, and fit the model accordingly:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `statsmodels` 估计一个普通最小二乘回归模型，如前所示。我们选择一个前向回报，例如，一个5天的持有期，并相应地拟合模型：
- en: '[PRE34]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Diagnostic statistics
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 诊断统计
- en: 'You can view the full summary output in the notebook. We will omit it here
    to save some space, given the large number of features, and only display the diagnostic
    statistics:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在笔记本中查看完整的摘要输出。我们将在这里省略它以节省一些空间，鉴于特征数量很大，并且只显示诊断统计：
- en: '[PRE35]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The diagnostic statistics show a low p-value for the Jarque–Bera statistic,
    suggesting that the residuals are not normally distributed: they exhibit negative
    skew and high kurtosis. The left panel of *Figure 7.5* plots the residual distribution
    versus the normal distribution and highlights this shortcoming. In practice, this
    implies that the model is making more large errors than "normal":'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断统计显示 Jarque-Bera 统计量的 p 值较低，这表明残差不服从正态分布：它们呈负偏斜和高峰度。*图 7.5* 的左侧面板绘制了残差分布与正态分布的对比，并突出显示了这个缺点。实际上，这意味着模型产生的大误差比“正常”更多：
- en: '![](img/B15439_07_05.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_05.png)'
- en: 'Figure 7.5: Residual distribution and autocorrelation plots'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：残差分布和自相关图
- en: 'Furthermore, the Durbin–Watson statistic is low at 0.43 so that we comfortably
    reject the null hypothesis of "no autocorrelation" at the 5 percent level. Hence,
    the residuals are likely positively correlated. The right panel of the preceding
    figure plots the autocorrelation coefficients for the first 10 lags, pointing
    to a significant positive correlation up to lag 4\. This result is due to the
    overlap in our outcomes: we are predicting 5-day returns for each day so that
    outcomes for consecutive days contain four identical returns.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，杜宾-沃森统计量为0.43，因此我们可以在5%的水平下舒适地拒绝“无自相关”的零假设。因此，残差可能呈正相关。前一图的右侧面板绘制了前10个滞后的自相关系数，指出了直到滞后4的显著正相关性。这个结果是由于我们结果的重叠造成的：我们为每一天预测5天的回报，因此连续天的结果包含四个相同的回报。
- en: If our goal were to understand which factors are significantly associated with
    forward returns, we would need to rerun the regression using robust standard errors
    (a parameter in statsmodels' `.fit()` method) or use a different method altogether,
    such as a panel model that allows for more complex error covariance.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的目标是了解哪些因素与前向回报显著相关，我们将需要使用稳健标准误差重新运行回归（`statsmodels` 的 `.fit()` 方法中的一个参数）或者完全使用不同的方法，例如允许更复杂误差协方差的面板模型。
- en: Linear regression using scikit-learn
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 进行线性回归
- en: Since sklearn is tailored toward prediction, we will evaluate the linear regression
    model based on its predictive performance using cross-validation. You can find
    the code samples for this section in the notebook `05_predicting_stock_returns_with_linear_regression.ipynb`.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 sklearn 面向预测，我们将基于交叉验证评估线性回归模型的预测性能。您可以在笔记本 `05_predicting_stock_returns_with_linear_regression.ipynb`
    中找到此部分的代码示例。
- en: Selecting features and targets
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择特征和目标
- en: We will select the universe for our experiment, as we did previously in the
    OLS case, limiting tickers to the 100 most traded in terms of the dollar value
    on any given date. The sample still contains 5 years of data from 2013-2017.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们的实验选择股票池，就像我们在 OLS 情况下那样，将股票代码限制在任何给定日期按美元价值交易量排名前100的股票中。样本仍然包含2013年至2017年的5年数据。
- en: Cross-validating the model
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证模型
- en: Our data consists of numerous time series, one for each security. As discussed
    in *Chapter 6*, *The Machine Learning Process*, sequential data like time series
    requires careful cross-validation to be set up so that we do not inadvertently
    introduce look-ahead bias or leakage.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据包含大量的时间序列，每个安全性一个。如*第6章*，*机器学习过程*中所讨论的那样，像时间序列这样的顺序数据需要进行谨慎的交叉验证，以便我们不会不经意地引入前瞻性偏见或泄漏。
- en: We can achieve this using the `MultipleTimeSeriesCV` class that we introduced
    in *Chapter 6*, *The Machine Learning Process*. We initialize it with the desired
    lengths for the train and test periods, the number of test periods that we would
    like to run, and the number of periods in our forecasting horizon. The `split()`
    method returns a generator yielding pairs of train and test indices, which we
    can then use to select outcomes and features. The number of pairs depends on the
    parameter `n_splits`.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用我们在*第6章*，*机器学习过程*中介绍的 `MultipleTimeSeriesCV` 类来实现这一点。我们用所需的训练和测试期长度，我们想要运行的测试期数量，以及我们预测视野中的期数来初始化它。`split()`
    方法返回一个生成器，产生训练和测试索引对，然后我们可以用它来选择结果和特征。成对的数量取决于参数 `n_splits`。
- en: The test periods do not overlap and are located at the end of the period available
    in the data. After a test period is used, it becomes part of the training data
    that rolls forward and remains constant in size.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 测试期不重叠，位于数据可用期间的末尾。使用完测试期后，它将成为向前滚动的训练数据的一部分，并保持大小不变。
- en: 'We will test this using 63 trading days, or 3 months, to train the model and
    then predict 1-day returns for the following 10 days. As a result, we can use
    around 75 10-day splits during the 3 years, starting in 2015\. We will begin by
    defining the basic parameters and data structures, as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用63个交易日或3个月的时间来训练模型，然后预测接下来10天的1日回报。因此，在2015年开始，我们可以使用大约75个10天的分割期在3年期间进行测试。我们将首先定义基本参数和数据结构，如下所示：
- en: '[PRE36]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The cross-validation loop iterates over the train and test indices provided
    by `TimeSeriesCV`, selects features and outcomes, trains the model, and predicts
    the returns for the test features. We also capture the root mean squared error
    and the Spearman rank correlation between the actual and predicted values:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证循环遍历由 `TimeSeriesCV` 提供的训练和测试索引，选择特征和结果，训练模型，并预测测试特征的回报。我们还捕获实际值和预测值之间的均方根误差和Spearman秩相关性：
- en: '[PRE37]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The cross-validation process takes 2 seconds. We'll evaluate the results in
    the next section.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证过程需要2秒。我们将在下一节中评估结果。
- en: Evaluating the results – information coefficient and RMSE
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果 - 信息系数和RMSE
- en: We have captured 3 years of daily test predictions for our universe. To evaluate
    the model's predictive performance, we can compute the information coefficient
    for each trading day, as well as for the entire period by pooling all forecasts.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经捕获了我们宇宙中每天测试预测的3年数据。为了评估模型的预测性能，我们可以计算每个交易日的信息系数，以及通过汇总所有预测来计算整个期间的信息系数。
- en: The left panel of *Figure 7.6* (see the code in the notebook) shows the distribution
    of the rank correlation coefficients computed for each day and displays their
    mean and median, which are close to 1.95 and 2.56, respectively.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6的左侧面板（请查看笔记本中的代码）显示了为每一天计算的秩相关系数的分布，并显示它们的平均值和中位数，分别接近1.95和2.56。
- en: 'The figure''s right panel shows a scatterplot of the predicted and actual 1-day
    returns across all test periods. The seaborn `jointplot` estimates a robust regression
    that assigns lower weights to outliers and shows a small positive relationship.
    The rank correlation of actual and predicted returns for the entire 3-year test
    period is positive but low at 0.017 and statistically significant:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 图的右侧面板显示了在所有测试期间内预测和实际1日回报的散点图。seaborn `jointplot` 估计了一个鲁棒回归，对离群值赋予较低的权重，并显示了一个小的正相关关系。在整个3年的测试期间，实际和预测回报的秩相关性是正的，但较低，为0.017，并且在统计上显著：
- en: '![](img/B15439_07_06.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_06.png)'
- en: 'Figure 7.6: Daily and pooled IC for linear regression'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：线性回归的每日和汇总IC
- en: 'In addition, we can track how predictions performed in terms of the IC on a
    daily basis. *Figure 7.7* displays a 21-day rolling average for both the daily
    information coefficient and the RMSE, as well as their respective means for the
    validation period. This perspective highlights that the small positive IC for
    the entire period hides substantial variation that ranges from -10 to +10:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以跟踪预测在IC方面的每日表现。*图7.7*显示了每日信息系数和RMSE的21天滚动平均值，以及它们在验证期间的平均值。这个视角突显了整个时期的小正IC隐藏了从-10到+10的大幅度变化：
- en: '![](img/B15439_07_07.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_07.png)'
- en: 'Figure 7.7: 21-day rolling average for the daily IC and RMSE for the linear
    regression model'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：线性回归模型每日IC和RMSE的21天滚动平均值
- en: Ridge regression using scikit-learn
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用scikit-learn进行岭回归
- en: 'We will now move on to the regularized ridge model, which we will use to evaluate
    whether parameter constraints improve on the linear regression''s predictive performance.
    Using the ridge model allows us to select the hyperparameter that determines the
    weight of the penalty term in the model''s objective function, as discussed previously
    in the section *Shrinkage methods: regularization for linear regression*.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将转向正则化岭模型，我们将使用它来评估参数约束是否改善了线性回归的预测性能。使用岭模型使我们能够选择确定模型目标函数中惩罚项权重的超参数，正如前面的*收缩方法：线性回归的正则化*部分所讨论的那样。
- en: Tuning the regularization parameters using cross-validation
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用交叉验证调整正则化参数
- en: 'For ridge regression, we need to tune the regularization parameter with the
    keyword `alpha`, which corresponds to the ![](img/B15439_07_058.png) we used previously.
    We will try 18 values from 10^(-4) to 10⁴, where larger values imply stronger
    regularization:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 对于岭回归，我们需要使用关键字`alpha`调整正则化参数，该参数对应于我们先前使用的![](img/B15439_07_058.png)。我们将尝试从10^(-4)到10⁴的18个值，其中较大的值意味着更强的正则化：
- en: '[PRE38]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We will apply the same cross-validation parameters as in the linear regression
    case, training for 3 months to predict 10 days of daily returns.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用与线性回归案例相同的交叉验证参数，训练3个月以预测10天的每日收益。
- en: 'The scale sensitivity of the ridge penalty requires us to standardize the inputs
    using `StandardScaler`. Note that we always learn the mean and the standard deviation
    from the training set using the `.fit_transform()` method and then apply these
    learned parameters to the test set using the `.transform()` method. To automate
    the preprocessing, we create a `Pipeline`, as illustrated in the following code
    example. We also collect the ridge coefficients. Otherwise, cross-validation resembles
    the linear regression process:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚的尺度敏感性要求我们使用`StandardScaler`对输入进行标准化。请注意，我们始终从训练集中学习平均值和标准差，使用`.fit_transform()`方法，然后将这些学到的参数应用于测试集，使用`.transform()`方法。为了自动化预处理，我们创建了一个`Pipeline`，如下面的代码示例所示。我们还收集了岭系数。否则，交叉验证类似于线性回归过程：
- en: '[PRE39]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Cross-validation results and ridge coefficient paths
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证结果和岭系数路径
- en: We can now plot the IC for each hyperparameter value to visualize how it evolves
    as the regularization increases. The results show that we get the highest mean
    and median IC value for ![](img/B15439_07_070.png).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以绘制每个超参数值的IC，以可视化随着正则化的增加而如何演变。结果显示，我们得到了![](img/B15439_07_070.png)的最高平均和中位数IC值
- en: 'For these levels of regularization, the right panel of *Figure 7.8* shows that
    the coefficients have been slightly shrunk compared to the (almost) unconstrained
    model with ![](img/B15439_07_071.png):'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些正则化水平，*图7.8*的右侧面板显示，与（几乎）无约束模型相比，系数略有收缩，其中包括![](img/B15439_07_071.png)：
- en: '![](img/B15439_07_08.png)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_08.png)'
- en: 'Figure 7.8: Ridge regression cross-validation results'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：岭回归交叉验证结果
- en: The left panel of the figure shows that the predictive accuracy increases only
    slightly in terms of the mean and median IC values for optimal regularization
    values.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 图的左侧面板显示，对于最优正则化值，预测准确性在平均和中位数IC值方面仅略有增加。
- en: Top 10 coefficients
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前10个系数
- en: 'The standardization of the coefficients allows us to draw conclusions about
    their relative importance by comparing their absolute magnitude. *Figure 7.9*
    displays the 10 most relevant coefficients for regularization using ![](img/B15439_07_072.png),
    averaged over all trained models:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的标准化使我们能够通过比较它们的绝对值大小来得出关于它们相对重要性的结论。*图7.9*显示了使用![](img/B15439_07_072.png)进行正则化的10个最相关系数，这些系数是在所有训练模型上进行了平均：
- en: '![](img/B15439_07_09.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_09.png)'
- en: 'Figure 7.9: Daily IC distribution and most important coefficients'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9：每日 IC 分布和最重要的系数
- en: For this simple model and sample period, lagged monthly returns and various
    sector indicators played the most important role.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简单模型和样本期间，滞后的月度收益和各种部门指标发挥了最重要的作用。
- en: Lasso regression using sklearn
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 sklearn 进行 Lasso 回归
- en: The lasso implementation looks very similar to the ridge model we just ran.
    The main difference is that lasso needs to arrive at a solution using iterative
    coordinate descent, whereas ridge regression can rely on a closed-form solution.
    This can lead to longer training times.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: Lasso 实现看起来与我们刚刚运行的岭模型非常相似。主要区别在于，Lasso 需要使用迭代坐标下降来找到解决方案，而岭回归可以依赖封闭形式的解决方案。这可能导致较长的训练时间。
- en: Cross-validating the lasso model
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证 Lasso 模型
- en: The cross-validation code only differs with respect to the `Pipeline` setup.
    The `Lasso` object lets you set the tolerance and the maximum number of iterations
    it uses to determine whether it has converged or should abort, respectively. You
    can also rely on a `warm_start` so that the next training starts from the last
    optimal coefficient values. Please refer to the sklearn documentation and the
    notebook for additional detail.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证代码仅在`Pipeline`设置方面有所不同。`Lasso`对象允许您设置容忍度和用于确定是否已收敛或应该中止的最大迭代次数。您还可以依赖`warm_start`，以便下一次训练从最后的最佳系数值开始。请参考
    sklearn 文档和笔记本以获取更多详细信息。
- en: 'We will use eight `alpha` values in the range 10^(-10) to 10^(-3):'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在范围为10^(-10)到10^(-3)的八个`alpha`值中使用：
- en: '[PRE40]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Evaluating the results – IC and lasso path
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果 - IC 和 Lasso 路径
- en: As we did previously, we can plot the average information coefficient for all
    test sets used during cross-validation. We can see once more that regularization
    improves the IC over the unconstrained model, delivering the best out-of-sample
    result at a level of ![](img/B15439_07_073.png).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，我们可以绘制交叉验证期间所有测试集的平均信息系数。我们再次可以看到，正则化改善了无约束模型的 IC，在![](img/B15439_07_073.png)的水平上提供了最佳的样本外结果。
- en: 'The optimal regularization value is different from ridge regression because
    the penalty consists of the sum of the absolute, not the squared values of the
    relatively small coefficient values. We can also see in *Figure 7.10* that for
    this regularization level, the coefficients have been similarly shrunk, as in
    the ridge regression case:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳正则化值与岭回归不同，因为惩罚由相对较小的系数值的绝对值之和组成。我们还可以在*图 7.10*中看到，对于这个正则化水平，系数已经被类似地缩小，如岭回归案例中所示：
- en: '![](img/B15439_07_10.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_10.png)'
- en: 'Figure 7.10: Lasso cross-validation results'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10：Lasso 交叉验证结果
- en: 'The mean and median IC coefficients are slightly higher for lasso regression
    in this case, and the best-performing models use, on average, a different set
    of coefficients:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Lasso 回归的平均和中位数 IC 系数略高，并且性能最佳的模型平均使用了不同的系数集：
- en: '![](img/B15439_07_11.png)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_11.png)'
- en: 'Figure 7.11: Lasso daily IC distribution and top 10 coefficients'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11：Lasso 每日 IC 分布和前 10 个系数
- en: Comparing the quality of the predictive signals
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较预测信号的质量
- en: In sum, ridge and lasso regression often produce similar results. Ridge regression
    often computes faster, but lasso regression also offers continuous feature subset
    selection by gradually reducing coefficients to zero, hence eliminating features.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，岭回归和 Lasso 回归通常会产生类似的结果。岭回归通常计算速度更快，但 Lasso 回归也通过逐渐将系数减少到零来提供连续的特征子集选择，从而消除了特征。
- en: 'In this particular setting, lasso regression produces the best mean and median
    IC values, as displayed in *Figure 7.12*:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种特定情况下，Lasso 回归产生了最佳的平均和中位数 IC 值，如*图 7.12*所示：
- en: '![](img/B15439_07_12.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_12.png)'
- en: 'Figure 7.12: Mean and median daily IC for the three models'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12：三个模型的日均和中位 IC
- en: Furthermore, we can use Alphalens to compute various metrics and visualizations
    that reflect the signal quality of the model's predictions, as introduced in *Chapter
    4*, *Financial Feature Engineering – How to Research Alpha Factors*. The notebook
    `06_evaluating_signals_using_alphalens.ipynb` contains the code examples that
    combine the model predictions with price information to generate the alpha factor
    input needed by Alphalens.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以使用 Alphalens 计算各种度量和反映模型预测信号质量的可视化效果，如*第 4 章*中介绍的*金融特征工程 - 如何研究 Alpha
    因子*。笔记本`06_evaluating_signals_using_alphalens.ipynb`包含了将模型预测与价格信息结合以生成 Alphalens
    所需的 alpha 因子输入的代码示例。
- en: 'The following table shows the alpha and beta values for portfolios invested
    in, according to different quintiles of the model predictions. In this simple
    example, the differences in performance are very small:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了按照模型预测的不同五分位数投资组合的 alpha 和 beta 值。在这个简单的例子中，性能差异非常小：
- en: '| Metric | Alpha |  | Beta |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | Alpha |  | Beta |'
- en: '| Model | 1D | 5D | 10D | 21D |  | 1D | 5D | 10D | 21D |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 1D | 5D | 10D | 21D |  | 1D | 5D | 10D | 21D |'
- en: '| Linear regression | 0.03 | 0.02 | 0.007 | 0.004 |  | -0.012 | -0.081 | -0.059
    | 0.019 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 线性回归 | 0.03 | 0.02 | 0.007 | 0.004 |  | -0.012 | -0.081 | -0.059 | 0.019
    |'
- en: '| Ridge regression | 0.029 | 0.022 | 0.012 | 0.008 |  | -0.01 | -0.083 | -0.060
    | 0.021 |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 岭回归 | 0.029 | 0.022 | 0.012 | 0.008 |  | -0.01 | -0.083 | -0.060 | 0.021
    |'
- en: '| Lasso regression | 0.03 | 0.021 | 0.009 | 0.006 |  | -0.011 | -0.081 | -0.057
    | 0.02 |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| Lasso 回归 | 0.03 | 0.021 | 0.009 | 0.006 |  | -0.011 | -0.081 | -0.057 | 0.02
    |'
- en: Linear classification
  id: totrans-402
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性分类
- en: The linear regression model discussed so far assumes a quantitative response
    variable. In this section, we will focus on approaches to modeling qualitative
    output variables for inference and prediction, a process that is known as **classification**
    and that occurs even more frequently than regression in practice.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的线性回归模型假设了一个定量的响应变量。在这一部分中，我们将重点介绍对定性输出变量进行建模的方法，进行推断和预测，这个过程被称为**分类**，在实践中比回归更频繁地发生。
- en: Predicting a qualitative response for a data point is called classifying that
    observation because it involves assigning the observation to a category, or class.
    In practice, classification methods often predict probabilities for each of the
    categories of a qualitative variable and then use this probability to decide on
    the proper classification.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 预测数据点的定性响应称为对该观察进行分类，因为它涉及将观察分配给类别或类别。在实践中，分类方法通常为定性变量的每个类别预测概率，然后使用此概率来确定适当的分类。
- en: We could approach this classification problem by ignoring the fact that the
    output variable assumes discrete values, and then applying the linear regression
    model to try to predict a categorical output using multiple input variables. However,
    it is easy to construct examples where this method performs very poorly. Furthermore,
    it doesn't make intuitive sense for the model to produce values larger than 1
    or smaller than 0 when we know that ![](img/B15439_07_074.png).
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过忽略输出变量取离散值的事实来解决这个分类问题，然后应用线性回归模型尝试使用多个输入变量预测分类输出。然而，很容易构造出这种方法表现非常差的示例。此外，当我们知道![](img/B15439_07_074.png)时，模型产生大于1或小于0的值并不直观。
- en: There are many different classification techniques, or classifiers, that are
    available to predict a qualitative response. In this section, we will introduce
    the widely used logistic regression, which is closely related to linear regression.
    We will address more complex methods in the following chapters on generalized
    additive models, which includes decision trees and random forests, as well as
    gradient boosting machines and neural networks.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的分类技术或分类器可用于预测定性响应。在这一部分中，我们将介绍广泛使用的逻辑回归，它与线性回归密切相关。在接下来关于广义可加模型的章节中，我们将介绍更复杂的方法，包括决策树和随机森林，以及梯度提升机和神经网络。
- en: The logistic regression model
  id: totrans-407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归模型
- en: The logistic regression model arises from the desire to model the probabilities
    of the output classes, given a function that is linear in *x*, just like the linear
    regression model, while at the same time ensuring that they sum to one and remain
    in [0, 1], as we would expect from probabilities.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型的提出源于希望在 *x* 中线性的函数给定情况下建模输出类别的概率，就像线性回归模型一样，同时确保它们总和为1并保持在[0, 1]之间，这是我们从概率中期望的。
- en: In this section, we will introduce the objective and functional form of the
    logistic regression model and describe the training method. We will then illustrate
    how to use logistic regression for statistical inference with macro data using
    `statsmodels`, as well as how to predict price movements using the regularized
    logistic regression implemented by sklearn.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将介绍逻辑回归模型的目标和功能形式，并描述训练方法。然后我们将用`statsmodels`演示如何使用逻辑回归进行宏观数据的统计推断，以及如何使用sklearn实现的正则化逻辑回归来预测价格变动。
- en: The objective function
  id: totrans-410
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标函数
- en: 'To illustrate the **objective function**, we''ll use the output variable *y*,
    which takes on the value 1 if a stock return is positive over a given time horizon
    *d*, and 0 otherwise:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明**目标函数**，我们将使用输出变量 *y*，如果股票回报在给定时间范围 *d* 内为正，则取值为 1，否则为 0：
- en: '![](img/B15439_07_075.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_075.png)'
- en: We could easily extend *y* to three categories, where 0 and 2 reflect negative
    and positive price moves beyond a certain threshold, and 1 otherwise.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地将 *y* 扩展到三个类别，其中 0 和 2 反映了超出某个阈值的负面和正面价格变动，否则为 1。
- en: 'Rather than modeling the output variable *y* directly, logistic regression
    models the probability that *y* belongs to either of the categories, given a vector
    of alpha factors or features *x*[t]. In other words, logistic regression models
    the probability that the stock price goes up, depending on the values of the variables
    included in the model:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 与直接建模输出变量 *y* 不同，逻辑回归模型输出 *y* 属于哪个类别的概率，给定了一个 alpha 因子或特征 *x*[t] 的向量。换句话说，逻辑回归模型建模了股价上涨的概率，这取决于模型中包含的变量的值：
- en: '![](img/B15439_07_076.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_076.png)'
- en: The logistic function
  id: totrans-416
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: 'To prevent the model from producing values outside the [0, 1] interval, we
    must model *p*(*x*) using a function that only gives outputs between 0 and 1 over
    the entire domain of *x*. The **logistic function** meets this requirement and
    always produces an S-shaped curve and so, regardless of the value of *x*, we will
    obtain a prediction that makes sense in probability terms:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止模型产生超出 [0, 1] 区间的值，我们必须使用一个只在整个 *x* 的定义域上给出 0 和 1 之间输出的函数来对 *p*(*x*) 建模。**逻辑函数**满足这一要求，总是产生
    S 形曲线，因此，无论 *x* 的值如何，我们都会得到一个在概率术语中有意义的预测：
- en: '![](img/B15439_07_077.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_077.png)'
- en: 'Here, the vector *x* includes a 1 for the intercept captured by the first component
    of ![](img/B15439_07_078.png). We can transform this expression to isolate the
    part that looks like a linear regression to arrive at:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，向量 *x* 包括一个截距为 ![](img/B15439_07_078.png) 的第一个分量。我们可以转换这个表达式以分离类似线性回归的部分，得到：
- en: '![](img/B15439_07_079.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_079.png)'
- en: The quantity *p*(*x*)/[1−*p*(*x*)] is called the **odds**, an alternative way
    to express probabilities that may be familiar from gambling. This can take on
    any value odds between 0 and ![](img/B15439_07_080.png), where low values also
    imply low probabilities and high values imply high probabilities.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 量 *p*(*x*)/[1−*p*(*x*)] 称为**赔率**，这是一种表达概率的替代方式，可能在赌博中很常见。它可以取任何在 0 和 ![](img/B15439_07_080.png)
    之间的赔率值，低值也意味着低概率，高值意味着高概率。
- en: The logit is also called **log-odds** (since it is the logarithm of the odds).
    Hence, logistic regression represents a logit that is linear in *x* and looks
    a lot like the preceding linear regression.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数也称为**对数几率**（因为它是赔率的对数）。因此，逻辑回归表示在 *x* 中是线性的 logit，看起来很像前面的线性回归。
- en: Maximum likelihood estimation
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: 'The coefficient vector ![](img/B15439_07_081.png) must be estimated using the
    available training data. Although we could use (nonlinear) least squares to fit
    the logistic regression model, the more general method of maximum likelihood is
    preferred, since it has better statistical properties. As we have just discussed,
    the basic intuition behind using maximum likelihood to fit a logistic regression
    model is to seek estimates for ![](img/B15439_07_081.png) such that the predicted
    probability ![](img/B15439_07_083.png) corresponds as closely as possible to the
    actual outcome. In other words, we try to find ![](img/B15439_07_084.png) such
    that these estimates yield a number close to 1 for all cases where the stock price
    went up, and a number close to 0 otherwise. More formally, we are seeking to maximize
    the likelihood function:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 必须使用可用的训练数据估计系数向量 ![](img/B15439_07_081.png)。虽然我们可以使用（非线性）最小二乘法拟合 logistic 回归模型，但更一般的最大似然方法更受青睐，因为它具有更好的统计特性。正如我们刚刚讨论的，使用最大似然拟合
    logistic 回归模型的基本直觉是寻求估计 ![](img/B15439_07_081.png)，使得预测概率 ![](img/B15439_07_083.png)
    尽可能与实际结果相符。换句话说，我们试图找到 ![](img/B15439_07_084.png)，使得这些估计在股价上涨的所有情况下产生接近 1 的数字，并在其他情况下产生接近
    0 的数字。更正式地说，我们正在寻求最大化似然函数：
- en: '![](img/B15439_07_085.png)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_085.png)'
- en: 'It is easier to work with sums than with products, so let''s take logs on both
    sides to get the log-likelihood function and the corresponding definition of the
    logistic regression coefficients:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 用总和比乘积更容易处理，因此让我们在两边取对数，得到对数似然函数和 logistic 回归系数的相应定义：
- en: '![](img/B15439_07_086.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_086.png)'
- en: To maximize this equation, we set the derivatives of ![](img/B15439_07_087.png)
    with respect to ![](img/B15439_07_081.png) to zero. This yields *p*+1 so-called
    score equations, which are nonlinear in the parameters and can be solved using
    iterative numerical methods.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化这个方程，我们将![](img/B15439_07_087.png)对![](img/B15439_07_081.png)的导数设为零。这产生了*p*+1个所谓的得分方程，这些方程对参数非线性，并且可以使用迭代数值方法求解。
- en: How to conduct inference with statsmodels
  id: totrans-429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用statsmodels进行推断
- en: We will illustrate how to use logistic regression with `statsmodels` based on
    a simple built-in dataset containing quarterly US macro data from 1959 to 2009
    (see the notebook `logistic_regression_macro_data` for details).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何根据包含从1959年到2009年的季度美国宏观数据的简单内置数据集使用`statsmodels`进行逻辑回归（有关详情，请参见笔记本`logistic_regression_macro_data`）。
- en: 'The variables and their transformations are listed in the following table:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 变量及其转换列在以下表中：
- en: '| Variable | Description | Transformation |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 变量 | 描述 | 转换 |'
- en: '| `realgdp` | Real gross domestic product | Annual Growth Rate |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| `realgdp` | 国内生产总值真实值 | 年增长率 |'
- en: '| `realcons` | Real personal consumption expenditures | Annual Growth Rate
    |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| `realcons` | 真实个人消费支出 | 年增长率 |'
- en: '| `realinv` | Real gross private domestic investment | Annual Growth Rate |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| `realinv` | 真实私人国内生产总投资 | 年增长率 |'
- en: '| `realgovt` | Real federal expenditures and gross investment | Annual Growth
    Rate |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| `realgovt` | 联邦政府实际支出和总投资 | 年增长率 |'
- en: '| `realdpi` | Real private disposable income | Annual Growth Rate |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| `realdpi` | 真实私人可支配收入 | 年增长率 |'
- en: '| `m1` | M1 nominal money stock | Annual Growth Rate |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| `m1` | M1名义货币存量 | 年增长率 |'
- en: '| `tbilrate` | Monthly Treasury bill rate | Level |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| `tbilrate` | 月度国库券利率 | 水平 |'
- en: '| `unemp` | Seasonally adjusted unemployment rate (%) | Level |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| `unemp` | 季调失业率（%） | 水平 |'
- en: '| `infl` | Inflation rate | Level |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| `infl` | 通货膨胀率 | 水平 |'
- en: '| `realint` | Real interest rate | Level |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| `realint` | 实际利率 | 水平 |'
- en: To obtain a binary target variable, we compute the 20-quarter rolling average
    of the annual growth rate of quarterly real GDP. We then assign 1 if the current
    growth exceeds the moving average and 0 otherwise. Finally, we shift the indicator
    variables to align the next quarter's outcome with the current quarter.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得二进制目标变量，我们计算季度实际GDP年增长率的20季度滚动平均值。然后，如果当前增长超过移动平均值，则分配1，否则为0。最后，我们将指示变量移位以将下一个季度的结果与当前季度对齐。
- en: 'We use an intercept and convert the quarter values into dummy variables and
    train the logistic regression model, as follows:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个截距，并将季度值转换为虚拟变量，并训练逻辑回归模型，如下所示：
- en: '[PRE41]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This produces the following summary for our model, which shows 198 observations
    and 13 variables, including an intercept:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型生成了以下摘要，显示了198个观测值和13个变量，包括一个截距：
- en: '![](img/B15439_07_13.png)'
  id: totrans-447
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_13.png)'
- en: 'Figure 7.13: Logit regression results'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.13：Logit回归结果
- en: The summary indicates that the model has been trained using maximum likelihood
    and provides the maximized value of the log-likelihood function at -67.9.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要表明，该模型是使用最大似然法进行训练的，并提供了对数似然函数的最大化值为-67.9。
- en: The LL-Null value of -136.42 is the result of the maximized log-likelihood function
    when only an intercept is included. It forms the basis for the **pseudo-R2 statistic**
    and the **log-likelihood ratio** (**LLR**) test.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: -136.42的LL-Null值是仅包括截距时最大化对数似然函数的结果。它构成**伪R²统计量**和**对数似然比**（**LLR**）测试的依据。
- en: 'The pseudo-R² statistic is a substitute for the familiar R² available under
    least squares. It is computed based on the ratio of the maximized log-likelihood
    function for the null model *m*[0] and the full model *m*[1], as follows:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 伪R²统计量是最小二乘法下可用的熟悉R²的替代品。它基于零模型*m*[0]和完全模型*m*[1]的最大化对数似然函数的比率计算，如下所示：
- en: '![](img/B15439_07_089.png)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_089.png)'
- en: The values vary from 0 (when the model does not improve the likelihood) to 1,
    where the model fits perfectly and the log-likelihood is maximized at 0\. Consequently,
    higher values indicate a better fit.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 值从0（当模型不改善似然函数时）到1（当模型完全适配并且对数似然在0处最大化时）变化。因此，较高的值表示拟合度较好。
- en: 'The LLR test generally compares a more restricted model and is computed as:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: LLR测试通常比较更受限制的模型，并计算如下：
- en: '![](img/B15439_07_090.png)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_090.png)'
- en: The null hypothesis is that the restricted model performs better, but the low
    p-value suggests that we can reject this hypothesis and prefer the full model
    over the null model. This is similar to the F-test for linear regression (where
    we can also use the LLR test when we estimate the model using MLE).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 零假设是受限模型表现更好，但低的 p 值表明我们可以拒绝这个假设，而更倾向于完整模型而不是空模型。这类似于线性回归的 F 检验（当我们使用 MLE 估计模型时，我们也可以使用
    LLR 检验）。
- en: The z-statistic plays the same role as the t-statistic in the linear regression
    output and is equally computed as the ratio of the coefficient estimate and its
    standard error. The p-values also indicate the probability of observing the test
    statistic, assuming the null hypothesis ![](img/B15439_07_091.png) that the population
    coefficient is zero. We can reject this hypothesis for the `intercept`, `realcons`,
    `realinv`, `realgovt`, `realdpi`, and `unemp`.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: z 统计量在线性回归输出中扮演与 t 统计量相同的角色，并且与系数估计和其标准误的比率一样计算。p 值还指示了在假设零假设 ![](img/B15439_07_091.png)
    下观察测试统计量的概率，即总体系数为零。我们可以拒绝这个假设对于 `intercept`、`realcons`、`realinv`、`realgovt`、`realdpi`
    和 `unemp`。
- en: Predicting price movements with logistic regression
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用逻辑回归预测价格变动
- en: The lasso L1 penalty and the ridge L2 penalty can both be used with logistic
    regression. They have the same shrinkage effect that we have just discussed, and
    the lasso can again be used for variable selection with any linear regression
    model.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 套索 L1 惩罚和岭 L2 惩罚都可以与逻辑回归一起使用。它们具有我们刚刚讨论的相同的收缩效应，套索可以再次用于任何线性回归模型的变量选择。
- en: Just as with linear regression, it is important to standardize the input variables
    as the regularized models are scale sensitive. The regularization hyperparameter
    also requires tuning using cross-validation, as in the case of linear regression.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 就像线性回归一样，对输入变量进行标准化非常重要，因为正则化模型对尺度敏感。正则化超参数也需要使用交叉验证进行调优，就像线性回归的情况一样。
- en: How to convert a regression into a classification problem
  id: totrans-461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何将回归问题转化为分类问题
- en: 'We will continue with the price prediction example, but now we will binarize
    the outcome variable so that it takes on the value 1 whenever the 1-day return
    is positive and 0 otherwise (see the notebook `predicting_price_movements_with_logistic_regression.ipynb`
    for the code examples given in this section):'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用价格预测示例，但现在我们将使结果变量二元化，以便每当 1 天回报为正时取值为 1，否则取值为 0（请参阅笔记本 `predicting_price_movements_with_logistic_regression.ipynb`
    中给出的代码示例）：
- en: '[PRE42]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The outcomes are slightly unbalanced, with more positive than negative moves:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 结果略显不平衡，正面移动比负面移动多：
- en: '[PRE43]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: With this new categorical outcome variable, we can now train a logistic regression
    using the default L2 regularization.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个新的分类结果变量，我们现在可以使用默认的 L2 正则化来训练逻辑回归。
- en: Cross-validating the logistic regression hyperparameters
  id: totrans-467
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对逻辑回归超参数进行交叉验证
- en: 'For logistic regression, the regularization is formulated inversely to linear
    regression: higher values for ![](img/B15439_07_059.png) imply less regularization
    and vice versa.'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逻辑回归，正则化的制定与线性回归相反：较高的值 ![](img/B15439_07_059.png) 意味着较少的正则化，反之亦然。
- en: 'We will cross-validate 11 options for the regularization hyperparameter using
    our custom `TimeSeriesCV`, as follows:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们的自定义 `TimeSeriesCV` 对 11 个正则化超参数选项进行交叉验证，如下所示：
- en: '[PRE44]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The `train-test` loop now uses sklearn''s `LogisticRegression` and computes
    the `roc_auc_score` (see the notebook for details):'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`train-test` 循环采用 sklearn 的 `LogisticRegression` 并计算 `roc_auc_score`（详情请参阅笔记本）：
- en: '[PRE45]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In addition, we can also compute the IC based on the predicted probabilities
    and the actual returns:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们还可以基于预测概率和实际回报来计算信息系数（IC）：
- en: '[PRE46]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Evaluating the results using AUC and IC
  id: totrans-475
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 AUC 和 IC 评估结果
- en: 'We can again plot the AUC result for the range of hyperparameter values. In
    *Figure 7.14*, the left panel shows that the best median AUC results for *C*=0.1,
    whereas the best mean AUC corresponds to *C*=10^(-3). The right panel displays
    the distribution of the information coefficients for the model with *C*=10⁴. This
    also highlights that we obtain somewhat higher values for the mean and the median
    compared to the regression models shown previously:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次绘制一系列超参数值的 AUC 结果。在 *图 7.14* 中，左侧面板显示了 *C*=0.1 时最佳的中位数 AUC 结果，而最佳均值 AUC
    对应于 *C*=10^(-3)。右侧面板显示了具有 *C*=10⁴ 的模型的信息系数分布。这也突显了与先前显示的回归模型相比，我们获得的中位数和均值略高的值：
- en: '![](img/B15439_07_14.png)'
  id: totrans-477
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_14.png)'
- en: 'Figure 7.14: Logistic regression'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14：逻辑回归
- en: In the next chapter, we will use the predictions produced by these basic models
    to generate signals for trading strategies and demonstrate how to backtest their
    performance.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将利用这些基本模型产生的预测来为交易策略生成信号，并演示如何对其性能进行回测。
- en: Summary
  id: totrans-480
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced the first of our machine learning models using
    the important baseline case of linear models for regression and classification.
    We explored the formulation of the objective functions for both tasks, learned
    about various training methods, and learned how to use the model for both inference
    and prediction.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了我们的第一个机器学习模型，使用线性模型作为回归和分类的重要基线案例。我们探讨了两种任务的目标函数的构造，学习了各种训练方法，并学会了如何对模型进行推断和预测。
- en: We applied these new machine learning techniques to estimate linear factor models
    that are very useful to manage risks, assess new alpha factors, and attribute
    performance. We also applied linear regression and classification to accomplish
    the first predictive task of predicting stock returns in absolute and directional
    terms.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些新的机器学习技术应用于估计线性因子模型，这些模型对于管理风险、评估新的α因子以及评估绩效都非常有用。我们还应用了线性回归和分类来完成第一个预测任务，即绝对和方向性地预测股票回报。
- en: In the next chapter, we will put together what we have covered so far in the
    form of the machine learning for trading workflow. This process starts with sourcing
    and preparing the data about a specific investment universe and the computation
    of useful features, continues with the design and evaluation of machine learning
    models to extract actionable signals from these features, and culminates in the
    simulated execution and evaluation of a strategy that translates these signals
    into optimized portfolios.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将总结迄今为止所学内容，并以机器学习用于交易的工作流程形式呈现出来。这个过程从收集和准备关于特定投资领域的数据以及计算有用特征开始，继续设计和评估机器学习模型以从这些特征中提取可操作的信号，最终以模拟执行和评估策略告终，将这些信号转化为优化组合。
