- en: '20'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '20'
- en: Autoencoders for Conditional Risk Factors and Asset Pricing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器用于条件风险因子和资产定价
- en: This chapter shows how unsupervised learning can leverage deep learning for
    trading. More specifically, we'll discuss **autoencoders** that have been around
    for decades but have recently attracted fresh interest.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了无监督学习如何利用深度学习进行交易。更具体地说，我们将讨论数十年来存在但最近引起新关注的**自编码器**。
- en: '**Unsupervised learning** addresses practical ML challenges such as the limited
    availability of labeled data and the curse of dimensionality, which requires exponentially
    more samples for successful learning from complex, real-life data with many features.
    At a conceptual level, unsupervised learning resembles human learning and the
    development of common sense much more closely than supervised and reinforcement
    learning, which we''ll cover in the next chapter. It is also called **predictive
    learning** because it aims to discover structure and regularities from data so
    that it can predict missing inputs, that is, fill in the blanks from the observed
    parts.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习**解决了实际机器学习挑战，比如有标签数据的有限可用性和维度灾难，后者需要指数级更多的样本才能成功地从具有许多特征的复杂现实数据中学习。在概念层面上，无监督学习更类似于人类学习和常识的发展，而不是监督学习和强化学习，我们将在下一章中介绍。它也被称为**预测学习**，因为它旨在从数据中发现结构和规律，以便可以预测缺失的输入，也就是从观察到的部分填补空白。'
- en: 'An **autoencode**r is a **neural network** (**NN**) trained to reproduce the
    input while learning a new representation of the data, encoded by the parameters
    of a hidden layer. Autoencoders have long been used for nonlinear dimensionality
    reduction and manifold learning (see *Chapter 13*, *Data-Driven Risk Factors and
    Asset Allocation with Unsupervised Learning*). A variety of designs leverage the
    feedforward, convolutional, and recurrent network architectures we covered in
    the last three chapters. We will see how autoencoders can underpin a **trading
    strategy**: we will build a deep neural network that uses an autoencoder to extract
    risk factors and predict equity returns, conditioned on a range of equity attributes
    (Gu, Kelly, and Xiu 2020).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**自编码器**是一个**神经网络**（**NN**）训练成为复制输入同时学习数据的新表示的神经网络，由隐藏层的参数编码。自编码器长期以来一直用于非线性降维和流形学习（见*第13章*，*使用无监督学习进行数据驱动的风险因子和资产配置*）。各种设计利用了我们在最后三章中介绍的前馈、卷积和递归网络架构。我们将看到自编码器如何支撑一个**交易策略**：我们将构建一个深度神经网络，该网络使用自编码器来提取风险因子并预测股票回报，条件是一系列股票属性（Gu、Kelly
    和 Xiu 2020）。'
- en: 'More specifically, in this chapter you will learn about:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，在本章中，您将学习以下内容：
- en: Which types of autoencoders are of practical use and how they work
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些类型的自编码器具有实际用途以及它们的工作原理
- en: Building and training autoencoders using Python
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 构建和训练自编码器
- en: Using autoencoders to extract data-driven risk factors that take into account
    asset characteristics to predict returns
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自编码器提取考虑资产特征以预测回报的数据驱动风险因子
- en: You can find the code samples for this chapter and links to additional resources
    in the corresponding directory of the GitHub repository. The notebooks include
    color versions of the images.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 仓库的相应目录中找到本章的代码示例和其他资源的链接。笔记本包括图像的彩色版本。
- en: Autoencoders for nonlinear feature extraction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于非线性特征提取的自编码器
- en: In *Chapter 17*, *Deep Learning for Trading*, we saw how neural networks succeed
    at supervised learning by extracting a hierarchical feature representation useful
    for the given task. **Convolutional neural networks** (**CNNs**), for example,
    learn and synthesize increasingly complex patterns from grid-like data, for example,
    to identify or detect objects in an image or to classify time series.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第17章*，*交易的深度学习* 中，我们看到神经网络如何通过提取对给定任务有用的分层特征表示而成功进行监督学习。例如，**卷积神经网络**（**CNNs**）从类似网格的数据中学习和合成越来越复杂的模式，例如，在图像中识别或检测对象，或者对时间序列进行分类。
- en: An autoencoder, in contrast, is a neural network designed exclusively to learn
    a **new representation** that encodes the input in a way that helps solve another
    task. To this end, the training forces the network to reproduce the input. Since
    autoencoders typically use the same data as input and output, they are also considered
    an instance of **self-supervised learning**. In the process, the parameters of
    a hidden layer *h* become the code that represents the input, similar to the word2vec
    model covered in *Chapter 16*, *Word Embeddings for Earnings Calls and SEC Filings*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相反，自编码器是专门设计用来学习一个**新表示**的神经网络，该表示以一种有助于解决另一个任务的方式对输入进行编码。为此，训练强制网络重现输入。由于自编码器通常使用相同的数据作为输入和输出，它们也被视为**自监督学习**的一种实例。在这个过程中，隐藏层的参数*h*成为表示输入的编码，类似于第16章*《用于收益电话和SEC文件的词嵌入》*中介绍的word2vec模型。
- en: 'More specifically, the network can be viewed as consisting of an encoder function
    *h=f(x)* that learns the hidden layer''s parameters from input *x*, and a decoder
    function g that learns to reconstruct the input from the encoding *h*. Rather
    than learning the identity function:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，网络可以被视为由一个编码器函数*h=f(x)*和一个解码器函数*g*组成，编码器函数从输入*x*中学习隐藏层的参数，解码器函数学习从编码*h*中重构输入。而不是学习身份函数：
- en: '![](img/B15439_20_001.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_001.png)'
- en: which simply copies the input, autoencoders use **constraints** that force the
    hidden layer to **prioritize which aspects of the data to encod**e. The goal is
    to obtain a representation of practical value.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器不是简单地复制输入，而是使用**约束**来强制隐藏层**优先编码数据的哪些方面**。目标是获得实用价值的表示。
- en: Autoencoders can also be viewed as a **special case of a feedforward neural
    network** (see *Chapter 17*, *Deep Learning for Trading*) and can be trained using
    the same techniques. Just as with other models, excess capacity will lead to overfitting,
    preventing the autoencoder from producing an informative encoding that generalizes
    beyond the training samples. See *Chapters 14* and *15* of Goodfellow, Bengio,
    and Courville (2016) for additional background.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器也可以被视为**前馈神经网络的特例**（见*第17章，用于交易的深度学习*），并且可以使用相同的技术进行训练。与其他模型一样，过量的容量会导致过拟合，阻止自编码器产生超出训练样本的通用编码。有关更多背景信息，请参阅Goodfellow、Bengio和Courville
    (2016)的*第14*和*15*章。
- en: Generalizing linear dimensionality reduction
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泛化线性降维
- en: 'A traditional use case includes dimensionality reduction, achieved by limiting
    the size of the hidden layer and thus creating a "bottleneck" so that it performs
    lossy compression. Such an autoencoder is called **undercomplete**, and the purpose
    is to learn the most salient properties of the data by minimizing a loss function
    *L* of the form:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 传统用例包括降维，通过限制隐藏层的大小从而创建一个“瓶颈”，使其执行有损压缩。这样的自编码器被称为**欠完备**，其目的是通过最小化形式为*L*的损失函数来学习数据的最显著属性：
- en: '![](img/B15439_20_002.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_002.png)'
- en: An example loss function that we will explore in the next section is simply
    the mean squared error evaluated on the pixel values of the input images and their
    reconstruction. We will also use this loss function to extract risk factors from
    time series of financial features when we build a conditional autoencoder for
    trading.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中探讨的一个示例损失函数仅仅是在输入图像的像素值及其重构上计算的均方误差。当我们构建用于交易的条件自编码器时，我们还将使用这个损失函数来从金融特征的时间序列中提取风险因子。
- en: Undercomplete autoencoders differ from linear dimensionality reduction methods
    like **principal component analysis** (**PCA**; see *Chapter 13*, *Data-Driven
    Risk Factors and Asset Allocation with Unsupervised Learning*) when they use **nonlinear
    activation functions**; otherwise, they learn the same subspace as PCA. They can
    thus be viewed as a nonlinear generalization of PCA capable of learning a wider
    range of encodings.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与主成分分析（**PCA**；见*第13章，用于无监督学习的数据驱动风险因子和资产配置*）等线性降维方法不同，欠完备自编码器使用**非线性激活函数**；否则，它们学习与PCA相同的子空间。因此，它们可以被视为PCA的非线性推广，能够学习更广泛的编码。
- en: '*Figure 20.1* illustrates the encoder-decoder logic of an undercomplete feedforward
    autoencoder with three hidden layers: the encoder and decoder have one hidden
    layer each plus a shared encoder output/decoder input layer containing the encoding.
    The three hidden layers use nonlinear activation functions, like **rectified linear
    units** (**ReLU**), *sigmoid*, or *tanh* (see *Chapter 17*, *Deep Learning for
    Trading*) and have fewer units than the input that the network aims to reconstruct.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.1*说明了具有三个隐藏层的欠完备前馈自编码器的编码器-解码器逻辑：编码器和解码器各有一个隐藏层，再加上包含编码的共享编码器输出/解码器输入层。这三个隐藏层使用非线性激活函数，如**修正线性单元**（**ReLU**）、*sigmoid*或*tanh*（参见*第17章*，*交易的深度学习*），并且比网络要重建的输入单元更少。'
- en: '![](img/B15439_20_01.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_01.png)'
- en: 'Figure 20.1: Undercomplete encoder-decoder architecture'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.1：欠完备编码器-解码器架构
- en: Depending on the task, a simple autoencoder with a single encoder and decoder
    layer may be adequate. However, **deeper autoencoders** with additional layers
    can have several advantages, just as for other neural networks. These advantages
    include the ability to learn more complex encodings, achieve better compression,
    and do so with less computational effort and fewer training samples, subject to
    the perennial risk of overfitting.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务的不同，一个具有单个编码器和解码器层的简单自编码器可能是足够的。然而，具有额外层的**更深的自编码器**可以有几个优点，就像对其他神经网络一样。这些优点包括学习更复杂的编码、实现更好的压缩，并且在更少的计算和更少的训练样本的情况下完成，但会受到过拟合的固有风险的影响。
- en: Convolutional autoencoders for image compression
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于图像压缩的卷积自编码器
- en: As discussed in *Chapter 18*, *CNNs for Financial Time Series and Satellite
    Images*, fully connected feedforward architectures are not well suited to capture
    local correlations typical to data with a grid-like structure. Instead, autoencoders
    can also use convolutional layers to learn a hierarchical feature representation.
    Convolutional autoencoders leverage convolutions and parameter sharing to learn
    hierarchical patterns and features irrespective of their location, translation,
    or changes in size.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如*第18章*所讨论的，*用于金融时间序列和卫星图像的CNN*，全连接前馈架构不适合捕获具有网格结构的数据的局部相关性。相反，自编码器也可以使用卷积层来学习分层特征表示。卷积自编码器利用卷积和参数共享来学习层次化模式和特征，而不受其位置、平移或大小变化的影响。
- en: We will illustrate different implementations of convolutional autoencoders for
    image data below. Alternatively, convolutional autoencoders could be applied to
    multivariate time series data arranged in a grid-like format as illustrated in
    *Chapter 18*, *CNNs for Financial Time Series and Satellite Images*.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下面为图像数据演示卷积自编码器的不同实现。或者，卷积自编码器也可以应用于网格形式排列的多变量时间序列数据，如*第18章*所示，*用于金融时间序列和卫星图像的CNN*。
- en: Managing overfitting with regularized autoencoders
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过正则化自编码器管理过拟合
- en: The powerful capabilities of neural networks to represent complex functions
    require tight controls of the capacity of encoders and decoders to extract signals
    rather than noise so that the encoding is more useful for a downstream task. In
    other words, when it is too easy for the network to recreate the input, it fails
    to learn only the most interesting aspects of the data and improve the performance
    of a machine learning model that uses the encoding as inputs.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络表示复杂函数的强大能力要求对编码器和解码器的容量进行严格控制，以提取信号而不是噪声，从而使编码更适用于下游任务。换句话说，当网络太容易重新创建输入时，它无法仅学习数据的最有趣的方面，并提高使用编码作为输入的机器学习模型的性能。
- en: 'Just as for other models with excessive capacity for the given task, **regularization**
    can help to address the **overfitting** challenge by constraining the autoencoder''s
    learning process and forcing it to produce a useful representation (see, for instance,
    *Chapter 7*, *Linear Models – From Risk Factors to Return Forecasts*, on regularization
    for linear models, and *Chapter 17*, *Deep Learning for Trading*, for neural networks).
    Ideally, we could precisely match the model''s capacity to the complexity of the
    distribution of the data. In practice, the optimal model often combines (limited)
    excess capacity with appropriate regularization. To this end, we add a sparsity
    penalty ![](img/B15439_20_003.png) that depends on the weights of the encoding
    layer *h* to the training objective:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他具有给定任务的过度容量的模型一样，**正则化**可以帮助解决**过拟合**挑战，通过约束自编码器的学习过程并强制其产生有用的表示（例如，参见*第7章*，*线性模型-从风险因素到回报预测*，关于线性模型的正则化，以及*第17章*，*用于交易的深度学习*，关于神经网络）。
    理想情况下，我们可以将模型的容量精确匹配到数据分布的复杂性。 在实践中，最佳模型通常结合（有限的）过剩容量和适当的正则化。 为此，我们将一个依赖于编码层*h*的权重的稀疏度惩罚![](img/B15439_20_003.png)添加到训练目标中：
- en: '![](img/B15439_20_004.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_004.png)'
- en: A common approach that we explore later in this chapter is the use of **L1 regularization**,
    which adds a penalty to the loss function in the form of the sum of the absolute
    values of the weights. The L1 norm results in sparse encodings because it forces
    the values of parameters to zero if they do not capture independent variation
    in the data (see *Chapter 7*, *Linear Models – From Risk Factors to Return Forecasts*).
    As a result, even overcomplete autoencoders with hidden layers of a higher dimension
    than the input may be able to learn signal content.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章稍后探讨的一种常见方法是使用**L1正则化**，它在损失函数中添加了一种惩罚，即权重的绝对值之和。 L1范数会导致稀疏编码，因为它会强制将参数的值设为零，如果它们不能捕获数据中的独立变化（参见*第7章*，*线性模型-从风险因素到回报预测*）。
    因此，即使是隐藏层维度比输入高的超完备自编码器也可能学会学习信号内容。
- en: Fixing corrupted data with denoising autoencoders
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用去噪自编码器修复损坏的数据
- en: 'The autoencoders we have discussed so far are designed to reproduce the input
    despite capacity constraints. An alternative approach trains autoencoders with
    corrupted inputs ![](img/B15439_20_005.png) to output the desired, original data
    points. In this case, the autoencoder minimizes a loss *L*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的自编码器设计用于尽管容量有限但重现输入。 另一种方法是训练带有损坏输入的自编码器![](img/B15439_20_005.png)以输出所需的原始数据点。
    在这种情况下，自编码器最小化损失*L*：
- en: '![](img/B15439_20_006.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_006.png)'
- en: Corrupted inputs are a different way of preventing the network from learning
    the identity function and rather extracting the signal or salient features from
    the data. Denoising autoencoders have been shown to learn the data generating
    process of the original data and have become popular in generative modeling where
    the goal is **to learn the probability distribution** that gives rise to the input
    (Vincent et al., 2008).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 损坏的输入是防止网络学习身份函数而不是从数据中提取信号或显著特征的另一种方法。 已经证明去噪自编码器学会了原始数据的数据生成过程，并且在生成建模中变得流行，其中目标是**学习产生输入的概率分布**（Vincent等，2008）。
- en: Seq2seq autoencoders for time series features
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于时间序列特征的Seq2seq自编码器
- en: '**Recurrent neural networks** (**RNNs**) have been developed for sequential
    data characterized by longitudinal dependencies between data points, potentially
    over long ranges (*Chapter 19*, *RNNs for Multivariate Time Series and Sentiment
    Analysis*). Similarly, sequence-to-sequence (seq2seq) autoencoders aim to learn
    representations attuned to the nature of data generated in sequence (Srivastava,
    Mansimov, and Salakhutdinov, 2016).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**循环神经网络**（**RNNs**）已经发展用于具有数据点之间长期依赖关系的顺序数据，可能覆盖长距离（*第19章*，*用于多元时间序列和情感分析的RNNs*）。
    类似地，序列到序列（seq2seq）自编码器旨在学习适应序列生成数据性质的表示（Srivastava，Mansimov和Salakhutdinov，2016）。'
- en: Seq2seq autoencoders are based on RNN components like **long short-term memory**
    (**LSTM**) or gated recurrent unit. They learn a representation of sequential
    data and have been successfully applied to video, text, audio, and time series
    data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Seq2seq自编码器基于RNN组件，如**长短期记忆**（**LSTM**）或门控循环单元。 它们学习顺序数据的表示，并已成功应用于视频，文本，音频和时间序列数据。
- en: 'As mentioned in the last chapter, encoder-decoder architectures allow RNNs
    to process input and output sequences with variable length. These architectures
    underpin many advances in complex sequence prediction tasks, like speech recognition
    and text translation, and are being increasingly applied to (financial) time series.
    At a high level, they work as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如上一章所述，编码器-解码器架构允许RNN处理具有可变长度的输入和输出序列。这些架构支撑了许多复杂序列预测任务的进展，如语音识别和文本翻译，并且越来越多地应用于（金融）时间序列。在高层次上，它们的工作原理如下：
- en: The LSTM encoder processes the input sequence step by step to learn a hidden
    state.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTM编码器逐步处理输入序列以学习隐藏状态。
- en: This state becomes a learned representation of the sequence in the form of a fixed-length
    vector.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此状态成为序列的学习表示，以固定长度的向量形式呈现。
- en: The LSTM decoder receives this state as input and uses it to generate the output
    sequence.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTM解码器接收此状态作为输入，并使用它来生成输出序列。
- en: See references linked on GitHub for examples on building sequence-to-sequence
    autoencoders to **compress time series data** and **detect anomalies** in time
    series to allow, for example, regulators to uncover potentially illegal trading
    activity.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见GitHub上链接的参考示例，了解构建序列到序列自动编码器以**压缩时间序列数据**和**检测时间序列中的异常**的示例，以便例如监管机构发现潜在的非法交易活动。
- en: Generative modeling with variational autoencoders
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用变分自动编码器进行生成建模
- en: '**Variational autoencoders** (**VAE**) were developed more recently (Kingma
    and Welling, 2014) and focus on generative modeling. In contrast to a discriminative
    model that learns a predictor given data, a generative model aims to solve the
    more general problem of learning a joint probability distribution over all variables.
    If successful, it could simulate how the data is produced in the first place.
    Learning the data-generating process is very valuable: it reveals underlying causal
    relationships and supports semi-supervised learning to effectively generalize
    from a small labeled dataset to a large unlabeled one.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**变分自动编码器**（**VAE**）是最近发展起来的（Kingma和Welling，2014），专注于生成建模。与给定数据学习预测器的判别模型相反，生成模型旨在解决更一般的问题，即学习所有变量的联合概率分布。如果成功，它可以模拟数据首次生成的方式。学习数据生成过程非常有价值：它揭示了潜在的因果关系，并支持半监督学习，以有效地从小型标记数据集推广到大型未标记数据集。'
- en: More specifically, VAEs are designed to learn the latent (meaning *unobserved*)
    variables of the model responsible for the input data. Note that we encountered
    latent variables in *Chapter 15*, *Topic Modeling – Summarizing Financial News*,
    and *Chapter 16*, *Word Embeddings for Earnings Calls and SEC Filings*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，VAEs旨在学习模型负责输入数据的潜在（意思是*未观察到*）变量。请注意，在*第15章*，*主题建模 - 总结财务新闻*和*第16章*，*用于盈利电话和SEC备案的词嵌入*中，我们遇到了潜在变量。
- en: Just like the autoencoders discussed so far, VAEs do not let the network learn
    arbitrary functions as long as it faithfully reproduces the input. Instead, they
    aim to learn the parameters of a probability distribution that generates the input
    data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 就像迄今讨论的自动编码器一样，VAEs不允许网络学习任意函数，只要它忠实地重现输入即可。相反，它们旨在学习生成输入数据的概率分布的参数。
- en: In other words, VAEs are generative models because, if successful, you can generate
    new data points by sampling from the distribution learned by the VAE.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，VAEs是生成模型，因为如果成功，您可以通过从VAE学习的分布中抽样来生成新的数据点。
- en: The operation of a VAE is more complex than the autoencoders discussed so far
    because it involves stochastic backpropagation, that is, taking derivatives of
    stochastic variables, and the details are beyond the scope of this book. They
    are able to learn high-capacity input encodings without regularization that are
    useful because the models aim to maximize the probability of the training data
    rather than to reproduce the input. For a detailed introduction, see Kingma and
    Welling (2019).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: VAE的操作比迄今讨论的自动编码器更复杂，因为它涉及随机反向传播，即对随机变量的导数，并且细节超出了本书的范围。它们能够学习没有正则化的高容量输入编码，这是有用的，因为模型旨在最大化训练数据的概率，而不是复制输入。有关详细介绍，请参见Kingma和Welling（2019）。
- en: The `variational_autoencoder.ipynb` notebook includes a sample VAE implementation
    applied to the Fashion MNIST data, adapted from a Keras tutorial by Francois Chollet
    to work with TensorFlow 2\. The resources linked on GitHub contain a VAE tutorial
    with references to PyTorch and TensorFlow 2 implementations and many additional
    references. See Wang et al. (2019) for an application that combines a VAE with
    an RNN using LSTM and outperforms various benchmark models in futures markets.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`variational_autoencoder.ipynb` 笔记本包含了一个应用于时尚 MNIST 数据集的样本 VAE 实现，该实现改编自 François
    Chollet 的 Keras 教程，以适配 TensorFlow 2。GitHub 上链接的资源包含一个 VAE 教程，其中包含指向 PyTorch 和
    TensorFlow 2 实现的参考资料以及许多其他参考文献。参见 Wang 等人（2019）的应用，该应用将 VAE 与使用 LSTM 的 RNN 结合起来，并在期货市场中表现出优于各种基准模型的效果。'
- en: Implementing autoencoders with TensorFlow 2
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 2 实现自编码器
- en: In this section, we'll illustrate how to implement several of the autoencoder
    models introduced in the previous section using the Keras interface of TensorFlow
    2\. We'll first load and prepare an image dataset that we'll use throughout this
    section. We will use images instead of financial time series because it makes
    it easier to visualize the results of the encoding process. The next section shows
    how to use an autoencoder with financial data as part of a more complex architecture
    that can serve as the basis for a trading strategy.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将说明如何使用 TensorFlow 2 的 Keras 接口来实现上一节介绍的几种自编码器模型。我们首先加载和准备一个图像数据集，我们将在本节中始终使用该数据集。我们将使用图像而不是金融时间序列，因为这样更容易可视化编码过程的结果。下一节将说明如何将自编码器与金融数据结合起来，作为更复杂架构的一部分，该架构可以作为交易策略的基础。
- en: After preparing the data, we'll proceed to build autoencoders using deep feedforward
    nets, sparsity constraints, and convolutions and apply the latter to denoise images.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好数据后，我们将继续构建使用深度前馈网络、稀疏约束和卷积的自编码器，并将后者应用于图像去噪。
- en: How to prepare the data
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何准备数据
- en: For illustration, we'll use the Fashion MNIST dataset, a modern drop-in replacement
    for the classic MNIST handwritten digit dataset popularized by Lecun et al. (1998)
    with LeNet. We also relied on this dataset in *Chapter 13*, *Data-Driven Risk
    Factors and Asset Allocation with Unsupervised Learning*, on unsupervised learning.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将使用时尚 MNIST 数据集，这是由 Lecun 等人（1998）与 LeNet 结合使用的经典 MNIST 手写数字数据集的现代替代品。我们还在
    *第 13 章*，*使用无监督学习进行数据驱动风险因素和资产配置* 中依赖于该数据集。
- en: 'Keras makes it easy to access the 60,000 training and 10,000 test grayscale
    samples with a resolution of 28 × 28 pixels:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 使得很容易访问具有分辨率为 28 × 28 像素的 60,000 个训练和 10,000 个测试灰度样本：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The data contains clothing items from 10 classes. *Figure 20.2* plots a sample
    image for each class:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据包含来自 10 类的服装物品。*图 20.2* 绘制了每个类别的一个样本图像：
- en: '![](img/B15439_20_02.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_02.png)'
- en: 'Figure 20.2: Fashion MNIST sample images'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.2：时尚 MNIST 样本图像
- en: 'We reshape the data so that each image is represented by a flat one-dimensional
    pixel vector with 28 × 28 = 784 elements normalized to the range [0, 1]:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重新塑造数据，使每个图像由一个扁平的一维像素向量表示，其中有 28 × 28 = 784 个元素，规范化到 [0, 1] 范围内：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: One-layer feedforward autoencoder
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单层前馈自编码器
- en: We start with a vanilla feedforward autoencoder with a single hidden layer to
    illustrate the general design approach using the Functional Keras API and establish
    a performance baseline.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个具有单个隐藏层的普通前馈自编码器开始，以说明使用 Functional Keras API 的一般设计方法，并建立性能基线。
- en: 'The first step is a placeholder for the flattened image vectors with 784 elements:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用 784 个元素的扁平图像向量的占位符：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The encoder part of the model consists of a fully connected layer that learns
    the new, compressed representation of the input. We use 32 units for a compression
    ratio of 24.5:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的编码器部分由一个全连接层组成，用于学习输入的新压缩表示。我们使用 32 个单元，压缩比为 24.5：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The decoding part reconstructs the compressed data to its original size in
    a single step:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 解码部分将压缩的数据一次性重构为其原始大小：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We instantiate the `Model` class with the chained input and output elements
    that implicitly define the computational graph as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用链式输入和输出元素实例化 `Model` 类，这些元素隐含地定义了计算图，如下所示：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The encoder-decoder computation thus defined uses almost 51,000 parameters:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，所定义的编码器-解码器计算使用了近 51,000 个参数：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The Functional API allows us to use parts of the model's chain as separate encoder
    and decoder models that use the autoencoder's parameters learned during training.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Functional API 允许我们使用模型链的部分作为单独的编码器和解码器模型，这些模型使用训练期间学到的自编码器的参数。
- en: Defining the encoder
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义编码器
- en: 'The encoder just uses the input and hidden layer with about half the total
    parameters:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器仅使用输入和隐藏层，总参数约为一半：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will see shortly that, once we train the autoencoder, we can use the encoder
    to compress the data.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 不久我们将看到，一旦训练了自动编码器，我们就可以使用编码器来压缩数据。
- en: Defining the decoder
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义解码器
- en: 'The decoder consists of the last autoencoder layer, fed by a placeholder for
    the encoded data:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器由最后一个自动编码器层组成，由编码数据的占位符提供：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Training the model
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'We compile the model to use the Adam optimizer (see *Chapter 17*, *Deep Learning
    for Trading*) to minimize the mean squared error between the input data and the
    reproduction achieved by the autoencoder. To ensure that the autoencoder learns
    to reproduce the input, we train the model using the same input and output data:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编译模型以使用 Adam 优化器（参见*第17章*，*交易的深度学习*）来最小化输入数据和自动编码器实现的复制之间的均方误差。为了确保自动编码器学会复制输入，我们使用相同的输入和输出数据来训练模型：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Evaluating the results
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果
- en: 'Training stops after some 20 epochs with a test RMSE of 0.1121:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在一定的20个周期后停止，测试 RMSE 为 0.1121：
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To encode data, we use the encoder we just defined like so:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要对数据进行编码，我们使用刚刚定义的编码器如下：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The decoder takes the compressed data and reproduces the output according to
    the autoencoder training results:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器获取压缩数据，并根据自动编码器的训练结果重现输出：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*Figure 20.3* shows 10 original images and their reconstruction by the autoencoder
    and illustrates the loss after compression:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.3*显示了10张原始图像及其经自动编码器重建后的图像，并展示了压缩后的损失：'
- en: '![](img/B15439_20_03.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_03.png)'
- en: 'Figure 20.3: Sample Fashion MNIST images, original and reconstructed'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.3：示例时尚 MNIST 图像，原始和重建
- en: Feedforward autoencoder with sparsity constraints
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 带稀疏约束的前馈自动编码器
- en: 'The addition of regularization is fairly straightforward. We can apply it to
    the dense encoder layer using Keras'' `activity_regularizer` as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 添加正则化相当简单。我们可以使用 Keras 的`activity_regularizer`将其应用于密集编码器层，如下所示：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The input and decoding layers remain unchanged. In this example with compression
    of factor 24.5, regularization negatively affects performance with a test RMSE
    of 0.1229\.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 输入和解码层保持不变。在这个例子中，压缩因子为24.5，正则化对性能产生了负面影响，测试 RMSE 为0.1229。
- en: Deep feedforward autoencoder
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度前馈自动编码器
- en: 'To illustrate the benefit of adding depth to the autoencoder, we will build
    a three-layer feedforward model that successively compresses the input from 784
    to 128, 64, and 32 units, respectively:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明向自动编码器添加深度的好处，我们将构建一个三层前馈模型，依次将输入从784压缩到128、64和32个单元：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The resulting model has over 222,000 parameters, more than four times the capacity
    of the previous single-layer model:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 结果模型有超过222,000个参数，比之前的单层模型的容量多四倍多：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Training stops after 45 epochs and results in a 14 percent reduction of the
    test RMSE to 0.097\. Due to the low resolution, it is difficult to visually note
    the better reconstruction.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在45个周期后停止，并将测试 RMSE 减少了14%，达到了0.097。由于分辨率较低，难以明显注意到更好的重建。
- en: Visualizing the encoding
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化编码
- en: We can use the manifold learning technique **t-distributed Stochastic Neighbor
    Embedding** (**t-SNE**; see *Chapter 13*, *Data-Driven Risk Factors and Asset
    Allocation with Unsupervised Learning*) to visualize and assess the quality of
    the encoding learned by the autoencoder's hidden layer.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用流形学习技术**t-分布随机邻域嵌入**（**t-SNE**；参见*第13章*，*使用无监督学习的数据驱动风险因子和资产配置*）来可视化和评估自动编码器隐藏层学习到的编码的质量。
- en: 'If the encoding is successful in capturing the salient features of the data,
    then the compressed representation of the data should still reveal a structure
    aligned with the 10 classes that differentiate the observations. We use the output
    of the deep encoder we just trained to obtain the 32-dimensional representation
    of the test set:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果编码成功捕捉到数据的显著特征，那么数据的压缩表示仍应显示与区分观察的10个类别对齐的结构。我们使用刚刚训练的深度编码器的输出来获取测试集的32维表示：
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '*Figure 20.4* shows that the 10 classes are well separated, suggesting that
    the encoding is useful as a lower-dimensional representation that preserves the
    key characteristics of the data (see the `variational_autoencoder.ipynb` notebook
    for a color version):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.4*显示出10个类别很好地分离，表明编码对于作为保存数据关键特征的较低维度表示是有用的（请参见`variational_autoencoder.ipynb`笔记本以获取彩色版本）：'
- en: '![](img/B15439_20_04.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_04.png)'
- en: 'Figure 20.4: t-SNE visualization of the Fashion MNIST autoencoder embedding'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.4：Fashion MNIST自编码器嵌入的t-SNE可视化
- en: Convolutional autoencoders
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积自编码器
- en: The insights from *Chapter 18*, *CNNs for Financial Time Series and Satellite
    Images*, on CNNs suggest we incorporate convolutional layers into the autoencoder
    to extract information characteristic of the grid-like structure of image data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从*第18章*《金融时间序列和卫星图像的CNN》，关于CNN的见解表明我们应该将卷积层合并到自编码器中，以提取具有图像数据网格结构特征的信息。
- en: 'We define a three-layer encoder that uses 2D convolutions with 32, 16, and
    8 filters, respectively, ReLU activations, and `''same''` padding to maintain
    the input size. The resulting encoding size at the third layer is ![](img/B15439_20_007.png),
    higher than for the previous examples:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个三层编码器，它使用32、16和8个滤波器的2D卷积，分别使用ReLU激活和`'same'`填充以保持输入大小。第三层的结果编码大小为![](img/B15439_20_007.png)，比之前的示例要高：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We also define a matching decoder that reverses the number of filters and uses
    2D upsampling instead of max pooling to reverse the reduction of the filter sizes.
    The three-layer autoencoder has 12,785 parameters, a little more than 5 percent
    of the capacity of the deep autoencoder.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还定义了一个相匹配的解码器，它反转了滤波器数量，并使用2D上采样而不是最大池化来反转滤波器大小的减小。三层自编码器有12,785个参数，略多于深度自编码器容量的5％。
- en: Training stops after 67 epochs and results in a further 9 percent reduction
    in the test RMSE, due to a combination of the ability of convolutional filters
    to learn more efficiently from image data and the larger encoding size.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 训练在67个时代后停止，并导致测试RMSE进一步降低了9％，这是由于卷积滤波器能够更有效地从图像数据中学习以及较大的编码大小的能力的结合。
- en: Denoising autoencoders
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 去噪自编码器
- en: 'The application of an autoencoder to a denoising task only affects the training
    stage. In this example, we add noise from a standard normal distribution to the
    Fashion MNIST data while maintaining the pixel values in the range [0, 1] as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器应用于去噪任务只影响训练阶段。在本例中，我们向Fashion MNIST数据添加了来自标准正态分布的噪声，同时保持像素值在[0, 1]范围内，如下所示：
- en: '[PRE18]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We then proceed to train the convolutional autoencoder on noisy inputs, the
    objective being to learn how to generate the uncorrupted originals:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续在嘈杂的输入上训练卷积自编码器，目标是学习如何生成未损坏的原始图像：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The test RMSE after 60 epochs is 0.0931, unsurprisingly higher than before.
    *Figure 20.5* shows, from top to bottom, the original images as well as the noisy
    and denoised versions. It illustrates that the autoencoder is successful in producing
    compressed encodings from the noisy images that are quite similar to those produced
    from the original images:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 60个时代后的测试RMSE为0.0931，毫不奇怪地比以前高。*图20.5*显示，从上到下，原始图像以及嘈杂和去噪版本。它说明了自编码器成功地从嘈杂的图像中产生了与从原始图像中产生的相似的压缩编码：
- en: '![](img/B15439_20_05.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_05.png)'
- en: 'Figure 20.5: Denoising input and output examples'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.5：去噪输入和输出示例
- en: A conditional autoencoder for trading
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于交易的有条件自编码器
- en: Recent research by Gu, Kelly, and Xiu (GKX, 2019) developed an asset pricing
    model based on the exposure of securities to risk factors. It builds on the concept
    of **data-driven risk factors** that we discussed in *Chapter 13*, *Data-Driven
    Risk Factors and Asset Allocation with Unsupervised Learning*, when introducing
    PCA as well as the risk factor models covered in *Chapter 4*, *Financial Feature
    Engineering – How to Research Alpha Factors*. They aim to show that the asset
    characteristics used by factor models to capture the systematic drivers of "anomalies"
    are just proxies for the time-varying exposure to risk factors that cannot be
    directly measured. In this context, anomalies are returns in excess of those explained
    by the exposure to aggregate market risk (see the discussion of the capital asset
    pricing model in *Chapter 5*, *Portfolio Optimization and Performance Evaluation*).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Gu、Kelly和Xiu（GKX，2019）最近的研究开发了一种基于证券对风险因素的暴露的资产定价模型。当我们在*第13章*《数据驱动的风险因素和无监督学习的资产配置》中介绍PCA以及在*第4章*《金融特征工程-如何研究Alpha因子》中介绍的风险因素模型时，它建立在我们讨论的**数据驱动风险因素**概念上。他们的目标是表明因子模型用于捕捉“异常”系统驱动因素的资产特征只是无法直接测量的风险因素的时间变化暴露的代理。在这种情况下，“异常”是超过由暴露于总体市场风险的回报（请参阅*第5章*《投资组合优化和绩效评估》中对资本资产定价模型的讨论）所解释的回报。
- en: 'The **Fama-French factor models** discussed in *Chapter 4* and *Chapter 7*
    explain returns by specifying risk factors like firm size based on empirical observations
    of differences in average stock returns beyond those due to aggregate market risk.
    Given such **specific risk factors**, these models are able to measure the reward
    an investor receives for taking on factor risk using portfolios designed accordingly:
    sort stocks by size, buy the smallest quintile, sell the largest quintile, and
    compute the return. The observed risk factor return then allows linear regression
    to estimate the sensitivity of assets to these factors (called **factor loadings**),
    which in turn helps to predict the returns of (many) assets based on forecasts
    of (far fewer) factor returns.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第 4 章*和*第 7 章*讨论的**Fama-French 因子模型**通过指定风险因素如公司规模来解释回报，基于对超过聚合市场风险所致平均股票回报的经验观察。鉴于这些**特定的风险因素**，这些模型能够通过相应设计的组合度量投资者为承担因子风险而获得的回报：按规模分类股票，购买最小的五分位数，卖出最大的五分位数，并计算回报。观察到的风险因素回报然后允许线性回归估计资产对这些因子的敏感性（称为**因子加载**），从而有助于基于（较少的）因子回报的预测来预测（许多）资产的回报。
- en: In contrast, GKX treat **risk factors as latent, or non-observable**, drivers
    of covariance among a number of assets large enough to prevent investors from
    avoiding exposure through diversification. Therefore, investors require a reward
    that adjusts like any price to achieve equilibrium, providing in turn an economic
    rationale for return differences that are no longer anomalous. In this view, risk
    factors are purely statistical in nature while the underlying economic forces
    can be of arbitrary and varying origin.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，GKX 将**风险因素视为潜在的或不可观察的**，在许多资产之间驱动协方差，从而阻止投资者通过分散化来避免暴露。因此，投资者需要一种调整的回报，就像任何价格一样来实现均衡，进而提供不再异常的回报差异的经济合理性。在这种观点中，风险因素纯粹是统计性质的，而潜在的经济力量可以是任意的和多变的来源。
- en: In another recent paper (Kelly, Pruitt, and Su, 2019), Kelly—who teaches finance
    at Yale, works with AQR, and is one of the pioneers in applying ML to trading—and
    his coauthors developed a linear model dubbed **Instrumented Principal Component
    Analysis** (IPCA) to **estimate latent risk factors and the assets' factor loadings
    from data**. IPCA extends PCA to include asset characteristics as covariates and
    produce time-varying factor loadings. (See *Chapter 13*, *Data-Driven Risk Factors
    and Asset Allocation with Unsupervised Learning*, for coverage of PCA.) By conditioning
    asset exposure to factors on observable asset characteristics, IPCA aims to answer
    whether there is a set of common latent risk factors that explain an observed
    anomaly rather than whether there is a specific observable factor that can do
    so.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一篇最近的论文中（Kelly, Pruitt, and Su, 2019），Kelly——在耶鲁大学教授金融学，与 AQR 合作，并是将机器学习应用于交易的先驱之一——及其合著者开发了一个线性模型称为**工具化主成分分析**（IPCA），以**从数据中估计潜在的风险因素和资产的因子加载**。
    IPCA 将 PCA 扩展到包括资产特征作为协变量，并产生时变的因子加载。通过将资产暴露于可观察的资产特征的因素上，IPCA 的目标是回答是否有一组共同的潜在风险因素来解释观察到的异常，而不是是否有一个特定的可观察因素可以这样做。
- en: GKX creates a **conditional autoencoder architecture** to reflect the nonlinear
    nature of return dynamics ignored by the linear Fama-French models and the IPCA
    approach. The result is a deep neural network that simultaneously learns the premia
    on a given number of unobservable factors using an autoencoder, and the factor
    loadings for a large universe of equities based on a broad range of time-varying
    asset characteristics using a feedforward network. The model succeeds in explaining
    and predicting asset returns. It demonstrates a relationship that is both statistically
    and economically significant, yielding an attractive Sharpe ratio when translated
    into a long-short decile spread strategy similar to the examples we have used
    throughout this book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: GKX 创建了一个**条件自编码器架构**，以反映线性 Fama-French 模型和 IPCA 方法所忽略的回报动态的非线性性质。结果是一个深度神经网络，它同时使用自编码器学习给定数量的不可观测因素的溢价，并使用前馈网络基于广泛的时间变化资产特征学习大量股票的因子加载。该模型成功地解释和预测资产回报。它展示了一个在统计上和经济上都显著的关系，当转化为类似于我们在本书中使用的例子的长短十分位差异策略时，产生了具有吸引力的夏普比率。
- en: In this section, we'll create a simplified version of this model to demonstrate
    how you can **leverage autoencoders to generate tradeable signals**. To this end,
    we'll build a new dataset of close to 4,000 US stocks over the 1990-2019 period
    using yfinance, because it provides some additional information that facilitates
    the computation of the asset characteristics. We'll take a few shortcuts, such
    as using fewer assets and only the most important characteristics. We'll also
    omit some implementation details to simplify the exposition. We'll highlight the
    most important differences so that you can enhance the model accordingly.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建这个模型的简化版本，以演示如何**利用自动编码器生成可交易的信号**。为此，我们将使用yfinance在1990年至2019年期间构建一个接近4,000只美国股票的新数据集，因为它提供了一些额外的信息，有助于计算资产特征。我们会采取一些捷径，比如使用较少的资产和仅最重要的特征。我们还会省略一些实现细节，以简化表达。我们将重点介绍最重要的差异，以便您相应地增强模型。
- en: We'll first show how to prepare the data before we explain, build, and train
    the model and evaluate its predictive performance. Please see the above references
    for additional background on the theory and implementation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先展示如何准备数据，然后解释、构建和训练模型并评估其预测性能。请参阅上述参考资料以了解更多有关理论和实现的背景。
- en: Sourcing stock prices and metadata information
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取股票价格和元数据信息
- en: The GKX reference implementation uses stock price and firm characteristic data
    for over 30,000 US equities from the Center for Research in Security Prices (CRSP)
    from 1957-2016 at a monthly frequency. It computes 94 metrics that include a broad
    range of asset attributes suggested as predictive of returns in previous academic
    research and listed in Green, Hand, and Zhang (2017), who set out to verify these
    claims.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: GKX参考实现使用了来自1957年至2016年的中心研究安全价格（CRSP）的超过30,000只美国股票的股价和公司特征数据，频率为每月一次。它计算了94个指标，其中包括了一系列在以往学术研究中被建议用于预测收益的资产属性，这些属性在Green、Hand和Zhang（2017年）中列出，他们旨在验证这些说法。
- en: 'Since we do not have access to the high-quality but costly CRSP data, we leverage
    yfinance (see *Chapter 2*, *Market and Fundamental Data – Sources and Techniques*)
    to download price and metadata from Yahoo Finance. There are downsides to choosing
    free data, including:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们无法获得高质量但昂贵的CRSP数据，我们利用了yfinance（见*第2章*，*市场和基本数据-来源和技术*）从Yahoo Finance下载价格和元数据。选择免费数据有一些缺点，包括：
- en: The lack of quality control regarding adjustments
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏关于调整的质量控制
- en: Survivorship bias because we cannot get data for stocks that are no longer listed
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存活偏差，因为我们无法获取不再上市的股票的数据
- en: A smaller scope in terms of both the number of equities and the length of their
    history
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在股票数量和历史长度方面范围较小
- en: The `build_us_stock_dataset.ipynb` notebook contains the relevant code examples
    for this section.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`build_us_stock_dataset.ipynb` 笔记本包含了本节的相关代码示例。'
- en: 'To obtain the data, we get a list of the 8,882 currently traded symbols from
    NASDAQ using pandas-datareader (see *Chapter 2*, *Market and Fundamental Data
    – Sources and Techniques*):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取数据，我们使用pandas-datareader（见*第2章*，*市场和基本数据-来源和技术*）从NASDAQ获取了8,882个当前交易符号的列表：
- en: '[PRE20]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We remove ETFs and create yfinance `Ticker()` objects for the remainder:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们移除ETF，并为其余部分创建yfinance `Ticker()`对象。
- en: '[PRE21]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Each ticker''s `.info` attribute contains data points scraped from Yahoo Finance,
    ranging from the outstanding number of shares and other fundamentals to the latest
    market capitalization; coverage varies by security:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 每个股票的`.info`属性包含从Yahoo Finance抓取的数据点，从未偿还的股票数量和其他基本面到最新的市值；覆盖范围因证券而异：
- en: '[PRE22]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For the tickers with metadata, we download both adjusted and unadjusted prices,
    the latter including corporate actions like stock splits and dividend payments
    that we could use to create a Zipline bundle for strategy backtesting (see *Chapter
    8*, *The ML4T Workflow – From Model to Strategy Backtesting*).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有元数据的股票，我们同时下载调整后和未调整的价格，后者包括像股票分割和股息支付之类的企业行动，我们可以使用这些信息创建一个Zipline bundle用于策略回测（见*第8章*，*ML4T工作流程-从模型到策略回测*）。
- en: 'We get adjusted OHLCV data on 4,314 stocks as follows:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了4,314支股票的调整后的OHLCV数据，具体如下：
- en: '[PRE23]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Absent any quality control regarding the underlying price data and the adjustments
    for stock splits, we remove equities with suspicious values such as daily returns
    above 100 percent or below -100 percent:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有关于基础价格数据和股票分割调整的任何质量控制的情况下，我们删除了具有可疑值的股票，如日回报超过100%或低于-100%的股票：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This removes around 10 percent of the tickers, leaving us with close to 3,900
    assets for the 1990-2019 period.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做会移除大约10%的股票，使我们在1990-2019年期间拥有接近3900个资产。
- en: Computing predictive asset characteristics
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算预测性资产特征
- en: 'GKX tested 94 asset attributes based on Green et al. (2017) and identified
    the 20 most influential metrics while asserting that feature importance drops
    off quickly thereafter. The top 20 stock characteristics fall into three categories,
    namely:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: GKX根据Green等人（2017年）测试了94个资产属性，并确定了20个最具影响力的指标，同时断言特征重要性随后迅速下降。这20个最重要的股票特征分为三类，即：
- en: '**Price trend**, including (industry) momentum, short- and long-term reversal,
    or the recent maximum return'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价格趋势**，包括（行业）动量、短期和长期逆转，或最近的最大收益'
- en: '**Liquidity,** such as turnover, dollar volume, or market capitalization'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流动性**，例如周转率、美元成交量或市值'
- en: '**Risk measures**, for instance, total and idiosyncratic return volatility
    or market beta'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风险测量**，例如，总体和特异性回报波动率或市场贝塔'
- en: Of these 20, we limit the analysis to 16 for which we have or can approximate
    the relevant inputs. The `conditional_autoencoder_for_trading_data.ipynb` notebook
    demonstrates how to calculate the relevant metrics. We highlight a few examples
    in this section; see also the *Appendix*, *Alpha Factor Library*.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这20个指标中，我们将分析限制在16个指标上，这些指标我们已经或者可以近似计算相关的输入。 `conditional_autoencoder_for_trading_data.ipynb`
    笔记本演示了如何计算相关指标。我们在本节中突出了一些例子；另请参阅*附录*，*Alpha因子库*。
- en: 'Some metrics require information like sector, market cap, and outstanding shares,
    so we limit our stock price dataset to the securities with relevant metadata:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一些指标需要诸如行业、市值和流通股数等信息，因此我们将我们的股价数据集限制在具有相关元数据的证券上：
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We run our analysis at a weekly instead of monthly return frequency to compensate
    for the 50 percent shorter time period and around 80 percent lower number of stocks.
    We obtain weekly returns as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以每周而不是每月的回报频率运行我们的分析，以弥补时间周期减少50%和股票数量减少约80%的情况。我们得到的每周回报如下所示：
- en: '[PRE26]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Most metrics are fairly straightforward to compute. **Stock momentum**, the
    11-month cumulative stock returns ending 1 month before the current date, can
    be derived as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数指标都相当容易计算。**股票动量**，即截止到当前日期前1个月的11个月累积股票回报，可以如下推导：
- en: '[PRE27]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The **Amihud Illiquidity** measure is the ratio of a stock''s absolute returns
    relative to its dollar volume, measured as a rolling 21-day average:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amihud流动性**测量是股票绝对收益与其交易额的比率，以滚动的21天平均值表示：'
- en: '[PRE28]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Idiosyncratic volatility** is measured as the standard deviation of a regression
    of residuals of weekly returns on the returns of equally weighted market index
    returns for the prior three years. We compute this computationally intensive metric
    using `statsmodels`:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性波动性**被测量为最近三年等权重市场指数收益的回归残差的标准差。我们使用`statsmodels`进行这个计算密集型指标的计算：'
- en: '[PRE29]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'For the **market beta**, we can use statsmodels'' `RollingOLS` class with the
    weekly asset returns as outcome and the equal-weighted index as input:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**市场贝塔**，我们可以使用statsmodels的`RollingOLS`类，周资产收益作为结果，等权重指数作为输入：
- en: '[PRE30]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We end up with around 3 million observations on 16 metrics for some 3,800 securities
    over the 1990-2019 period. *Figure 20.6* displays a histogram of the number of
    stock returns per week (the left panel) and boxplots outlining the distribution
    of the number of observations for each characteristic:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终在1990-2019年期间的大约3800个证券上得到了约1600万次观察结果。*图20.6*显示了每周股票收益数量的直方图（左侧面板）和每种特征的观察数量分布的箱线图：
- en: '![](img/B15439_20_06.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_06.png)'
- en: 'Figure 20.6: Number of tickers over time and per - stock characteristic'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.6：随时间和每种 - 股票特征的股票数目
- en: 'To limit the influence of outliers, we follow GKX and rank-normalize the characteristics
    to the [-1, 1] interval:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 为了限制离群值的影响，我们遵循GKX并对特征进行等级标准化，使其落在[-1, 1]的区间内：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Since the neural network cannot handle missing data, we set missing values to
    -2, which lies outside the range for both weekly returns and the characteristics.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 由于神经网络无法处理缺失数据，我们将缺失值设置为-2，该值位于每周收益和特征的范围之外。
- en: The authors apply additional methods to avoid overweighting microcap stocks
    like market-value-weighted least-squares regression. They also adjust for data-snooping
    biases by factoring in conservative reporting lags for the characteristics.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 作者采用额外的方法来避免过度权重的小市值股票，例如市值加权最小二乘回归。他们还通过考虑特征的保守报告滞后来调整数据窥探偏差。
- en: Creating the conditional autoencoder architecture
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建条件自编码器架构
- en: The conditional autoencoder proposed by GKX allows for time-varying return distributions
    that take into account changing asset characteristics. To this end, the authors
    extend standard autoencoder architectures that we discussed in the first section
    of this chapter to allow for features to shape the encoding.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: GKX提出的条件自编码器允许考虑到变化的资产特征的时变回报分布。为此，作者将我们在本章第一节中讨论的标准自编码器架构扩展，以允许特征来塑造编码。
- en: '*Figure 20.7* illustrates the architecture that models the outcome (asset returns,
    top) as a function of both asset characteristics (left input) and, again, individual
    asset returns (right input). The authors allow for asset returns to be individual
    stock returns or portfolios that are formed from the stocks in the sample based
    on the asset characteristics, similar to the Fama-French factor portfolios we
    discussed in *Chapter 4*, *Financial Feature Engineering – How to Research Alpha
    Factors*, and summarized in the introduction to this section (hence the dotted
    lines from stocks to portfolios in the lower-right box). We will use individual
    stock returns; see GKX for details on how and why to use portfolios instead.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '*图20.7*说明了该架构将结果（资产回报，顶部）建模为资产特征（左侧输入）和再次个体资产回报（右侧输入）的函数。作者允许资产回报是个体股票回报或根据资产特征从样本中的股票组成的组合，类似于我们在*第4章*中讨论的法玛-法rench因子组合投资组合，并在本节的介绍中总结（因此从股票到组合的虚线）。我们将使用个体股票回报；有关使用组合而不是个体股票的详细信息，请参阅GKX。'
- en: '![](img/B15439_20_07.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_07.png)'
- en: 'Figure 20.7: Conditional autoencoder architecture designed by GKX'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.7：GKX设计的条件自编码器架构
- en: The **feedforward neural network** on the left side of the conditional autoencoder
    models the *K* factor loadings (beta output) of *N* individual stocks as a function
    of their *P* characteristics (input). In our case, *N* is around 3,800 and *P*
    equals 16\. The authors experiment with up to three hidden layers with 32, 16,
    and 8 units, respectively, and find two layers to perform best. Due to the smaller
    number of characteristics, we only use a similar layer and find 8 units most effective.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的**前馈神经网络**模拟了作为其*P*特征（输入）的函数的*N*个个体股票的*K*因子载荷（beta输出）。在我们的案例中，*N*约为3,800，*P*等于16。作者尝试了最多三个隐藏层，分别具有32、16和8个单元，并发现两个层表现最佳。由于特征数量较少，我们仅使用了一个类似的层，并发现8个单元最有效。
- en: The right side of this architecture is a traditional autoencoder when used with
    individual asset returns as inputs because it maps *N* asset returns onto themselves.
    The authors use it in this way to measure how well the derived factors explain
    contemporaneous returns. In addition, they use the autoencoder to predict future
    returns by using input returns from period *t*-1 with output returns from period
    t. We will focus on the use of the architecture for prediction, underlining that
    autoencoders are a special case of a feedforward neural network as mentioned in
    the first section of this chapter.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当以个体资产回报作为输入时，该架构的右侧是传统的自编码器，因为它将*N*个资产回报映射到它们自己。作者以这种方式使用它来衡量导出的因子如何解释同时发生的回报。此外，他们使用自编码器通过使用来自期间*t*-1的输入回报和期间*t*的输出回报来预测未来回报。我们将重点关注该架构用于预测的用途，强调自编码器是本章第一节中提到的前馈神经网络的特殊情况。
- en: The model output is the dot product of the ![](img/B15439_20_008.png) factor
    loadings on the left with the ![](img/B15439_20_009.png) factor premia on the
    right. The authors experiment with values of *K* in the range 2-6, similar to
    established factor models.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 模型输出是左侧的![](img/B15439_20_008.png)因子载荷与右侧的![](img/B15439_20_009.png)因子溢价的点积。作者在范围为2-6的*K*值上进行了实验，与已建立的因子模型类似。
- en: 'To create this architecture using TensorFlow 2, we use the Functional Keras
    API and define a `make_model()` function that automates the model compilation
    process as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用TensorFlow 2创建此架构，我们使用Functional Keras API并定义一个`make_model()`函数，该函数自动化了模型编译过程如下：
- en: '[PRE32]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We follow the authors in using batch normalization and compile the model to
    use mean squared error for this regression task and the Adam optimizer. This model
    has 12,418 parameters (see the notebook).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循作者的做法，使用批量归一化并编译模型以在此回归任务中使用均方误差和Adam优化器。该模型有12,418个参数（请参阅笔记本）。
- en: The authors use additional regularization techniques such as L1 penalties on
    network weights and combine the results of various networks with the same architecture
    but using different random seeds. They also use early stopping.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用了额外的正则化技术，例如对网络权重的 L1 惩罚，并结合了具有相同架构但使用不同随机种子的各种网络的结果。他们还使用了提前停止。
- en: 'We cross-validate using 20 years for training and predict the following year
    of weekly returns with five folds corresponding to the years 2015-2019\. We evaluate
    combinations of numbers of factors *K* from 2 to 6 and 8, 16, or 32 hidden layer
    units by computing the **information coefficient** (**IC**) for the validation
    set as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 20 年的数据进行交叉验证，用五个对应于 2015-2019 年的折叠来预测下一年的每周回报。我们通过计算验证集的信息系数（IC）来评估从 2
    到 6 个因子 K 和 8、16 或 32 个隐藏层单元的组合：
- en: '[PRE33]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '*Figure 20.8* plots the validation IC averaged over the five annual folds by
    epoch for the five-factor count and three hidden-layer size combinations. The
    upper panel shows the IC across the 52 weeks and the lower panel shows the average
    weekly IC (see the notebook for the color version):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20.8* 绘制了五因子计数和三种隐藏层大小组合在五个年度交叉验证折叠中每个时期的验证 IC 的平均值。上面的面板显示了 52 周的 IC，下面的面板显示了平均每周的
    IC（有关彩色版本，请参阅笔记本）：'
- en: '![](img/B15439_20_08.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_08.png)'
- en: 'Figure 20.8: Cross-validation performance for all factor and hidden-layer size
    combinations'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.8：所有因子和隐藏层大小组合的交叉验证性能
- en: The results suggest that more factors and fewer hidden layer units work better;
    in particular, four and six factors with eight units perform best with overall
    IC values in the range of 0.02-0.03\.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，更多的因子和较少的隐藏层单元效果更好；特别是，具有八个单元的四和六个因子在 0.02-0.03 的整体 IC 值范围内表现最佳。
- en: To evaluate the economic significance of the model's predictive performance,
    we generate predictions for a four-factor model with eight units trained for 15
    epochs. Then we use Alphalens to compute the spreads between equal-weighted portfolios
    invested by a quintile of the predictions for each point in time, while ignoring
    transaction costs (see the `alphalens_analysis.ipynb` notebook).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型预测性能的经济意义，我们生成了一个具有八个单元的四因子模型的预测，训练了 15 个周期。然后，我们使用 Alphalens 来计算预测的五分位等权重投资组合之间的价差，同时忽略交易成本（请参阅
    `alphalens_analysis.ipynb` 笔记本）。
- en: '*Figure 20.9* shows the mean spread for holding periods from 5 to 21 days.
    For the shorter end that also reflects the prediction horizon, the spread between
    the bottom and the top decile is around 10 basis points:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 20.9* 显示了持有期从 5 天到 21 天的平均价差。对于较短的期限，这也反映了预测视野，底部和顶部十分位数之间的价差约为 10 个基点：'
- en: '![](img/B15439_20_09.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_09.png)'
- en: 'Figure 20.9: Mean period-wise spread by prediction quintile'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.9：预测五分位的平均期间差异
- en: 'To evaluate how the predictive performance might translate into returns over
    time, we lot the cumulative returns of similarly invested portfolios, as well
    as the cumulative return for a long-short portfolio invested in the top and bottom
    half, respectively:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估预测性能如何随时间转化为回报，我们绘制了类似投资组合的累积回报图，以及分别投资于前半部分和后半部分的多空投资组合的累积回报：
- en: '![](img/B15439_20_10.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_20_10.png)'
- en: 'Figure 20.10: Cumulative returns of quintile-based and long-short portfolios'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20.10：基于五分位和多空组合的累积回报
- en: The results show significant spreads between quintile portfolios and positive
    cumulative returns for the broader-based long-short portfolio over time. This
    supports the hypothesis that the conditional autoencoder model could contribute
    to a profitable trading strategy.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示了五分位投资组合之间的显著差距，以及长期以来更广泛的多空投资组合的正累积回报。这支持了条件自编码器模型可能有助于盈利交易策略的假设。
- en: Lessons learned and next steps
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学到的经验和下一步计划
- en: The conditional autoencoder combines a nonlinear version of the data-driven
    risk factors we explored using PCA in *Chapter 13*, *Data-Driven Risk Factors
    and Asset Allocation with Unsupervised Learning*, with the risk factor approach
    to modeling returns discussed in *Chapter 4* and *Chapter 7*. It illustrates how
    deep neural network architectures can be flexibly adapted to various tasks as
    well as the fluid boundary between autoencoders and feedforward neural networks.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 条件自编码器结合了我们在*第 13 章*《数据驱动的风险因素和使用无监督学习进行资产配置》中使用 PCA 探索的数据驱动风险因素的非线性版本，以及在*第
    4 章*和*第 7 章*中讨论的建模回报的风险因素方法。它说明了深度神经网络架构如何能够灵活适应各种任务，以及自编码器和前馈神经网络之间的流动边界。
- en: 'The numerous simplifications from the data source to the architecture point
    to several avenues for improvements. Besides sourcing more data of better quality
    that also allows the computation of additional characteristics, the following
    modifications are a starting point—there are certainly many more:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据源到架构的众多简化指向了几个改进途径。除了获取更多质量更好的数据，并且还可以计算出额外特征的数据外，以下修改是一个起点——当然还有许多其他途径：
- en: Experiment with **data frequencies** other than weekly and forecast horizons
    other than annual, where shorter periods will also increase the amount of training
    data
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试与周频以外的**数据频率**，以及年度以外的预测时段，其中较短的周期还将增加训练数据的数量。
- en: Modify the **model architecture**, especially if using more data, which might
    reverse the finding that an even smaller hidden layer would estimate better factor
    loadings
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改**模型架构**，特别是在使用更多数据的情况下，可能会推翻这样一个发现：一个更小的隐藏层会更好地估计因子载荷。
- en: Summary
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced how unsupervised learning leverages deep learning.
    Autoencoders learn sophisticated, nonlinear feature representations that are capable
    of significantly compressing complex data while losing little information. As
    a result, they are very useful to counter the curse of dimensionality associated
    with rich datasets that have many features, especially common datasets with alternative
    data. We also saw how to implement various types of autoencoders using TensorFlow
    2.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了无监督学习如何利用深度学习。自动编码器学习复杂的、非线性的特征表示，能够显著压缩复杂数据而损失很少信息。因此，它们对于应对与具有许多特征的丰富数据相关的维度灾难特别有用，尤其是具有替代数据的常见数据集。我们还看到如何使用
    TensorFlow 2 实现各种类型的自动编码器。
- en: Most importantly, we implemented recent academic research that extracts data-driven
    risk factors from data to predict returns. Different from our linear approach
    to this challenge in *Chapter 13*, *Data-Driven Risk Factors and Asset Allocation
    with Unsupervised Learning*, autoencoders capture nonlinear relationships. Moreover,
    the flexibility of deep learning allowed us to incorporate numerous key asset
    characteristics to model more sensitive factors that helped predict returns.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，我们实现了最近的学术研究，从数据中提取数据驱动的风险因素来预测回报。与我们在*第13章*中对这一挑战的线性方法不同，*基于数据驱动的风险因素和无监督学习的资产配置*，自动编码器捕捉非线性关系。此外，深度学习的灵活性使我们能够将许多关键资产特征纳入模型中，以建模更敏感的因素，有助于预测回报。
- en: In the next chapter, we focus on generative adversarial networks, which have
    often been called one of the most exciting recent developments in artificial intelligence,
    and see how they are capable of creating synthetic training data.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重点研究生成对抗网络，它们常被称为人工智能最令人兴奋的最新发展之一，并看看它们如何能够创建合成的训练数据。
