["```py\nfrom tensorflow.keras.datasets import fashion_mnist\n(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\nX_train.shape, X_test.shape\n((60000, 28, 28), (10000, 28, 28)) \n```", "```py\nimage_size = 28              # pixels per side\ninput_size = image_size ** 2 # 784\ndef data_prep(x, size=input_size):\n    return x.reshape(-1, size).astype('float32')/255\nX_train_scaled = data_prep(X_train)\nX_test_scaled = data_prep(X_test)\nX_train_scaled.shape, X_test_scaled.shape\n((60000, 784), (10000, 784)) \n```", "```py\ninput_ = Input(shape=(input_size,), name='Input') \n```", "```py\nencoding_size = 32 # compression factor: 784 / 32 = 24.5\nencoding = Dense(units=encoding_size,\n                 activation='relu',\n                 name='Encoder')(input_) \n```", "```py\ndecoding = Dense(units=input_size,\n                 activation='sigmoid',\n                 name='Decoder')(encoding) \n```", "```py\nautoencoder = Model(inputs=input_,\n                    outputs=decoding,\n                    name='Autoencoder') \n```", "```py\nLayer (type)                 Output Shape              Param #   \nInput (InputLayer)           (None, 784)               0         \nEncoder (Dense)              (None, 32)                25120     \nDecoder (Dense)              (None, 784)               25872     \nTotal params: 50,992\nTrainable params: 50,992\nNon-trainable params: 0 \n```", "```py\nencoder = Model(inputs=input_, outputs=encoding, name='Encoder')\nencoder.summary()\nLayer (type)                 Output Shape              Param #   \nInput (InputLayer)           (None, 784)               0         \nEncoder (Dense)              (None, 32)                25120     \nTotal params: 25,120\nTrainable params: 25,120\nNon-trainable params: 0 \n```", "```py\nencoded_input = Input(shape=(encoding_size,), name='Decoder_Input')\ndecoder_layer = autoencoder.layers[-1](encoded_input)\ndecoder = Model(inputs=encoded_input, outputs=decoder_layer)\ndecoder.summary()\nLayer (type)                 Output Shape              Param #   \nDecoder_Input (InputLayer)   (None, 32)                0         \nDecoder (Dense)              (None, 784)               25872     \nTotal params: 25,872\nTrainable params: 25,872\nNon-trainable params: 0 \n```", "```py\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.fit(x=X_train_scaled, y=X_train_scaled,\n                epochs=100, batch_size=32,\n                shuffle=True, validation_split=.1,\n                callbacks=[tb_callback, early_stopping, checkpointer]) \n```", "```py\nmse = autoencoder.evaluate(x=X_test_scaled, y=X_test_scaled)\nf'MSE: {mse:.4f} | RMSE {mse**.5:.4f}'\n'MSE: 0.0126 | RMSE 0.1121' \n```", "```py\nencoded_test_img = encoder.predict(X_test_scaled)\nEncoded_test_img.shape\n(10000, 32) \n```", "```py\ndecoded_test_img = decoder.predict(encoded_test_img)\ndecoded_test_img.shape\n(10000, 784) \n```", "```py\nencoding_l1 = Dense(units=encoding_size,\n                    activation='relu',\n                    activity_regularizer=regularizers.l1(10e-5),\n                    name='Encoder_L1')(input_) \n```", "```py\ninput_ = Input(shape=(input_size,))\nx = Dense(128, activation='relu', name='Encoding1')(input_)\nx = Dense(64, activation='relu', name='Encoding2')(x)\nencoding_deep = Dense(32, activation='relu', name='Encoding3')(x)\nx = Dense(64, activation='relu', name='Decoding1')(encoding_deep)\nx = Dense(128, activation='relu', name='Decoding2')(x)\ndecoding_deep = Dense(input_size, activation='sigmoid', name='Decoding3')(x)\nautoencoder_deep = Model(input_, decoding_deep) \n```", "```py\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 784)               0         \n_________________________________________________________________\nEncoding1 (Dense)            (None, 128)               100480    \n_________________________________________________________________\nEncoding2 (Dense)            (None, 64)                8256      \n_________________________________________________________________\nEncoding3 (Dense)            (None, 32)                2080      \n_________________________________________________________________\nDecoding1 (Dense)            (None, 64)                2112      \n_________________________________________________________________\nDecoding2 (Dense)            (None, 128)               8320      \n_________________________________________________________________\nDecoding3 (Dense)            (None, 784)               101136    \n=================================================================\nTotal params: 222,384\nTrainable params: 222,384\nNon-trainable params: 0 \n```", "```py\ntsne = TSNE(perplexity=25, n_iter=5000)\ntrain_embed = tsne.fit_transform(encoder_deep.predict(X_train_scaled)) \n```", "```py\nx = Conv2D(filters=32,\n           kernel_size=(3, 3),\n           activation='relu',\n           padding='same',\n           name='Encoding_Conv_1')(input_)\nx = MaxPooling2D(pool_size=(2, 2), padding='same', name='Encoding_Max_1')(x)\nx = Conv2D(filters=16,\n           kernel_size=(3, 3),\n           activation='relu',\n           padding='same',\n           name='Encoding_Conv_2')(x)\nx = MaxPooling2D(pool_size=(2, 2), padding='same', name='Encoding_Max_2')(x)\nx = Conv2D(filters=8,\n           kernel_size=(3, 3),\n           activation='relu',\n           padding='same',\n           name='Encoding_Conv_3')(x)\nencoded_conv = MaxPooling2D(pool_size=(2, 2),\n                            padding='same',\n                            name='Encoding_Max_3')(x) \n```", "```py\ndef add_noise(x, noise_factor=.3):\n    return np.clip(x  + noise_factor * np.random.normal(size=x.shape), 0, 1)\nX_train_noisy = add_noise(X_train_scaled)\nX_test_noisy = add_noise(X_test_scaled) \n```", "```py\nautoencoder_denoise.fit(x=X_train_noisy,\n                        y=X_train_scaled,\n                        ...) \n```", "```py\nfrom pandas_datareader.nasdaq_trader import get_nasdaq_symbols\ntraded_symbols = get_nasdaq_symbols() \n```", "```py\nimport yfinance as yf\ntickers = yf.Tickers(traded_symbols[~traded_symbols.ETF].index.to_list()) \n```", "```py\ninfo = []\nfor ticker in tickers.tickers:\n    info.append(pd.Series(ticker.info).to_frame(ticker.ticker))\ninfo = pd.concat(info, axis=1).dropna(how='all').T\ninfo = info.apply(pd.to_numeric, errors='ignore') \n```", "```py\nprices_adj = []\nwith pd.HDFStore('chunks.h5') as store:\n    for i, chunk in enumerate(chunks(tickers, 100)):\n        print(i, end=' ', flush=True)\n        prices_adj.append(yf.download(chunk,\n                                      period='max',\n                                      auto_adjust=True).stack(-1))\nprices_adj = (pd.concat(prices_adj)\n              .dropna(how='all', axis=1)\n              .rename(columns=str.lower)\n              .swaplevel())\nprices_adj.index.names = ['ticker', 'date'] \n```", "```py\ndf = prices_adj.close.unstack('ticker')\npmax = df.pct_change().max()\npmin = df.pct_change().min()\nto_drop = pmax[pmax > 1].index.union(pmin[pmin<-1].index) \n```", "```py\ntickers_with_metadata = (metadata[metadata.sector.isin(sectors) & \n                                 metadata.marketcap.notnull() &\n                                 metadata.sharesoutstanding.notnull() & \n                                (metadata.sharesoutstanding > 0)]\n                                 .index.drop(tickers_with_errors)) \n```", "```py\nreturns = (prices.close\n           .unstack('ticker')\n           .resample('W-FRI').last()\n           .sort_index().pct_change().iloc[1:]) \n```", "```py\nMONTH = 21\nmom12m = (close\n            .pct_change(periods=11 * MONTH)\n            .shift(MONTH)\n            .resample('W-FRI')\n            .last()\n            .stack()\n            .to_frame('mom12m')) \n```", "```py\ndv = close.mul(volume)\nill = (close.pct_change().abs()\n       .div(dv)\n       .rolling(21)\n       .mean()\n       .resample('W-FRI').last()\n       .stack()\n       .to_frame('ill')) \n```", "```py\nindex = close.resample('W-FRI').last().pct_change().mean(1).to_frame('x')\ndef get_ols_residuals(y, x=index):\n    df = x.join(y.to_frame('y')).dropna()\n    model = sm.OLS(endog=df.y, exog=sm.add_constant(df[['x']]))\n    result = model.fit()\n    return result.resid.std()\nidiovol = (returns.apply(lambda x: x.rolling(3 * 52)\n                         .apply(get_ols_residuals))) \n```", "```py\ndef get_market_beta(y, x=index):\n    df = x.join(y.to_frame('y')).dropna()\n    model = RollingOLS(endog=df.y, \n                       exog=sm.add_constant(df[['x']]),\n                       window=3*52)\n    return model.fit(params_only=True).params['x']\nbeta = (returns.dropna(thresh=3*52, axis=1)\n        .apply(get_market_beta).stack().to_frame('beta')) \n```", "```py\ndata.loc[:, characteristics] = (data.loc[:, characteristics]\n                                .groupby(level='date')\n                                .apply(lambda x:\n                                      pd.DataFrame(quantile_transform(\n                                      x, \n                                      copy=True, \n                                      n_quantiles=x.shape[0]),\n                                      columns=characteristics,\n                                        index=x.index.get_level_values('ticker'))\n                                      )\n                               .mul(2).sub(1)) \n```", "```py\ndef make_model(hidden_units=8, n_factors=3):\n    input_beta = Input((n_tickers, n_characteristics), name='input_beta')\n    input_factor = Input((n_tickers,), name='input_factor')\n    hidden_layer = Dense(units=hidden_units,\n                         activation='relu',\n                         name='hidden_layer')(input_beta)\n    batch_norm = BatchNormalization(name='batch_norm')(hidden_layer)\n\n    output_beta = Dense(units=n_factors, name='output_beta')(batch_norm)\n    output_factor = Dense(units=n_factors,\n                          name='output_factor')(input_factor)\n    output = Dot(axes=(2,1),\n                 name='output_layer')([output_beta, output_factor])\n    model = Model(inputs=[input_beta, input_factor], outputs=output)\n    model.compile(loss='mse', optimizer='adam')\n    return model \n```", "```py\nfactor_opts = [2, 3, 4, 5, 6]\nunit_opts = [8, 16, 32]\nparam_grid = list(product(unit_opts, factor_opts))\nfor units, n_factors in param_grid:\n    scores = []\n    model = make_model(hidden_units=units, n_factors=n_factors)\n    for fold, (train_idx, val_idx) in enumerate(cv.split(data)):\n        X1_train, X2_train, y_train, X1_val, X2_val, y_val = \\\n            get_train_valid_data(data, train_idx, val_idx)\n        for epoch in range(250):         \n            model.fit([X1_train, X2_train], y_train,\n                      batch_size=batch_size,\n                      validation_data=([X1_val, X2_val], y_val),\n                      epochs=epoch + 1,\n                      initial_epoch=epoch, \n                      verbose=0, shuffle=True)\n            result = (pd.DataFrame({'y_pred': model.predict([X1_val,\n                                                             X2_val])\n                                   .reshape(-1),\n                                    'y_true': y_val.stack().values},\n                                  index=y_val.stack().index)\n                      .replace(-2, np.nan).dropna())\n            r0 = spearmanr(result.y_true, result.y_pred)[0]\n            r1 = result.groupby(level='date').apply(lambda x: \n                                                    spearmanr(x.y_pred, \n                                                              x.y_true)[0])\n            scores.append([units, n_factors, fold, epoch, r0, r1.mean(),\n                           r1.std(), r1.median()]) \n```"]