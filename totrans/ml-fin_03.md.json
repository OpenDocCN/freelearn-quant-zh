["```py\nfrom keras.datasets import mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n```", "```py\nx_train.shape\n```", "```py\nout: (60000, 28, 28)\n\n```", "```py\nimport numpy as np\nx_train = np.expand_dims(x_train,-1)\nx_test = np.expand_dims(x_test,-1)\nx_train.shape\n```", "```py\nout: (60000, 28, 28, 1)\n\n```", "```py\nfrom keras.layers import Conv2D\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\nimg_shape = (28,28,1)\n\nmodel.add(Conv2D(filters=6,\n                 kernel_size=3,\n                 strides=1,\n                 padding='valid',\n                 input_shape=img_shape))\n```", "```py\nmodel.add(Conv2D(6,3,input_shape=img_shape))\n```", "```py\nfrom keras.layers import Activation\nmodel.add(Activation('relu'))\n```", "```py\nfrom keras.layers import MaxPool2D\n\nmodel.add(MaxPool2D(pool_size=2, \n                    strides=None, \n                    padding='valid'))\n```", "```py\nmodel.add(MaxPool2D(2))\n```", "```py\nfrom keras.layers import Flatten\n\nmodel.add(Flatten())\n```", "```py\nfrom keras.layers import Dense\nmodel.add(Dense(10))\n```", "```py\nmodel.add(Activation('softmax'))\n```", "```py\nfrom keras.layers import Conv2D, Activation, MaxPool2D, Flatten, Dense\nfrom keras.models import Sequential\n\nimg_shape = (28,28,1)\n\nmodel = Sequential()\n\nmodel.add(Conv2D(6,3,input_shape=img_shape))\n\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPool2D(2))\n\nmodel.add(Conv2D(12,3))\n\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPool2D(2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(10))\n\nmodel.add(Activation('softmax'))\n```", "```py\nConv2D\nPool \n\nConv2D\nPool\n\nFlatten\n\nDense\n```", "```py\nmodel.summary()\n```", "```py\nLayer (type)                 Output Shape              Param # \n=================================================================\nconv2d_2 (Conv2D)            (None, 26, 26, 6)         60 \n_________________________________________________________________\nactivation_3 (Activation)    (None, 26, 26, 6)         0 \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 13, 13, 6)         0 \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 11, 11, 12)        660 \n_________________________________________________________________\nactivation_4 (Activation)    (None, 11, 11, 12)        0 \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 5, 5, 12)          0 \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 300)               0 \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                3010 \n_________________________________________________________________\nactivation_5 (Activation)    (None, 10)                0 \n=================================================================\nTotal params: 3,730\nTrainable params: 3,730\nNon-trainable params: 0\n_________________________________________________________________\n\n```", "```py\nfrom keras.datasets import mnist\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n```", "```py\nx_train.shape\n```", "```py\nout:\n(60000, 28, 28)\n\n```", "```py\nimport numpy as np\n\nx_train = np.expand_dims(x_train,-1)\n\nx_test = np.expand_dims(x_test,-1)\n```", "```py\nx_train.shape\n```", "```py\nout:\n(60000, 28, 28,1)\n\n```", "```py\ny_train.shape\n```", "```py\nout:\n(60000,)\n\n```", "```py\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['acc'])\n```", "```py\nhistory = model.fit(x_train,y_train,batch_size=32,epochs=5,validation_data=(x_test,y_test))\n```", "```py\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 19s 309us/step - loss: 5.3931 - acc: 0.6464 - val_loss: 1.9519 - val_acc: 0.8542\nEpoch 2/10\n60000/60000 [==============================] - 18s 297us/step - loss: 0.8855 - acc: 0.9136 - val_loss: 0.1279 - val_acc: 0.9635\n....\nEpoch 10/10\n60000/60000 [==============================] - 18s 296us/step - loss: 0.0473 - acc: 0.9854 - val_loss: 0.0663 - val_acc: 0.9814\n\n```", "```py\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(figsize=(10,6))\ngen = ax.plot(history.history['val_acc'], label='Validation Accuracy')\nfr = ax.plot(history.history['acc'],dashes=[5, 2], label='Training Accuracy')\n\nlegend = ax.legend(loc='lower center', shadow=True)\n\nplt.show()\n```", "```py\nfrom keras.optimizers import SGD\nmomentum_optimizer = SGD(lr=0.01, momentum=0.9)\n```", "```py\nmodel.compile(optimizer=momentum_optimizer,loss='sparse_categorical_crossentropy',metrics=['acc'])\n```", "```py\nfrom keras.optimizers import adam\n\nadam_optimizer=adam(lr=0.1,beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\nmodel.compile(optimizer=adam_optimizer,loss='sparse_categorical_crossentropy',metrics=['acc'])\n```", "```py\nfrom keras.regularizers import l2\n\nmodel = Sequential()\n\nmodel.add(Conv2D(6,3,input_shape=img_shape, kernel_regularizer=l2(0.01)))\n\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPool2D(2))\n\nmodel.add(Conv2D(12,3,activity_regularizer=l2(0.01)))\n\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPool2D(2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(10,bias_regularizer=l2(0.01)))\n\nmodel.add(Activation('softmax'))\n```", "```py\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer = 'adam',metrics=['acc'])\n\nhistory = model.fit(x_train,y_train,batch_size=32,epochs=10,validation_data=(x_test,y_test))\n\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 22s 374us/step - loss: 7707.2773 - acc: 0.6556 - val_loss: 55.7280 - val_acc: 0.7322\nEpoch 2/10\n60000/60000 [==============================] - 21s 344us/step - loss: 20.5613 - acc: 0.7088 - val_loss: 6.1601 - val_acc: 0.6771\n....\nEpoch 10/10\n60000/60000 [==============================] - 20s 329us/step - loss: 0.9231 - acc: 0.8650 - val_loss: 0.8309 - val_acc: 0.8749\n\n```", "```py\nfrom keras.layers import Dropout\nmodel = Sequential()\n\nmodel.add(Conv2D(6,3,input_shape=img_shape))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(2))\n\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(12,3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(2))\n\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(10,bias_regularizer=l2(0.01)))\n\nmodel.add(Activation('softmax'))\n```", "```py\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer = 'adam',metrics=['acc'])\n\nhistory = model.fit(x_train,y_train,batch_size=32,epochs=10,validation_data=(x_test,y_test))\n```", "```py\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 22s 371us/step - loss: 5.6472 - acc: 0.6039 - val_loss: 0.2495 - val_acc: 0.9265\nEpoch 2/10\n60000/60000 [==============================] - 21s 356us/step - loss: 0.2920 - acc: 0.9104 - val_loss: 0.1253 - val_acc: 0.9627\n....\nEpoch 10/10\n60000/60000 [==============================] - 21s 344us/step - loss: 0.1064 - acc: 0.9662 - val_loss: 0.0545 - val_acc: 0.9835\n\n```", "```py\nfrom keras.layers import BatchNormalization\n\nmodel = Sequential()\n\nmodel.add(Conv2D(6,3,input_shape=img_shape))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(2))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(12,3))\nmodel.add(Activation('relu'))\nmodel.add(MaxPool2D(2))\n\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(10,bias_regularizer=l2(0.01)))\n\nmodel.add(Activation('softmax'))\nmodel.compile(loss='sparse_categorical_crossentropy',optimizer = 'adam',metrics=['acc'])\n\nhistory = model.fit(x_train,y_train,batch_size=32,epochs=10,validation_data=(x_test,y_test))\n```", "```py\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\n60000/60000 [==============================] - 25s 420us/step - loss: 0.2229 - acc: 0.9328 - val_loss: 0.0775 - val_acc: 0.9768\nEpoch 2/10\n60000/60000 [==============================] - 26s 429us/step - loss: 0.0744 - acc: 0.9766 - val_loss: 0.0668 - val_acc: 0.9795\n....\nEpoch 10/10\n60000/60000 [==============================] - 26s 432us/step - loss: 0.0314 - acc: 0.9897 - val_loss: 0.0518 - val_acc: 0.9843\n\n```", "```py\nfrom keras.preprocessing.image import ImageDataGenerator\n```", "```py\nimgen = ImageDataGenerator(rescale=1/255)\n```", "```py\ntrain_generator = imgen.flow_from_directory('train',batch_size=32, target_size=(150,150))\nvalidation_generator = imgen.flow_from_directory('validation',batch_size=32, tar get_size=(150,150))\n```", "```py\nfrom keras.applications.vgg16 import VGG16\nvgg_model = VGG16(include_top=False,input_shape=(150,150,3))\n```", "```py\nout: \nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 5s 0us/step\n\n```", "```py\nvgg_model.summary()\n```", "```py\nout: \n_________________________________________________________________\nLayer (type)                 Output Shape              Param # \n=================================================================\ninput_1 (InputLayer)         (None, 150, 150, 3)       0 \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 150, 150, 64)      1792 \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 150, 150, 64)      36928 \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 75, 75, 64)        0 \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 75, 75, 128)       73856 \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 75, 75, 128)       147584 \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 37, 37, 128)       0 \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 37, 37, 256)       295168 \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 37, 37, 256)       590080 \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 37, 37, 256)       590080 \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 18, 18, 256)       0 \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160 \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808 \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808 \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 9, 9, 512)         0 \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808 \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808 \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808 \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0 \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n\n```", "```py\nfor the layer in vgg_model.layers:\n  layer.trainable = False\n```", "```py\nfinetune = Sequential(layers = vgg_model.layers)\n```", "```py\nfinetune.add(Flatten())\nfinetune.add(Dense(12))\nfinetune.add(Activation('softmax'))\n```", "```py\nfinetune.compile(loss='categorical_crossentropy',optimizer='adam',metrics = ['acc'])\n\nfinetune.fit_generator(train_generator,epochs=8,steps_per_epoch= 4606 // 32, validation_data=validation_generator, validation_steps= 144//32)\n```", "```py\ntrain_datagen = ImageDataGenerator(\n  rescale = 1/255,\n  rotation_range=90,\n  width_shift_range=0.2,\n  height_shift_range=0.2,\n  shear_range=0.2,\n  zoom_range=0.1,\n  horizontal_flip=True,\n  fill_mode='nearest')\n```", "```py\nfrom keras.preprocessing import image\nfname = 'train/Charlock/270209308.png'\n```", "```py\nimg = image.load_img(fname, target_size=(150, 150))\nimg = image.img_to_array(img)\n```", "```py\nimg = np.expand_dims(img,axis=0)\n```", "```py\ngen = train_datagen.flow(img, batch_size=1)\n```", "```py\nfor i in range(4):\n    plt.figure(i)\n    batch = next(gen)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n\nplt.show()\n```"]