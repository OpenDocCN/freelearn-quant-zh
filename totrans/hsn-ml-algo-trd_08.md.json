["```py\nimport statsmodels.tsa.api as tsa\nindustrial_production = web.DataReader('IPGMFN', 'fred', '1988', '2017-12').squeeze()\ncomponents = tsa.seasonal_decompose(industrial_production, model='additive')\nts = (industrial_production.to_frame('Original')\n      .assign(Trend=components.trend)\n      .assign(Seasonality=components.seasonal)\n      .assign(Residual=components.resid))\nts.plot(subplots=True, figsize=(14, 8));\n```", "```py\nfor p1 in range(4):                # AR order\n    for q1 in range(4):            # MA order\n        for p2 in range(3):        # seasonal AR order\n            for q2 in range(3):    # seasonal MA order\n                y_pred = []\n                for i, T in enumerate(range(train_size, len(data))):\n                    train_set = data.iloc[T - train_size:T]\n                    model = tsa.SARIMAX(endog=train_set,            # model specification\n                                        order=(p1, 0, q1),\n                                        seasonal_order=(p2, 0, q2, 12)).fit()\n\n                    preds.iloc[i, 1] = model.forecast(steps=1)[0]    # 1-step ahead forecast\n\n                mse = mean_squared_error(preds.y_true, preds.y_pred)\n                test_results[(p1, q1, p2, q2)] = [np.sqrt(mse),\n                                                  preds.y_true.sub(preds.y_pred).std(),\n                                                  np.mean(aic)]\n```", "```py\n                 RMSE         AIC         BIC\np1 q1 p2 q2                                  \n2  3  1  0   0.009323 -772.247023 -752.734581\n3  2  1  0   0.009467 -768.844028 -749.331586\n2  2  1  0   0.009540 -770.904835 -754.179884\n   3  0  0   0.009773 -760.248885 -743.523935\n   2  0  0   0.009986 -758.775827 -744.838368\n\n```", "```py\nbest_model = tsa.SARIMAX(endog=industrial_production_log_diff, order=(2, 0, 3),\n                         seasonal_order=(1, 0, 0, 12)).fit()\nprint(best_model.summary())\n```", "```py\nnasdaq = web.DataReader('NASDAQCOM', 'fred', '1998', '2017-12-31').squeeze()\nnasdaq_returns = np.log(nasdaq).diff().dropna().mul(100) # rescale to facilitate optimization\n```", "```py\nplot_correlogram(nasdaq_returns.sub(nasdaq_returns.mean()).pow(2), lags=120, title='NASDAQ Daily Volatility')\n```", "```py\ntrainsize = 10 * 252  # 10 years\ndata = nasdaq_returns.clip(lower=nasdaq_returns.quantile(.05),\n                           upper=nasdaq_returns.quantile(.95))\nT = len(nasdaq_returns)\ntest_results = {}\nfor p in range(1, 5):\n    for q in range(1, 5):\n        print(f'{p} | {q}')\n        result = []\n        for s, t in enumerate(range(trainsize, T-1)):\n            train_set = data.iloc[s: t]\n            test_set = data.iloc[t+1]  # 1-step ahead forecast\n            model = arch_model(y=train_set, p=p, q=q).fit(disp='off')\n            forecast = model.forecast(horizon=1)\n            mu = forecast.mean.iloc[-1, 0]\n            var = forecast.variance.iloc[-1, 0]\n            result.append([(test_set-mu)**2, var])\n        df = pd.DataFrame(result, columns=['y_true', 'y_pred'])\n        test_results[(p, q)] = np.sqrt(mean_squared_error(df.y_true, df.y_pred))\n```", "```py\nam = ConstantMean(nasdaq_returns.clip(lower=nasdaq_returns.quantile(.05),\n                                      upper=nasdaq_returns.quantile(.95)))\nam.volatility = GARCH(2, 0, 2)\nam.distribution = Normal()\nmodel = am.fit(update_freq=5)\nprint(model.summary())\n```", "```py\ndf = web.DataReader(['UMCSENT', 'IPGMFN'], 'fred', '1970', '2017-12').dropna()\ndf.columns = ['sentiment', 'ip']\n```", "```py\ndf_transformed = pd.DataFrame({'ip': np.log(df.ip).diff(12),\n                              'sentiment': df.sentiment.diff(12)}).dropna()\n\ntest_unit_root(df_transformed) # see notebook for details and additional plots\n\n          p-value\nip          0.0003\nsentiment   0.0000\n```", "```py\nmodel = VARMAX(df_transformed.iloc[:480], order=(1,1), trend='c').fit(maxiter=1000)\n```", "```py\npreds = model.predict(start=480, end=len(df_transformed)-1)\n```"]