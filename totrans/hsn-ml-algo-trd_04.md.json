["```py\nidx = pd.IndexSlice\nwith pd.HDFStore('../../data/assets.h5') as store:\n    prices = store['quandl/wiki/prices'].loc[idx['2000':'2018', :], \n                   'adj_close'].unstack('ticker')\n\nprices.info()\nDatetimeIndex: 4706 entries, 2000-01-03 to 2018-03-27\nColumns: 3199 entries, A to ZUMZ\n```", "```py\nmonthly_prices = prices.resample('M').last()\n```", "```py\noutlier_cutoff = 0.01\ndata = pd.DataFrame()\nlags = [1, 2, 3, 6, 9, 12]\nfor lag in lags:\n    data[f'return_{lag}m'] = (monthly_prices\n                           .pct_change(lag)\n                           .stack()\n                           .pipe(lambda x: x.clip(lower=x.quantile(outlier_cutoff),\n                        upper=x.quantile(1-outlier_cutoff)))\n                           .add(1)\n                           .pow(1/lag)\n                           .sub(1)\n                           )\ndata = data.swaplevel().dropna()\ndata.info()\n\nMultiIndex: 521806 entries, (A, 2001-01-31 00:00:00) to (ZUMZ, 2018-03-\n                             31 00:00:00)\nData columns (total 6 columns):\nreturn_1m 521806 non-null float64\nreturn_2m 521806 non-null float64\nreturn_3m 521806 non-null float64\nreturn_6m 521806 non-null float64\nreturn_9m 521806 non-null float64\nreturn_12m 521806 non-null float6\n```", "```py\nfor lag in [2,3,6,9,12]:\n    data[f'momentum_{lag}'] = data[f'return_{lag}m'].sub(data.return_1m)\ndata[f'momentum_3_12'] = data[f'return_12m'].sub(data.return_3m)\n```", "```py\nfor t in range(1, 7):\n    data[f'return_1m_t-{t}'] = data.groupby(level='ticker').return_1m.shift(t)\n```", "```py\nfor t in [1,2,3,6,12]:\n    data[f'target_{t}m'] = data.groupby(level='ticker')[f'return_{t}m'].shift(-t)\n```", "```py\nfactors = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\nfactor_data = web.DataReader('F-F_Research_Data_5_Factors_2x3', \n              'famafrench', start='2000')[0].drop('RF', axis=1)\nfactor_data.index = factor_data.index.to_timestamp()\nfactor_data = factor_data.resample('M').last().div(100)\nfactor_data.index.name = 'date'\nfactor_data = factor_data.join(data['return_1m']).sort_index()\n\nT = 24\nbetas = (factor_data\n         .groupby(level='ticker', group_keys=False)\n         .apply(lambda x: PandasRollingOLS(window=min(T, x.shape[0]-1), y=x.return_1m, x=x.drop('return_1m', axis=1)).beta))\n```", "```py\n$ QUANDL_API_KEY=<yourkey> zipline ingest [-b <bundle>]\n```", "```py\nfrom zipline.api import attach_pipeline, pipeline_output, record\nfrom zipline.pipeline import Pipeline, CustomFactor\nfrom zipline.pipeline.factors import Returns, AverageDollarVolume\nfrom zipline import run_algorithm\n\nMONTH, YEAR = 21, 252\nN_LONGS = N_SHORTS = 25\nVOL_SCREEN = 1000\n\nclass MeanReversion(CustomFactor):\n    \"\"\"Compute ratio of latest monthly return to 12m average,\n       normalized by std dev of monthly returns\"\"\"\n    inputs = [Returns(window_length=MONTH)]\n    window_length = YEAR\n\n    def compute(self, today, assets, out, monthly_returns):\n        df = pd.DataFrame(monthly_returns)\n        out[:] = df.iloc[-1].sub(df.mean()).div(df.std())\n\ndef compute_factors():\n    \"\"\"Create factor pipeline incl. mean reversion,\n        filtered by 30d Dollar Volume; capture factor ranks\"\"\"\n    mean_reversion = MeanReversion()\n    dollar_volume = AverageDollarVolume(window_length=30)\n    return Pipeline(columns={'longs'  : mean_reversion.bottom(N_LONGS),\n                             'shorts' : mean_reversion.top(N_SHORTS),\n                             'ranking': \n                          mean_reversion.rank(ascending=False)},\n                          screen=dollar_volume.top(VOL_SCREEN))\n```", "```py\ndef initialize(context):\n    \"\"\"Setup: register pipeline, schedule rebalancing,\n        and set trading params\"\"\"\n    attach_pipeline(compute_factors(), 'factor_pipeline')\n\ndef before_trading_start(context, data):\n    \"\"\"Run factor pipeline\"\"\"\n    context.factor_data = pipeline_output('factor_pipeline')\n    record(factor_data=context.factor_data.ranking)\n    assets = context.factor_data.index\n    record(prices=data.current(assets, 'price'))\n```", "```py\nstart, end = pd.Timestamp('2015-01-01', tz='UTC'), pd.Timestamp('2018-\n             01-01', tz='UTC')\ncapital_base = 1e7\n\nperformance = run_algorithm(start=start,\n                            end=end,\n                            initialize=initialize,\n                            before_trading_start=before_trading_start,\n                            capital_base=capital_base)\n\nperformance.to_pickle('single_factor.pickle')\n```", "```py\nfrom quantopian.research import run_pipeline\nfrom quantopian.pipeline import Pipeline\nfrom quantopian.pipeline.data.builtin import USEquityPricing\nfrom quantopian.pipeline.data.morningstar import income_statement, \n     operation_ratios, balance_sheet\nfrom quantopian.pipeline.data.psychsignal import stocktwits\nfrom quantopian.pipeline.factors import CustomFactor, \n     SimpleMovingAverage, Returns\nfrom quantopian.pipeline.filters import QTradableStocksUS\n```", "```py\nclass AggregateFundamentals(CustomFactor):\n    def compute(self, today, assets, out, inputs):\n        out[:] = inputs[0]\n```", "```py\ndef compute_factors():\n    universe = QTradableStocksUS()\n\n    profitability = (AggregateFundamentals(inputs=\n                     [income_statement.gross_profit],\n                                           window_length=YEAR) /\n                     balance_sheet.total_assets.latest).rank(mask=universe)\n\n    roic = operation_ratios.roic.latest.rank(mask=universe)\n    ebitda_yield = (AggregateFundamentals(inputs=\n                             [income_statement.ebitda],\n                                          window_length=YEAR) /\n                    USEquityPricing.close.latest).rank(mask=universe)\n    mean_reversion = MeanReversion().rank(mask=universe)\n    price_momentum = Returns(window_length=QTR).rank(mask=universe)\n    sentiment = SimpleMovingAverage(inputs=\n                            [stocktwits.bull_minus_bear],\n\n                            window_length=5).rank(mask=universe)\n\n    factor = profitability + roic + ebitda_yield + mean_reversion + \n             price_momentum + sentiment\n\n    return Pipeline(\n            columns={'Profitability'      : profitability,\n                     'ROIC'               : roic,\n                     'EBITDA Yield'       : ebitda_yield,\n                     \"Mean Reversion (1M)\": mean_reversion,\n                     'Sentiment'          : sentiment,\n                     \"Price Momentum (3M)\": price_momentum,\n                     'Alpha Factor'       : factor})\n```", "```py\nperformance = pd.read_pickle('single_factor.pickle')\n\nprices = pd.concat([df.to_frame(d) for d, df in performance.prices.items()],axis=1).T\nprices.columns = [re.findall(r\"\\[(.+)\\]\", str(col))[0] for col in \n                  prices.columns]\nprices.index = prices.index.normalize()\nprices.info()\n\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 755 entries, 2015-01-02 to 2017-12-29\nColumns: 1661 entries, A to ZTS\ndtypes: float64(1661)\n```", "```py\nHOLDING_PERIODS = (5, 10, 21, 42)\nQUANTILES = 5\nalphalens_data = get_clean_factor_and_forward_returns(factor=factor_data,\n                                     prices=prices,\n                                     periods=HOLDING_PERIODS,\n                                     quantiles=QUANTILES)\n\nDropped 14.5% entries from factor data: 14.5% in forward returns computation and 0.0% in binning phase (set max_loss=0 to see potentially suppressed Exceptions). max_loss is 35.0%, not exceeded: OK!\n```", "```py\nfrom alphalens.performance import mean_return_by_quantile\nfrom alphalens.plotting import plot_quantile_returns_bar\nmean_return_by_q, std_err = mean_return_by_quantile(alphalens_data)\nplot_quantile_returns_bar(mean_return_by_q);\n```", "```py\nfrom alphalens.plotting import plot_cumulative_returns_by_quantile\nmean_return_by_q_daily, std_err =     \n     mean_return_by_quantile(alphalens_data, by_date=True)\nplot_cumulative_returns_by_quantile(mean_return_by_q_daily['5D'], \n     period='5D');\n```", "```py\nfrom alphalens.plotting import plot_quantile_returns_violin\nplot_quantile_returns_violin(mean_return_by_q_daily);\n```", "```py\nfrom alphalens.performance import factor_information_coefficient\nfrom alphalens.plotting import plot_ic_ts\nic = factor_information_coefficient(alphalens_data)\nplot_ic_ts(ic[['5D']])\n```", "```py\nic = factor_information_coefficient(alphalens_data)\nic_by_year = ic.resample('A').mean()\nic_by_year.index = ic_by_year.index.year\nic_by_year.plot.bar(figsize=(14, 6))\n```", "```py\ncreate_turnover_tear_sheet(alphalens_data)\n```"]