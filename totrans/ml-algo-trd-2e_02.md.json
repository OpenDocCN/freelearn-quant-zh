["```py\n8=FIX.5.0|9=127|35=A|59=theBroker.123456|56=CSERVER|34=1|32=20180117- 08:03:04|57=TRADE|50=any_string|98=2|108=34|141=Y|553=12345|554=passw0rd!|10=131| \n```", "```py\n    formats = {\n        ('integer', 2): 'H',  # int of length 2 => format string 'H'\n        ('integer', 4): 'I',\n        ('integer', 6): '6s', # int of length 6 => parse as string, \n          convert later\n        ('integer', 8): 'Q',\n        ('alpha', 1)  : 's',\n        ('alpha', 2)  : '2s',\n        ('alpha', 4)  : '4s',\n        ('alpha', 8)  : '8s',\n        ('price_4', 4): 'I',\n        ('price_8', 8): 'Q',\n    } \n    ```", "```py\n    # Get ITCH specs and create formatting (type, length) tuples\n    specs = pd.read_csv('message_types.csv')\n    specs['formats'] = specs[['value', 'length']].apply(tuple, \n                               axis=1).map(formats)\n    # Formatting for alpha fields\n    alpha_fields = specs[specs.value == 'alpha'].set_index('name')\n    alpha_msgs = alpha_fields.groupby('message_type')\n    alpha_formats = {k: v.to_dict() for k, v in alpha_msgs.formats}\n    alpha_length = {k: v.add(5).to_dict() for k, v in alpha_msgs.length}\n    # Generate message classes as named tuples and format strings\n    message_fields, fstring = {}, {}\n    for t, message in specs.groupby('message_type'):\n        message_fields[t] = namedtuple(typename=t,\n                                      field_names=message.name.tolist())\n        fstring[t] = '>' + ''.join(message.formats.tolist()) \n    ```", "```py\n    def format_alpha(mtype, data):\n        \"\"\"Process byte strings of type alpha\"\"\"\n        for col in alpha_formats.get(mtype).keys():\n            if mtype != 'R' and col == 'stock':\n                data = data.drop(col, axis=1)\n                continue\n            data.loc[:, col] = (data.loc[:, col]\n                                .str.decode(\"utf-8\")\n                                .str.strip())\n            if encoding.get(col):\n                data.loc[:, col] = data.loc[:, col].map(encoding.get(col))\n        return data \n    ```", "```py\nwith (data_path / file_name).open('rb') as data:\n    while True:\n        message_size = int.from_bytes(data.read(2), byteorder='big', \n                       signed=False)\n        message_type = data.read(1).decode('ascii')\n        message_type_counter.update([message_type])\n        record = data.read(message_size - 1)\n        message = message_fields[message_type]._make(\n            unpack(fstring[message_type], record))\n        messages[message_type].append(message)\n\n        # deal with system events like market open/close\n        if message_type == 'S':\n            timestamp = int.from_bytes(message.timestamp, \n                                       byteorder='big')\n            if message.event_code.decode('ascii') == 'C': # close\n                store_messages(messages)\n                break \n```", "```py\nwith pd.HDFStore(itch_store) as store:\n    stocks = store['R'].loc[:, ['stock_locate', 'stock']]\n    trades = (store['P'].append(\n            store['Q'].rename(columns={'cross_price': 'price'}),\n            sort=False).merge(stocks))\ntrades['value'] = trades.shares.mul(trades.price)\ntrades['value_share'] = trades.value.div(trades.value.sum())\ntrade_summary = (trades.groupby('stock').value_share\n                 .sum().sort_values(ascending=False))\ntrade_summary.iloc[:50].plot.bar(figsize=(14, 6),\n                                 color='darkblue',\n                                 title='Share of Traded Value')\nf = lambda y, _: '{:.0%}'.format(y)\nplt.gca().yaxis.set_major_formatter(FuncFormatter(f)) \n```", "```py\ndef get_messages(date, stock=stock):\n    \"\"\"Collect trading messages for given stock\"\"\"\n    with pd.HDFStore(itch_store) as store:\n        stock_locate = store.select('R', where='stock = \n                                     stock').stock_locate.iloc[0]\n        target = 'stock_locate = stock_locate'\n        data = {}\n        # relevant message types\n        messages = ['A', 'F', 'E', 'C', 'X', 'D', 'U', 'P', 'Q']\n        for m in messages:\n            data[m] = store.select(m,  \n              where=target).drop('stock_locate', axis=1).assign(type=m)\n    order_cols = ['order_reference_number', 'buy_sell_indicator', \n                  'shares', 'price']\n    orders = pd.concat([data['A'], data['F']], sort=False,  \n                        ignore_index=True).loc[:, order_cols]\n    for m in messages[2: -3]:\n        data[m] = data[m].merge(orders, how='left')\n    data['U'] = data['U'].merge(orders, how='left',\n                                right_on='order_reference_number',\n                                left_on='original_order_reference_number',\n                                suffixes=['', '_replaced'])\n    data['Q'].rename(columns={'cross_price': 'price'}, inplace=True)\n    data['X']['shares'] = data['X']['cancelled_shares']\n    data['X'] = data['X'].dropna(subset=['price'])\n    data = pd.concat([data[m] for m in messages], ignore_index=True, \n                      sort=False) \n```", "```py\ndef get_trades(m):\n    \"\"\"Combine C, E, P and Q messages into trading records\"\"\"\n    trade_dict = {'executed_shares': 'shares', 'execution_price': 'price'}\n    cols = ['timestamp', 'executed_shares']\n    trades = pd.concat([m.loc[m.type == 'E',\n                              cols + ['price']].rename(columns=trade_dict),\n                        m.loc[m.type == 'C',\n                              cols + ['execution_price']]\n                        .rename(columns=trade_dict),\n                        m.loc[m.type == 'P', ['timestamp', 'price',\n                                              'shares']],\n                        m.loc[m.type == 'Q',\n                              ['timestamp', 'price', 'shares']]\n                        .assign(cross=1), ],\n                       sort=False).dropna(subset=['price']).fillna(0)\n    return trades.set_index('timestamp').sort_index().astype(int) \n```", "```py\ndef add_orders(orders, buysell, nlevels):\n    new_order = []\n    items = sorted(orders.copy().items())\n    if buysell == 1:\n        items = reversed(items)  \n    for i, (p, s) in enumerate(items, 1):\n        new_order.append((p, s))\n        if i == nlevels:\n            break\n    return orders, new_order \n```", "```py\nfor message in messages.itertuples():\n    i = message[0]\n    if np.isnan(message.buy_sell_indicator):\n        continue\n    message_counter.update(message.type)\n    buysell = message.buy_sell_indicator\n    price, shares = None, None\n    if message.type in ['A', 'F', 'U']:\n        price, shares = int(message.price), int(message.shares)\n        current_orders[buysell].update({price: shares})\n        current_orders[buysell], new_order = \n          add_orders(current_orders[buysell], buysell, nlevels)\n        order_book[buysell][message.timestamp] = new_order\n    if message.type in ['E', 'C', 'X', 'D', 'U']:\n        if message.type == 'U':\n            if not np.isnan(message.shares_replaced):\n                price = int(message.price_replaced)\n                shares = -int(message.shares_replaced)\n        else:\n            if not np.isnan(message.price):\n                price = int(message.price)\n                shares = -int(message.shares)\n        if price is not None:\n            current_orders[buysell].update({price: shares})\n            if current_orders[buysell][price] <= 0:\n                current_orders[buysell].pop(price)\n            current_orders[buysell], new_order = \n              add_orders(current_orders[buysell], buysell, nlevels)\n            order_book[buysell][message.timestamp] = new_order \n```", "```py\nstock, date = 'AAPL', '20191030'\ntitle = '{} | {}'.format(stock, pd.to_datetime(date).date()\nwith pd.HDFStore(itch_store) as store:\n    sys_events = store['S'].set_index('event_code') # system events\n    sys_events.timestamp = sys_events.timestamp.add(pd.to_datetime(date)).dt.time\n    market_open = sys_events.loc['Q', 'timestamp'] \n    market_close = sys_events.loc['M', 'timestamp']\nwith pd.HDFStore(stock_store) as store:\n    trades = store['{}/trades'.format(stock)].reset_index()\ntrades = trades[trades.cross == 0] # excluding data from open/close crossings\ntrades.price = trades.price.mul(1e-4) # format price\ntrades = trades[trades.cross == 0]    # exclude crossing trades\ntrades = trades.between_time(market_open, market_close) # market hours only\ntick_bars = trades.set_index('timestamp')\ntick_bars.index = tick_bars.index.time\ntick_bars.price.plot(figsize=(10, 5), title=title), lw=1) \n```", "```py\nfrom scipy.stats import normaltest\nnormaltest(tick_bars.price.pct_change().dropna())\nNormaltestResult(statistic=62408.76562431228, pvalue=0.0) \n```", "```py\ndef get_bar_stats(agg_trades):\n    vwap = agg_trades.apply(lambda x: np.average(x.price, \n           weights=x.shares)).to_frame('vwap')\n    ohlc = agg_trades.price.ohlc()\n    vol = agg_trades.shares.sum().to_frame('vol')\n    txn = agg_trades.shares.size().to_frame('txn')\n    return pd.concat([ohlc, vwap, vol, txn], axis=1)\nresampled = trades.groupby(pd.Grouper(freq='1Min'))\ntime_bars = get_bar_stats(resampled) \n```", "```py\ndef price_volume(df, price='vwap', vol='vol', suptitle=title, fname=None):\n    fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(15, 8))\n    axes[0].plot(df.index, df[price])\n    axes[1].bar(df.index, df[vol], width=1 / (len(df.index)), \n                color='r')\n    xfmt = mpl.dates.DateFormatter('%H:%M')\n    axes[1].xaxis.set_major_locator(mpl.dates.HourLocator(interval=3))\n    axes[1].xaxis.set_major_formatter(xfmt)\n    axes[1].get_xaxis().set_tick_params(which='major', pad=25)\n    axes[0].set_title('Price', fontsize=14)\n    axes[1].set_title('Volume', fontsize=14)\n    fig.autofmt_xdate()\n    fig.suptitle(suptitle)\n    fig.tight_layout()\n    plt.subplots_adjust(top=0.9)\nprice_volume(time_bars) \n```", "```py\nresampled = trades.groupby(pd.Grouper(freq='5Min')) # 5 Min bars for better print\ndf = get_bar_stats(resampled)\nincrease = df.close > df.open\ndecrease = df.open > df.close\nw = 2.5 * 60 * 1000 # 2.5 min in ms\nWIDGETS = \"pan, wheel_zoom, box_zoom, reset, save\"\np = figure(x_axis_type='datetime', tools=WIDGETS, plot_width=1500, \n          title = \"AAPL Candlestick\")\np.xaxis.major_label_orientation = pi/4\np.grid.grid_line_alpha=0.4\np.segment(df.index, df.high, df.index, df.low, color=\"black\")\np.vbar(df.index[increase], w, df.open[increase], df.close[increase], \n       fill_color=\"#D5E1DD\", line_color=\"black\")\np.vbar(df.index[decrease], w, df.open[decrease], df.close[decrease], \n       fill_color=\"#F2583E\", line_color=\"black\")\nshow(p) \n```", "```py\nmin_per_trading_day = 60 * 7.5\ntrades_per_min = trades.shares.sum() / min_per_trading_day\ntrades['cumul_vol'] = trades.shares.cumsum()\ndf = trades.reset_index()\nby_vol = (df.groupby(df.cumul_vol.\n                     div(trades_per_min)\n                     .round().astype(int)))\nvol_bars = pd.concat([by_vol.timestamp.last().to_frame('timestamp'),\n                      get_bar_stats(by_vol)], axis=1)\nprice_volume(vol_bars.set_index('timestamp')) \n```", "```py\nvalue_per_min = trades.shares.mul(trades.price).sum()/(60*7.5) # min per trading day\ntrades['cumul_val'] = trades.shares.mul(trades.price).cumsum()\ndf = trades.reset_index()\nby_value = df.groupby(df.cumul_val.div(value_per_min).round().astype(int))\ndollar_bars = pd.concat([by_value.timestamp.last().to_frame('timestamp'), get_bar_stats(by_value)], axis=1)\nprice_volume(dollar_bars.set_index('timestamp'), \n             suptitle=f'Dollar Bars | {stock} | {pd.to_datetime(date).date()}') \n```", "```py\ndirectories = [Path(d) for d in ['1min_trades']]\ntarget = directory / 'parquet'\nfor zipped_file in directory.glob('*/**/*.zip'):\n    fname = zipped_file.stem\n    print('\\t', fname)\n    zf = ZipFile(zipped_file)\n    files = zf.namelist()\n    data = (pd.concat([pd.read_csv(zf.open(f),\n                                   parse_dates=[['Date',\n                                                 'TimeBarStart']])\n                       for f in files],\n                      ignore_index=True)\n            .rename(columns=lambda x: x.lower())\n            .rename(columns={'date_timebarstart': 'date_time'})\n            .set_index(['ticker', 'date_time']))\n    data.to_parquet(target / (fname + '.parquet')) \n```", "```py\npath = Path('1min_trades/parquet')\ndf = pd.concat([pd.read_parquet(f) for f in path.glob('*.parquet')]).dropna(how='all', axis=1)\ndf.columns = ['open', 'high', 'low', 'close', 'trades', 'volume', 'vwap']\ndf.to_hdf('data.h5', '1min_trades')\nprint(df.info(null_counts=True))\nMultiIndex: 53864194 entries, (AAL, 2014-12-22 07:05:00) to (YHOO, 2017-06-16 19:59:00)\nData columns (total 7 columns):\nopen      53864194 non-null float64\nhigh      53864194 non-null float64\nLow       53864194 non-null float64\nclose     53864194 non-null float64\ntrades    53864194 non-null int64\nvolume    53864194 non-null int64\nvwap      53852029 non-null float64 \n```", "```py\nidx = pd.IndexSlice\nwith pd.HDFStore('data.h5') as store:\n    print(store.info())\n    df = (store['1min_trades']\n          .loc[idx['AAPL', '2017-12-29'], :]\n          .reset_index())\nfig = go.Figure(data=go.Ohlc(x=df.date_time,\n                             open=df.open,\n                             high=df.high,\n                             low=df.low,\n                             close=df.close)) \n```", "```py\nsp_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\nsp = pd.read_html(sp_url, header=0)[0] # returns a list for each table\nsp.info()\nRangeIndex: 505 entries, 0 to 504\nData columns (total 9 columns):\nSymbol                    505 non-null object\nSecurity                  505 non-null object\nSEC filings                505 non-null object\nGICS Sector               505 non-null object\nGICS Sub Industry         505 non-null object\nHeadquarters Location     505 non-null object\nDate first added           408 non-null object\nCIK                       505 non-null int64\nFounded                   234 non-null object \n```", "```py\nimport pandas_datareader.data as web\nfrom datetime import datetime\nstart = '2014'              # accepts strings\nend = datetime(2017, 5, 24) # or datetime objects\nyahoo= web.DataReader('FB', 'yahoo', start=start, end=end)\nyahoo.info()\nDatetimeIndex: 856 entries, 2014-01-02 to 2017-05-25\nData columns (total 6 columns):\nHigh         856 non-null float64\nLow          856 non-null float64\nOpen         856 non-null float64\nClose        856 non-null float64\nVolume       856 non-null int64\nAdj Close    856 non-null float64\ndtypes: float64(5), int64(1) \n```", "```py\nimport yfinance as yf\nsymbol = 'MSFT'\nticker = yf.Ticker(symbol) \n```", "```py\ndata = ticker.history(period='5d',\n                      interval='1m',\n                      actions=True,\n                      auto_adjust=True)\ndata.info()\nDatetimeIndex: 1747 entries, 2019-11-22 09:30:00-05:00 to 2019-11-29 13:00:00-05:00\nData columns (total 7 columns):\nOpen            1747 non-null float64\nHigh            1747 non-null float64\nLow             1747 non-null float64\nClose           1747 non-null float64\nVolume          1747 non-null int64\nDividends       1747 non-null int64\nStock Splits    1747 non-null int64 \n```", "```py\nticker.options\n('2019-12-05',  '2019-12-12',  '2019-12-19',..) \n```", "```py\noptions = ticker.option_chain('2019-12-05')\noptions.calls.info()\nData columns (total 14 columns):\ncontractSymbol       35 non-null object\nlastTradeDate        35 non-null datetime64[ns]\nstrike               35 non-null float64\nlastPrice            35 non-null float64\nbid                  35 non-null float64\nask                  35 non-null float64\nchange               35 non-null float64\npercentChange        35 non-null float64\nvolume               34 non-null float64\nopenInterest         35 non-null int64\nimpliedVolatility    35 non-null float64\ninTheMoney           35 non-null bool\ncontractSize         35 non-null object\ncurrency             35 non-null object \n```", "```py\n%load_ext zipline\n%%zipline --start 2010-1-1 --end 2018-1-1 --data-frequency daily\nfrom zipline.api import order_target, record, symbol\ndef initialize(context):\n    context.i = 0\n    context.assets = [symbol('FB'), symbol('GOOG'), symbol('AMZN')]\n\ndef handle_data(context, data):\n    df = data.history(context.assets, fields=['price', 'volume'], \n                      bar_count=1, frequency=\"1d\")\n    df = df.to_frame().reset_index()\n\n    if context.i == 0:\n        df.columns = ['date', 'asset', 'price', 'volume']\n        df.to_csv('stock_data.csv', index=False)\n    else:\n        df.to_csv('stock_data.csv', index=False, mode='a', header=None)\n    context.i += 1\ndf = pd.read_csv('stock_data.csv')\ndf.date = pd.to_datetime(df.date)\ndf.set_index('date').groupby('asset').price.plot(lw=2, legend=True, \n       figsize=(14, 6)); \n```", "```py\nimport quandl\noil = quandl.get('EIA/PET_RWTC_D').squeeze()\noil.plot(lw=2, title='WTI Crude Oil Price') \n```", "```py\nSEC_URL = 'https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/'\nfirst_year, this_year, this_quarter = 2014, 2018, 3\npast_years = range(2014, this_year)\nfiling_periods = [(y, q) for y in past_years for q in range(1, 5)]\nfiling_periods.extend([(this_year, q) for q in range(1, this_quarter + \n                                                    1)])\nfor i, (yr, qtr) in enumerate(filing_periods, 1):\n    filing = f'{yr}q{qtr}_notes.zip'\n    path = data_path / f'{yr}_{qtr}' / 'source'\n    response = requests.get(SEC_URL + filing).content\n    with ZipFile(BytesIO(response)) as zip_file:\n        for file in zip_file.namelist():\n            local_file = path / file\n            with local_file.open('wb') as output:\n                for line in zip_file.open(file).readlines():\n                    output.write(line) \n```", "```py\nfor f in data_path.glob('**/*.tsv'):\n    file_name = f.stem  + '.parquet'\n    path = Path(f.parents[1]) / 'parquet'\n    df = pd.read_csv(f, sep='\\t', encoding='latin1', low_memory=False)\n    df.to_parquet(path / file_name) \n```", "```py\napple = sub[sub.name == 'APPLE INC'].T.dropna().squeeze()\nkey_cols = ['name', 'adsh', 'cik', 'name', 'sic', 'countryba',  \n            'stprba', 'cityba', 'zipba', 'bas1', 'form', 'period', \n            'fy', 'fp', 'filed']\napple.loc[key_cols]\nname                    APPLE INC\nadsh                    0000320193-18-000070\ncik                     320193\nname                    APPLE INC\nsic                     3571\ncountryba               US\nstprba                  CA\ncityba                  CUPERTINO\nzipba                   95014\nbas1                    ONE APPLE PARK WAY\nform                    10-Q\nperiod                  20180331\nfy                      2018\nfp                      Q2\nfiled                   20180502 \n```", "```py\naapl_subs = pd.DataFrame()\nfor sub in data_path.glob('**/sub.parquet'):\n    sub = pd.read_parquet(sub)\n    aapl_sub = sub[(sub.cik.astype(int) == apple.cik) & \n                   (sub.form.isin(['10-Q', '10-K']))]\n    aapl_subs = pd.concat([aapl_subs, aapl_sub])\naapl_subs.form.value_counts()\n10-Q    15\n10-K     4 \n```", "```py\naapl_nums = pd.DataFrame()\nfor num in data_path.glob('**/num.parquet'):\n    num = pd.read_parquet(num).drop('dimh', axis=1)\n    aapl_num = num[num.adsh.isin(aapl_subs.adsh)]\n    aapl_nums = pd.concat([aapl_nums, aapl_num])\naapl_nums.ddate = pd.to_datetime(aapl_nums.ddate, format='%Y%m%d')\naapl_nums.shape\n(28281, 16) \n```", "```py\nfield = 'EarningsPerShareDiluted'\nstock_split = 7\nsplit_date = pd.to_datetime('20140604')\n# Filter by tag; keep only values measuring 1 quarter\neps = aapl_nums[(aapl_nums.tag == 'EarningsPerShareDiluted')\n                & (aapl_nums.qtrs == 1)].drop('tag', axis=1)\n# Keep only most recent data point from each filing\neps = eps.groupby('adsh').apply(lambda x: x.nlargest(n=1, columns=['ddate']))\n# Adjust earnings prior to stock split downward\neps.loc[eps.ddate < split_date,'value'] = eps.loc[eps.ddate < \n        split_date, 'value'].div(7)\neps = eps[['ddate', 'value']].set_index('ddate').squeeze()\n# create trailing 12-months eps from quarterly data\neps = eps.rolling(4, min_periods=4).sum().dropna() \n```", "```py\nimport pandas_datareader.data as web\nsymbol = 'AAPL.US'\naapl_stock = web.DataReader(symbol, 'quandl', start=eps.index.min())\naapl_stock = aapl_stock.resample('D').last() # ensure dates align with \n                                               eps data \n```", "```py\npe = aapl_stock.AdjClose.to_frame('price').join(eps.to_frame('eps'))\npe = pe.fillna(method='ffill').dropna()\npe['P/E Ratio'] = pe.price.div(pe.eps)\naxes = pe.plot(subplots=True, figsize=(16,8), legend=False, lw=2); \n```"]