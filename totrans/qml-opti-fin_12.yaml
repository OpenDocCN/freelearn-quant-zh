- en: '13'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Looking Ahead
  prefs: []
  type: TYPE_NORMAL
- en: The first generation of quantum algorithms appeared in the 1990s when quantum
    computers existed only as a concept. On the one hand, the absence of actual quantum
    hardware was a huge disadvantage since it made direct experiments impossible;
    on the other hand, it stimulated theoretical research not inhibited by the limitations
    and constraints of the imperfect early quantum computers. Researchers focused
    on devising algorithms that would achieve quadratic or even exponential speedup,
    assuming that powerful, error-free quantum computers would be available one day.
    It was the time when Shorâ€™s prime factorisation algorithmÂ Â [[265](Biblography.xhtml#XShor)]
    and Groverâ€™s search algorithmÂ Â [[117](Biblography.xhtml#XGrover)] were discovered.
    Incidentally, as the book was about to be released, Peter Shor was named one of
    the four recipients of the 2022 Breakthrough Prize in Fundamental Physics (along
    with C. H. Bennett, G. Brassard, and D. Deutsch) for their foundational work in
    quantum information. Many such algorithms, in turn, relied on basic building blocks
    such as Quantum Phase Estimation and Quantum Fourier TransformÂ Â [[278](Biblography.xhtml#XSutor2019)].
    These algorithms played an important role in demonstrating the capabilities of
    universal gate model quantum computers â€“ if only they were available!
  prefs: []
  type: TYPE_NORMAL
- en: 'A quarter of a century later we are facing a different problem: the development
    of practical quantum computing algorithms and techniques that would allow us to
    extract value from NISQ computers. While quantum computing hardware is improving
    at a breathtaking pace, it is still too far from a state where it can break RSA
    encryption. What are existing quantum computers capable of doing? What is their
    relative strength in comparison with classical computers? In this chapter we look
    at several new, NISQ-friendly algorithms that bring us one step closer to achieving
    the quantum advantage.'
  prefs: []
  type: TYPE_NORMAL
- en: 13.1 Quantum Kernels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We start with the popular classical kernel method and then describe its quantum
    counterpart based on parameterised quantum circuits.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.1 Classical kernel method
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A *kernel method* is the key element of a powerful classical supervised learning
    algorithm: Support Vector Machine (SVM). Unlike a feedforward-neural-network-based
    classifier whose objective is to minimise the classification error, the SVMâ€™s
    objective is to maximise the margin, defined as the distance between a separating
    hyperplane (decision boundary separating samples belonging to different classes)
    and the training samples that are closest to this hyperplaneÂ Â [[243](Biblography.xhtml#XRaschka2019)].
    The samples that are closest to the separating hyperplane are called *support
    vectors*, thus giving its name to the algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: The maximisation of the margins lowers the generalisation error and helps fight
    overfitting. This is a very important property but finding the separating hyperplane
    is not an easy task for non-linearly separable data. Fortunately, the kernel method
    allows us to overcome this difficulty, by creating non-linear combinations of
    the original features and projecting them onto a higher-dimensional space where
    the data samples become linearly separable.
  prefs: []
  type: TYPE_NORMAL
- en: Whereas an SVM with linearly separable data operates on the inner product ![âŸ¨xi,xjâŸ©](img/file1241.jpg)
    of the training samples, the generalised version to non-linearly separable data
    operates on the kernel function
  prefs: []
  type: TYPE_NORMAL
- en: '| ![k(xi,xj) := Ï•(xi)âŠ¤ Ï•(xj), ](img/file1242.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 'where *Ï•* : â„^N â†’â„^M, with *M* â‰« *N*, is the feature map that projects the
    *N*-dimensional feature x := (*x*[1]*,â€¦,x*[N]) onto the *M*-dimensional feature
    space. The inner productÂ ([13.1.1](#x1-2380001)) would be computationally expensive
    to calculate directly but the kernel function is computationally inexpensiveÂ â€“
    this is known as the *kernel trick*. The kernel function can be seen as a similarity
    function operating on a pair of samples. For example, the radial basis function'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ i j ( âˆ¥xi âˆ’ xjâˆ¥2) k(x,x ) = exp âˆ’ ---2Ïƒ2---- , ](img/file1243.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: translates the distance between samples x^i and x^j (defined on [0*,*âˆ)^N) into
    a similarity score (defined on the interval [0*,*1]).
  prefs: []
  type: TYPE_NORMAL
- en: The right choice of kernel function can make the classification task much easier.
    However, some kernels may be hard to compute. This is where quantum computing
    may play an important role by providing efficient quantum circuits to compute
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.2 Quantum kernel method
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Wang, Du, Luo, and TaÂ Â [[298](Biblography.xhtml#XWang2021)] have shown a close
    correspondence between classical and quantum kernels. The feature mapÂ *Ï•*(â‹…) coincides
    with the preparation of a quantum state via a parameterised quantum circuitÂ ğ’°(â‹…),
    which maps the input data sample into a high-dimensional Hilbert space described
    byÂ *n* qubits:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âŠ—n Ï•(x) â†’ &#124;Ïˆ(x)âŸ© = ğ’°(x) &#124;0âŸ© . ](img/file1244.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 'The kernel function then coincides with applying measurements on the prepared
    quantum states:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ &#124;âŸ¨ âŸ©&#124; k(xi,xj) â†’ &#124;Ïˆ (xj)&#124;Ïˆ(xi) &#124;2 , ](img/file1245.jpg)
    |  |'
  prefs: []
  type: TYPE_TB
- en: and allows for more expressive models in comparison with the alternative
  prefs: []
  type: TYPE_NORMAL
- en: '| ![k (xi,xj) = Ï•(xi)âŠ¤ Ï•(xj) â†’ âŸ¨Ïˆ(xj)&#124;Ïˆ (xi)âŸ©. ](img/file1246.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: Huang *et al.*Â Â [[143](Biblography.xhtml#XHuang2021)] argued that even though
    the kernel functionÂ ([13.1.2](#x1-2390002)) seems to be more natural, the quantum
    kernelÂ ([13.1.2](#x1-2390002)) can learn arbitrarily deep quantum neural networks
    (deep PQC). This is a strong result, especially in combination with the hierarchy
    of expressive power of parameterised quantum circuits (ChapterÂ [12](Chapter_12.xhtml#x1-22500012),
    EquationÂ ([10](Chapter_12.xhtml#x1-233002r10))).
  prefs: []
  type: TYPE_NORMAL
- en: 'HavlÃ­Äek *et al.*Â Â [[129](Biblography.xhtml#XHavlicek2019)] described how a
    quantum computer can be used to estimate the kernel. The kernel entries are the
    *fidelities* between different feature vectors (analogous to similarity scores
    in classical kernel methods). Burnham, Cleve, Watrous, and R. de WolfÂ Â [[50](Biblography.xhtml#XBurnham2001)]
    and Cincio, SubaÅŸi, Sornborger, and ColesÂ Â [[66](Biblography.xhtml#XCincio2018)]
    investigated various fidelity estimation methods such as quantum fingerprinting
    and machine learning approach (both relying on the application of a CSWAP gate
    implementing the swap test). However, by using the fact that the states in the
    feature space are not arbitrary, the overlap between the quantum states can be
    estimated from the transition probability:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![&#124;âŸ¨ j iâŸ©&#124;2 â€  j i 2 &#124; Ïˆ(x )&#124;Ïˆ(x )&#124; = &#124;âŸ¨0 &#124;ğ’°
    (x )ğ’° (x ) &#124;0âŸ©&#124;, ](img/file1247.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: where, for brevity, we used the notation ![|0 âŸ©](img/file1248.jpg) := ![|0âŸ©](img/file1249.jpg)^(âŠ—n).
    The first step is the application of a composition of two consecutive feature
    map circuits (representing the operators ğ’°(x^i) and ğ’°^â€ (x^j)) to the initial stateÂ ![|0âŸ©](img/file1250.jpg).
    The second step is the measurement of the final state in the computational basisÂ *K*
    times and counting the numberÂ *Îº* of all-zero stringsÂ ![|0âŸ©](img/file1251.jpg).
    The frequency *Îºâˆ•K* of the all-zero string is the estimate of the transition probability
    (the "similarity score").
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the supervising learning protocol is classical, allowing for the
    natural embedding of quantumly computed kernels into the overall framework: the
    algorithm remains essentially classical with only the classically hard task outsourced
    to the quantum chip.'
  prefs: []
  type: TYPE_NORMAL
- en: 13.1.3 Quantum circuits for the feature maps
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: FigureÂ [13.1](#13.1) displays a schematic representation of the feature map
    circuit. In this example, we work with an 8-dimensional dataset with features
    encoded in the rotation angles such that there is a direct mapping of a sample
    x^i := (*x*[1]^i*,â€¦,x*[8]^i) into the vector of adjustable circuit parameters
    ğœƒ^i := (*ğœƒ*[1]^i*,â€¦,ğœƒ*[8]^i). The first section of the circuit implements the
    operatorÂ ğ’°(x^i), creating an entangled state due to the layer of fixed two-qubit
    CZ gates, whereas the second section of the circuit implements ğ’°^â€ (x^j). Here
    we use the fact that
  prefs: []
  type: TYPE_NORMAL
- en: '![Râ€ X(ğœƒ) = RX(âˆ’ ğœƒ), Râ€ Y(ğœƒ) = RY(âˆ’ ğœƒ), CZâ€  = CZ. ](img/file1252.jpg)'
  prefs: []
  type: TYPE_IMG
- en: It is easy to see that if the samplesÂ x^i andÂ x^j are identical (so that ğœƒ^i
    = ğœƒ^j), then ğ’°(x^i)ğ’°^â€ (x^j) = â„ and allÂ *K* measurements will return the all-zero
    string ![|0 âŸ©](img/file1253.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: '![FigureÂ 13.1: Schematic quantum kernel circuit. ](img/file1254.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'FigureÂ 13.1: Schematic quantum kernel circuit.'
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the protocol is classical â€“ the quantum computer is used to assist
    the classifier with the calculation of a kernel function that would not be feasible
    if only classical computational resources were available.
  prefs: []
  type: TYPE_NORMAL
- en: Let us now apply the quantum kernel method to the Australian Credit Approval
    dataset (introduced in ChapterÂ [8](Chapter_8.xhtml#x1-1620008)) in order to estimate
    the degree of similarity between samples drawn from the same class and samples
    drawn from two different classes. The ACA dataset consists ofÂ 690 samples, withÂ 383
    samples labelled as ClassÂ 0 andÂ 307 samples labelled as ClassÂ 1, so the dataset
    is reasonably well balanced. Each sample consists ofÂ 14 features (continuous,
    integer, binary). In ChapterÂ [8](Chapter_8.xhtml#x1-1620008) we built a QNN classifier
    and tested its performance on the ACA dataset, employing the *angle encoding*
    scheme as explained in SectionÂ [7.2](Chapter_7.xhtml#x1-1520002). We would like
    to build a feature map that is consistent with the angle encoding scheme and does
    not require the construction of a too deep PQC. In fact, we would like to build
    a feature map using the PQC that is as close as possible to the one shown in FigureÂ [13.1](#13.1).
    The proposed scheme can be embedded into all existing NISQ systems we considered
    earlier in this book. For example, we can use IBMâ€™s Melbourne system shown in
    FigureÂ [13.2](#13.2).
  prefs: []
  type: TYPE_NORMAL
- en: '![FigureÂ 13.2: Embedding of the quantum kernel circuit into IBMâ€™s Melbourne
    system. ](img/file1255.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'FigureÂ 13.2: Embedding of the quantum kernel circuit into IBMâ€™s Melbourne system.'
  prefs: []
  type: TYPE_NORMAL
- en: We know that 7 quantum registers (shown as shaded qubits connected by the thick
    lines in FigureÂ [13.2](#13.2)) can encode a 14-feature data sample if we follow
    the angle encoding scheme. The corresponding circuit is shown in FigureÂ [13.3](#13.3).
    The linear sequential connectivity between the physical qubits makes the choice
    of the 2-qubit gates straightforward (and, in fact, similar to the one in FigureÂ [13.1](#13.1)).
  prefs: []
  type: TYPE_NORMAL
- en: '![FigureÂ 13.3: Quantum kernel circuit for the ACA dataset. ](img/file1256.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'FigureÂ 13.3: Quantum kernel circuit for the ACA dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: In the circuit shown in FigureÂ [13.3](#13.3), the anglesÂ ğœƒ^i andÂ ğœƒ^j encode
    the data samplesÂ x^i andÂ x^j, which can be drawn either from the same class or
    from two different classes. Running the circuitÂ *K* times and calculating the
    numberÂ *Îº* of all-zero bitstrings (after measurement) gives us the measure of
    similarity between samplesÂ x^i andÂ x^j (estimated as the ratio *Îºâˆ•K*). FigureÂ [13.4](#13.4)
    displays the mean values of the transition probabilities (similarity scores) obtained
    using the quantum kernelÂ ([13.1.2](#x1-2390002)) by running the quantum circuit
    on the Qiskit simulator *K* = 10*,*000 times for each pair of data samples. The
    mean values were calculated across all possible pairs of samples from the corresponding
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![FigureÂ 13.4: Mean values of the quantum kernelÂ (13.1.2) for the ACA dataset.
    ](img/file1257.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'FigureÂ 13.4: Mean values of the quantum kernelÂ ([13.1.2](#x1-2390002)) for
    the ACA dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: As expected, samples drawn from the same class have, on average, significantly
    larger similarity scores given by the quantum kernel compared with samples drawn
    from two different classes.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum kernels that can be efficiently calculated on quantum computers have
    the potential to improve the performance of hybrid quantum-classical machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 13.2 Quantum Generative Adversarial Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Generative Adversarial Networks (GANs) are powerful statistical techniques
    to generate (as much as needed) data close enough (in some sense) to given samples.
    They were introduced inÂ Â [[114](Biblography.xhtml#XGoodfellow2014)] and originally
    tested on image data. Since then, they have seen wide applications in finance,
    for time series generationÂ Â [[301](Biblography.xhtml#Xwiese2021multi),Â [302](Biblography.xhtml#Xwiese2020quant)],
    tuning of trading modelsÂ Â [[176](Biblography.xhtml#Xkoshiyama2021generative)],
    portfolio managementÂ Â [[196](Biblography.xhtml#Xlu2022autoencoding)], synthetic
    data generationÂ Â [[17](Biblography.xhtml#Xassefa2020generating)], and diverse
    types of fraud detectionÂ Â [[261](Biblography.xhtml#Xsethia2018data)]. The gist
    of it is to have a generator and a discriminator compete against each other in
    order to improve themselves: the generator improves by becoming better at generating
    good samples (i.e., close to real data) from random noise, whereas the discriminator
    improves by being able to recognise real data from "fake" (namely generated) data.
    Both the generator and the discriminator are usually built as neural networks
    with hyperparameters over which to optimise. Mathematically, given a generatorÂ (â‹…*,*ğœƒ^()
    and a discriminatorÂ (â‹…*,*ğœƒ^(), whereÂ ğœƒ ^(andÂ ğœƒ ^(represent the hyperparameters,
    the problem reads as follows:))))'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ { } min max ğ”¼xâˆ¼â„™data [log ((x;ğœƒ )]+ ğ”¼zâˆ¼â„™ ) [log (1âˆ’ ((z;ğœƒ);ğœƒ ))] , ğœƒ ğœƒ
    (â‹…,ğœƒ ](img/file1258.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: where x âˆ¼â„™[data] means some sampleÂ x generated from the original dataset, whereas
    z âˆ¼â„™ [refers to sample generated from the generatorÂ . We refer the interested
    reader toÂ Â [[95](Biblography.xhtml#Xeckerli2021generative)] for an overview of
    the advantages and the pitfalls of GANs in finance. Given this popularity and
    the existence of quantum neural networks (ChapterÂ [8](Chapter_8.xhtml#x1-1620008)),
    it is thus natural to explore the question of whether GANs can be extended to
    the quantum world, and whether there is any advantage in doing so.]
  prefs: []
  type: TYPE_NORMAL
- en: 'The main principles of Quantum Generative Adversarial Network (QGAN) â€“ introduced
    simultaneously by Lloyd and WeedbrookÂ Â [[192](Biblography.xhtml#Xlloyd2018quantum)]
    and by Dallaire-Demers and KilloranÂ Â [[77](Biblography.xhtml#Xdallaire2018quantum)]
    â€“ remain the same, relying on two actors, a generator and a discriminator, competing
    against each other. InÂ Â [[192](Biblography.xhtml#Xlloyd2018quantum)], the authors
    translated the classical problem in the language of density matrices (described
    in SectionÂ [1.3.1](Chapter_1.xhtml#x1-420001)): Given some data represented by
    a density matrixÂ *Ïƒ* (not necessarily describing a pure state) and a generatorÂ 
    generating some output density matrixÂ *Ï*, the discriminator is tasked with identifying
    the true data from the fake one. More precisely, it makes a positive operator-valued
    measurement (SectionÂ [1.2.3](Chapter_1.xhtml#x1-380003)) with outcomesÂ T (for
    True) orÂ  (for False). The probability that the measurement yields a positive
    answer given the true data is'
  prefs: []
  type: TYPE_NORMAL
- en: '![â„™(T |Ïƒ ) = (TÏƒ ), ](img/file1259.jpg)'
  prefs: []
  type: TYPE_IMG
- en: while the probability that it yields a positive answer given generated data
    is
  prefs: []
  type: TYPE_NORMAL
- en: '![â„™(T|) = (T Ï). ](img/file1260.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The adversarial game, similarly to the classical case, therefore reads
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ { } min max (T Ï)âˆ’ (TÏƒ ) . T ](img/file1261.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: Note that both the set of positive measurement operatorsÂ T (with 1-norm less
    than one) and the set of density matricesÂ *Ï* are convex, ensuring that the optimisation
    problemÂ ([13.2](#x1-2410002)) admits at least one optimum. However, these two
    sets are infinite dimensional, making the optimisation problem hard to solve.
    Following similar arguments, Dallaire-Demers and KilloranÂ Â [[77](Biblography.xhtml#Xdallaire2018quantum)]
    further proposed to model both the generator and the discriminator as variational
    quantum circuits parameterised by some vector of parameters describing, for example,
    the rotation angles of all the gates. A natural question then is whether some
    optimal architecture of variational quantum circuit might exist. While there is
    no clear answer at this stage â€“ as far as we know â€“ recent developments have improved
    our understanding and the power of such circuits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting fromÂ *n* qubits, a quantum generatorÂ : â„‚^(2^n) â†’â„‚^(2^n) takes the
    form of a multi-layer quantum neural network, for example of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âˆ1 := Ul(ğœƒl). l=L ](img/file1262.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 'For each layer *l* âˆˆ{1*,â€¦,L*}, the unitary gateÂ U[l](ğœƒ[l]) acts on allÂ *n*
    qubits at the same time, and depends on a vector of parameters (or hyperparameters)Â ğœƒ[l].
    In order to avoid (too expensive) high-order qubit gates, entanglement takes the
    form of pairwise controlled unitary gates, and we therefore assume that, for each
    *l* âˆˆ{1*,â€¦,L*}, U[l] is composed of one- or two-qubit gates only. One possible
    (though not the only one) way to parameteriseÂ U[l] is with the following principles
    in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: any one-qubit unitary gate can be decomposed into a sequence of three rotation
    gates R[Z], R[X] and R[Y], as proved inÂ Â [[223](Biblography.xhtml#XNielsen2010),Â Theorem
    4.1];
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: followingÂ Â [[256](Biblography.xhtml#Xschuld2020circuit)], *imprimitive* two-qubit
    gates (i.e., two-qubit gates that map product states to non-product states), together
    with one-qubit gates ensure quantum universalityÂ Â [[47](Biblography.xhtml#Xbrylinski2002universal)].
    In particular the decomposition R[X](*ğœƒ*)Q(*Ï•*) is universalÂ Â [[47](Biblography.xhtml#Xbrylinski2002universal),Â CorollaryÂ 9.2],
    for *ğœƒ,Ï•* âˆˆ [0*,*2*Ï€*), where
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![ âŒŠ âŒ‹ | 1 0 0 0 | || 0 1 0 0 || Q(Ï•) := | | . |âŒˆ 0 0 1 0 |âŒ‰ 0 0 0 eiÏ• ](img/file1263.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: The general form of the *L*-layer neural network is thereforeÂ ([13.2](#x1-2410002)),
    where each layer gateÂ U[l](ğœƒ[l]) takes the form
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ {âŠ—n } Ul(ğœƒl) = RX(ğœƒie)Q1+(i mod n)(ğœƒiimp) i=1 {( n ) ( n ) ( n ) } âŠ— R
    (ğœƒi ) âŠ— R (ğœƒi ) âŠ— R (ğœƒi ) , i=1 Z Z,l i=1 X X,l i=1 Y Y,l ](img/file1264.jpg)
    |  |'
  prefs: []
  type: TYPE_TB
- en: whereÂ Q^i means that qubitÂ *i* is the control qubit and the gate acts on qubitÂ (*i*
    + 1). Note that 1 + (*iÂ *mod*Â n*) = 1 + *i* when *i* âˆˆ{1*,â€¦,n*âˆ’ 1} and is equal
    toÂ 1 when *i* = *n*. The total number of hyperparameters is thereforeÂ 5*n* per
    layer, thusÂ 5*nL* in total. The discriminator itself may or may not be of quantum
    nature (following a construction similar to the generator), depending on the problem
    at hand (it is inÂ Â [[18](Biblography.xhtml#Xassouel2021quantum)] but not inÂ Â [[268](Biblography.xhtml#Xsitu2020quantum)]
    for example), and the nature of the problem â€“ in particular the potential need
    to encode/decode data from quantum to classical (with a high cost) may influence
    this choice.
  prefs: []
  type: TYPE_NORMAL
- en: The finite-dimensional optimisationÂ ([13.2](#x1-2410002)) is usually carried
    out via some gradient descent method; the gradients themselves are computed via
    separate quantum circuits inÂ Â [[77](Biblography.xhtml#Xdallaire2018quantum)],
    or rather â€“ more efficiently â€“ using the parameter-shift rule, explained in SectionÂ [8.2.3](Chapter_8.xhtml#x1-1670003)
    (see alsoÂ Â [[257](Biblography.xhtml#XSchuld2018)]), which allows for an exact
    computation of the gradient from the original circuit.
  prefs: []
  type: TYPE_NORMAL
- en: 'QGANs are a very new and active research area, and promise to be one where
    NISQ-based algorithms will be particularly fruitful. They are intimately linked
    with developments of QNNs as a whole, and current advances in the field relate
    to the following, which we encourage the reader to follow closely over the next
    few years:'
  prefs: []
  type: TYPE_NORMAL
- en: 'QGAN to generate probability distributions: we refer the interested reader
    toÂ Â [[18](Biblography.xhtml#Xassouel2021quantum),Â [268](Biblography.xhtml#Xsitu2020quantum),Â [314](Biblography.xhtml#XZoufal2019)]
    for univariate distributions, mostly in the context of finance, and toÂ Â [[5](Biblography.xhtml#Xagliardi2022optimal),Â [312](Biblography.xhtml#Xzhu2021generative)]
    for multivariate distributions;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Quantum Convolutional Neural Networks: InÂ Â [[160](Biblography.xhtml#Xkerenidis2019quantum)],
    the authors show how to handle non-linearities in (quantum) deep neural networks;
    Â [[69](Biblography.xhtml#Xcong2019quantum), Â [300](Biblography.xhtml#Xwei2022quantum)]
    explain how reduce the number of required gates (equivalently, the number of rotation
    parameters) in the circuit, andÂ Â [[142](Biblography.xhtml#Xhur2022quantum)] highlights
    the importance and sufficiency of two-qubit interactions, more amenable to NISQ
    devices;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Quantum Wasserstein GAN: InÂ Â [[55](Biblography.xhtml#Xchakrabarti2019quantum)]
    â€“ mimicking recent results in classical Wasserstein GANsÂ Â [[13](Biblography.xhtml#Xarjovsky2017wasserstein),Â [121](Biblography.xhtml#Xgulrajani2017improved)]
    â€“ the authors introduced a Wasserstein semimetric between quantum data, which
    they use to reduce the number of required quantum gates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 13.3 Bayesian Quantum Circuit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Parameterised quantum circuits can be used to construct a quantum state with
    desired properties and to modify it in a controlled way. Measuring the final state
    is then equivalent to drawing a sample from a probability distribution in a form
    of a bitstring. This is the key concept behind the Quantum Circuit Born Machine
    (QCBM) we considered in ChapterÂ [9](Chapter_9.xhtml#x1-1850009). The Bayesian
    Quantum Circuit (BQC) is another quantum generative machine learning model that
    extends the capabilities of QCBMÂ Â [[88](Biblography.xhtml#XDu2018)]. Unlike QCBM
    that operates only on *data* qubits encoding the desired probability distribution,
    BQC has additional *ancillary* qubits encoding the *prior* distribution. The BQC
    circuit is shown in FigureÂ [13.5](#13.5).
  prefs: []
  type: TYPE_NORMAL
- en: '![FigureÂ 13.5: Schematic representation of BQC. ](img/file1265.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'FigureÂ 13.5: Schematic representation of BQC.'
  prefs: []
  type: TYPE_NORMAL
- en: The first *m* quantum registers in the circuit are ancillary qubits. After applying
    *K* operator blocks U(*Î³*^i)[i=1,â€¦,K], to the initial state ![|0âŸ©](img/file1266.jpg)^(âŠ—m),
    we construct the state ![|Ïˆ âŸ©](img/file1267.jpg),
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ K &#124;ÏˆâŸ© = âˆ U(Î³i) &#124;0âŸ©âŠ—m , i=1 ](img/file1268.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: and measuring it generates a sample from the prior distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The next *n* quantum registers are data qubits. Quantum gates operating on them
    are conditional on the states of the ancillary qubits. Conditionally applying
    *l* Ã— *m* operator blocks to *n* data qubits, we obtain a state that is conditional
    onÂ ![|Ïˆ âŸ©](img/file1269.jpg). Measuring it will generate a sample from the conditional
    distribution, which is exactly what is needed to realise a Bayesian model. Bayesian
    modelling allows us to infer a *posterior* distribution over the parametersÂ ğœƒ
    of the model given some observed data *D* using Bayesâ€™ theoremÂ Â [[57](Biblography.xhtml#XChang2021)],
  prefs: []
  type: TYPE_NORMAL
- en: '| ![â„™(ğœƒ&#124;D) = â„™-(D-&#124;ğœƒ)â„™(ğœƒ) = âˆ«-â„™(D-&#124;ğœƒ-)â„™-(ğœƒ)--, â„™(D ) â„™(D &#124;ğœƒ)â„™(ğœƒ)dğœƒ
    ](img/file1270.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: where â„™(*D*|ğœƒ) is the likelihood, â„™(*D*) is the marginal likelihood or evidence,
    and â„™(ğœƒ) is the prior. We obtain â„™(ğœƒ) by repeatedly measuring the stateÂ ![|ÏˆâŸ©](img/file1271.jpg)
    given byÂ ([13.3](#x1-242002r3)), â„™(*D*|ğœƒ) by repeatedly measuring the final state
    after applying the conditional operators U(*Î²*), and â„™(*D*) by repeatedly measuring
    the final state after applying the operators U(*Î²*) unconditionally.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of BQC, the prior is parameterised by the parameters Î³ := (*Î³*Â¹*,â€¦,Î³*^K).
    The posterior can be used to model new unseen data, *D*^âˆ—, using the *posterior*
    *predictive*Â Â [[105](Biblography.xhtml#XFortuin2021)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âˆ« â„™(D âˆ—&#124;D) = â„™ (D âˆ—&#124;ğœƒ)â„™(ğœƒ&#124;D)dğœƒ. ](img/file1272.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: This integral averages predictions of all plausible models weighted by posterior
    probability and is called the *Bayesian model average*.
  prefs: []
  type: TYPE_NORMAL
- en: The BQC can be trained by minimising the maximum mean discrepancy cost function
    described in ChapterÂ [9](Chapter_9.xhtml#x1-1850009). In terms of expressive power,
    Du, Hsieh, Liu, and TaoÂ Â [[88](Biblography.xhtml#XDu2018)] showed that a better
    expressive power of BQC is obtained in comparison with MPQC from a computational
    complexity perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian networks can be used for financial asset price forecastingÂ Â [[21](Biblography.xhtml#XBack2019),Â [56](Biblography.xhtml#XChandra2021)],
    predicting dynamics of limit order book marketÂ Â [[199](Biblography.xhtml#XMagris2022)],
    predicting corporate bankruptcyÂ Â [[52](Biblography.xhtml#XCao2022)], and to model,
    analyse, and understand trading behaviourÂ Â [[282](Biblography.xhtml#XTicknor2013)].
  prefs: []
  type: TYPE_NORMAL
- en: The Bayesian Quantum Circuit model extends the capabilities of parameterised
    quantum circuits trained as generative models (QCBM) through the addition of ancillary
    quantum registers encoding the prior distribution. As a result, it achieves greater
    expressive power than MPQC.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4 Quantum Semidefinite Programming
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Semidefinite Programming (SDP), one optimises a linear function subject to
    the constraint that an affine combination of symmetric matrices is positive semidefinite.
    Such a constraint is non-linear and non-smooth, but convex, so semidefinite programs
    are convex optimisation problems. Semidefinite programming unifies several standard
    problems (e.g., linear and quadratic programming) and finds many applications
    in engineering and combinatorial optimisationÂ Â [[292](Biblography.xhtml#XVandenberghe1996)].
    Similarly to finding a quantum counterpart to the classical kernel method, we
    can specify a quantum version of the SDP.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.1 Classical semidefinite programming
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The SDP can be generally defined as the following optimisation problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ max Tr(CX ), subject to Tr(AjX ) â‰¤ bj, for all j âˆˆ [[M ]], Xâˆˆâ„³+N(â„) ](img/file1273.jpg)
    |  |'
  prefs: []
  type: TYPE_TB
- en: where [[*M*]] := {1*,â€¦,M*}, â„³[n]^+(â„) denotes the set of positive semidefinite
    matrices of size *N* Ã—*N*. Here, Hermitian matrices (A[j])[j=1,â€¦,M] andÂ C in â„³[N](â„),
    and (*b*[j])[jâˆˆ[[M]]] âˆˆâ„^M are the inputs of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: SDP can be applied to complex NP-hard optimisation problemsÂ Â [[112](Biblography.xhtml#XGoemans1997)],
    such as various portfolio optimisation problems. For example, it is typically
    an unrealistic assumption that the distribution of asset returns is known exactly.
    The necessary information may not be complete and estimates are subject to estimation
    errors as well as modelling errors (e.g., an assumption of stationarity of the
    distributions).
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.2 Maximum risk analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The classical maximum risk analysis problem, assuming there is uncertainty in
    the estimate of the covariance matrix of asset returns, Î£, can be formulated as
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âŠ¤ L U Î£âˆˆmâ„³a+x(â„)w Î£w, subject to Î£ij â‰¤ Î£ij â‰¤ Î£ ij, for all i,j âˆˆ [[N ]],
    N ](img/file1274.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 'where w is the fixed vector of weights and Î£ is the problem variable. For each
    *i,j* âˆˆ [[*N*]], the matrices Î£[ij]^L and Î£[ij]^U are fixed constraints in â„³[N]^+(â„).
    The task is to establish the maximum possible portfolio risk for the known asset
    allocation, given uncertainty in the estimate of covariance matrix of asset returns.
    The problem can be expressed as the following SDPÂ Â [[229](Biblography.xhtml#XPaini2018)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ max Tr(w âŠ¤Î£w ) , Î£âˆˆâ„³+N(â„) ({ L subject to Tr(âˆ’ EijÎ£) â‰¤ âˆ’ Î£ ij, for all
    (i,j) âˆˆ [[N ]]Ã— [[N ]], ( Tr(EijÎ£ ) â‰¤ Î£U , ij ](img/file1275.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: where we denote (*E*[ij])[Î±Î²] := *Î´*[iÎ±]*Î´*[jÎ²]. The maximum risk analysis problem
    can be expressed in the same form with different risk measures such as VaR or
    Expected Shortfall.
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.3 Robust portfolio construction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The robust portfolio construction problem aims at finding an asset allocation
    method that would achieve the minimum *estimation error* in the suggested asset
    allocation weights. This problem has been addressed inÂ Â [[194](Biblography.xhtml#XMLDP2019)]
    using Monte Carlo simulations to determine the most robust asset allocation method
    with respect to small changes in the input covariance matrix for the given portfolio.
  prefs: []
  type: TYPE_NORMAL
- en: In the most general case, it can be formulated as the Min-Max problem
  prefs: []
  type: TYPE_NORMAL
- en: '| ![min max w âŠ¤Î£w, wâˆˆğ’² Î£âˆˆğ’® ](img/file1276.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: with
  prefs: []
  type: TYPE_NORMAL
- en: '| ğ’® | := ![{](img/file1277.jpg)Î£ âˆˆâ„³[N]^+(â„) : Î£ [ij]^L â‰¤ Î£ [ij] â‰¤ Î£[ij]^U*,*
    for all *i,j* âˆˆ [[*N*]]![}](img/file1278.jpg)*,* |'
  prefs: []
  type: TYPE_TB
- en: '| ğ’² | := ![{ N âŠ¤ âŠ¤ } w âˆˆ â„ : 1 w = 1, Î¼ w â‰¥ Rmin](img/file1279.jpg)*,* |'
  prefs: []
  type: TYPE_TB
- en: where w is the vector of weights, *Î¼* is the vector of expected asset returns,
    and Î£ is the covariance matrix of asset returns.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following theorem (first proven by von NeumannÂ Â [[297](Biblography.xhtml#XvonNeumann28)]
    in 1928) establishes the equivalence of the Min-Max and Max-Min optimisation problemsÂ Â [[288](Biblography.xhtml#XTuy2004)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Theorem 11** (Minimax Theorem)**.** *Let* ğ’³ âŠ‚â„^n *and* ğ’´ âŠ‚â„^m *be compact*
    *convex sets. If the function* *f* : ğ’³ Ã—ğ’´ â†’â„ *is continuous and concave inÂ **x*
    *for fixedÂ **y* *and continuous and convex inÂ **y* *for fixedÂ **x**, then*'
  prefs: []
  type: TYPE_NORMAL
- en: '![min max f (x, y) = max minf (x, y). yâˆˆğ’´ xâˆˆğ’³ xâˆˆ ğ’³ yâˆˆğ’´ ](img/file1280.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, in general, the Min-Max robust portfolio construction problem (which
    is convex in w and concave in Î£) is equivalent to the Max-Min problem and can
    be expressed for the constraints above as an SDP in all variablesÂ Â [[229](Biblography.xhtml#XPaini2018)].
  prefs: []
  type: TYPE_NORMAL
- en: 13.4.4 Quantum semidefinite programming
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The key idea behind Quantum Semidefinite Programming (QSDP) is based on the
    observation that a normalised positive semidefinite matrix can be naturally represented
    as a quantum state. Operations on quantum states can sometimes be computationally
    cheaper to perform on a quantum computer than classical matrix operations. This
    idea prompted the development of quantum algorithms for SDPsÂ Â [[42](Biblography.xhtml#XBrandao2016)].
  prefs: []
  type: TYPE_NORMAL
- en: Consider the SDPÂ ([13.4.1](#x1-2440001)) and let *ğœ€ >* 0 be small. An algorithm
    is called an *ğœ€*-*approximate quantum SDP oracle*Â Â [[290](Biblography.xhtml#XJvA2018)]
    if for all inputs *g* âˆˆâ„ and *Î¶* âˆˆ (0*,*1), it finds, with success probability
    1 âˆ’*Î¶*, a vector y âˆˆâ„^(M+1) and a real numberÂ *z* such that for the density matrix
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ ( ) âˆ‘M Ï = ---e(xp--âˆ’(---j=1yjAj-+-y0C--)), Tr exp âˆ’ âˆ‘M y A + y C j=1
    j j 0 ](img/file1281.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: we have that *zÏ* is an *ğœ€*-feasible solution with objective value at least
    *g* âˆ’ *ğœ€*, that is
  prefs: []
  type: TYPE_NORMAL
- en: '| ![( { Tr(z ÏAj) â‰¤ bj + ğœ€, for all j âˆˆ [[M ]], ( Tr(z ÏC) â‰¥ g âˆ’ ğœ€, ](img/file1282.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: or concludes that no such *z* and y exist even if we set *ğœ€* = 0.
  prefs: []
  type: TYPE_NORMAL
- en: A general QSDP-solver for sparse matrices was implemented by BrandÃ£o and SvoreÂ Â [[42](Biblography.xhtml#XBrandao2016)]
    using the Arora-Kale frameworkÂ Â [[14](Biblography.xhtml#XArora2016)]. They observed
    that the density matrixÂ *Ï* inÂ ([13.4.4](#x1-2470004)) is in fact a log(*N*)-qubit
    Gibbs state and can be efficiently prepared as a quantum state on a quantum computer.
  prefs: []
  type: TYPE_NORMAL
- en: The reader should already be familiar with the Gibbs state (Gibbs distribution)
    in the form
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âˆ’ Î²â„‹ Ï = -e------, Tr(eâˆ’ Î²â„‹) ](img/file1283.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: whereÂ â„‹ is the problem Hamiltonian and Tr(exp(âˆ’*Î²*â„‹)) is the partition function.
    The Gibbs (Boltzmann) sampling and the Gibbs (Boltzmann) distribution were discussed
    in ChapterÂ [5](Chapter_5.xhtml#x1-960005) (inÂ ([5.4.1](Chapter_5.xhtml#x1-1090001))
    andÂ ([5.4.1](Chapter_5.xhtml#x1-1090001))). The form of the partition function
    inÂ ([13.4.4](#x1-2470004)) should not be confusing. Recall fromÂ ([10.1](Chapter_10.xhtml#x1-2030001)),
    that since the Hamiltonian is a Hermitian operator, its spectral decomposition
    yields the representation
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âˆ‘ â„‹ = Ei &#124;ÏˆiâŸ©âŸ¨Ïˆi&#124;, i ](img/file1284.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 'which gives the following expression for the Gibbs state:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ eâˆ’Î²â„‹ 1 âˆ‘ Ï = -----= -- eâˆ’Î²Ei &#124;ÏˆiâŸ©âŸ¨Ïˆi&#124;, Z Z i ](img/file1285.jpg)
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the partition functionÂ *Z* is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( ) âˆ‘ Z = Tr eâˆ’ Î²â„‹ = eâˆ’ Î²Ei. i ](img/file1286.jpg)'
  prefs: []
  type: TYPE_IMG
- en: QSDP gives a square-root unconditional speedup over any classical method for
    solving SDPs both inÂ *N* andÂ *M*Â Â [[42](Biblography.xhtml#XBrandao2016)].
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Semidefinite Programming is yet another example where quantum speedup
    can be achieved since operations on quantum states performed on a quantum computer
    are less computationally expensive than the corresponding matrix operations on
    a classical computer.
  prefs: []
  type: TYPE_NORMAL
- en: We would like to finish this chapter (and the book!) with a glance beyond the
    capabilities of the NISQ computers. The last section presents several important
    algorithms which, one day, will become the main building blocks of many quantum
    computing applications.
  prefs: []
  type: TYPE_NORMAL
- en: 13.5 Beyond NISQ
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we start with describing the workhorse of many important quantum
    algorithms, the Quantum Fourier Transform (QFT), before moving to its flagship
    application, the Quantum Phase Estimation (QPE), and then discussing the possibility
    of achieving quantum speedup with the Quantum Monte Carlo (QMC) and the Quantum
    Linear Solver (QLS) algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 13.5.1 Quantum Fourier Transform
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the classical setting, the discrete Fourier transform maps a vector x :=
    (*x*[0]*,â€¦,x*[2^nâˆ’1]) âˆˆâ„‚^(2^n) to a vector y := (*y*[0]*,â€¦,y*[2^nâˆ’1]) âˆˆâ„‚^(2^n)
    , the components of which read
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ n 1 2âˆ‘âˆ’1 ( 2Ï€ijk) n yk = âˆš-n- exp -2n--- xj, for each k = 0,...,2 âˆ’ 1\.
    2 j=0 ](img/file1287.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: Similarly, the quantum Fourier transform is the linear map
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ 1 2âˆ‘nâˆ’1 ( 2Ï€ikj ) &#124;kâŸ© â†¦âˆ’ â†’ âˆš-n- exp --n--- &#124;jâŸ© , 2 j=0 2 ](img/file1288.jpg)
    |  |'
  prefs: []
  type: TYPE_TB
- en: and the operator
  prefs: []
  type: TYPE_NORMAL
- en: '![ 2nâˆ’1 ( ) â„± := âˆš1---âˆ‘ exp 2Ï€ikj- |jâŸ©âŸ¨k| q 2n 2n k,j=0 ](img/file1289.jpg)'
  prefs: []
  type: TYPE_IMG
- en: represents the Fourier transform matrix which is unitary as qâ„±qâ„±^â€  = â„. In an
    *n*-qubit system with basis (![|0âŸ©](img/file1290.jpg)*,â€¦,*![|2n âˆ’ 1âŸ©](img/file1291.jpg)),
    for a given stateÂ ![|jâŸ©](img/file1292.jpg), we use the binary representation
  prefs: []
  type: TYPE_NORMAL
- en: '| ![j := j-â‹…â‹…â‹…j-, 1 n ](img/file1293.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: with (*j*[1]*,â€¦,j*[n]) âˆˆ{0*,*1}^n so that ![|jâŸ©](img/file1294.jpg) = ![|j1â‹…â‹…â‹…jnâŸ©](img/file1295.jpg)
    = ![|j1âŸ©](img/file1296.jpg)âŠ—*â€¦*âŠ—![|jnâŸ©](img/file1297.jpg). Likewise, the notation
    0*.j*[1]*j*[2]*â€¦j*[n] represents the binary fraction âˆ‘ [i=1]^n2^(âˆ’i)*j*[i]. Elementary
    algebra (seeÂ Â [[223](Biblography.xhtml#XNielsen2010),Â SectionÂ 5.1] for details)
    then yields
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ --1- ( 2Ï€i0.jn ) ( 2Ï€i0.jnâˆ’1jn ) qâ„± &#124;jâŸ© = âˆš2n- &#124;0âŸ©+ e &#124;1âŸ©
    âŠ— &#124;0 âŸ©+ e &#124;1âŸ© âŠ— â‹…â‹…â‹… ( ------ ) â‹…â‹…â‹…âŠ— &#124;0âŸ© + e2Ï€i0.j1...jn &#124;1âŸ©
    . ](img/file1298.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 13.5.2 Quantum Phase Estimation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The goal of QPE is to estimate the unknown phase *Ï†* âˆˆ [0*,*1) for a given unitary
    operatorÂ ğ’° with an eigenvectorÂ ![|uâŸ©](img/file1299.jpg) and eigenvalue exp(2*Ï€*i*Ï†*).
    Consider a register of sizeÂ *m* and define
  prefs: []
  type: TYPE_NORMAL
- en: '![ { ---------} bâˆ— := sup j = 2m 0.j1 â‹…â‹…â‹…jm . jâ‰¤2m Ï† ](img/file1300.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Thus with *b*^âˆ— = *b*[1]![â‹…â‹…â‹…](img/file1301.jpg)*b*[m], we obtain that 2^(âˆ’m)*b*^âˆ—
    = 0*.b*[1]![â‹…â‹…â‹…](img/file1302.jpg)*b*[m] is the best *m*-bit approximation ofÂ *Ï†*
    from below. The QPE procedure uses two registers, with the first containingÂ *m*
    qubits initially in the stateÂ ![|0âŸ©](img/file1303.jpg). SelectingÂ *m* relies on
    the number of digits of accuracy for the estimate ofÂ *Ï†*, and the probability
    with which we wish to obtain a successful phase estimation procedure.
  prefs: []
  type: TYPE_NORMAL
- en: QPE allows us to implement a measurement for any Hermitian operator. Note that
    we always measure individual qubits. If we want to measure a more complex observable,
    we can use a QPE that implements the von Neumannâ€™s measurement schemeÂ Â [[212](Biblography.xhtml#XMello2013)].
    The routine prepares an eigenstate of the Hermitian operator in one register and
    stores the corresponding eigenvalue in a second register.
  prefs: []
  type: TYPE_NORMAL
- en: Up to a SWAP transformation, the quantum phase circuitÂ Â [[223](Biblography.xhtml#XNielsen2010),Â SectionÂ 5.2]
    gives the output
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ 1 ( 2Ï€i0.Ï†m ) ( 2Ï€i0.Ï†mâˆ’-1Ï†m- ) &#124;ÏˆâŸ© = âˆš-m-- &#124;0âŸ©+ e &#124;1âŸ©
    âŠ— &#124;0âŸ©+ e &#124;1âŸ© âŠ— â‹…â‹…â‹… 2 ( ------- ) â‹…â‹…â‹…âŠ— &#124;0âŸ©+ e2Ï€i0.Ï†1...Ï†m &#124;1âŸ©
    , ](img/file1304.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: which is exactly equal to the QFT for the state ![ m |2 Ï†âŸ©](img/file1305.jpg)
    = ![|Ï†1Ï†2 ...Ï†mâŸ©](img/file1306.jpg) as inÂ ([13.5.1](#x1-2490001)), and therefore
    ![|Ïˆ âŸ©](img/file1307.jpg) = qâ„±![|2m Ï†âŸ©](img/file1308.jpg). Since the QFT is a
    unitary transformation, we can inverse the process to retrieve ![ m |2 Ï†âŸ©](img/file1309.jpg).
    AlgorithmÂ [10](#x1-250008r10) below provides pseudocode for the QPE procedure,
    and we refer the interested reader toÂ Â [[223](Biblography.xhtml#XNielsen2010),Â Chapter
    5.2] for detailed explanations.
  prefs: []
  type: TYPE_NORMAL
- en: '![--------------------------------------------------------------------- -Algorithm---10:-Quantum--Phase-Estimation---------------------------
    Input: â€¢ Unitary matrix (gate) U with U |uâŸ© = e2Ï€iÏ† |uâŸ©; â€¢ m ancilla qubits initialised
    at |0 âŸ©. âŠ—m 1: Prepare the initial state with |0âŸ© being the m -qubit ancilla register
    and |uâŸ© being the n -qubit eigenstate register. 2: Map to 2mâˆ’ 1 âˆš-1-- âˆ‘ |jâŸ© |u
    âŸ© 2m j=0 with Hadamard gates applied to the ancilla register. 3: Map to 2mâˆ‘âˆ’ 1
    2mâˆ‘ âˆ’1 âˆš-1-- |jâŸ©Uj |uâŸ© = âˆš1-- |jâŸ©e2Ï€ijÏ† |u âŸ© 2m j=0 2m j=0 with Controlled Uj
    gates applied to the eigenstate register. 4: Compute |Ï†^âŸ© |uâŸ© using the inverse
    QFT, where Ï†^is an m -qubit approximation of Ï†. 5: Measure to deduceÏ†^. Result:
    Phase estimate ^Ï†. ---------------------------------------------------------------------
    ](img/file1310.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 13.5.3 Monte Carlo speedup
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Leveraging on the speedup provided by the Quantum Phase Estimation, MontanaroÂ Â [[216](Biblography.xhtml#XMontanaro_QSpeedup)]
    devised a Monte Carlo scheme providing quantum speedup compared to the classical
    one.
  prefs: []
  type: TYPE_NORMAL
- en: Classical Monte Carlo
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Monte Carlo techniques represent a wide array of methods to simulate statistics
    of random processes. We refer the interested reader to the excellent monographÂ Â [[111](Biblography.xhtml#Xglasserman2004monte)]
    for a full description and analysis. Consider a one-dimensional random variableÂ *X*
    and a function *Ï•* : â„ â†’ [0*,*1] such that both ğ”­ := ğ”¼[*Ï•*(*X*)] and *Ïƒ*Â² := ğ•[*Ï•*(*X*)]
    are well defined. By the Central Limit Theorem, given an iid collection of random
    variables (*X*[1]*,â€¦,X*[N]) distributed asÂ *X*, then'
  prefs: []
  type: TYPE_NORMAL
- en: '![âˆš --^ğ”­N-âˆ’-ğ”­- N Ïƒ ](img/file1311.jpg)'
  prefs: []
  type: TYPE_IMG
- en: converges to a centered Gaussian with unit variance ğ’©(0*,*1) asÂ *N* tends to
    infinity, where ğ”­[N] := ![1- N](img/file1312.jpg) âˆ‘ [i=1]^N*X*[i] is the empirical
    mean. This implies that, for any *ğœ€ >* 0, we can estimate
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( âˆš --) (||^ || ) ğœ€--N- â„™ ğ”­N âˆ’ ğ”­ â‰¤ ğœ€ = â„™ |ğ’© (0,1)| â‰¤ Ïƒ , ](img/file1313.jpg)'
  prefs: []
  type: TYPE_IMG
- en: so that, for any *z >* 0 and *Î´* âˆˆ (0*,*1), in order to get an estimate of the
    form â„™![(| | ) |^ğ”­N âˆ’ ğ”­| â‰¤ z](img/file1314.jpg) = 1 âˆ’ *Î´*, we need *N* = ğ’ª(1*âˆ•ğœ€*Â²)
    samples.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum Monte Carlo
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Consider now an operator ğ’œ of the form
  prefs: []
  type: TYPE_NORMAL
- en: '![ âŠ—n âˆ‘ ğ’œ |0âŸ© = Î±x |ÏˆxâŸ© |xâŸ©, xâˆˆ{0,1}k ](img/file1315.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'for some *k* â‰¤ *n*, where each ![|ÏˆxâŸ©](img/file1316.jpg) is a quantum state
    with *n*âˆ’*k* qubits andÂ ![|xâŸ©](img/file1317.jpg) a quantum state withÂ *k* qubits,
    and *Î±*[x] âˆˆâ„‚ is some amplitude, the meaning of which will be made clear below.
    We simply assume that {![|ÏˆxâŸ©](img/file1318.jpg)}[xâˆˆ{0,1}^k] forms an orthogonal
    family and are in fact "garbage qubits", i.e., qubits that are, for example, used
    as controlled to build the solution vectorÂ ![|xâŸ©](img/file1319.jpg) from the data.
    Given the encoded dataÂ ![|xâŸ©](img/file1320.jpg), assume further the existence
    of the operator ğ’²:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( âˆ˜ -------- âˆ˜ ---- ) ğ’² |xâŸ© |0âŸ© = |xâŸ© 1âˆ’ Ï• (x) |0âŸ© + Ï•(x) |1âŸ© . ](img/file1321.jpg)'
  prefs: []
  type: TYPE_IMG
- en: This can be achieved for example by using the following lemma.
  prefs: []
  type: TYPE_NORMAL
- en: '**Lemma 9** (Conditional Rotation. TheoremÂ 3.5 inÂ Â [[184](Biblography.xhtml#XLandman2021)])**.**
    *Given a quantum stateÂ *![|Ïˆa âŸ©](img/file1322.jpg)*, encoding* *a* âˆˆ [âˆ’1*,*âˆ’1]
    *inÂ **q* *qubits, there exists a* *quantum circuit performing the unitary mapping*
    ![|Ïˆ âŸ© a](img/file1323.jpg)![|0âŸ©](img/file1324.jpg)![â†¦âˆ’â†’](img/file1325.jpg)![|Ïˆ
    âŸ© a](img/file1326.jpg)![(](img/file1327.jpg)*a*![|0âŸ©](img/file1328.jpg) + ![âˆš
    ------ 1âˆ’ a2](img/file1329.jpg)![ |1âŸ©](img/file1330.jpg)![)](img/file1331.jpg)*.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider now the operator â„³:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( ) ( ) â„³ := â„nâˆ’ k âŠ— ğ’² ğ’œ âŠ— â„ , ](img/file1332.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where â„^(nâˆ’k) means the identity operator acting on *n* âˆ’ *k* qubits, so that
  prefs: []
  type: TYPE_NORMAL
- en: '| ![&#124;ÏˆâŸ©](img/file1333.jpg) | := â„³![&#124;0âŸ©](img/file1334.jpg)^(âŠ—(n+1))
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | = ![(](img/file1335.jpg)â„^(nâˆ’k) âŠ—ğ’²![)](img/file1336.jpg)![( ) âˆ‘ ( Î±x &#124;ÏˆxâŸ©
    &#124;xâŸ©) xâˆˆ{0,1}k](img/file1337.jpg)![&#124;0âŸ©](img/file1338.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '|  | = âˆ‘ [xâˆˆ{0,1}^k]*Î±*[x]![(](img/file1339.jpg)â„^(nâˆ’k) âŠ—ğ’²![)](img/file1340.jpg)![&#124;Ïˆx
    âŸ©](img/file1341.jpg)![&#124;xâŸ©](img/file1342.jpg)![&#124;0âŸ©](img/file1343.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | = âˆ‘ [xâˆˆ{0,1}^k]*Î±*[x]![&#124;ÏˆxâŸ©](img/file1344.jpg)![&#124;xâŸ©](img/file1345.jpg)![(âˆ˜
    -------- âˆ˜ ---- ) 1âˆ’ Ï•(x) &#124;0âŸ© + Ï•(x) &#124;1âŸ©](img/file1346.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '|  | =: ![&#124;Î¨B âŸ©](img/file1347.jpg)![&#124;0âŸ©](img/file1348.jpg) + ![&#124;Î¨G
    âŸ©](img/file1349.jpg)![&#124;1âŸ©](img/file1350.jpg)*,* | (13.5.1) |  |'
  prefs: []
  type: TYPE_TB
- en: whereÂ ![|Î¨ âŸ© B](img/file1351.jpg),
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âˆ‘ âˆ˜ -------- &#124;Î¨B âŸ© := Î±x 1âˆ’ Ï• (x ) &#124;ÏˆxâŸ© &#124;xâŸ©, xâˆˆ {0,1}k
    ](img/file1352.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: stands for the â€˜badâ€™ state, andÂ ![|Î¨G âŸ©](img/file1353.jpg),
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ âˆ‘ âˆ˜ ---- &#124;Î¨G âŸ© := Î±x Ï•(x) &#124;ÏˆxâŸ© &#124;xâŸ©, xâˆˆ{0,1}k ](img/file1354.jpg)
    |  |'
  prefs: []
  type: TYPE_TB
- en: stands for the â€˜goodâ€™ state.
  prefs: []
  type: TYPE_NORMAL
- en: Consider now the projector ğ’« := â„^n![|1âŸ©](img/file1355.jpg)âŸ¨1| and measure the
    probability of the last qubit ofÂ ![|ÏˆâŸ©](img/file1356.jpg) to be in stateÂ ![|1âŸ©](img/file1357.jpg),
    namely
  prefs: []
  type: TYPE_NORMAL
- en: '| âŸ¨*Ïˆ*&#124;ğ’«^â€ ğ’«![&#124;Ïˆ âŸ©](img/file1358.jpg) | = âŸ¨*Ïˆ*&#124;ğ’«![&#124;ÏˆâŸ©](img/file1359.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | = ![(](img/file1360.jpg)âŸ¨0&#124;âŸ¨Î¨[B]&#124; + âŸ¨1&#124;âŸ¨Î¨[G]&#124;![)](img/file1361.jpg)ğ’«![(](img/file1362.jpg)![&#124;Î¨
    âŸ© B](img/file1363.jpg)![&#124;0âŸ©](img/file1364.jpg) + ![&#124;Î¨ âŸ© G](img/file1365.jpg)![&#124;1âŸ©](img/file1366.jpg)![)](img/file1367.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | = ![(](img/file1368.jpg)âŸ¨0&#124;âŸ¨Î¨[B]&#124; + âŸ¨1&#124;âŸ¨Î¨[G]&#124;![)](img/file1369.jpg)![(](img/file1370.jpg)![&#124;Î¨B
    âŸ©](img/file1371.jpg)![&#124;1âŸ©](img/file1372.jpg)![ âŸ¨1&#124;0âŸ©](img/file1373.jpg)
    + ![&#124;Î¨G âŸ©](img/file1374.jpg)![&#124;1âŸ©](img/file1375.jpg)![ âŸ¨1&#124;1âŸ©](img/file1376.jpg)![)](img/file1377.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | = ![(](img/file1378.jpg)âŸ¨0&#124;âŸ¨Î¨[B]&#124; + âŸ¨1&#124;âŸ¨Î¨[G]&#124;![)](img/file1379.jpg)![&#124;Î¨G
    âŸ©](img/file1380.jpg)![ &#124;1âŸ©](img/file1381.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '|  | = âŸ¨0&#124;![âŸ¨Î¨B &#124;Î¨G âŸ©](img/file1382.jpg)![&#124;1âŸ©](img/file1383.jpg)
    + âŸ¨1&#124;![âŸ¨Î¨G &#124;Î¨G âŸ©](img/file1384.jpg)![ &#124;1âŸ©](img/file1385.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '|  | = ![âŸ¨Î¨B &#124;Î¨G âŸ©](img/file1386.jpg)![ âŸ¨0&#124;1âŸ©](img/file1387.jpg)
    + ![âŸ¨Î¨G &#124;Î¨G âŸ©](img/file1388.jpg)![ âŸ¨1&#124;1âŸ©](img/file1389.jpg) = &#124;Î¨[G]&#124;Â²*.*
    |'
  prefs: []
  type: TYPE_TB
- en: Now, since the family {![|ÏˆxâŸ©](img/file1390.jpg)}[x] is orthogonal, it is easy
    to see fromÂ ([13.5.3](#x1-253004r3)) that
  prefs: []
  type: TYPE_NORMAL
- en: '| &#124;Î¨[G]&#124;Â² | = ![âŸ¨Î¨G &#124;Î¨G âŸ©](img/file1391.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '|  | = ![( ) âˆ‘ âˆ˜ ---- ( Î±âˆ—x Ï•(x)âŸ¨x&#124;âŸ¨Ïˆx&#124;) xâˆˆ{0,1}k](img/file1392.jpg)![(
    ) âˆ‘ âˆ˜ ---- ( Î±y Ï• (y) &#124;Ïˆy âŸ© &#124;yâŸ©) yâˆˆ{0,1}k](img/file1393.jpg) |'
  prefs: []
  type: TYPE_TB
- en: '|  | = âˆ‘ [x,yâˆˆ{0,1}^k]*Î±*[x]^âˆ—*Î±* [y]![âˆ˜ ---- Ï• (x )](img/file1394.jpg)![âˆ˜
    ---- Ï• (y )](img/file1395.jpg)âŸ¨x&#124;![âŸ¨Ïˆx&#124;ÏˆyâŸ©](img/file1396.jpg)![&#124;yâŸ©](img/file1397.jpg)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | = âˆ‘ [xâˆˆ{0,1}^k]&#124;*Î±*[x]&#124;Â²*Ï•*(x)*,* |'
  prefs: []
  type: TYPE_TB
- en: which corresponds precisely to the expectation ğ”¼[*Ï•*(*X*)] where the random
    variableÂ *X* is discretised over the set with labels {0*,*1}^k, and where eachÂ |*Î±*[x]|Â²
    corresponds to the discrete probability ofÂ *X* being inÂ x.
  prefs: []
  type: TYPE_NORMAL
- en: In order to retrieve the expectation we are after, we therefore simply need
    to run the circuit corresponding toÂ â„³, measure the output in the computational
    basis, and determine the probability of observing the stateÂ ![|1âŸ©](img/file1398.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: QMC speedup
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The actual speedup of QMC resides in a subtle application of the *Amplitude*
    *Estimation* theorem and the *Powering Lemma*, which we present now.
  prefs: []
  type: TYPE_NORMAL
- en: '**Theorem 12** (Amplitude Estimation. TheoremÂ 12 inÂ Â [[43](Biblography.xhtml#Xbrassard2002quantum)])**.**
    *Assume that we have access to a quantum unitary operatorÂ *ğ’° *such that* ğ’°![|0âŸ©](img/file1399.jpg)
    = ![âˆš----- 1 âˆ’ ğ”­](img/file1400.jpg)![|Î¨B âŸ©](img/file1401.jpg)![|0âŸ©](img/file1402.jpg)+![âˆš
    -- ğ”­](img/file1403.jpg)![|Î¨G âŸ©](img/file1404.jpg)![|1âŸ©](img/file1405.jpg)*, for
    some statesÂ *![|Î¨B âŸ©](img/file1406.jpg)*,*![|Î¨G âŸ©](img/file1407.jpg)*. Then,*
    *for any* *N* âˆˆâ„•*, the amplitude estimation algorithms outputs the estimate* ğ”­
    *such that*'
  prefs: []
  type: TYPE_NORMAL
- en: '![ âˆ˜ -------- | | ğ”­(1 âˆ’ ğ”­) Ï€2 |^ğ”­ âˆ’ ğ”­| â‰¤ 2Ï€----N-----+ N2- ](img/file1408.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '*with probability at least* 8*âˆ•Ï€*Â²*. To achieve this takes exactlyÂ **N* *iterations.*'
  prefs: []
  type: TYPE_NORMAL
- en: '**Lemma 10** (Powering Lemma. Lemma 6.1 inÂ Â [[150](Biblography.xhtml#Xjerrum1986random)])**.**
    *LetÂ *ğ”­ *be a quantity* *to estimate andÂ *ğ’° *an algorithm that output* ğ”­ *such
    that* ![||^ || ğ”­ âˆ’ ğ”­](img/file1409.jpg) â‰¤ *ğœ€* *except* *with probability smaller
    thanÂ *1*âˆ•*2*. Then, for any* *Î´* âˆˆ (0*,*1)*, it suffices to* *repeatÂ *ğ’° *about*
    ğ’ª(log(1*âˆ•Î´*)) *times and to take the median to obtain* ![|| || ^ğ”­ âˆ’ ğ”­](img/file1410.jpg)â‰¤
    *ğœ€* *with probability at least* 1 âˆ’ *Î´**.*'
  prefs: []
  type: TYPE_NORMAL
- en: In light ofÂ ([13.5.1](#x1-253004r1)), the Amplitude Estimation theorem, combined
    with the Powering Lemma, shows that in order to obtain an estimate of the empirical
    mean
  prefs: []
  type: TYPE_NORMAL
- en: '![ â€  2 âŸ¨Ïˆ|ğ’« ğ’« |Ïˆ âŸ© = |Î¨G | ](img/file1411.jpg)'
  prefs: []
  type: TYPE_IMG
- en: with probability at least 1 âˆ’ *Î´* (for any *Î´* âˆˆ (0*,*1)), i.e.,
  prefs: []
  type: TYPE_NORMAL
- en: '![â„™(||^ğ”­âˆ’ ğ”­|| â‰¤ ğœ€) â‰¥ 1âˆ’ Î´, ](img/file1412.jpg)'
  prefs: []
  type: TYPE_IMG
- en: it suffices to apply the operatorsÂ â„³ andÂ ğ’« about ğ’ª(*N* log(1*âˆ•Î´*)) times, with
  prefs: []
  type: TYPE_NORMAL
- en: '![ -------- âˆ˜ ğ”­(1 âˆ’ ğ”­) ğœ€ = 2Ï€----------, N ](img/file1413.jpg)'
  prefs: []
  type: TYPE_IMG
- en: so that, for any fixed *Î´* âˆˆ (0*,*1), the computational cost is of order ğ’ª(1*âˆ•ğœ€*),
    achieving quadratic speedup compared to classical Monte Carlo.
  prefs: []
  type: TYPE_NORMAL
- en: 13.5.4 Quantum Linear Solver
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Harrow, Hassidim and LloydÂ Â [[126](Biblography.xhtml#XHHL2009)] devised a quantum
    algorithm to solve linear systems, beating classical computation times. Linear
    systems are ubiquitous in applications, and many aspects of quantitative finance
    rely on being able to solve such (low- or high-dimensional) systems. We highlight
    below two key examples of fundamental importance in finance: solving Partial Differential
    Equations (PDEs) and portfolio optimisation.'
  prefs: []
  type: TYPE_NORMAL
- en: Theoretical aspects
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The problem can be stated as follows: given a matrix A âˆˆâ„³[N](â„‚) and a vector
    b âˆˆâ„‚^N, find the vector x âˆˆâ„‚^N such that'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Ax = b. ](img/file1414.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: In order for the algorithm to work, the matrixÂ A needs to be Hermitian. IfÂ A
    is not so, we can nevertheless consider the augmented system
  prefs: []
  type: TYPE_NORMAL
- en: '![( ) ( ) ( ) (0N,N A ) (0N,1 ) = ( b ) , A â€  0N,N x 0N,1 ](img/file1415.jpg)'
  prefs: []
  type: TYPE_IMG
- en: similarly to the Hamiltonian embedding in SectionÂ [7.6](Chapter_7.xhtml#x1-1590006).
    We assume from now now thatÂ A is indeed Hermitian. The first step of the algorithm
    is to assume that the vectorÂ b can be encoded into a quantum stateÂ ![|bâŸ©](img/file1416.jpg)
    and to then rewriteÂ ([13.5.4](#x1-2560004)) as
  prefs: []
  type: TYPE_NORMAL
- en: '| ![A &#124;xâŸ© = &#124;bâŸ©, ](img/file1417.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: where we now look for the solution, not as an element ofÂ â„‚^N, but as a quantum
    state.
  prefs: []
  type: TYPE_NORMAL
- en: SinceÂ A is Hermitian, it admits the spectral decomposition (SectionÂ [1.1.5](Chapter_1.xhtml#x1-280005))
  prefs: []
  type: TYPE_NORMAL
- en: '![ Nâˆ’ 1 âˆ‘ A = Î»j |Ï•jâŸ©âŸ¨Ï•j|, j=0 ](img/file1418.jpg)'
  prefs: []
  type: TYPE_IMG
- en: where *Î»*[0]*,â€¦,Î»*[Nâˆ’1] are its (not necessarily distinct) strictly positive
    eigenvalues with corresponding eigenstates ![|Ï•0âŸ©](img/file1419.jpg)*,â€¦,*![|Ï•N
    âˆ’1âŸ©](img/file1420.jpg), and we immediately obtain that its inverse reads
  prefs: []
  type: TYPE_NORMAL
- en: '![ Nâˆ’1 A âˆ’1 = âˆ‘ 1--|Ï• âŸ© âŸ¨Ï• |. j=0 Î»j j j ](img/file1421.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We can also decompose ![|b âŸ©](img/file1422.jpg) into the (![|Ï• âŸ© j](img/file1423.jpg))[j=0,â€¦,Nâˆ’1]
    basis as
  prefs: []
  type: TYPE_NORMAL
- en: '![ Nâˆ’1 |bâŸ© = âˆ‘ b |Ï• âŸ© , j=0 i j ](img/file1424.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and therefore the solution toÂ ([13.5.4](#x1-2560004)) reads
  prefs: []
  type: TYPE_NORMAL
- en: '![ Nâˆ’ 1 |xâŸ© = A âˆ’1 |bâŸ© = âˆ‘ bj-|Ï• âŸ©. j=0 Î»j j ](img/file1425.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The goal of the QLS algorithm is thus to construct such a state, and we summarise
    it as AlgorithmÂ [11](#x1-256007r11) below. Note that, sinceÂ A is Hermitian then,
    for any *t* âˆˆâ„, U := exp(iA*t*) is unitary with decomposition
  prefs: []
  type: TYPE_NORMAL
- en: '![ Nâˆ‘âˆ’ 1 U = eiÎ»jt |Ï•jâŸ©âŸ¨Ï•j|. j=0 ](img/file1426.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In total, the QLS algorithm requires *n*[l] + *n*[b] + 1 qubits, whereÂ *n*[l]
    is the number of qubits used to encode the *n*[l]-bit binary representation of
    (*Î»*[j])[j=0,â€¦,Nâˆ’1] andÂ *n*[b] is the number of qubits used to convertÂ b intoÂ ![|b
    âŸ©](img/file1427.jpg) (and also the number of qubits to write the solution state).
  prefs: []
  type: TYPE_NORMAL
- en: In terms of computation time, Harrow, Hassidim, and Lloyd showed that the stated
    runtime is of order poly(log(*N*)*,Îº*) assuming thatÂ A is sparse with condition
    numberÂ *Îº*, which yields an exponential speedup compared to the classical ğ’ª(*N*![âˆš--
    Îº](img/file1428.jpg)) runtime.
  prefs: []
  type: TYPE_NORMAL
- en: '![--------------------------------------------------------------------- -Algorithm---11:-HHL--Quantum--Linear-Solver--------------------------
    Input: Hermitian matrix A and nl + nb + 1 qubits initialised at âŠ—nl âŠ—nb |0âŸ© |0âŸ©
    |0âŸ©. 1: Load the data b into |bâŸ© using n qubits (with N = 2nb). b 2: Apply QPE
    with U := exp(iAt), after which the quantum state of the register is Nâˆ‘ âˆ’1 bj
    |Î»jâŸ©n |Ï•jâŸ©n |0âŸ© . j=0 l b 3: Rotate the ancillary qubit |0âŸ© controlled by |Î»jâŸ©n
    to obtain l Nâˆ‘âˆ’ 1 ( âˆ˜ ------2 ) bj |Î»jâŸ© |Ï•jâŸ© 1 âˆ’ C--|0âŸ©+ C-|1âŸ© , j=0 nl nb Î»2j
    Î»j for some normalising constant C (with |C | < minj Î»j). 4: Apply the inverse
    QPE to obtain N âˆ’1 ( âˆ˜ ------- ) âˆ‘ b |0âŸ© |Ï• âŸ© 1âˆ’ C2- |0âŸ© + C--|1âŸ© . j nl j nb
    Î»2j Î»j j=0 5: Measure the ancillary qubit in the computational basis. If the outcome
    is |1âŸ©, the register is in the post- measurement state Nâˆ‘âˆ’ 1 C bi |0âŸ©n |Ï•jâŸ© ,
    j=0 Î»i l nb which up to a normalisation factor corresponds to the solution. Result:
    Solution |xâŸ©: N âˆ’1 âˆ’1 âˆ‘ bj- |xâŸ© = A |b âŸ© = Î»j |Ï•jâŸ©. j=0 ---------------------------------------------------------------------
    ](img/file1429.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Solving PDEs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: One important example is finite-difference schemes for partial differential
    equations; standard tools can be consulted inÂ Â [[269](Biblography.xhtml#Xsmith1985numerical)]
    for example, and specific applications to finance can be found inÂ Â [[89](Biblography.xhtml#Xduffy2013finite)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider for example the Black-Scholes parabolic PDE:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ Ïƒ2- 2 2 âˆ‚tVt + rS âˆ‚SVt + 2 S âˆ‚SSVt = rVt, ](img/file1430.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: with boundary condition *V* [T] (*S*) (for instance for a European call option
    with maturity *T >* 0 and strike *K >* 0, we have *V* [T] (*S*) = ![(ST âˆ’ K )](img/file1431.jpg)[+]
    := max![(ST âˆ’ K, 0)](img/file1432.jpg)). Before trying to solve it, it is standard
    to simplify it. Let *Ï„* := *T* âˆ’ *t* and define *g*[Ï„](*S*) := *V* [t](*S*), then
    *âˆ‚*[t]*V* [t](*S*) = âˆ’*âˆ‚*[Ï„]*g*[Ï„](*S*) and hence
  prefs: []
  type: TYPE_NORMAL
- en: '![ 2 âˆ’ âˆ‚ g + rS âˆ‚ g + Ïƒ-S2âˆ‚2 g = rg , Ï„ Ï„ S Ï„ 2 SS Ï„ Ï„ ](img/file1433.jpg)'
  prefs: []
  type: TYPE_IMG
- en: with boundary condition *g*[0](*S*). Introduce now *f*[Ï„](*S*) := e^(rÏ„)*g*[Ï„](*S*),
    so that
  prefs: []
  type: TYPE_NORMAL
- en: '![ 2 âˆ’ âˆ‚Ï„fÏ„ + rS âˆ‚SfÏ„ + Ïƒ-S2âˆ‚2SSfÏ„ = 0, 2 ](img/file1434.jpg)'
  prefs: []
  type: TYPE_IMG
- en: with boundary condition *f*[0](*S*). The transformation *x* := log(*S*) and
    the map *Ïˆ*[Ï„](*x*) := *f*[Ï„](*S*) yield, after simplifications,
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ ( ) Ïƒ2- Ïƒ2-2 âˆ’ âˆ‚Ï„ÏˆÏ„ + r âˆ’ 2 âˆ‚xÏˆÏ„ + 2 âˆ‚xxÏˆ Ï„ = 0, ](img/file1435.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: 'with boundary condition *Ïˆ*[0](*x*). Finally, setting *Ï•*[Ï„] via *Ïˆ*[Ï„](*x*)
    =: e^(Î±x+Î²Ï„)*Ï•*[Ï„](*x*) with'
  prefs: []
  type: TYPE_NORMAL
- en: '![ ( 2) ( 2 )2 Î± := âˆ’ 12- r âˆ’ Ïƒ-- and Î² := âˆ’-12- r âˆ’ Ïƒ-- , Ïƒ 2 2Ïƒ 2 ](img/file1436.jpg)'
  prefs: []
  type: TYPE_IMG
- en: implies that equationÂ ([13.5.4](#x1-2570004)) becomes the heat equation
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ Ïƒ2-2 âˆ‚Ï„Ï•Ï„(x) = 2 âˆ‚xxÏ•Ï„(x), ](img/file1437.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: for all *x* âˆˆâ„ with (Dirichlet) boundary condition *Ï•*[0](*x*) = e^(âˆ’Î±x)*Ïˆ*[0](*x*).
  prefs: []
  type: TYPE_NORMAL
- en: We now discretise this PDE using an explicit scheme, where the time derivative
    *âˆ‚*[Ï„] is evaluated by forward difference while the space derivative *âˆ‚*[xx] is
    approximated with a central difference scheme (implicit schemes or more general
    *ğœƒ*-schemes follow a similar logic). We considerÂ ([13.5.4](#x1-2570004)) for *Ï„
    >* 0 andÂ *x* in some interval [*x*[L]*,x*[U]] âˆˆâ„, with (Dirichlet) boundary conditions
    *Ï•*(0*,x*) = *f*(*x*) (payoff at maturity), *Ï•*(*Ï„,x*[L]) = *f*[L](*Ï„*), and *Ï•*(*Ï„,x*[U])
    = *f*[U](*Ï„*).
  prefs: []
  type: TYPE_NORMAL
- en: We start by constructing the time-space grid for the approximation scheme. For
    two integersÂ *m* andÂ *n*, we consider a uniform grid, i.e., we split the space
    axis into *m* intervals and the time axis intoÂ *n* intervals, and we denote ğ’±
    := {0*,*1*,â€¦,n*} and ğ’² := {0*,*1*,â€¦,m*}. This means that each point on the grid
    has coordinates (*iÎ´*[T] *,x*[L] + *jÎ´*[x]) for *i* âˆˆğ’± and *j* âˆˆğ’², where
  prefs: []
  type: TYPE_NORMAL
- en: '![ T x âˆ’ x Î´T :=-- and Î´x :=-U-----L. n m ](img/file1438.jpg)'
  prefs: []
  type: TYPE_IMG
- en: At each node, we let *Ï•*[i,j] := *Ï•*(*iÎ´*[T] *,x*[L] + *jÎ´*[x]) denote the value
    of the function *u*. Note in particular that the boundary conditions imply
  prefs: []
  type: TYPE_NORMAL
- en: '![Ï•0,j = f (xL + jÎ´x), Ï•i,0 = fL(iÎ´T), Ï•i,m = fU (iÎ´T). ](img/file1439.jpg)'
  prefs: []
  type: TYPE_IMG
- en: More precisely we consider the following approximations
  prefs: []
  type: TYPE_NORMAL
- en: '| *âˆ‚*[Ï„]*Ï•*(*Ï„,x*) | = ![Ï•(Ï„-+-Î´T,x)-âˆ’-Ï•(Ï„,x) Î´T](img/file1440.jpg) + ğ’ª![(Î´
    ) T](img/file1441.jpg)*,* |'
  prefs: []
  type: TYPE_TB
- en: '| *âˆ‚*[xx]*Ï•*(*Ï„,x*) | = ![Ï•(Ï„,x + Î´x)âˆ’ 2Ï• (Ï„,x) + Ï•(Ï„,xâˆ’ Î´x) -----------------2----------------
    Î´x](img/file1442.jpg) + ğ’ª![( ) Î´2x](img/file1443.jpg)*.* |'
  prefs: []
  type: TYPE_TB
- en: Ignoring the terms inÂ *Î´*[T] andÂ *Î´*[x]Â², the heat equation at the node (*iÎ´*[T]
    *,x*[L] + *jÎ´*[x]) becomes
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Ï• âˆ’ Ï• Ïƒ2Ï• âˆ’ 2Ï• + Ï• ( ) -i+1,j----i,j + ğ’ª (Î´T ) = ---i,j+1-----i2,j----i,jâˆ’1+
    ğ’ª Î´x2 , Î´T 2 Î´x ](img/file1444.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: which we can rewrite
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ Î´ Ïƒ2 ( Î´ ) Î´ Ïƒ2 Ï•i+1,j = -T2---Ï•i,j+1 + 1âˆ’ -T2Ïƒ2 Ï•i,j + -T2---Ï•i,jâˆ’1,
    Î´x 2 Î´x Î´x 2 ](img/file1445.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: for all *i* = 0*,â€¦,n*âˆ’ 1, *j* = 1*,â€¦,m*âˆ’ 1\. To rewrite this in matrix form,
    introduce for each *i* = 0*,â€¦,n*, [i] âˆˆâ„^(mâˆ’1), B[i] âˆˆâ„^(mâˆ’1) and the matrix A
    âˆˆâ„³[mâˆ’1](â„) by
  prefs: []
  type: TYPE_NORMAL
- en: '| [i] | := ![(Ï• ,...,Ï• ) i,1 i,mâˆ’1](img/file1446.jpg)^âŠ¤*,* |'
  prefs: []
  type: TYPE_TB
- en: '| B[i] | := ![(Ï•i,0,0,...,0,Ï•i,m)](img/file1447.jpg)^âŠ¤*,* |'
  prefs: []
  type: TYPE_TB
- en: '| A | := T[mâˆ’1]![( 2 2) 1 âˆ’ Î±Ïƒ2, Î±Ïƒ-, Î±Ïƒ-- 2 2](img/file1448.jpg)*,* |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '![Î± := Î´T- Î´2x ](img/file1449.jpg)'
  prefs: []
  type: TYPE_IMG
- en: and whereÂ T[mâˆ’1](â‹…) denotes the tridiagonal matrix of dimension (*m*âˆ’ 1) Ã— (*m*âˆ’
    1).
  prefs: []
  type: TYPE_NORMAL
- en: The recursionÂ ([13.5.4](#x1-2570004)) thus becomes
  prefs: []
  type: TYPE_NORMAL
- en: '| ![ 2 i+1= Ai + Î±-Ïƒ-Bi, for each i = 0,...,n âˆ’ 1, 2 ](img/file1450.jpg) |  |'
  prefs: []
  type: TYPE_TB
- en: with the time boundary condition
  prefs: []
  type: TYPE_NORMAL
- en: '![0 = (Ï•0,1,...,Ï•0,mâˆ’ 1)âŠ¤ = (f (xL + Î´x),...,f(xL + (m âˆ’ 1)Î´x))âŠ¤. ](img/file1451.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Leaving the boundary termÂ B[i] aside, the recursionÂ ([13.5.4](#x1-2570004))
    thus is exactly of the formÂ ([13.5.4](#x1-2560004)), and can therefore be tackled
    using the HHL algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: This is the obvious first step to investigate the use of HHL-type algorithms
    in quantitative finance, and further developments have already been proposed inÂ Â [[104](Biblography.xhtml#Xfontanela2021quantum),Â [108](Biblography.xhtml#Xgarcia2021solving),Â [188](Biblography.xhtml#Xlinden2022quantum),Â [310](Biblography.xhtml#Xzhao2022quantum)],
    with or without finance applications in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Application to portfolio optimisation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The second immediate application of QLS in finance is for portfolio optimisation.
    Indeed, the standard Markowitz-type problem of the formÂ ([3.3](Chapter_3.xhtml#x1-740003))
    in SectionÂ [3.3](Chapter_3.xhtml#x1-740003) is readily formulated (at least for
    weights in {0*,*1}) as a linear problem, the constraints only increasing the dimension
    as Lagrange multipliers. We shall not dive into the details here as this is a
    rather novel development with huge potential but limited results so far, and instead
    refer the reader toÂ Â [[306](Biblography.xhtml#Xyalovetzky2021nisq),Â [187](Biblography.xhtml#Xli2022portfolio)]
    for promising implementations and details.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this chapter, we introduced several new promising quantum algorithms. First,
    we learned about quantum kernels, which can replace classical kernels in hybrid
    quantum-classical protocols.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we introduced the Bayesian quantum circuit model that expands the concept
    of a Bayesian neural network to parameterised quantum circuits. BQC is a promising
    generative model with larger expressive power than QCBM/MPQC (covered in ChaptersÂ [9](Chapter_9.xhtml#x1-1850009)
    andÂ [12](Chapter_12.xhtml#x1-22500012)).
  prefs: []
  type: TYPE_NORMAL
- en: Then we looked at quantum SDP and its potential to outperform classical SDP.
    This is a topic of active research.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we covered several important quantum algorithms that rely on the existence
    of a quantum computing hardware with characteristics that exceed the capabilities
    of currently available NISQ computers. However, the very presence of these algorithms
    and their potential to achieve quadratic or even exponential speedup provides
    strong motivation for the rapid development of quantum computers.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter completes the book. Looking ahead, we see a bright future for quantum
    computing. In the update to their quantum computing development roadmapÂ Â [[145](Biblography.xhtml#XIBMRoadmap2022)],
    IBM outlined an exciting vision with the goal to build quantum-centric supercomputers.
    The latter will incorporate quantum processors, classical processors, quantum
    communication networks, and classical networks. The immediate deliverables are
    expected to be the 433-qubit *Osprey* processor (expected to be released in 2022)
    and the 1,121-qubit *Condor* processor (expected to be released in 2023). The
    next step will be to develop ways to link processors together into a modular system
    capable of scaling without physical limitations.
  prefs: []
  type: TYPE_NORMAL
- en: The modular, multi-chip scaling technology is also envisaged by Rigetti. Rigetti
    anticipates the launch of their next generation single-chip 84-qubit quantum computer
    in 2023 and 336-qubit multi-chip processor later in 2023\. The 336-qubit multi-chip
    processor is expected to combine the anticipated improvements of the 84-qubit
    processor with the modular, multi-chip scaling technology of Rigettiâ€™s Aspen-M
    machine. These machines are expected to deliver increased performance across the
    key dimensions of speed, scale, and fidelityÂ Â [[246](Biblography.xhtml#XRigettiRoadmap2022)].
  prefs: []
  type: TYPE_NORMAL
- en: We also expect to see significant progress in the trapped ion space. IonQ announced
    several major breakthroughs that may have a major impact on the way quantum algorithms
    are designed and run on trapped ion quantum computing hardware. This includes,
    for example, a new family of *n*-qubit gates, such as the *n*-qubit Toffoli gate,
    which flips a select qubit if and only if all the other qubits are in a particular
    state. Unlike standard two-qubit quantum computing gates, the *n*-qubit Toffoli
    gate acts on many qubits at once, leading to more efficient operationsÂ Â [[146](Biblography.xhtml#XIonQ2022)].
  prefs: []
  type: TYPE_NORMAL
- en: Quantum annealing is going from strength to strength. In a recent white paperÂ Â [[39](Biblography.xhtml#XBoothby2021)],
    D-Wave introduced the new *Zephyr* graph with better connectivity than its predecessors,
    *Chimera* and *Pegasus*. Plans are in place for a 7,000-qubit chip based on *Zephyr*,
    scheduled to be available in 2023-2024Â Â [[93](Biblography.xhtml#XDW2022)]. Early
    benchmarks with smaller-scale prototype systems consisting of 500+ qubits have
    demonstrated more compact embedding, lower error rates, improved solution quality,
    and an increased probability of finding optimal solutionsÂ Â [[210](Biblography.xhtml#XMcGeoch2022)].
  prefs: []
  type: TYPE_NORMAL
- en: But, ultimately, it is up to the users to try and test various hardware and
    software solutions on a variety of use cases. We encourage our readers to experiment
    and apply the methods of quantum computing to their own spheres of interest and
    discover new quantum algorithms and applications. This is an exciting journey
    and a great opportunity to participate in the collective effort of achieving quantum
    advantage for the benefits of wider society.
  prefs: []
  type: TYPE_NORMAL
