- en: Chapter 6. Using Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用生成模型
- en: Generative models generate new data. In a way, they are the exact opposite of
    the models that we've dealt with in prior chapters. While an image classifier
    takes in a high-dimensional input, the image, and outputs a low-dimensional output
    such as the content of the image, a generative model goes about things in exactly
    the opposite way around. It might, for example, draw images from the description
    of what's in them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型生成新的数据。从某种意义上说，它们与我们在前几章中处理的模型完全相反。图像分类器接受高维度的输入——图像，并输出低维度的输出，例如图像的内容，而生成模型的处理方式正好相反。它可能会根据图像的描述来绘制图像。
- en: Generative models are still in the experimental phase of their development,
    and are currently used mostly in image applications. However, they are an important
    model as shown by the fact that there have already been several applications that
    have used generative models that have caused an uproar within the industry.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型仍处于开发的实验阶段，目前主要用于图像应用。然而，它们是一个重要的模型，正如已经有多个应用使用生成模型并在行业内引起轩然大波这一事实所显示的那样。
- en: 'In 2017, so-called *DeepFakes* began to appear on the internet. **Generative
    Adversarial Networks** (**GANs**), which we will cover later in this chapter,
    were used to generate pornographic videos featuring famous celebrities. The year
    before, in 2016, researchers showcased a system in which they could generate videos
    of politicians saying anything the researcher wanted them to say, complete with
    realistic mouth movements and facial expressions. An example of this can be seen
    in a fake speech made by former US president Barack Obama that news site BuzzFeed
    produced in 2018: [https://youtu.be/cQ54GDm1eL0](https://youtu.be/cQ54GDm1eL0).'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年，所谓的*DeepFakes*开始在互联网上出现。**生成对抗网络**（**GANs**），我们将在本章稍后讨论的技术，被用来生成包含著名名人的色情视频。前一年，2016年，研究人员展示了一个系统，通过该系统，他们可以生成政治家说任何研究人员希望他们说的话，并且配有逼真的口型和面部表情。一个例子是2018年新闻网站BuzzFeed制作的前美国总统巴拉克·奥巴马的假演讲：[https://youtu.be/cQ54GDm1eL0](https://youtu.be/cQ54GDm1eL0)。
- en: This technology is not completely negative, there are positive applications
    as well, especially if the generative model's data is sparse. If this is the case,
    generative models can generate realistic data that other models can then train
    on. Generative models are able to "translate" images, a prime example being taking
    satellite images and turning them into street maps. Another example is that generative
    models can generate code from website screenshots. They can even be used to combat
    unfairness and discrimination in machine learning models, as we will see in [Chapter 9](ch09.xhtml
    "Chapter 9. Fighting Bias"), *Fighting Bias*.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这项技术并非完全负面，它也有积极的应用，尤其是在生成模型的数据稀缺的情况下。如果是这种情况，生成模型可以生成逼真的数据，其他模型可以在这些数据上进行训练。生成模型能够“翻译”图像，一个典型的例子是将卫星图像转换为街道地图。另一个例子是生成模型可以根据网站截图生成代码。它们甚至可以用来应对机器学习模型中的不公平和歧视问题，正如我们将在[第9章](ch09.xhtml
    "第9章. 对抗偏见")，*对抗偏见*中看到的那样。
- en: In the field of finance, data is frequently sparse. Think back to the fraud
    case from [Chapter 2](ch02.xhtml "Chapter 2. Applying Machine Learning to Structured
    Data"), *Applying Machine Learning to Structured Data,* in which we were classifying
    fraudulent transactions from transaction metadata. We found that there was not
    much fraud taking place in the dataset that we used, so the model had a hard time
    detecting when fraud was taking place. Usually, when this occurs, engineers make
    assumptions and create synthetic data. Machine learning models, however, can do
    this themselves, and in the process, they might even discover some useful features
    that can help with fraud detection.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，数据通常是稀缺的。回想一下在[第2章](ch02.xhtml "第2章. 应用机器学习于结构化数据")中提到的欺诈案件，*应用机器学习于结构化数据*，我们当时正在从交易元数据中分类识别欺诈交易。我们发现数据集中发生的欺诈交易并不多，因此模型很难检测到欺诈行为。通常，当这种情况发生时，工程师会做出假设并生成合成数据。然而，机器学习模型本身可以做到这一点，在此过程中，它们甚至可能发现一些有助于欺诈检测的有用特征。
- en: In algorithmic trading, data is frequently generated in simulators. Want to
    know how your algorithm would do in a global selloff? Luckily, there are not that
    many global selloffs, so engineers at quantitative analysis firms spend a lot
    of their time creating simulations of selloffs. These simulators are often biased
    by the engineer's experience and their feelings about what a selloff should look
    like. However, what if the models could learn what a selloff fundamentally looks
    like, and then create data describing an infinite number of selloffs?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在算法交易中，数据通常是在模拟器中生成的。想知道你的算法在全球股市暴跌时会表现如何吗？幸运的是，全球暴跌的情况并不多见，因此定量分析公司的工程师大部分时间都在创建股市暴跌的模拟。这些模拟通常会受到工程师的经验和他们对股市暴跌应有模样的主观看法的影响。但是，假如模型能够学习股市暴跌的基本特征，并生成描述无限数量暴跌的数据呢？
- en: 'In this chapter, we''ll be focusing on two families of generative models: autoencoders
    and GANs. Firstly there is the family of **autoencoders**, which aim to compress
    data into a lower dimensional representation and then reconstruct the data faithfully.
    The second family is that of the **GANs**, which aim to train a generator so that
    a separate discriminator cannot tell fake images from true images.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将重点关注两类生成模型：自编码器和生成对抗网络（GAN）。首先是**自编码器**这一类，它们旨在将数据压缩成低维表示，并随后忠实地重构数据。第二类是**生成对抗网络（GANs）**，它们的目标是训练一个生成器，使得一个独立的判别器无法分辨伪造图像和真实图像。
- en: Understanding autoencoders
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解自编码器
- en: Technically, autoencoders are not generative models since they cannot create
    completely new kinds of data. Yet, variational autoencoders, a minor tweak to
    vanilla autoencoders, can. So, it makes sense to first understand autoencoders
    by themselves, before adding the generative element.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，自编码器并不是生成模型，因为它们无法创造完全新的数据类型。然而，变分自编码器（VAE），即对传统自编码器的小幅调整，能够做到这一点。因此，首先理解自编码器本身，再添加生成元素是有意义的。
- en: Autoencoders by themselves have some interesting properties that can be exploited
    for applications such as detecting credit card fraud, which is useful in our focus
    on finance.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器本身具有一些有趣的属性，可以被用于如检测信用卡欺诈等应用，这在我们关注的金融领域中非常有用。
- en: 'Given an input, *x*, an autoencoder learns how to output *x*. It aims to find
    a function, *f,* so that the following is true:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个输入 *x*，自编码器学习如何输出 *x*。它的目标是找到一个函数 *f*，使得以下条件成立：
- en: '![Understanding autoencoders](img/B10354_06_001.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![理解自编码器](img/B10354_06_001.jpg)'
- en: This might sound trivial at first, but the trick here is that autoencoders have
    a bottleneck. The middle hidden layer's size is smaller than the size of the input,
    *x*. Therefore, the model has to learn a compressed representation that captures
    all of the important elements of *x* in a smaller vector.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 起初这可能听起来很简单，但这里的关键是自编码器有一个瓶颈。中间的隐藏层的大小比输入 *x* 的大小要小。因此，模型必须学习一个压缩的表示，能够在一个更小的向量中捕捉
    *x* 的所有重要元素。
- en: 'This can best be shown in the following diagram, where we can see a compressed
    representation of the Autoencoder scheme:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这一点可以通过下面的图示来最好地展示，在图中我们可以看到 Autoencoder 结构的压缩表示：
- en: '![Understanding autoencoders](img/B10354_06_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![理解自编码器](img/B10354_06_01.jpg)'
- en: Autoencoder scheme
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器结构
- en: This compressed representation aims to capture the essence of the input, which turns
    out to be useful for us. We might, for example, want to capture what essentially
    distinguishes a fraudulent transaction from a genuine one. Vanilla autoencoders
    accomplish this with something similar to standard **principal component analysis**
    (**PCA**). They allow us to reduce the dimensionality of our data and focus on
    what matters. But in contrast to PCA, autoencoders can be extended in order to
    generate more data of a certain type. For example, autoencoders can better deal
    with image or video data since they can make use of the spatiality of data using
    convolutional layers.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个压缩表示旨在捕捉输入的本质，而这对我们是有用的。比如，我们可能希望捕捉到本质上区分欺诈交易和真实交易的特征。传统自编码器通过类似于标准**主成分分析（PCA）**的方式来实现这一点。它们可以让我们减少数据的维度，并专注于重要的部分。但与
    PCA 不同，自编码器可以扩展，以生成某种类型的更多数据。例如，自编码器能够更好地处理图像或视频数据，因为它们可以利用卷积层来利用数据的空间特性。
- en: In this section, we will build two autoencoders. The first will be used for
    handwritten digits from the MNIST dataset. Generative models are easier to debug
    and understand for visual data due to the fact that humans are intuitively good
    at judging whether two pictures show something similar, but are less good at judging
    abstract data. The second autoencoder is for a fraud detection task, using similar
    methods as the MNIST dataset.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将构建两个自编码器。第一个将用于MNIST数据集中的手写数字。生成模型对于可视数据来说更容易调试和理解，因为人类天生擅长判断两张图片是否相似，但不太擅长判断抽象数据。第二个自编码器用于欺诈检测任务，使用与MNIST数据集相似的方法。
- en: Autoencoder for MNIST
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MNIST的自编码器
- en: Let's start with a simple autoencoder for the MNIST dataset of handwritten digits.
    An MNIST image is 28x28 pixels and can be flattened into a vector of 784 elements,
    which equals 28x28\. We will compress this data into a vector with only 32 elements
    by using an autoencoder.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个简单的自编码器开始，处理MNIST手写数字数据集。MNIST图像是28x28像素，可以被展平为一个784元素的向量，即28x28。我们将通过使用自编码器将此数据压缩为仅包含32个元素的向量。
- en: Before diving into the code described here, make sure you have saved the MNIST
    dataset on the right path, successfully imported both the NumPy and Matplotlib
    libraries, and set a random seed to ensure that your experiments are reproducible.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解此处描述的代码之前，请确保已将MNIST数据集保存在正确的路径中，成功导入了NumPy和Matplotlib库，并设置了随机种子以确保实验可重复性。
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can find the code for the MNIST autoencoder and variational autoencoder
    under the following URL [https://www.kaggle.com/jannesklaas/mnist-autoencoder-vae.](https://www.kaggle.com/jannesklaas/mnist-autoencoder-vae.)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：你可以在以下网址找到MNIST自编码器和变分自编码器的代码 [https://www.kaggle.com/jannesklaas/mnist-autoencoder-vae.](https://www.kaggle.com/jannesklaas/mnist-autoencoder-vae.)'
- en: 'We''re going to set the encoding dimensionality hyperparameter now so that
    we can use it later:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在设置编码维度的超参数，以便稍后使用：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then, we construct the autoencoder using the Keras functional API. While a simple
    autoencoder could be constructed using the sequential API, this is a good refresher
    for us on how the functional API works.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用Keras功能性API构建自编码器。虽然使用顺序API也可以构建一个简单的自编码器，但这对我们复习功能性API的工作原理是一个很好的机会。
- en: 'First, we import the `Model` class, which allows us to create functional API
    models. We also need to import both the `Input` and `Dense` layers. You''ll remember
    from previous chapters how the functional API needs a separate input layer, while
    the sequential API does not need one. To import both layers, we need to run the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入`Model`类，它允许我们创建功能性API模型。我们还需要导入`Input`和`Dense`层。你会记得在前面的章节中，功能性API需要一个单独的输入层，而顺序API则不需要。为了导入这两个层，我们需要运行以下代码：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now we are chaining up the autoencoder''s layers: an `Input` layer followed
    by a `Dense` layer that encodes the image to a smaller representation.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在连接自编码器的各个层：一个`Input`层，后接一个`Dense`层，将图像编码为更小的表示。
- en: 'This is followed by a `Dense` decoding layer that aims to reconstruct the original
    image:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是一个`Dense`解码层，旨在重建原始图像：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After we have created and chained up the layers, we are then able to create
    a model that maps from the input to the decoded image:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建并连接好各个层后，就可以创建一个模型，将输入映射到解码后的图像：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To get a better idea of what is going on, we can plot a visualization of the
    resulting autoencoder model with the following code:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地了解发生了什么，我们可以使用以下代码绘制出结果自编码器模型的可视化图：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can see our autoencoder as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们的自编码器如下所示：
- en: '![Autoencoder for MNIST](img/B10354_06_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST的自编码器](img/B10354_06_02.jpg)'
- en: Autoencoder model
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器模型
- en: 'Which we can compile with:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码进行编译：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To train this autoencoder, we use the *X* values as both the input and output:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练这个自编码器，我们使用*X*值作为输入和输出：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After we train this autoencoder, which will take between one and two minutes,
    we can visually inspect how well it is doing. To do this, we first extract a single
    image from the test set, before adding a batch dimension to the image in order
    to run it through the model, which is what we use `np.expand_dims` for:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们训练这个自编码器之后，训练过程将持续一到两分钟，我们可以通过可视化检查它的表现。为此，我们首先从测试集提取一张图像，然后为图像添加一个批次维度，以便将其输入到模型中，这就是我们使用`np.expand_dims`的目的：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we''re going to run the original image through the autoencoder. You''ll
    remember that the original MNIST image showed us a number seven, so we''re hoping
    that the output of our autoencoder shows a seven as well:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将把原始图像输入到自编码器中。你应该记得原始的MNIST图像展示了数字七，因此我们希望自编码器的输出也能显示数字七：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we''re going to reshape both the autoencoder output as well as the original
    image back into 28x28-pixel images:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把自编码器的输出和原始图像都重新调整为28x28像素的图像：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We then plot the original and reconstructed image next to each other. `matplotlib`
    does not allow the image to have a batch dimension, therefore we need to pass
    an array without it. By indexing the images with `[0,:,:]`, we'll only pass the
    first item in the batch with all pixels.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将原始图像和重建图像并排显示。`matplotlib`不允许图像具有批处理维度，因此我们需要传递一个不包含批处理维度的数组。通过使用索引`[0,:,:]`，我们将仅传递批次中的第一项，并包含所有像素。
- en: 'This first item now doesn''t have a batch dimension anymore:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个第一项已经没有批处理维度了：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After running that code, you''ll see that our hopes have been achieved! Compared
    to the original image (left), our autoencoder image (right) is also showing a
    seven!:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 运行完这段代码后，你会看到我们的期望已经实现！与原始图像（左）相比，我们的自编码器图像（右）同样显示了数字七！：
- en: '![Autoencoder for MNIST](img/B10354_06_03.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST自编码器](img/B10354_06_03.jpg)'
- en: Autoencoder result
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器结果
- en: As you can see in the preceding screenshot, the reconstructed seven is still
    a seven, so the autoencoder was able to capture the general idea of what a seven
    is. It's not perfect though, as you can see it's a bit blurry around the edges,
    especially in the top left. It seems that while the autoencoder is unsure about
    the length of the lines, it does have a good idea that there are two lines in
    a seven and it is aware of the general direction they follow.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在前面的截图中看到的，重建的七仍然是一个七，因此自编码器能够捕捉到数字七的基本概念。然而，它并不完美，你可以看到它的边缘有些模糊，特别是在左上角。看起来虽然自编码器不确定线条的长度，但它知道七是由两条线组成的，并且能够识别它们的大致方向。
- en: An autoencoder such as this one performs nonlinear PCA. It learns which components
    matter the most for a seven to be a seven. The usefulness of being able to learn
    this representation goes beyond images. Within credit card fraud detection, such
    principal components would make for good features that another classifier would
    be able to work with.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的自编码器执行的是非线性PCA。它学习哪些组件对数字七的识别最为重要。能够学习这种表示的有用性超越了图像。在信用卡欺诈检测中，这样的主成分将作为良好的特征，供其他分类器使用。
- en: In the next section, we will apply an autoencoder to the credit card fraud problem.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将应用自编码器解决信用卡欺诈问题。
- en: Autoencoder for credit cards
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信用卡自编码器
- en: Throughout this section, we will once again be dealing with the problem of credit
    card fraud. This time, we will be using a slightly different dataset from that
    in [Chapter 2](ch02.xhtml "Chapter 2. Applying Machine Learning to Structured
    Data"), *Applying Machine Learning to Structured Data*.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将再次处理信用卡欺诈问题。这次，我们将使用一个与[第二章](ch02.xhtml "第二章：应用机器学习于结构化数据")中稍有不同的数据集，*应用机器学习于结构化数据*。
- en: This new dataset contains records of actual credit card transactions with anonymized
    features; however, it does not lend itself much to feature engineering. Therefore,
    we will have to rely on end-to-end learning methods in order to build a good fraud
    detector.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新数据集包含了实际信用卡交易的记录，特征已被匿名化；然而，它并不适合进行太多的特征工程。因此，我们将不得不依赖端到端的学习方法来构建一个良好的欺诈检测器。
- en: Note
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can find the dataset at: [https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)
    and the notebook with an implementation of an autoencoder and variational autoencoder
    at: [https://www.kaggle.com/jannesklaas/credit-vae](https://www.kaggle.com/jannesklaas/credit-vae).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：你可以在以下网址找到数据集：[https://www.kaggle.com/mlg-ulb/creditcardfraud](https://www.kaggle.com/mlg-ulb/creditcardfraud)，并且可以在以下网址找到一个包含自编码器和变分自编码器实现的笔记本：[https://www.kaggle.com/jannesklaas/credit-vae](https://www.kaggle.com/jannesklaas/credit-vae)。'
- en: 'As usual, we first load the data. The `Time` feature shows the absolute time
    of the transaction, which makes the data a bit hard to deal with here. Therefore,
    we will just drop it, which we can do by running:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，我们首先加载数据。`Time`特征显示的是交易的绝对时间，这使得数据在这里处理起来有些困难。因此，我们将直接丢弃它，可以通过运行以下代码来实现：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We then separate the `X` data on the transaction from the classification of
    the transaction and extract the NumPy array that underlies the pandas DataFrame:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将交易的 `X` 数据与交易的分类分开，并提取出支撑 pandas DataFrame 的 NumPy 数组：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now we need to scale the features. Feature scaling makes it easier for our model
    to learn a good representation of the data. This time around, we're going employ
    a slightly different method of feature scaling than what we did before. We'll
    scale all features to be between zero and one, as opposed to having a mean of
    zero and a standard deviation of one. By doing this, we ensure that there are
    neither any very high nor very low values in the dataset.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要对特征进行缩放。特征缩放使得我们的模型更容易学习数据的良好表示。这一次，我们将采用与之前不同的特征缩放方法。我们将所有特征缩放到零和一之间，而不是使其均值为零，标准差为一。通过这样做，我们确保数据集中没有过高或过低的值。
- en: We must be aware that this method is susceptible to outliers influencing the
    result. For each column, we first subtract the minimum value, so that the new
    minimum value becomes zero. Next, we divide by the maximum value so that the new
    maximum value becomes one.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须注意，这种方法容易受到异常值的影响。对于每一列，我们首先减去最小值，使得新的最小值为零。接着，我们除以最大值，使得新的最大值为一。
- en: 'By specifying `axis=0`, we perform the scaling column-wise:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定 `axis=0`，我们按列进行缩放：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, finally, we split our data:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，最后，我们将数据进行拆分：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We then create the exact same autoencoder as we did before; however, this time,
    we do it with different dimensions. Our input now has 29 dimensions, which we
    compress down to 12 dimensions before aiming to restore the original 29-dimensional
    output.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后创建与之前完全相同的自动编码器；不过这一次，我们使用不同的维度。我们的输入现在有 29 个维度，我们将其压缩到 12 个维度，然后尝试恢复原始的
    29 维输出。
- en: 'While 12 dimensions is a somewhat arbitrary choice here, it allows for enough
    capacity to capture all the relevant information while still significantly compressing
    the data:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 12 个维度在这里是一个相对随意的选择，但它提供了足够的容量来捕捉所有相关信息，同时仍然显著压缩数据：
- en: '[PRE15]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We are going to use the sigmoid activation function for the decoded data. This
    is only possible because we've scaled the data to have values between zero and
    one. We are also using a tanh activation within the encoded layer. This is just
    a style choice that worked well in experiments and ensures that encoded values
    are all between minus one and one. With that being said, you may use different
    activation functions depending on your individual needs.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 sigmoid 激活函数处理解码后的数据。这只有在我们将数据缩放到零和一之间的值时才可能实现。我们还在编码层中使用了 tanh 激活函数。这只是一个在实验中效果良好的风格选择，并确保编码后的值都在-1到1之间。话虽如此，您可以根据个人需求使用不同的激活函数。
- en: 'If you are working with images or deeper networks, a ReLU activation is usually
    a good choice. However, if you are working with a shallower network, as we are
    doing here, then a tanh activation often works well:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您处理的是图像或更深的网络，ReLU 激活函数通常是一个不错的选择。然而，如果您处理的是较浅的网络，如我们在这里做的那样，那么 tanh 激活函数通常效果很好：
- en: '[PRE16]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In this example, we've used a mean squared error loss. This seems a bit of an
    unusual choice at first, using a sigmoid activation with a mean squared error
    loss, yet it makes sense. Most people think that sigmoid activations have to be
    used with a cross-entropy loss, but cross-entropy loss encourages values to either
    be zero or one, which works well for classification tasks where this is the case.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用了均方误差损失。最开始看起来，这似乎是一个不太常见的选择，因为使用了 sigmoid 激活函数和均方误差损失，但它是有道理的。大多数人认为
    sigmoid 激活函数必须与交叉熵损失一起使用，但交叉熵损失鼓励值接近零或一，这在分类任务中非常有效。
- en: 'In our credit card example, most values will be around 0.5\. Mean squared error,
    which we can see being implemented in the code below, is better at dealing with
    values where the target is not binary, but on a spectrum. Binary cross entropy
    forces values to be close to zero and one, which is not what we always want:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的信用卡示例中，大多数值会接近 0.5。我们可以在下面的代码中看到，均方误差更适合处理目标不是二元的，而是处于某种范围内的值。二元交叉熵损失将值强制接近零或一，而这并不是我们总是需要的：
- en: '[PRE17]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After training, which will take around two minutes, the autoencoder converges
    to a low loss:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后，自动编码器会在大约两分钟内收敛到一个较低的损失值：
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The reconstruction loss is low, but how do we know whether our autoencoder is
    working well? Once again, a visual inspection will come to the rescue. As we've
    explained before, humans are very good at judging things visually, but not very
    good at judging abstract numbers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 重建损失较低，但我们怎么知道我们的自编码器是否工作得好呢？再次，视觉检查将为我们提供帮助。正如我们之前解释过的，人类在视觉判断方面非常擅长，但在判断抽象数字时却不太擅长。
- en: 'To run a visual inspection, first we must make some predictions, in which we''ll
    run a subset of our test set through the autoencoder:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行视觉检查，首先我们需要做一些预测，我们将在自编码器中运行一部分测试集：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We must can then plot individual samples. The following code produces an overlaid bar
    chart comparing the original transaction data with the reconstructed transaction
    data:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以绘制单个样本。以下代码生成一个重叠的条形图，比较原始交易数据和重建的交易数据：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This code will then give us the following chart:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将为我们生成以下图表：
- en: '![Autoencoder for credit cards](img/B10354_06_04.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![信用卡的自编码器](img/B10354_06_04.jpg)'
- en: Autoencoder reconstruction versus original data
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器重建与原始数据
- en: As you can see, our model does a fine job at reconstructing the original values.
    The reconstructed values often match the true values, and if they don't, then
    they only deviate by a small margin. As you can see, visual inspection gives more
    insight than looking at abstract numbers.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们的模型在重建原始值方面表现不错。重建值通常与真实值相匹配，如果不匹配，也只是略有偏差。正如您所见，视觉检查比查看抽象数字能提供更多的洞察。
- en: Visualizing latent spaces with t-SNE
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 t-SNE 可视化潜在空间
- en: We now have an autoencoder that takes in a credit card transaction and outputs
    a credit card transaction that looks more or less the same. However, this is not
    why we built the autoencoder. The main advantage of an autoencoder is that we
    can now encode the transaction into a lower dimensional representation that captures
    the main elements of the transaction.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个自编码器，它输入一个信用卡交易并输出一个看起来大致相同的信用卡交易。然而，这并不是我们构建自编码器的目的。自编码器的主要优势在于，我们现在可以将交易编码为一个低维表示，从而捕捉交易的主要元素。
- en: 'To create the encoder model, all we have to do is to define a new Keras model
    that maps from the input to the encoded state:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建编码器模型，我们只需定义一个新的 Keras 模型，将输入映射到编码后的状态：
- en: '[PRE21]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that you don't need to train this model again. The layers keep the weights
    from the previously trained autoencoder.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您无需再次训练此模型。该层会保留之前训练的自编码器的权重。
- en: 'To encode our data, we now use the encoder model:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 为了编码我们的数据，我们现在使用编码器模型：
- en: '[PRE22]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: But how would we know whether these encodings contain any meaningful information
    about fraud? Once again, visual representation is key. While our encodings have
    fewer dimensions than the input data, they still have 12 dimensions. It's impossible
    for humans to think about a 12-dimensional space, so we need to draw our encodings
    in a lower dimensional space while still preserving the characteristics we care
    about.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们如何知道这些编码是否包含有关欺诈的有意义信息呢？再次，视觉表示是关键。虽然我们的编码比输入数据的维度更少，但它们仍然有 12 维。人类不可能思考一个
    12 维的空间，因此我们需要在低维空间中绘制我们的编码，同时仍然保留我们关心的特征。
- en: In our case, the characteristic we care about is *proximity*. We want points
    that are close to each other in the 12-dimensional space to be close to each other
    in the 2-dimensional plot. More precisely, we care about the neighborhood. We
    want the points that are closest to each other in the high-dimensional space to
    also be closest to each other in the low-dimensional space.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，关心的特征是*邻近性*。我们希望在 12 维空间中相互接近的点，在二维图中也能彼此接近。更准确地说，我们关心的是邻域。我们希望在高维空间中最接近的点，在低维空间中也能最接近。
- en: Preserving the neighborhood is important because we want to find clusters of
    fraud. If we find that fraudulent transactions form a cluster in our high-dimensional
    encodings, then we can use a simple check if a new transaction falls into the
    fraud cluster to flag a transaction as fraudulent. A popular method to project
    high-dimensional data into low-dimensional plots while preserving neighborhoods
    is called **t-distributed stochastic neighbor embedding,** or **t-SNE**.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 保持邻域关系很重要，因为我们希望找到欺诈的聚类。如果我们发现欺诈交易在高维编码中形成了一个聚类，那么我们可以简单地检查新交易是否落入该欺诈聚类，从而将其标记为欺诈交易。将高维数据投影到低维图中，同时保持邻域关系的一个流行方法叫做
    **t-分布随机邻居嵌入（t-SNE）**。
- en: 'In a nutshell, t-SNE aims to faithfully represent the probability that two
    points are neighbors in a random sample of all points. That is, it tries to find
    a low-dimensional representation of data in which points in a random sample have
    the same probability of being the closest neighbors as in the high-dimensional
    data:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，t-SNE旨在忠实地表示在所有点的随机样本中，两个点是邻居的概率。也就是说，它试图找到数据的低维表示，使得在随机样本中，点之间成为最近邻的概率与高维数据中的相同：
- en: '![Visualizing latent spaces with t-SNE](img/B10354_06_05.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![通过t-SNE可视化潜在空间](img/B10354_06_05.jpg)'
- en: How t-SNE measures similarity
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE如何衡量相似度
- en: 'The t-SNE algorithm follows these steps:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE算法的步骤如下：
- en: Calculate the Gaussian similarity between all points. This is done by calculating
    the Euclidean (spatial) distance between points and then calculating the value
    of a Gaussian curve at that distance, as you can see in the preceding diagram.
    The Gaussian similarity for all points, *j,* from point *i* can be calculated
    as follows:![Visualizing latent spaces with t-SNE](img/B10354_06_002.jpg)
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算所有点之间的高斯相似度。这个过程通过计算点之间的欧几里得（空间）距离，然后计算该距离下高斯曲线的值，如前图所示。点 *i* 和点 *j* 之间的高斯相似度可以通过以下公式计算：![通过t-SNE可视化潜在空间](img/B10354_06_002.jpg)
- en: 'In the preceding formula, ![Visualizing latent spaces with t-SNE](img/B10354_06_003.jpg)2
    is the variance of the Gaussian distribution. We will look at how to determine
    this variance later on in this chapter. Note that since the similarity between
    points *i* and *j* is scaled by the sum of distances between *i* and all other
    points (expressed as *k*), the similarity between *i* and *j*,![Visualizing latent
    spaces with t-SNE](img/B10354_06_004.jpg), can be different from the similarity
    between *j* and *i*, ![Visualizing latent spaces with t-SNE](img/B10354_06_005.jpg).
    Therefore, we average the two similarities to gain the final similarity that we''ll
    work with going forward:'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的公式中，![通过t-SNE可视化潜在空间](img/B10354_06_003.jpg)² 是高斯分布的方差。我们将在本章后面讨论如何确定这个方差。请注意，由于点
    *i* 和点 *j* 之间的相似度是通过 *i* 和所有其他点之间的距离总和（表示为 *k*）进行缩放的，因此 *i* 和 *j* 之间的相似度，![通过t-SNE可视化潜在空间](img/B10354_06_004.jpg)，可能与
    *j* 和 *i* 之间的相似度，![通过t-SNE可视化潜在空间](img/B10354_06_005.jpg)，不同。因此，我们将两者的相似度平均，以得到我们后续工作中使用的最终相似度：
- en: '![Visualizing latent spaces with t-SNE](img/B10354_06_006.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![通过t-SNE可视化潜在空间](img/B10354_06_006.jpg)'
- en: In the preceding formula, *n* is the number of data points.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的公式中，*n* 是数据点的数量。
- en: Randomly position the data points in the lower dimensional space.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在低维空间中随机定位数据点。
- en: Calculate the *t-similarity* between all the points in the lower dimensional
    space:![Visualizing latent spaces with t-SNE](img/B10354_06_007.jpg)
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算低维空间中所有点之间的*t-相似度*：![通过t-SNE可视化潜在空间](img/B10354_06_007.jpg)
- en: Just like in training neural networks, we will optimize the positions of the
    data points in the lower dimensional space by following the gradient of a loss
    function. The loss function, in this case, is the **Kullback–Leibler** (**KL**)
    divergence between the similarities in the higher and lower dimensional space.
    We will give the KL divergence a closer look in the section on variational autoencoders.
    For now, just think of it as a way to measure the difference between two distributions.
    The derivative of the loss function with respect to the position *y[i]* of data
    point *i* in the lower dimensional space is as follows:![Visualizing latent spaces
    with t-SNE](img/B10354_06_008.jpg)
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就像训练神经网络一样，我们将通过遵循损失函数的梯度来优化数据点在低维空间中的位置。此处的损失函数是高维空间和低维空间中相似度之间的**Kullback-Leibler**（**KL**）散度。我们将在变分自编码器的部分更详细地介绍KL散度。现在，先将其理解为衡量两个分布之间差异的一种方式。损失函数关于低维空间中数据点
    *i* 位置 *y[i]* 的导数如下所示：![通过t-SNE可视化潜在空间](img/B10354_06_008.jpg)
- en: Adjust the data points in the lower dimensional space by using gradient descent,
    moving points that were close in the high-dimensional data closer together and
    moving points that were further away further from each other:![Visualizing latent
    spaces with t-SNE](img/B10354_06_009.jpg)
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用梯度下降调整低维空间中的数据点，令那些在高维数据中接近的点互相靠近，而将那些相距较远的点进一步分开：![通过t-SNE可视化潜在空间](img/B10354_06_009.jpg)
- en: You will recognize this as a form of gradient descent with momentum, as the
    previous gradient is incorporated into the updated position.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将会识别到这是一种具有动量的梯度下降形式，因为先前的梯度被纳入更新后的位置。
- en: The t-distribution used always has one degree of freedom. This freedom leads
    to a simpler formula as well as some nice numerical properties that lead to faster
    computation and more useful charts.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的t分布总是具有一个自由度。这个自由度导致了一个更简单的公式，并且具有一些很好的数值特性，从而加速了计算并生成了更有用的图表。
- en: 'The standard deviation of the Gaussian distribution can be influenced by the
    user with a *perplexity* hyperparameter. Perplexity can be interpreted as the
    number of neighbors we expect a point to have. A low perplexity value emphasizes
    local proximities, while a high perplexity value emphasizes global perplexity
    values. Mathematically, perplexity can be calculated as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 高斯分布的标准差可以通过*困惑度*超参数由用户控制。困惑度可以理解为我们期望每个点的邻居数量。低困惑度值强调局部接近性，而高困惑度值则强调全局困惑度值。从数学上讲，困惑度可以按如下方式计算：
- en: '![Visualizing latent spaces with t-SNE](img/B10354_06_010.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![使用t-SNE可视化潜在空间](img/B10354_06_010.jpg)'
- en: 'Here *P[i]* is a probability distribution over the position of all data points
    in the dataset and ![Visualizing latent spaces with t-SNE](img/B10354_06_011.jpg)
    is the Shanon entropy of this distribution, calculated as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里*P[i]*是数据集所有数据点位置的概率分布，![使用t-SNE可视化潜在空间](img/B10354_06_011.jpg)是该分布的香农熵，计算公式如下：
- en: '![Visualizing latent spaces with t-SNE](img/B10354_06_012.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![使用t-SNE可视化潜在空间](img/B10354_06_012.jpg)'
- en: While the details of this formula are not very relevant to using t-SNE, it is
    important to know that t-SNE performs a search over values of the standard deviation,
    ![Visualizing latent spaces with t-SNE](img/B10354_06_013.jpg), so that it finds
    a global distribution, *P[i],* for which the entropy over our data is of our desired
    perplexity. In other words, you need to specify the perplexity by hand, but what
    that perplexity means for your dataset also depends on the dataset itself.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个公式的细节对于使用t-SNE来说并不非常重要，但需要知道t-SNE会在标准差的值上进行搜索，![使用t-SNE可视化潜在空间](img/B10354_06_013.jpg)，以便找到一个全局分布，*P[i]*，使得我们的数据的熵具有我们期望的困惑度。换句话说，你需要手动指定困惑度，但这个困惑度对你的数据集的含义也取决于数据集本身。
- en: Laurens Van Maarten and Geoffrey Hinton, the inventors of t-SNE, report that
    the algorithm is relatively robust for choices of perplexity between 5 and 50\.
    The default value in most libraries is 30, which is a fine value for most datasets.
    However, if you find that your visualizations are not satisfactory, then tuning
    the perplexity value is probably the first thing you would want to do.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE的发明者Laurens Van Maarten和Geoffrey Hinton报告称，该算法在困惑度值为5到50之间时相对稳定。大多数库中的默认值是30，这是大多数数据集的理想选择。然而，如果你发现你的可视化效果不理想，调整困惑度值可能是你最先需要做的事情。
- en: For all the math involved, using t-SNE is surprisingly simple. Scikit-learn
    has a handy t-SNE implementation that we can use just like any algorithm in scikit-learn.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管涉及到一定的数学，使用t-SNE却出奇的简单。Scikit-learn提供了一个方便的t-SNE实现，我们可以像使用scikit-learn中的其他算法一样使用它。
- en: 'We first import the `TSNE` class, and then we can create a new `TSNE` instance.
    We define that we want to train for 5000 epochs, and use the default perplexity
    of 30 and the default learning rate of 200\. We also specify that we would like
    output during the training process. We then call `fit_transform`, which transforms
    our 12 encodings into 2-dimensional projections:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入`TSNE`类，然后可以创建一个新的`TSNE`实例。我们定义训练5000个周期，使用默认的困惑度值30和默认的学习率200。我们还指定希望在训练过程中输出信息。然后，我们调用`fit_transform`，将12个编码转换为二维投影：
- en: '[PRE23]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: As a word of warning, t-SNE is quite slow as it needs to compute the distances
    between all the points. By default, scikit-learn uses a faster version of t-SNE
    called the Barnes Hut approximation. While it's not as precise, it's significantly
    faster.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 作为警告，t-SNE运算非常慢，因为它需要计算所有点之间的距离。默认情况下，scikit-learn使用一种更快的t-SNE版本，称为Barnes Hut近似法。虽然它的精度较低，但速度要快得多。
- en: There's also a faster Python implementation of t-SNE that can be used as a drop-in
    replacement of the scikit-learn implementation. However, this is not as well documented
    and contains fewer features, therefore we will not be covering it in this book.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个更快的Python实现版本的t-SNE，可以作为scikit-learn实现的替代品。不过，这个实现文档不完善，功能也较少，因此我们在本书中不会介绍它。
- en: Note
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can find the faster implementation with installation instructions
    under the following URL [https://github.com/DmitryUlyanov/Multicore-TSNE](https://github.com/DmitryUlyanov/Multicore-TSNE).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：您可以在以下网址找到更快的实现和安装说明：[https://github.com/DmitryUlyanov/Multicore-TSNE](https://github.com/DmitryUlyanov/Multicore-TSNE)。'
- en: 'We can then plot our t-SNE results as a scatterplot. For illustration, we will
    distinguish frauds from non-frauds by color, with frauds being plotted in red
    and non-frauds being plotted in blue. Since the actual values of t-SNE do not
    matter as much, we will hide the axes:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将t-SNE结果绘制为散点图。为了说明，我们将通过颜色区分欺诈和非欺诈，欺诈用红色表示，非欺诈用蓝色表示。由于t-SNE的实际数值并不那么重要，我们将隐藏坐标轴：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let''s now see, what the output chart will look like:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看，输出图表会是什么样子：
- en: '![Visualizing latent spaces with t-SNE](img/B10354_06_06.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![使用t-SNE可视化潜在空间](img/B10354_06_06.jpg)'
- en: t-SNE results in the form of a scatter graph
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: t-SNE结果以散点图形式呈现
- en: For easier spotting, and for those reading the print version, the cluster containing
    the most frauds, those that are marked red, has been marked with a circle. You
    can see that the frauds are nicely separate from the rest of the genuine transactions,
    those in blue. Clearly, our autoencoder has found a way to distinguish frauds
    from the genuine transaction without being given labels. This is a form of unsupervised
    learning.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更容易观察，并且方便打印版本的读者，包含最多欺诈交易的聚类（用红色标记）已被圈出。你可以看到，欺诈交易与其余真实交易（用蓝色标记）清晰分开。显然，我们的自动编码器已经找到了区分欺诈和真实交易的方法，而无需标签。这是一种无监督学习。
- en: In fact, plain autoencoders perform an approximation of PCA, which is useful
    for unsupervised learning. In the output chart, you can see that there are a few
    more clusters that are clearly separate from the other transactions, yet these
    are not frauds. Using autoencoders and unsupervised learning, it is possible to
    separate and group our data in ways that we did not even think of before. For
    example, we might be able to cluster transactions by purchase type.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，普通的自动编码器执行的是PCA的近似，这对于无监督学习非常有用。在输出图表中，你可以看到有几个聚类明显与其他交易分开，然而这些并不是欺诈交易。通过使用自动编码器和无监督学习，我们可以以我们之前没有想到的方式对数据进行分离和分组。例如，我们可能能够按照购买类型对交易进行聚类。
- en: Using our autoencoder, we could now use the encoded information as features
    for a classifier. However, what's even better is that with only a slight modification
    of the autoencoder, we can generate more data that has the underlying properties
    of a fraud case while having different features. This is done with a variational
    autoencoder, which will be the focus of the next section.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的自动编码器，我们现在可以将编码后的信息作为分类器的特征。然而，更好的做法是，通过对自动编码器做轻微修改，我们可以生成更多具有欺诈案件潜在特征但具有不同特征的数据。这是通过变分自动编码器（VAE）实现的，接下来的章节将重点介绍这一内容。
- en: Variational autoencoders
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变分自动编码器
- en: Autoencoders are basically an approximation for PCA. However, they can be extended
    to become generative models. Given an input, **variational autoencoders** (**VAEs**)
    can create encoding *distributions*. This means that for a fraud case, the encoder
    would produce a distribution of possible encodings that all represent the most
    important characteristics of the transaction. The decoder would then turn all
    of the encodings back into the original transaction.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器基本上是PCA的近似。 然而，它们可以扩展为生成模型。给定输入，**变分自动编码器**（**VAE**）可以生成编码的*分布*。这意味着，对于一个欺诈案件，编码器将生成一个可能的编码分布，这些编码都代表了交易的最重要特征。解码器随后将所有编码转回原始交易。
- en: This is useful since it allows us to generate data about transactions. One problem
    of fraud detection that we discovered earlier is that there are not all that many
    fraudulent transactions. Therefore, by using a VAE, we can sample any amount of transaction
    encodings and train our classifier with more fraudulent transaction data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常有用，因为它可以帮助我们生成关于交易的数据。我们之前发现的一个欺诈检测问题是，欺诈交易并不多。因此，通过使用变分自动编码器（VAE），我们可以对任何数量的交易编码进行采样，并用更多的欺诈交易数据来训练我们的分类器。
- en: 'So, how do VAEs do it? Instead of having just one compressed representation
    vector, a VAE has two: one for the mean encoding, ![Variational autoencoders](img/B10354_06_014.jpg),
    and one for the standard deviation of this encoding, ![Variational autoencoders](img/B10354_06_015.jpg):'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，VAE 是怎么做到的呢？VAE 不仅仅有一个压缩的表示向量，而是有两个：一个是均值编码，![变分自编码器](img/B10354_06_014.jpg)，另一个是这个编码的标准差，![变分自编码器](img/B10354_06_015.jpg)：
- en: '![Variational autoencoders](img/B10354_06_07.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![变分自编码器](img/B10354_06_07.jpg)'
- en: VAE scheme
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: VAE 方案
- en: Both the mean and standard deviation are vectors, just as with the encoding
    vector we used for the vanilla autoencoder. However, to create the actual encoding,
    we simply need to add random noise with the standard deviation, ![Variational
    autoencoders](img/B10354_06_016.jpg), to our encoding vector.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 均值和标准差都是向量，就像我们在传统自编码器中使用的编码向量一样。然而，为了创建实际的编码，我们只需将带有标准差的随机噪声，![变分自编码器](img/B10354_06_016.jpg)，添加到我们的编码向量中。
- en: 'To achieve a broad distribution of values, our network trains with a combination
    of two losses: the reconstruction loss, which you know from the vanilla autoencoder;
    and the KL divergence loss between the encoding distribution and a standard Gaussian
    distribution with a standard deviation of one.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现值的广泛分布，我们的网络结合了两种损失进行训练：重构损失，这在传统自编码器中你应该已经知道；以及编码分布与标准高斯分布（标准差为1）之间的 KL
    散度损失。
- en: MNIST example
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MNIST 示例
- en: Now on to our first VAE. This VAE will work with the MNIST dataset and give
    you a better idea about how VAEs work. In the next section, we will build the
    same VAE for credit card fraud detection.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在开始我们的第一个 VAE。这个 VAE 将与 MNIST 数据集一起使用，并帮助你更好地理解 VAE 是如何工作的。在下一节中，我们将为信用卡欺诈检测构建相同的
    VAE。
- en: 'Firstly, we need to import several elements, which we can do simply by running:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要导入几个元素，可以通过运行以下代码轻松完成：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Notice the two new imports, the `Lambda` layer and the `metrics` module. The
    `metrics` module provides metrics, such as the cross-entropy loss, which we will
    use to build our custom loss function. Meanwhile the `Lambda` layer allows us
    to use Python functions as layers, which we will use to sample from the encoding
    distribution. We will see just how the `Lambda` layer works in a bit, but first,
    we need to set up the rest of the neural network.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 注意两个新导入的元素，`Lambda` 层和 `metrics` 模块。`metrics` 模块提供了各种度量，例如交叉熵损失，我们将使用它来构建我们的自定义损失函数。与此同时，`Lambda`
    层允许我们将 Python 函数作为层使用，稍后我们将使用它从编码分布中进行采样。我们稍后将看到 `Lambda` 层是如何工作的，但首先，我们需要设置神经网络的其余部分。
- en: 'The first thing we need to do is to define a few hyperparameters. Our data
    has an original dimensionality of 784, which we compress into a latent vector
    with 32 dimensions. Our network has an intermediate layer between the input and
    the latent vector, which has 256 dimensions. We will train for 50 epochs with
    a batch size of 100:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义一些超参数。我们的数据的原始维度是 784，我们将其压缩成一个具有 32 维的潜在向量。我们的网络在输入和潜在向量之间有一个中间层，维度为
    256。我们将训练 50 个 epoch，批大小为 100：
- en: '[PRE26]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'For computational reasons, it is easier to learn the log of the standard deviation
    rather than the standard deviation itself. To do this we create the first half
    of our network, in which the input, `x,` maps to the intermediate layer, `h`.
    From this layer, our network splits into `z_mean`, which expresses ![MNIST example](img/B10354_06_017.jpg)
    and `z_log_var`, which expresses ![MNIST example](img/B10354_06_018.jpg):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 出于计算原因，学习标准差的对数比直接学习标准差本身要容易。为此，我们创建了网络的前半部分，其中输入 `x` 映射到中间层 `h`。从该层开始，我们的网络分为
    `z_mean`，表示 ![MNIST 示例](img/B10354_06_017.jpg) 和 `z_log_var`，表示 ![MNIST 示例](img/B10354_06_018.jpg)：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Using the Lambda layer
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Lambda 层
- en: The `Lambda` layer wraps an arbitrary expression, that is, a Python function,
    as a Keras layer. Yet there are a few requirements in order to make this work.
    For backpropagation to work, the function needs to be differentiable. After all,
    we want to update the network weights by the gradient of the loss. Luckily, Keras
    comes with a number of functions in its `backend` module that are all differentiable,
    and simple Python math, such as *y = x + 4*, is fine as well.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`Lambda` 层将任意表达式（即 Python 函数）封装为 Keras 层。但是，要使其正常工作，有一些要求。为了使反向传播有效，函数需要是可微的。毕竟，我们希望通过损失的梯度更新网络权重。幸运的是，Keras
    在其 `backend` 模块中提供了许多可微的函数，简单的 Python 数学运算，例如 *y = x + 4*，也是可以的。'
- en: Additionally, a `Lambda` function can only take one input argument. In the layer
    we want to create, the input is just the previous layer's output tensor. In this
    case, we want to create a layer with two inputs, ![Using the Lambda layer](img/B10354_06_019.jpg)
    and ![Using the Lambda layer](img/B10354_06_20.jpg). Therefore, we will wrap both
    inputs into a tuple that we can then take apart.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`Lambda` 函数只能接受一个输入参数。在我们要创建的层中，输入就是前一层的输出张量。在这种情况下，我们想要创建一个具有两个输入的层，![使用
    Lambda 层](img/B10354_06_019.jpg) 和 ![使用 Lambda 层](img/B10354_06_20.jpg)。因此，我们将把这两个输入打包成一个元组，然后我们可以将其拆解开。
- en: 'You can see the function for sampling below:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到下面的采样函数：
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s take a minute to break down the function:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花一点时间来解析这个函数：
- en: We take apart the input tuple and have our two input tensors.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们拆解输入元组，并得到我们的两个输入张量。
- en: We create a tensor containing random, normally distributed noise with a mean
    of zero and a standard deviation of one. The tensor has the shape as our input
    tensors (`batch_size`, `latent_dim`).
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个包含随机、正态分布噪声的张量，均值为零，标准差为一。这个张量的形状与我们的输入张量相同（`batch_size`，`latent_dim`）。
- en: Finally, we multiply the random noise with our standard deviation to give it
    the learned standard deviation and add the learned mean. Since we are learning
    the log standard deviation, we have to apply the exponent function to our learned
    tensor.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将随机噪声与标准差相乘，赋予它学习到的标准差，并加上学习到的均值。由于我们在学习对数标准差，我们需要对学习到的张量应用指数函数。
- en: 'All these operations are differentiable since we are using the Keras backend
    functions. Now we can turn this function into a layer and connect it to the previous
    two layers with one line:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些操作都是可微分的，因为我们使用的是 Keras 后端函数。现在我们可以将这个函数转化为一个层，并用一行代码将它与前两个层连接起来：
- en: '[PRE29]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: And voilà! We've now got a custom layer that samples from a normal distribution
    described by two tensors. Keras can automatically backpropagate through this layer
    and train the weights of the layers before it.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！我们现在有了一个自定义层，可以从由两个张量描述的正态分布中进行采样。Keras 可以自动通过该层反向传播，并训练其前面层的权重。
- en: 'Now that we have encoded our data, we also need to decode it as well. We are
    able to do this with two `Dense` layers:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经编码了我们的数据，我们还需要解码它。我们可以通过两个 `Dense` 层来实现：
- en: '[PRE30]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Our network is now complete. This network will encode any MNIST image into a
    mean and a standard deviation tensor from which the decoding part then reconstructs
    the image. The only thing missing is the custom loss incentivizing the network
    to both reconstruct images and produce a normal Gaussian distribution in its encodings.
    Let's address that now.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的网络现在已经完成。这个网络会将任何 MNIST 图像编码成一个均值和标准差张量，然后解码部分再重建图像。唯一缺少的就是自定义损失函数，促使网络既能重建图像，又能在编码中产生一个正态高斯分布。我们现在来解决这个问题。
- en: Kullback–Leibler divergence
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kullback–Leibler 散度
- en: To create the custom loss for our VAE, we need a custom loss function. This
    loss function will be based on the **Kullback-Leibler** (**KL**) divergence.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为我们的 VAE 创建自定义损失函数，我们需要一个自定义损失函数。这个损失函数将基于**Kullback-Leibler**（**KL**）散度。
- en: KL divergence, is one of the metrics, just like cross-entropy, that machine
    learning inherited from information theory. While it is used frequently, there
    are many struggles you can encounter when trying to understand it.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: KL 散度是度量之一，就像交叉熵一样，是机器学习从信息论继承来的。虽然它经常被使用，但在尝试理解它时，你可能会遇到许多困难。
- en: At its core, KL divergence measures how much information is lost when distribution
    *p* is approximated with distribution *q*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，KL 散度衡量的是当分布 *p* 被分布 *q* 近似时，丢失了多少信息。
- en: 'Imagine you are working on a financial model and have collected data on the
    returns of a security investment. Your financial modeling tools all assume a normal
    distribution of returns. The following chart shows the actual distribution of
    returns versus an approximation using a normal distribution model. For the sake
    of this example, let''s assume there are only discrete returns. Before we go ahead,
    be assured that we''ll cover continuous distributions later:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你正在做一个金融模型，并收集了一个证券投资的回报数据。你的金融建模工具都假设回报是正态分布的。下图展示了回报的实际分布与使用正态分布模型的近似分布。为了简化这个例子，我们假设只有离散的回报。在我们继续之前，请放心，我们稍后会涵盖连续分布：
- en: '![Kullback–Leibler divergence](img/B10354_06_08.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler 散度](img/B10354_06_08.jpg)'
- en: Approximation versus actual
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 近似值与实际值
- en: 'Of course, the returns in your data are not exactly normally distributed. So,
    just how much information about returns would you lose if you did lose the approximation?
    This is exactly what the KL divergence is measuring:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你的数据中的回报并不是完全符合正态分布。那么，如果你失去了这种近似，关于回报你会丢失多少信息呢？这正是KL散度在衡量的内容：
- en: '![Kullback–Leibler divergence](img/B10354_06_021.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_021.jpg)'
- en: 'Here ![Kullback–Leibler divergence](img/B10354_06_022.jpg) and ![Kullback–Leibler
    divergence](img/B10354_06_023.jpg) are the probabilities that *x*, in this case,
    the return, has some value *i*, say 5%. The preceding formula effectively expresses
    the expected difference in the logarithm of probabilities of the distributions
    *p* and *q*:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这里![Kullback–Leibler divergence](img/B10354_06_022.jpg)和![Kullback–Leibler divergence](img/B10354_06_023.jpg)是*x*的概率，在这种情况下，回报有某个值*i*，比如说5%。前面的公式有效地表达了分布*p*和*q*的概率对数差异的期望：
- en: '![Kullback–Leibler divergence](img/B10354_06_024.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_024.jpg)'
- en: 'This expected difference of log probabilities is the same as the average information
    lost if you approximate distribution *p* with distribution *q*. See the following:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对数概率差异的期望值与如果你用分布*q*近似分布*p*时丢失的平均信息是相同的。见下文：
- en: '![Kullback–Leibler divergence](img/B10354_06_025.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_025.jpg)'
- en: 'Given that the KL divergence is usually written out as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于KL散度通常被写成如下形式：
- en: '![Kullback–Leibler divergence](img/B10354_06_026.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_026.jpg)'
- en: 'It can also be written in its continuous form as:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可以以连续形式写成：
- en: '![Kullback–Leibler divergence](img/B10354_06_027.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_027.jpg)'
- en: For VAEs, we want the distribution of encodings to be a normal Gaussian distribution
    with a mean of zero and a standard deviation of one.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 对于VAE，我们希望编码的分布是均值为零、标准差为一的正态高斯分布。
- en: 'When *p* is substituted with the normal Gaussian distribution, ![Kullback–Leibler
    divergence](img/B10354_06_028.jpg), and the approximation *q* is a normal distribution
    with a mean of ![Kullback–Leibler divergence](img/B10354_06_029.jpg) and a standard
    deviation of ![Kullback–Leibler divergence](img/B10354_06_30.jpg), ![Kullback–Leibler
    divergence](img/B10354_06_031.jpg), the KL divergence, simplifies to the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 当*p*被正态高斯分布替代时，![Kullback–Leibler divergence](img/B10354_06_028.jpg)，而近似*q*是均值为![Kullback–Leibler
    divergence](img/B10354_06_029.jpg)，标准差为![Kullback–Leibler divergence](img/B10354_06_30.jpg)的正态分布，![Kullback–Leibler
    divergence](img/B10354_06_031.jpg)，KL散度简化为以下公式：
- en: '![Kullback–Leibler divergence](img/B10354_06_032.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_032.jpg)'
- en: 'The partial derivatives to our mean and standard deviation vectors are, therefore
    as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们对均值和标准差向量的偏导数如下：
- en: '![Kullback–Leibler divergence](img/B10354_06_033.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_033.jpg)'
- en: 'With the other being:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个为：
- en: '![Kullback–Leibler divergence](img/B10354_06_034.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![Kullback–Leibler divergence](img/B10354_06_034.jpg)'
- en: You can see that the derivative with respect to ![Kullback–Leibler divergence](img/B10354_06_035.jpg)
    is zero if ![Kullback–Leibler divergence](img/B10354_06_036.jpg) is zero, and
    the derivative with respect to ![Kullback–Leibler divergence](img/B10354_06_037.jpg)
    is zero if ![Kullback–Leibler divergence](img/B10354_06_038.jpg) is one. This
    loss term is added to the reconstruction loss.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，如果![Kullback–Leibler divergence](img/B10354_06_035.jpg)为零，那么对![Kullback–Leibler
    divergence](img/B10354_06_036.jpg)的导数为零；如果![Kullback–Leibler divergence](img/B10354_06_037.jpg)为一，那么对![Kullback–Leibler
    divergence](img/B10354_06_038.jpg)的导数为零。这个损失项被加到重构损失中。
- en: Creating a custom loss
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建自定义损失
- en: 'The VAE loss is a combination of two losses: a reconstruction loss incentivizing
    the model to reconstruct its input well, and a KL divergence loss which is incentivizing
    the model to approximate a normal Gaussian distribution with its encodings. To
    create this combined loss, we have to first calculate the two loss components
    separately before combining them.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: VAE损失是两种损失的组合：一种重构损失，激励模型很好地重构其输入；另一种是KL散度损失，激励模型用其编码近似正态高斯分布。为了创建这种组合损失，我们必须首先分别计算这两部分损失，然后再将它们结合起来。
- en: 'The reconstruction loss is the same loss that we applied for the vanilla autoencoder.
    Binary cross-entropy is an appropriate loss for MNIST reconstruction. Since Keras''
    implementation of a binary cross-entropy loss already takes the mean across the
    batch, an operation we only want to do later, we have to scale the loss back up,
    so that we can divide it by the output dimensionality:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 重建损失与我们应用于普通自动编码器的损失相同。二元交叉熵是用于 MNIST 重建的合适损失。由于 Keras 的二元交叉熵实现已经对批次中的均值进行了处理，而我们希望在稍后进行此操作，因此我们需要将损失缩放回来，以便能够根据输出维度进行划分：
- en: '[PRE31]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The KL divergence loss is the simplified version of KL divergence, which we discussed
    earlier on in the section on KL divergence:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: KL 散度损失是 KL 散度的简化版本，我们在 KL 散度章节中曾讨论过：
- en: '![Creating a custom loss](img/B10354_06_039.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![创建自定义损失](img/B10354_06_039.jpg)'
- en: 'Expressed in Python, the KL divergence loss appears like the following code:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 用 Python 表达时，KL 散度损失如下所示的代码：
- en: '[PRE32]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Our final loss is then the mean of the sum of the reconstruction loss and KL
    divergence loss:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的损失是重建损失和 KL 散度损失之和的均值：
- en: '[PRE33]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Since we have used the Keras backend for all of the calculations, the resulting
    loss is a tensor that can be automatically differentiated. Now we can create our
    model as usual:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用了 Keras 后端进行所有计算，最终的损失是一个可以自动求导的张量。现在我们可以像往常一样创建我们的模型：
- en: '[PRE34]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Since we are using a custom loss, we have the loss separately, and we can''t
    just add it in the `compile` statement:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用了自定义损失，我们将损失分开处理，不能仅仅在 `compile` 语句中直接相加：
- en: '[PRE35]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now we will compile the model. Since our model already has a loss, we only
    have to specify the optimizer:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将编译模型。由于我们的模型已经有了损失，我们只需要指定优化器：
- en: '[PRE36]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Another side effect of the custom loss is that it compares the *output* of
    the VAE with the *input* of the VAE, which makes sense as we want to reconstruct
    the input. Therefore, we do not have to specify the *y* values, as only specifying
    an input is enough:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义损失的另一个副作用是它将 VAE 的 *输出* 与 VAE 的 *输入* 进行比较，这很有意义，因为我们想要重建输入。因此，我们不需要指定 *y*
    值，仅指定输入即可：
- en: '[PRE37]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In the next section we will learn how we can use a VAE to generate data.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习如何使用 VAE 来生成数据。
- en: Using a VAE to generate data
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 VAE 生成数据
- en: So, we've got our autoencoder, but how do we generate more data? Well, we take
    an input, say, a picture of a seven, and run it through the autoencoder multiple
    times. Since the autoencoder is randomly sampling from a distribution, the output
    will be slightly different at each run.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们已经得到了自动编码器，但我们如何生成更多的数据呢？我们通过输入，比如一张七的图片，并将其多次通过自动编码器。由于自动编码器是从一个分布中随机采样，每次运行时输出会略有不同。
- en: 'To showcase this, from our test data, we''re going to take a seven:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示这一点，我们将从测试数据中取出一个七：
- en: '[PRE38]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We then add a batch dimension and repeat the seven across the batch four times.
    After which we now have a batch of four, identical sevens:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们添加一个批次维度，并将七重复四次，构成一个四个相同七的批次：
- en: '[PRE39]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can then make a prediction on that batch, in which case, we get back the
    reconstructed sevens:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以对该批次进行预测，在这种情况下，我们会得到重建的七：
- en: '[PRE40]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The next step is broken in two parts. Firstly, we''re going to reshape all
    the sevens back into image form:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步分为两部分。首先，我们将把所有的七重塑回图像形式：
- en: '[PRE41]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then we are going to plot them:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将绘制它们：
- en: '[PRE42]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'As a result of running the code that we''ve just walked through, we''ll then
    see the following screenshot showing our four sevens as our output:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 运行我们刚刚讲解的代码后，我们将看到以下截图，显示我们四个七作为输出：
- en: '![Using a VAE to generate data](img/B10354_06_09.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![使用 VAE 生成数据](img/B10354_06_09.jpg)'
- en: A collection of sevens
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一组七
- en: As you can see, all of the images show a seven. While they look quite similar,
    if you look closely, you can see that there are several distinct differences.
    The seven on the top left has a less pronounced stroke than the seven on the bottom
    left. Meanwhile, the seven on the bottom right has a sight bow at the end.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，所有图像都显示的是七。虽然它们看起来相似，但如果仔细观察，你会发现几个明显的区别。左上角的七笔画比左下角的七要轻一些。与此同时，右下角的七在末端有一个轻微的弯曲。
- en: What we've just witnessed is the VAE successfully creating new data. While using
    this data for more training is not as good as compared to using using completely
    new real-world data, it is still very useful. While generative models such as
    this one are nice on the eye we will now discuss how this technique can be used
    for credit card fraud detection.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到的是VAE成功生成新数据。虽然使用这些数据进行更多的训练不如使用全新的真实世界数据效果好，但它仍然非常有用。尽管像这样的生成模型在视觉上很吸引人，我们现在将讨论如何将这种技术应用于信用卡欺诈检测。
- en: VAEs for an end-to-end fraud detection system
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于端到端欺诈检测系统的VAE
- en: 'To transfer the VAE from an MNIST example to a real fraud detection problem,
    all we have to do is change three hyperparameters: the input, the intermediate,
    and the latent dimensionality of the credit card VAE, which are all smaller than
    for the MNIST VAE. Everything else will remain the same:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将VAE从MNIST示例转移到实际的欺诈检测问题，我们只需要更改三个超参数：输入、隐层和潜在维度的大小，这些都比MNIST VAE的要小。其他的一切将保持不变：
- en: '[PRE43]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The following visualization shows the resulting VAE including both the input
    and output shapes:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下可视化展示了生成的VAE，包括输入和输出的形状：
- en: '![VAEs for an end-to-end fraud detection system](img/B10354_06_10.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![用于端到端欺诈检测系统的VAE](img/B10354_06_10.jpg)'
- en: Overview of the credit card VAE
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 信用卡VAE概览
- en: Armed with a VAE that can encode and generate credit card data, we can now tackle
    the task of an end-to-end fraud detection system. This can reduce bias in predictions
    as we can learn complicated rules directly from data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 凭借能够编码和生成信用卡数据的变分自编码器（VAE），我们现在可以着手处理端到端的欺诈检测系统任务。这可以减少预测中的偏差，因为我们可以直接从数据中学习复杂的规则。
- en: We are using the encoding part of the autoencoder as a feature extractor as
    well as a method to give us more data where we need it. How exactly that works
    will be covered in the section on active learning, but for now, let's take a little
    detour and look at how VAEs work for time series.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用自编码器的编码部分作为特征提取器，同时也作为一种在需要时为我们提供更多数据的方法。具体如何操作将在主动学习章节中详细讨论，但现在让我们稍作绕道，了解VAE如何在时间序列中工作。
- en: VAEs for time series
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列的VAE
- en: This section covers the how and why of time series VAEs and gives a couple of
    examples where they have been used. Time series are such a big topic in finance
    that [Chapter 4](ch04.xhtml "Chapter 4. Understanding Time Series"), *Understanding
    Time Series,* is heavily focused to it.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍时间序列VAE的原理和应用，并给出一些使用实例。时间序列在金融领域是一个庞大的话题，因此[第4章](ch04.xhtml "第4章：理解时间序列")，《理解时间序列》一章将大量聚焦于此。
- en: Autoencoders have found applications in connection to time series as they are
    able to encode a long time series into a single, descriptive vector. This vector
    can then, for example, be used to efficiently compare one time series to another
    time series, based on specific and complex patterns that cannot be captured with
    a simple correlation, for instance.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器在时间序列领域得到了应用，因为它们能够将长时间序列编码成一个单一的描述性向量。这个向量可以用于例如高效地将一个时间序列与另一个时间序列进行比较，基于特定的复杂模式，这些模式是简单相关性无法捕捉的。
- en: Consider the 2010 "Flash Crash." On May 6, 2010, starting at 02:32, US markets
    saw a major loss of value. The Dow Jones Industrial Average lost about 9%, which
    equates to about a trillion dollars' worth of value being wiped out in a couple
    of minutes. 36 minutes later, the crash was over, most of the lost value was regained,
    and people started wondering what on earth had just happened.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑2010年的“闪电崩盘”。2010年5月6日，从02:32开始，美国市场经历了大幅度的价值损失。道琼斯工业平均指数下跌了约9%，相当于在几分钟内消失了约一万亿美元的市场价值。36分钟后，崩盘结束，大部分失去的价值得以恢复，人们开始想知道刚刚发生了什么。
- en: Five years later, a man named Navinder Singh Sarao was arrested for having in
    part caused the flash crash and having made $40 million in the process. Sarao
    engaged in a practice called "spoofing" in which he used an automated bot to place
    large sell orders that could not be filled in the market but would drive prices
    down.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 五年后，一名叫Navinder Singh Sarao的男子因部分导致闪电崩盘并因此赚取4000万美元而被逮捕。Sarao从事一种叫做“虚假订单”的做法，利用自动化机器人下达大量无法成交的卖单，这些卖单会压低市场价格。
- en: The bot would leave the orders in the order books of the stock exchange for
    only a short period of time before canceling them. In the mean time, Sarao would
    buy the stock at the new lower prices and then profit when the stocks started
    rebounding after the canceled sales orders. While Sarao was certainly not the
    only one responsible for the flash crash, practices such as spoofing are now illegal,
    and exchanges, such as the NASDAQ (US), Tokyo (Japan), and Bombay (India) Stock
    Exchanges, now have to monitor and flag such cases.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这个机器人会将订单留在股票交易所的订单簿上短时间，然后取消它们。与此同时，Sarao 会以新的更低价格购买股票，并在被取消的销售订单之后，当股票开始反弹时获利。虽然
    Sarao 无疑不是闪崩事件的唯一责任人，但像虚假交易这样的做法现在已被禁止，像纳斯达克（美国）、东京（日本）和孟买（印度）证券交易所等交易所现在必须监控并标记此类情况。
- en: If you dig back into old blog posts about high-frequency trading, such as Bloomberg's
    *Spoofers Keep Markets Honest*, which you can view at [https://www.bloomberg.com/opinion/articles/2015-01-23/high-frequency-trading-spoofers-and-front-running](https://www.bloomberg.com/opinion/articles/2015-01-23/high-frequency-trading-spoofers-and-front-running),
    then you will find that some traders working at large firms openly recommend spoofing
    or front-running large orders, but that is a story for another time.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你翻阅一下关于高频交易的旧博客文章，比如 Bloomberg 的 *Spoofers Keep Markets Honest*，你可以在 [https://www.bloomberg.com/opinion/articles/2015-01-23/high-frequency-trading-spoofers-and-front-running](https://www.bloomberg.com/opinion/articles/2015-01-23/high-frequency-trading-spoofers-and-front-running)
    阅读到，它提到一些在大公司工作的交易员公开推荐进行虚假交易或前置交易大单，但那是另一个话题。
- en: How would we detect when someone engages in spoofing? One way is to use an autoencoder.
    By using a large amount of order book information, we can train an autoencoder
    to reconstruct "normal" trading behavior. For traders whose trading patterns deviate
    a lot from normal trading, the reconstruction loss of the trained autoencoder
    for the transaction will be quite high.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何检测某人在进行虚假交易？一种方法是使用自编码器。通过使用大量的订单簿信息，我们可以训练一个自编码器来重构“正常”的交易行为。对于那些交易模式偏离正常交易较多的交易者来说，经过训练的自编码器对于这些交易的重构误差会非常高。
- en: Another option is to train the autoencoder on different kinds of patterns, whether
    these are illegal or not, and then cluster the patterns in the latent space, just
    as we did for the fraudulent credit card transactions.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是训练自编码器，使用不同类型的模式，不论这些模式是否合法，然后将这些模式在潜在空间中进行聚类，就像我们处理欺诈信用卡交易时所做的那样。
- en: 'Recurrent neural networks (RNNs), by default, take in a time series and output
    a single vector. They can also output sequences if Keras'' `return_sequences`
    argument is set to `True`. Using recurrent neural networks such as LSTMs, building an autoencoder
    for time series can be done using the following code:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNNs）默认处理时间序列并输出单一向量。如果将 Keras 的 `return_sequences` 参数设置为 `True`，它们也可以输出序列。使用循环神经网络如
    LSTMs，可以通过以下代码构建时间序列的自编码器：
- en: '[PRE44]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let''s pause for a second and break down what we''ve just coded. As you can
    see, there are four key elements to this code:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍作停顿，分解一下我们刚刚编写的代码。如你所见，这段代码包含四个关键元素：
- en: A simple autoencoder is built using the sequential API.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个简单的自编码器是使用顺序 API 构建的。
- en: We first feed our sequence length, `maxlen`, along with the number of features equal
    to `nb_features` into an LSTM. The LSTM will only return its last output, a single
    vector of dimension `latent_dim`. This vector is the encoding of our sequence.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先将序列长度 `maxlen` 和等于 `nb_features` 的特征数量输入到 LSTM 中。LSTM 只会返回最后的输出，即一个维度为 `latent_dim`
    的单一向量。这个向量就是我们序列的编码。
- en: To decode the vector, we need to repeat it over the length of the time series.
    This is done by the `RepeatVector` layer.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要解码向量，我们需要在时间序列的长度上重复它。这是通过 `RepeatVector` 层来完成的。
- en: Now we feed the sequence of repeated encodings into a decoding LSTM, which this
    time returns the full sequence.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将重复的编码序列输入到解码 LSTM 中，这次它会返回整个序列。
- en: VAEs can also find their way into trading. They can be used to augment backtesting
    by generating new, unseen data for testing. Likewise, we can use VAEs to generate
    data about contracts where data is missing.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: VAEs 也可以进入交易领域。它们可以通过生成新的、未见过的数据来增强回测功能，从而进行测试。同样，我们可以使用 VAEs 生成缺失数据的合同数据。
- en: It is reasonable to assume that just because two market days look a bit different,
    the same forces might be at work. Mathematically, we can assume that market data
    ![VAEs for time series](img/B10354_06_040.jpg) is sampled from a probability distribution,
    *p(x),* with a small number of latent variables, *h*. Using an autoencoder, we
    can then approximate *p(h|x)*, the distribution of *h* given *x*. This will allow
    us to analyze the driving forces, *h*, in a market.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 合理的假设是，仅仅因为两个市场日看起来有些不同，可能是相同的力量在起作用。从数学上讲，我们可以假设市场数据 ![VAEs for time series](img/B10354_06_040.jpg)
    是从概率分布*p(x)*中抽样的，其中包含少量潜在变量*h*。通过使用自编码器，我们可以近似*p(h|x)*，即给定*x*时*h*的分布。这将使我们能够分析市场中的驱动因素*h*。
- en: This solves the problem that a standard maximum likelihood model for this kind
    of problem is computationally intractable. Two other methods performing the same
    feat are the *Markov Chain Monte Carlo* and *Hamilton Monte Carlo* methods. While
    neither will be covered in depth here, though they will be featured in later chapters,
    it's worth understanding that VAEs address long-standing problems in mathematical
    finance in a computationally tractable way.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这解决了一个问题，即对于这种问题，标准的最大似然模型在计算上是不可处理的。另有两种方法可以实现相同的目标，它们分别是*马尔科夫链蒙特卡洛*和*汉密尔顿蒙特卡洛*方法。尽管本文不会深入讨论这两种方法，它们将在后续章节中出现，但值得理解的是，变分自编码器（VAE）以计算上可处理的方式解决了数学金融中长期存在的问题。
- en: 'Generative models can also be used to solve problems beyond the scope of traditional
    methods. Financial markets are fundamentally adversarial environments in which
    investors are trying to achieve something that is impossible in aggregate: above-average
    returns. Knowing that a company is doing well is not enough: if everyone knows
    the company is doing well, then the stock price will be high and returns will
    be low. The key is knowing that a company is doing well while everyone else believes
    it is doing poorly. Markets are a zero-sum game-theoretic environment. GANs make
    use of these dynamics to generate realistic data.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型还可以用来解决超出传统方法范围的问题。金融市场本质上是对抗性环境，投资者试图达成在整体上不可能实现的目标：高于平均水平的回报。知道一家公司经营得很好是不够的：如果每个人都知道这家公司做得很好，那么股票价格就会很高，回报率就会很低。关键在于，在其他人认为公司做得很差的时候，能够知道公司做得很好。市场是一个零和博弈的环境。GANs利用这些动态生成逼真的数据。
- en: GANs
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GANs
- en: GANs work a lot like an art forger and a museum curator. Every day, the art
    forger tries to sell some fake art to the museum, and every day the curator tries
    to distinguish whether a certain piece is real or fake. The forger learns from
    their failures. By trying to fool the curator and observing what leads to success
    and failure, they become a better forger. But the curator learns too. By trying
    to stay ahead of the forger, they become a better curator. As time passes, the
    forgeries become better and so does the distinguishing process. After years of
    battle, the art forger is an expert that can draw just as well as Picasso and
    the curator is an expert that can distinguish a real painting by tiny details.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的工作方式很像一个艺术伪造者和一个博物馆馆长。每天，艺术伪造者试图将一些假艺术品卖给博物馆，而每天馆长则试图辨别某件艺术品是真的还是假的。伪造者从失败中学习。通过试图欺骗馆长，并观察什么导致成功和失败，他们变得越来越擅长伪造。但馆长也在学习。通过试图超越伪造者，他们变得更为精明。随着时间的推移，伪造品越来越好，辨别过程也越来越精确。经过多年的对抗，艺术伪造者成为了一个能与毕加索相媲美的高手，而馆长则成为了一个能通过微小细节辨别真伪的专家。
- en: 'Technically, a GAN consists of two neural networks: a *generator,* which produces
    data from a random latent vector, and a *discriminator,* which classifies data
    as "real," that is, stemming from the training set, or "fake," that is, stemming
    from the generator.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，GAN由两个神经网络组成：一个*生成器*，它从随机潜在向量生成数据，和一个*判别器*，它将数据分类为“真实”的，即来自训练集，或“假”的，即来自生成器。
- en: 'We can visualize a GAN scheme, as we can see in the following diagram:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下图示来直观地了解GAN的结构：
- en: '![GANs](img/B10354_06_11.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![GANs](img/B10354_06_11.jpg)'
- en: GAN scheme
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: GAN结构
- en: Once again, generative models are easier to understand when images are generated,
    so in this section, we will look at image data, although all kinds of data can
    be used.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，生成模型在生成图像时更容易理解，因此在本节中，我们将查看图像数据，尽管各种数据都可以使用。
- en: 'The training process for a GAN works as follows:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的训练过程如下所示：
- en: A latent vector containing random numbers is created.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含随机数的潜在向量。
- en: The latent vector is fed into the generator, which produces an image.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将潜在向量输入到生成器中，生成器生成一张图像。
- en: A set of fake images from the generator is mixed with a set of real images from
    the training set. The discriminator is trained in the binary classification of
    real and fake data.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 来自生成器的一组假图像与来自训练集的一组真实图像混合在一起。判别器在真实和假数据的二分类任务中进行训练。
- en: After the discriminator has been trained for a while we feed in the fake images
    again. This time, we set the label of the fake images to "real." We backpropagate
    through the discriminator and obtain the loss gradient with respect to the *input*
    of the discriminator. We do *not* update the weights of the discriminator based
    on this information.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在判别器训练一段时间后，我们再次输入假图像。这一次，我们将假图像的标签设为“真实”。我们通过判别器进行反向传播，并获得相对于判别器*输入*的损失梯度。我们*不*基于此信息更新判别器的权重。
- en: We now have gradients describing how we would have to change our fake image
    so that the discriminator would classify it as a real image. We use these gradients
    to backpropagate and train the generator.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在有了梯度，描述了我们需要如何改变假的图像，以便判别器将其分类为真实图像。我们使用这些梯度进行反向传播，并训练生成器。
- en: With our new and improved generator, we once again create fake images, which
    get mixed with real images in order to train the discriminator, whose gradients
    are used to train the generator again.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们新改进的生成器，我们再次创建假的图像，这些图像与真实图像混合在一起，用来训练判别器，其梯度将用于再次训练生成器。
- en: Note
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: GAN training has a lot of similarities to the visualization of the
    network layers that we discussed in [Chapter 3](ch03.xhtml "Chapter 3. Utilizing
    Computer Vision"), *Utilizing Computer Vision*, only this time we don''t just
    create one image that maximizes an activation function, instead we create a generative
    network that specializes in maximizing the activation function of another network.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：GAN 训练与我们在[第3章](ch03.xhtml "第3章。利用计算机视觉")，*利用计算机视觉*，中讨论的网络层可视化有很多相似之处，只不过这次我们不仅创建一个最大化激活函数的图像，而是创建一个生成网络，专门用于最大化另一个网络的激活函数。'
- en: 'Mathematically, generator *G* and discriminator *D* play a mini-max two-player
    game with the value function *V(G,D)*:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学上，生成器 *G* 和判别器 *D* 通过值函数 *V(G,D)* 玩一个最小-最大（mini-max）双人游戏：
- en: '![GANs](img/B10354_06_041.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![GANs](img/B10354_06_041.jpg)'
- en: In this formula *x* is an item drawn from the distribution of real data, ![GANs](img/B10354_06_042.jpg),
    and *z* is a latent vector drawn from the latent vector space, *p[z]*.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，*x* 是从真实数据分布中抽取的一个项，![GANs](img/B10354_06_042.jpg)，*z* 是从潜在向量空间 *p[z]*
    中抽取的一个潜在向量。
- en: The output distribution of the generator is noted as *p[g]*. It can be shown
    that the global optimum of this game is
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的输出分布记作 *p[g]*。可以证明，这个博弈的全局最优解是
- en: '![GANs](img/B10354_06_043.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![GANs](img/B10354_06_043.jpg)'
- en: ', that is, if the distribution of the generated data is equal to the distribution
    of actual data.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，如果生成数据的分布等于实际数据的分布。
- en: GANs get optimized following a game-theoretic value function. Solving this type
    of optimization problem with deep learning is an active area of research, and
    an area we will visit again in [Chapter 8](ch08.xhtml "Chapter 8. Privacy, Debugging,
    and Launching Your Products"), *Privacy, Debugging, and Launching Your Products,*
    where we will discuss reinforcement learning. The fact that deep learning can
    be used to solve Minimax games is exciting news for the field of finance and economics,
    which features many such problems.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 的优化遵循博弈论的值函数。使用深度学习解决这种类型的优化问题是一个活跃的研究领域，而我们将在[第8章](ch08.xhtml "第8章。隐私、调试和发布你的产品")，*隐私、调试和发布你的产品*，再次讨论强化学习。深度学习能够解决最小-最大博弈问题，对于金融和经济领域来说，这是一个令人兴奋的消息，因为这个领域有许多类似的问题。
- en: A MNIST GAN
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个 MNIST GAN
- en: 'Let''s now implement a GAN in order to generate MNIST characters. Before we
    start, we need to do some imports. GANs are large models, and in this section
    you will see how to combine sequential and functional API models for easy model
    building:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来实现一个 GAN，以生成 MNIST 字符。在开始之前，我们需要做一些导入。GAN 是大型模型，在这一节中，你将看到如何结合顺序模型和函数式
    API 模型，便于构建模型：
- en: '[PRE45]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In this example we will be using a few new layer types:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用一些新的层类型：
- en: '[PRE46]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let''s look at some of the key elements:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些关键要素：
- en: '`LeakyReLU` is just like ReLU, except that the activation allows for small
    negative values. This prevents the gradient from ever becoming zero. This activation
    function works well for GANs, something we will discuss in the next section:'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LeakyReLU`与ReLU相似，唯一不同的是该激活函数允许小的负值。这防止了梯度永远变为零。这个激活函数在GAN中效果很好，这是我们将在下一节讨论的内容：'
- en: '![A MNIST GAN](img/B10354_06_12.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![一个MNIST GAN](img/B10354_06_12.jpg)'
- en: Leaky ReLU
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: Leaky ReLU
- en: '`Reshape` does the same as `np.reshape`: it brings a tensor into a new form.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Reshape`与`np.reshape`功能相同：它将张量转换为新形式。'
- en: '`UpSampling2D` scales a 2D feature map up, for example, by a factor of two,
    by repeating all numbers in the feature map.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`UpSampling2D`可以将2D特征图按倍数缩放，例如，通过重复特征图中的所有数字来将其放大两倍。'
- en: 'We will be using the `Adam` optimizer as we often do:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将像往常一样使用`Adam`优化器：
- en: '[PRE47]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Neural network layers get initialized randomly. Usually, the random numbers
    are drawn from a distribution that supports learning well. For GANs, it turns
    out that a normal Gaussian distribution is a better alternative:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络层会随机初始化。通常，这些随机数是从支持良好学习的分布中抽取的。对于GANs，事实证明，正态高斯分布是一个更好的选择：
- en: '[PRE48]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now we''re going to build the generator model:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将构建生成器模型：
- en: '[PRE49]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Again, let''s take a look at the generator model code, which consists of 10
    key steps:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 再次让我们看看生成器模型的代码，它由10个关键步骤组成：
- en: We construct the generator as a sequential model.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将生成器构建为一个顺序模型。
- en: The first layer takes in the random latent vector and maps it to a vector with
    dimensions *128 * 7 * 7 = 6,272*. It already significantly expands the dimensionality
    of our generated data. For this fully connected layer, it is important to initialize
    weights from a normal Gaussian distribution with a relatively small standard deviation.
    A Gaussian distribution, as opposed to a uniform distribution, will have fewer
    extreme values, which will make training easier.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一层接收随机潜在向量，并将其映射到一个维度为*128 * 7 * 7 = 6,272*的向量。这已经显著扩展了我们生成数据的维度。对于这个全连接层，重要的是从一个标准差较小的正态高斯分布中初始化权重。与均匀分布不同，高斯分布的极端值较少，这将使训练变得更加容易。
- en: The activation function for the first layer is `LeakyReLU`. We need to specify
    how steep the slope for negative inputs is; in this case, negative inputs are
    multiplied with 0.2.
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一层的激活函数是`LeakyReLU`。我们需要指定负输入的斜率陡度；在这种情况下，负输入乘以0.2。
- en: Now we reshape our flat vector into a 3D tensor. This is the opposite of using
    a `Flatten` layer, which we did in [Chapter 3](ch03.xhtml "Chapter 3. Utilizing
    Computer Vision"), *Utilizing Computer Vision*. We now have a tensor with 128
    channels in a 7x7-pixel image or feature map.
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将扁平化的向量重新塑形为一个3D张量。这是与使用`Flatten`层相反的操作，后者我们在[第3章](ch03.xhtml "第3章. 利用计算机视觉")中使用过，*利用计算机视觉*。现在我们得到一个7x7像素图像或特征图中的128个通道的张量。
- en: Using `UpSampling2D`, we enlarge this image to 14x14 pixels. The `size` argument
    specifies the multiplier factor for width and height.
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`UpSampling2D`，我们将图像放大到14x14像素。`size`参数指定了宽度和高度的放大倍数。
- en: Now we can apply a standard `Conv2D` layer. As opposed to the case with most
    image classifiers, we use a relatively large kernel size of 5x5 pixels.
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以应用一个标准的`Conv2D`层。与大多数图像分类器的情况不同，我们使用相对较大的5x5像素卷积核大小。
- en: The activation following the `Conv2D` layer is another `LeakyReLU`.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 紧随`Conv2D`层之后的激活函数是另一个`LeakyReLU`。
- en: We upsample again, bringing the image to 28x28 pixels, the same dimensions as
    an MNIST image.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们再次进行上采样，将图像放大到28x28像素，与MNIST图像的尺寸相同。
- en: The final convolutional layer of our generator outputs only a single channel
    image, as MNIST images are only black and white. Notice how the activation of
    this final layer is a `tanh` activation. `Tanh` squishes all values to between
    negative one and one. This might be unexpected as image data usually does not
    feature any values below zero. Empirically, it turned out, however, that `tanh`
    activations work much better for GANs than `sigmoid` activations.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们生成器的最终卷积层输出只有一个单通道图像，因为MNIST图像是黑白的。注意到这一层的激活函数是`tanh`激活。`Tanh`将所有值压缩到-1到1之间。这可能出乎意料，因为图像数据通常不会包含负值。然而，经过经验验证，`tanh`激活对于GAN效果要优于`sigmoid`激活。
- en: Finally, we compile the generator to train with the `Adam` optimizer with a
    very small learning rate and smaller-than-usual momentum.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们编译生成器，使用`Adam`优化器进行训练，并设置一个非常小的学习率和比通常更小的动量。
- en: 'The discriminator is a relatively standard image classifier that classifies
    images as real or fake. There are only a few GAN-specific modifications:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器是一个相对标准的图像分类器，用于将图像分类为真实或虚假。只有少数几个 GAN 特有的修改：
- en: '[PRE50]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'There are two key elements here:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个关键要素：
- en: As with the generator, the first layer of the discriminator should be initialized
    randomly from a Gaussian distribution.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与生成器一样，判别器的第一层应从高斯分布中随机初始化。
- en: Dropout is commonly used in image classifiers. For GANs, it should also be used
    just before the last layer.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dropout 在图像分类器中是常用的。对于 GAN，也应该在最后一层之前使用。
- en: Now we have both a generator and a discriminator. To train the generator, we
    have to get the gradients from the discriminator to backpropagate through and
    train the generator. This is where the power of Keras' modular design comes into
    play.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了生成器和判别器。为了训练生成器，我们需要从判别器获取梯度并通过反向传播来训练生成器。这正是 Keras 模块化设计的强大之处。
- en: Note
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: Keras models can be treated just like Keras layers.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：Keras 模型可以像 Keras 层一样处理。'
- en: 'The following code creates a GAN model that can be used to train the generator
    from the discriminator gradients:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码创建了一个可以用来从判别器梯度训练生成器的 GAN 模型：
- en: '[PRE51]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Within that code, there are six key stages:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，有六个关键阶段：
- en: When training the generator, we do not want to train `discriminator`. When setting
    `discriminator` to non-trainable, the weights are frozen only for the model that
    is compiled with the non-trainable weights. That is, we can still train the `discriminator`
    model on its own, but as soon as it becomes part of the GAN model that is compiled
    again, its weights are frozen.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练生成器时，我们不希望训练`discriminator`。当将`discriminator`设置为不可训练时，权重只会在与不可训练权重一起编译的模型中被冻结。也就是说，我们仍然可以单独训练`discriminator`模型，但一旦它成为再次编译的
    GAN 模型的一部分，它的权重就会被冻结。
- en: We create a new input for our GAN, which takes in the random latent vector.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为我们的 GAN 创建一个新的输入，它接收随机潜在向量。
- en: We connect the generator model to the `ganInput` layer. The model can be used
    just like a layer under the functional API.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将生成器模型连接到`ganInput`层。该模型可以像函数式 API 下的层一样使用。
- en: We now connect the discriminator with frozen weights to the generator. Again,
    we call the model in the same way we would use a layer in the functional API.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将带有冻结权重的判别器连接到生成器。再次地，我们像在函数式 API 中使用层一样调用模型。
- en: We create a model that maps an input to the output of the discriminator.
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个将输入映射到判别器输出的模型。
- en: We compile our GAN model. Since we call `compile` here, the weights of the discriminator
    model are frozen for as long as they are part of the GAN model. Keras will throw
    a warning on training time that the weights are not frozen for the actual discriminator
    model.
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们编译我们的 GAN 模型。由于我们在此调用了`compile`，判别器模型的权重会在它们作为 GAN 模型的一部分时被冻结。Keras 在训练时会发出警告，表明实际的判别器模型的权重未被冻结。
- en: 'Training our GAN requires some customization of the training process and a
    couple of GAN-specific tricks as well. More specifically, we have to write our
    own training loop, something that we''ll achieve with the following code:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 训练我们的 GAN 需要对训练过程进行一些定制，并且还需要一些 GAN 特有的技巧。更具体地说，我们必须编写自己的训练循环，下面的代码将实现这一目标：
- en: '[PRE52]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'That was a lot of code we just introduced. So, let''s take a minute to pause
    and think about the 16 key steps:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码刚才介绍了很多内容。让我们暂停一下，思考一下这16个关键步骤：
- en: We have to write a custom loop to loop over the batches. To know how many batches
    there are, we need to make an integer division of our dataset size by our batch
    size.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们必须编写一个自定义循环来遍历批次。要知道有多少个批次，我们需要将数据集大小除以批次大小并进行整数除法。
- en: In the outer loop, we iterate over the number of epochs we want to train.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在外部循环中，我们遍历要训练的 epoch 数量。
- en: In the inner loop, we iterate over the number of batches we want to train on
    in each epoch. The `tqdm` tool helps us keep track of progress within the batch.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在内部循环中，我们遍历每个 epoch 中要训练的批次数量。`tqdm`工具帮助我们跟踪批次的进度。
- en: We create a batch of random latent vectors.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一批随机潜在向量。
- en: We randomly sample a batch of real MNIST images.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随机抽取一批真实的 MNIST 图像。
- en: We use the generator to generate a batch of fake MNIST images.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用生成器生成一批虚假的 MNIST 图像。
- en: We stack the real and fake MNIST images together.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将真实和虚假的 MNIST 图像堆叠在一起。
- en: We create the target for our discriminator. Fake images are encoded with 0, and
    real images with 0.9\. This technique is called soft labels. Instead of hard labels
    (zero and one), we use something softer in order to not train the GAN too aggressively.
    This technique has been shown to make GAN training more stable.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为判别器创建目标。假图像编码为0，真实图像编码为0.9。这种技术称为软标签。与硬标签（0和1）不同，我们使用更柔和的标签，以免过于激进地训练GAN。研究表明，这种技术可以使GAN训练更加稳定。
- en: On top of using soft labels, we add some noise to the labels. This, once again,
    will make the training more stable.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了使用软标签外，我们还向标签中添加了一些噪声。这将再次使训练更加稳定。
- en: We make sure that the discriminator is trainable.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们确保判别器是可训练的。
- en: We train the discriminator on a batch of real and fake data.
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在一批真实和假数据上训练判别器。
- en: We create some more random latent vectors for training the generator.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为训练生成器创建更多的随机潜在向量。
- en: The target for generator training is always one. We want the discriminator to
    give us the gradients that would have made a fake image look like a real one.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成器训练的目标始终是1。我们希望判别器给出那些能让假图像看起来像真实图像的梯度。
- en: Just to be sure, we set the discriminator to be non-trainable, so that we can
    not break anything by accident.
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确保万无一失，我们将判别器设置为不可训练，以避免不小心破坏任何东西。
- en: We train the GAN model. We feed in a batch of random latent vectors and train
    the generator part of the GAN so that the discriminator part will classify the
    generated images as real.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们训练GAN模型。我们输入一批随机的潜在向量，训练GAN的生成器部分，以使判别器部分能够将生成的图像分类为真实的。
- en: We save the losses from training.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们保存训练中的损失值。
- en: 'In the following figure, you can see some of the generated MNIST characters:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，你可以看到一些生成的MNIST字符：
- en: '![A MNIST GAN](img/B10354_06_13.jpg)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST GAN](img/B10354_06_13.jpg)'
- en: GAN-generated MNIST characters
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: GAN生成的MNIST字符
- en: Most of these characters look like identifiable numbers, although some, such
    as those in the bottom left and right, seem a bit off.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数字符看起来像可识别的数字，尽管一些字符（例如左下角和右下角的字符）看起来有些不太对劲。
- en: The code that we wrote and explored is now outputted in the following chart,
    showing us the Discriminitive and Generative loss of an increasing number of Epochs.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写并探索的代码现在在以下图表中输出，展示了随着Epoch次数增加，判别器和生成器的损失。
- en: '![A MNIST GAN](img/B10354_06_14.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST GAN](img/B10354_06_14.jpg)'
- en: GAN training progress
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: GAN训练进展
- en: Note that the loss in GAN training is not interpretable as it is for supervised
    learning. The loss of a GAN will not decrease even as the GAN makes progress.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，GAN训练中的损失无法像监督学习中那样解释。即使GAN有所进展，其损失也不会下降。
- en: The loss of a generator and discriminator is dependent on how well the other
    model does. If the generator gets better at fooling the discriminator, then the
    discriminator loss will stay high. If one of the losses goes to zero, it means
    that the other model lost the race and cannot fool or properly discriminate the
    other model anymore.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器的损失取决于另一个模型的表现。如果生成器在欺骗判别器方面变得更强，判别器的损失就会保持较高。如果其中一个损失降到零，意味着另一个模型在比赛中失败，无法再欺骗或正确区分另一个模型。
- en: 'This is one of the things that makes GAN training so hard: **GANs don''t converge
    to a low loss solution**; they converge to an *equilibrium* in which the generator
    fools the discriminator not all the time, but many times. That equilibrium is
    not always stable. Part of the reason so much noise is added to labels and the
    networks themselves is that it increases the stability of the equilibrium.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是让GAN训练如此困难的原因之一：**GAN并不会收敛到低损失的解**；它们收敛到一种*平衡*状态，其中生成器并不是每次都能欺骗判别器，而是很多时候能做到。这个平衡状态并不总是稳定的。往标签和网络本身添加大量噪声的部分原因是，它增加了平衡状态的稳定性。
- en: As GANs are unstable and difficult, yet useful, a number of tricks has been
    developed over time that makes GAN training more stable. Knowing these tricks
    can help you with your GAN building process and save you countless hours, even
    though there is often no theoretical reason for why these tricks work.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GAN不稳定且难以训练，但又非常有用，因此随着时间的推移，已经开发出了许多技巧，使得GAN训练更加稳定。了解这些技巧可以帮助你在构建GAN时节省无数小时，即使这些技巧背后往往没有理论依据。
- en: Understanding GAN latent vectors
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解GAN的潜在向量
- en: For autoencoders, the latent space was a relatively straightforward approximation
    of PCA. VAEs create a latent space of distributions, which is useful but still
    easy to see as a form of PCA. So, what is the latent space of a GAN if we just
    sample randomly from it during training? As it turns out, GANs self-structure
    the latent space. Using the latent space of a GAN, you would still be able to
    cluster MNIST images by the characters they display.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自编码器，潜在空间是 PCA 的相对简单的近似。VAE 创建了一个分布的潜在空间，这虽然有用，但仍然可以视为 PCA 的一种形式。那么，如果我们在训练过程中仅从中随机采样，GAN
    的潜在空间是什么样的呢？事实证明，GANs 会自我构建潜在空间。使用 GAN 的潜在空间，你仍然可以根据显示的字符将 MNIST 图像聚类。
- en: Research has shown that the latent space of GANs often has some surprising features,
    such as "smile vectors," which arrange face images according to the width of the
    person's smile. Researchers have also shown that GANs can be used for latent space
    algebra, where adding the latent representation of different objects creates realistic,
    new objects. Yet, research on the latent space of GANs is still in its infancy
    and drawing conclusions about the world from its latent space representations
    is an active field of research.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，GANs 的潜在空间通常具有一些令人惊讶的特征，例如“笑容向量”，它们根据人们笑容的宽度排列面部图像。研究人员还表明，GANs 可以用于潜在空间代数，其中不同物体的潜在表示相加，可以创建现实的、新的物体。然而，关于
    GANs 潜在空间的研究仍处于起步阶段，从其潜在空间表示中推断世界的规律仍然是一个活跃的研究领域。
- en: GAN training tricks
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GAN 训练技巧
- en: 'GANs are tricky to train. They might collapse, diverge, or fail in a number
    of different ways. Researchers and practitioners have come up with a number of
    tricks that make GANs work better. While it may seem odd, it''s not known why
    these work, but all that matters to us is that they help in practice:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 的训练非常棘手。它们可能会崩溃、发散，或者以多种不同的方式失败。研究人员和实践者提出了许多技巧，使 GANs 更好地工作。虽然这可能看起来很奇怪，但我们并不清楚为什么这些方法有效，不过对我们来说，重要的是它们在实践中确实有帮助：
- en: '**Normalize the inputs**: GANs don''t work well with extreme values, so make
    sure you always have normalized inputs between -1 and 1\. This is also the reason
    why you should use the tanh function as your generator output.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规范化输入**：GANs 对极端值处理不好，所以确保你始终将输入规范化到 -1 和 1 之间。这也是为什么你应该使用 tanh 函数作为生成器输出的原因。'
- en: '**Don''t use the theoretical correct loss function**: If you read papers on
    GANs, you will find that they give the generator optimization goal as the following
    formula:![GAN training tricks](img/B10354_06_044.jpg)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要使用理论上的正确损失函数**：如果你读过关于 GANs 的论文，你会发现它们给出的生成器优化目标是以下公式：![GAN 训练技巧](img/B10354_06_044.jpg)'
- en: 'In this formula, *D* is the discriminator output. In practice, it works better
    if the objective of the generator is this:'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个公式中，*D* 是判别器的输出。实际上，如果生成器的目标是这样的，它会更有效：
- en: '![GAN training tricks](img/B10354_06_044-1.jpg)'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![GAN 训练技巧](img/B10354_06_044-1.jpg)'
- en: In other words, instead of minimizing the negative discriminator output, it is
    better to maximize the discriminator output. The reason is that the first objective
    often has vanishing gradients at the beginning of the GAN training process.
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 换句话说，与其最小化负的判别器输出，不如最大化判别器输出。原因是，第一个目标通常在 GAN 训练的初期会出现梯度消失的情况。
- en: '**Sample from a normal Gaussian distribution**: There are two reasons to sample
    from normal distributions instead of uniform distributions. First, GANs don''t
    work well with extreme values, and normal distributions have fewer extreme values
    than uniform distributions. Additionally, it has turned out that if the latent
    vectors are sampled from a normal distribution, then the latent space becomes
    a sphere. The relationships between latent vectors in this sphere are easier to
    describe than latent vectors in a cube space.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从正态高斯分布中采样**：从正态分布中采样而不是均匀分布有两个原因。首先，GANs 对极端值处理不好，而正态分布相比均匀分布包含较少的极端值。此外，事实证明，如果潜在向量是从正态分布中采样的，那么潜在空间会变成一个球体。这个球体中潜在向量之间的关系比立方体空间中的潜在向量关系更容易描述。'
- en: '**Use batch normalization**: We''ve already seen that GANs don''t work well
    with extreme values since they are so fragile. Another way to reduce extreme values
    is to use batch normalization, as we discussed in [Chapter 3](ch03.xhtml "Chapter 3. Utilizing
    Computer Vision"), *Utilizing Computer Vision*.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用批量归一化**：我们已经看到，由于 GANs 非常脆弱，它们对极端值的处理不好。减少极端值的另一种方法是使用批量归一化，正如我们在[第 3 章](ch03.xhtml
    "第 3 章. 利用计算机视觉")中讨论的，*利用计算机视觉*。'
- en: '**Use separate batches for real and fake data**: In the beginning of this process,
    real and fake data might have very different distributions. As batch norm applies
    normalization over a batch, using the batches'' mean and standard deviation, it
    is more advisable to keep the real and fake data separate. While this does lead
    to slightly less accurate gradient estimates, the gain from fewer extreme values
    is great.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为真实数据和假数据使用不同的批次**：在这个过程的初期，真实数据和假数据的分布可能差异很大。由于批量归一化是基于批次的均值和标准差进行标准化，因此最好将真实数据和假数据分开使用。虽然这样做会导致梯度估计稍微不准确，但由于极端值减少，这样的做法会带来较大的收益。'
- en: '**Use soft and noisy labels**: GANs are fragile; the use of soft labels reduces
    the gradients and keeps the gradients from tipping over. Adding some random noise
    to labels also helps to stabilize the system.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用软标签和噪声标签**：GANs非常脆弱，使用软标签可以减少梯度并避免梯度过大。向标签中添加一些随机噪声也有助于稳定系统。'
- en: '**Use basic GANs**: There is now a wide range of GAN models. Many of them claim
    wild performance improvements, whereas in reality they do not work much better,
    and are often worse, than a simple **deep convolutional generative adversarial
    network,** or **DCGAN**. That does not mean they have no justification for existing,
    but for the bulk of tasks, more basic GANs will perform better. Another GAN that
    works well is the adversarial autoencoder, which combines a VAE with a GAN by
    training the autoencoder on the gradients of a discriminator.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用基本的GAN**：现在有很多不同的GAN模型。许多模型声称性能有显著提升，但实际上它们的效果并不比简单的**深度卷积生成对抗网络（DCGAN）**好，甚至往往更差。这并不意味着这些模型没有存在的理由，但对于大多数任务来说，基础的GAN模型表现会更好。另一个表现良好的GAN是对抗自编码器，它通过在判别器的梯度上训练自编码器，将VAE与GAN结合起来。'
- en: '**Avoid ReLU and MaxPool**: ReLU activations and MaxPool layers are frequently
    used in deep learning, but they have the disadvantage of producing "sparse gradients."
    A ReLU activation will not have any gradient for negative inputs, and a MaxPool
    layer will not have any gradients for all inputs that were not the maximum input.
    Since gradients are what the generator is being trained on, sparse gradients will
    hurt generator training.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**避免使用ReLU和MaxPool**：ReLU激活函数和MaxPool层在深度学习中常被使用，但它们的缺点是产生“稀疏梯度”。ReLU激活函数对于负输入没有梯度，MaxPool层对于非最大输入也没有梯度。由于梯度是训练生成器的关键，稀疏梯度会影响生成器的训练效果。'
- en: '**Use the Adam optimizer**: This optimizer has been shown to work very well
    with GANs, while many other optimizers do not work well with them.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用Adam优化器**：研究表明，这种优化器在GANs中表现非常好，而许多其他优化器则不适用于它们。'
- en: '**Track failures early**: Sometimes, GANs can fail for random reasons. Just
    choosing the "wrong" random seed could set your training run up for failure. Usually,
    it is possible to see whether a GAN goes completely off track by observing outputs.
    They should slowly become more like real data.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尽早跟踪失败**：有时，GANs可能由于随机原因失败。仅仅选择一个“错误”的随机种子就可能导致训练失败。通常，通过观察输出，可以判断GAN是否完全偏离了正确的轨道。输出应该逐渐变得越来越像真实数据。'
- en: If the generator goes completely off track and produces only zeros, for instance,
    you will be able to see it before spending days of GPU time on training that will
    go nowhere.
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果生成器完全偏离轨道并且只输出零，比如说，你可以在浪费几天GPU时间进行无效训练之前就察觉到这一点。
- en: '**Don''t balance loss via statistics**: Keeping the balance between the generator
    and discriminator is a delicate task. Many practitioners, therefore, try to help
    the balance by training either the generator or discriminator a bit more depending
    on statistics. Usually, that does not work. GANs are very counterintuitive and
    trying to help them with an intuitive approach usually makes matters worse. That
    is not to say there are no ways to help out GAN equilibriums, but the help should
    stem from a principled approach, such as "train the generator while the generator
    loss is above *X*."'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不要通过统计来平衡损失**：保持生成器和判别器之间的平衡是一项微妙的任务。因此，许多从业者试图通过根据统计信息多训练生成器或判别器来帮助平衡。通常，这样做并不起作用。GANs是非常反直觉的，试图用直觉的方法来帮助它们，通常会让事情变得更糟。这并不是说没有办法帮助GAN的平衡，但是帮助应该来自于一种有原则的方法，例如“在生成器损失高于*X*时训练生成器”。'
- en: '**If you have labels, use them**: A slightly more sophisticated version of
    a GAN discriminator can not only classify data as real or fake but also classify
    the class of the data. In the MNIST case, the discriminator would have 11 outputs:
    an output for the 10 real numbers as well as an output for a fake. This allows
    us to create a GAN that can show more specific images. This is useful in the domain
    of semi-supervised learning, which we will cover in the next section.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如果你有标签，使用它们**：一个稍微复杂一点的 GAN 判别器版本，不仅能将数据分类为真实或假，还能分类数据的类别。在 MNIST 的案例中，判别器会有
    11 个输出：10 个真实数字的输出以及一个假的输出。这使得我们可以创建一个能够展示更具体图像的 GAN。这在半监督学习领域非常有用，我们将在下一节讨论这个话题。'
- en: '**Add noise to inputs, reduce it over time**: Noise adds stability to GAN training
    so it comes as no surprise that noisy inputs can help, especially in the early,
    unstable phases of training a GAN. Later, however, it can obfuscate too much and
    keep the GAN from generating realistic images. So, we should reduce the noise
    applied to inputs over time.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向输入添加噪声，随着时间减少噪声**：噪声能够增加 GAN 训练的稳定性，因此噪声输入有助于训练，尤其是在 GAN 训练的早期不稳定阶段。然而，随着训练的进行，噪声可能会干扰过多，从而阻止
    GAN 生成逼真的图像。所以，我们应该随着时间的推移减少输入中的噪声。'
- en: '**Use dropouts in G in both the train and test phases**: Some researchers find
    that using dropout on inference time leads to better results for the generated
    data. Why that is the case is still an open question.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在训练和测试阶段都在生成器中使用 dropout**：一些研究者发现，在推理时使用 dropout 会得到更好的生成数据结果。为什么会这样，仍然是一个悬而未决的问题。'
- en: '**Historical averaging**: GANs tend to "oscillate," with their weights moving
    rapidly around a mean during training. Historical averaging penalizes weights
    that are too far away from their historical average and reduces oscillation. It,
    therefore, increases the stability of GAN training.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**历史平均**：GAN 在训练过程中往往会“振荡”，其权重在均值周围快速变化。历史平均会惩罚那些偏离历史平均值过远的权重，并减少振荡。因此，它能够提高
    GAN 训练的稳定性。'
- en: '**Replay buffers**: Replay buffers keep a number of older generated images
    so they can be reused for training the discriminator. This has a similar effect
    as historical averaging, reducing oscillation and increasing stability. It also
    reduces the correlation and the test data.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回放缓冲区**：回放缓冲区保存一些较早生成的图像，以便它们可以被重新用于训练判别器。这和历史平均有类似的效果，可以减少振荡并提高稳定性。它还减少了与测试数据的相关性。'
- en: '**Target networks**: Another "anti-oscillation" trick is to use target networks.
    That is, to create copies of both the generator and discriminator, and then train
    the generator with a frozen copy of the discriminator and train the discriminator
    with a frozen copy of the generator.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标网络**：另一种“反振荡”技巧是使用目标网络。即创建生成器和判别器的副本，然后使用冻结的判别器副本训练生成器，使用冻结的生成器副本训练判别器。'
- en: '**Entropy regularization**: Entropy regularization means rewarding the network
    for outputting more different values. This can prevent the generator network from
    settling on a few things to produce, say, only the number seven. It is a regularization
    method as it prevents overfitting.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**熵正则化**：熵正则化意味着奖励网络输出更多不同的值。这可以防止生成器网络固守在某些特定的输出上，例如只生成数字 7。它是一种正则化方法，因为它可以防止过拟合。'
- en: '**Use dropout or noise layers**: Noise is good for GANs. Keras not only features
    dropout layers, but it also features a number of noise layers that add different
    kinds of noise to activations in a network. You can read the documentation of
    these layers to see whether they are helpful for your specific GAN application:
    [https://keras.io/layers/noise/](https://keras.io/layers/noise/).'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 dropout 或噪声层**：噪声对 GAN 是有益的。Keras 不仅具有 dropout 层，还提供了多种噪声层，可以向网络的激活添加不同种类的噪声。你可以阅读这些层的文档，查看它们是否对你的
    GAN 应用有帮助：[https://keras.io/layers/noise/](https://keras.io/layers/noise/)。'
- en: Using less data – active learning
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用更少的数据 – 主动学习
- en: Part of the motivation for generative models, be they GANs or VAEs, was always
    that they would allow us to generate data and therefore require less data. As
    data is inherently sparse, especially in finance, and we never have enough of
    it, generative models seem as though they are the free lunch that economists warn
    us about. Yet even the best GAN works with *no* data. In this section, we will
    have a look at the different methods used to bootstrap models with as little data
    as possible. This method is also called active learning or semi-supervised learning.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型的部分动机，无论是GAN还是VAE，始终是它们可以帮助我们生成数据，从而减少对数据的需求。由于数据本质上是稀疏的，尤其是在金融领域，而且我们永远都不会拥有足够的数据，生成模型看起来像是经济学家警告我们不要相信的“免费午餐”。然而，即便是最好的GAN也能在*没有*数据的情况下工作。在本节中，我们将看看使用尽可能少的数据来启动模型的不同方法。该方法也被称为主动学习或半监督学习。
- en: '**Unsupervised learning** uses unlabeled data to cluster data in different
    ways. An example is autoencoders, where images can be transformed into learned
    and latent vectors, which can then be clustered without the need for labels that
    describe the image.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '**无监督学习**使用未标记的数据以不同方式对数据进行聚类。一个例子是自编码器，其中图像可以转化为学习到的潜在向量，这些向量随后可以进行聚类，而无需描述图像的标签。'
- en: '**Supervised learning** uses data with labels. An example is the image classifier
    we built in [Chapter 3](ch03.xhtml "Chapter 3. Utilizing Computer Vision"), *Utilizing
    Computer Vision,* or most of the other models that we''ve built in this book.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习**使用带标签的数据。一个例子是我们在[第3章](ch03.xhtml "第3章. 利用计算机视觉")中构建的图像分类器，*利用计算机视觉*，或者我们在本书中构建的大多数其他模型。'
- en: '**Semi-supervised learning** aims to perform tasks usually done by supervised
    models, but with less data at hand and using either unsupervised or generative
    methods. There are three ways this can work: firstly, by making smarter use of
    humans; secondly, by making better use of unlabeled data, and thirdly, by using
    generative models.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '**半监督学习**旨在执行通常由监督模型完成的任务，但手头的数据较少，并且使用无监督或生成方法。有三种方式可以实现这一点：首先，通过更聪明地利用人类；其次，通过更好地利用未标记数据；第三，通过使用生成模型。'
- en: Using labeling budgets efficiently
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高效使用标签预算
- en: For all the talk about AI replacing humans, an awful lot of humans are required
    to train AI systems. Although the numbers are not clear, it's a safe bet that
    there are between 500,000 and 750,000 registered "Mechanical Turkers" on Amazon's
    MTurk service.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关于人工智能取代人类的讨论很多，但实际上训练AI系统仍然需要大量人类。虽然具体数字不清楚，但可以合理推测，亚马逊MTurk服务上注册的“机械土耳工”人数在500,000到750,000之间。
- en: MTurk is an Amazon website that offers, according to its own site, "Human intelligence
    through an API." In practice, this means that companies and researchers post simple
    jobs such as filling out a survey or classifying an image and people all over
    the world perform these tasks for a few cents per task. For an AI to learn, humans
    need to provide labeled data. If the task is large scale, then many companies
    will hire MTurk users in order to let humans do the labeling. If it is a small
    task, you will often find the company's own staff labeling the data.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: MTurk是亚马逊提供的一个网站，根据其自己的网站，提供“通过API实现的人类智能。”实际上，这意味着公司和研究人员发布简单的任务，如填写调查问卷或分类图像，全球各地的人们为这些任务支付少量费用。为了让AI学习，人类需要提供标注数据。如果任务规模较大，许多公司会雇佣MTurk用户来进行标注。如果任务较小，通常会是公司的员工来标注数据。
- en: 'Surprisingly little thought goes into what these humans label. Not all labels
    are equally useful. The following diagram shows a linear classifier. As you can
    see, the frontier point, which is close to the frontier between the two classes,
    determines where the decision boundary is, while the points further in the back
    are not as relevant:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，关于这些人类标注的内容，考虑得并不多。并非所有标签都是同等有用的。下图展示了一个线性分类器。正如你所看到的，靠近两个类之间的边界点决定了决策边界的位置，而那些距离较远的点则不那么相关：
- en: '![Using labeling budgets efficiently](img/B10354_06_15.jpg)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![高效使用标签预算](img/B10354_06_15.jpg)'
- en: Frontier points are more valuable
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 边界点更有价值
- en: 'As such, the frontier points are more valuable than points further away from
    the decision boundary. You can train on less data by doing the following:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，边界点比远离决策边界的点更有价值。你可以通过以下方式在更少的数据上进行训练：
- en: Labeling only a few images
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只标注少量图像
- en: Training a weak model
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个弱模型
- en: Letting that weak model make predictions for some unlabeled images
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让这个弱模型对一些未标记的图像进行预测
- en: Labeling the images that the model is least confident about and adding them
    to your training set
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标记模型最不确定的图像，并将其添加到训练集中
- en: Repeating the process
  id: totrans-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复这个过程
- en: This process of labeling data is much more efficient than just randomly labeling
    data and can accelerate your efforts quite drastically.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这种标注数据的过程比随机标注数据要高效得多，能够显著加速你的工作进程。
- en: Leveraging machines for human labeling
  id: totrans-403
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用机器进行人工标注
- en: In labeling, many companies rely on Microsoft Excel. They have human labelers
    look at something to label, such as an image or a text, and then that person will
    type the label into an Excel spreadsheet. While this is incredibly inefficient
    and error prone, it's a common practice. Some slightly more advanced labeling
    operations include building some simple web applications that let the user see
    the item to label and directly click on the label or press a hotkey. This can
    accelerate the labeling process quite substantially. However, it's still not optimal
    if there are a large number of label categories.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在标注过程中，许多公司依赖于 Microsoft Excel。他们让人工标注员查看需要标注的内容，如图像或文本，然后该人员将标签输入到 Excel 表格中。虽然这种方法极为低效且容易出错，但仍然是一种常见做法。一些稍微高级的标注操作包括构建简单的
    Web 应用程序，让用户查看需要标注的项目，并直接点击标签或按快捷键。这可以显著加速标注过程。然而，如果标签类别非常多，这种方法仍然不是最优的。
- en: Another way is to once again label a few images and pretrain a weak model. At
    the point where the labeling takes place, the computer shows the labeler the data
    as well as a label. The labeler only has to decide whether this label is correct.
    This can be done easily with hotkeys and the time it takes to label a single item
    goes down dramatically. If the label was wrong, the label interface can either
    bring up a list of possible options, sorted by the probability the model assigned
    to them, or just put the item back on the stack and display the next most likely
    label the next time.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是再次标注一些图像并预训练一个弱模型。在标注过程中，计算机会向标注员展示数据和标签。标注员只需要决定这个标签是否正确。这可以通过快捷键轻松完成，标注一个项目所需的时间大幅缩短。如果标签错误，标注界面可以弹出一个可能的标签选项列表，并按模型赋予的概率排序，或者直接将该项目放回堆栈，下次显示下一个最可能的标签。
- en: 'A great implementation of this technique is "Prodigy," a labeling tool by the
    company that makes spaCy, which we learned about in [Chapter 5](ch05.xhtml "Chapter 5. Parsing
    Textual Data with Natural Language Processing"), *Parsing Textual Data with Natural
    Language Processing*, we can see an example of the Prodigy tool in the following
    screenshot:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术的一个很好的实现是“Prodigy”，这是由制作 spaCy 的公司开发的一个标注工具，我们在[第 5 章](ch05.xhtml "第 5 章：使用自然语言处理解析文本数据")，《*使用自然语言处理解析文本数据*》中学到了这个工具，我们可以在以下屏幕截图中看到
    Prodigy 工具的示例：
- en: '![Leveraging machines for human labeling](img/B10354_06_16.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![利用机器进行人工标注](img/B10354_06_16.jpg)'
- en: Screenshot of the Prodigy labeling tool
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: Prodigy 标注工具的屏幕截图
- en: 'Prodigy is a labeling tool that leverages machines, you can find more out about
    it by reading its official documentation here: [https://prodi.gy/](https://prodi.gy/).'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: Prodigy 是一个利用机器的标注工具，你可以通过阅读其官方文档了解更多信息：[https://prodi.gy/](https://prodi.gy/)。
- en: Note
  id: totrans-410
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: A better user interface design and smart implementation of weak models
    can greatly accelerate the speed and quality of labeling.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：更好的用户界面设计和智能的弱模型实现可以大大加速标注的速度和质量。'
- en: Pseudo labeling for unlabeled data
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对未标记数据进行伪标签处理
- en: Often there is plenty of unlabeled data available, but only a small amount of
    data that has been labeled. That unlabeled data can still be used. First, you
    train a model on the labeled data that you have. Then you let that model make
    predictions on your corpus of unlabeled data. You treat those predictions as if
    they were true labels and train your model on the full pseudo-labeled dataset.
    However, actual true labels should be used more often than pseudo labels.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，未标注的数据非常充足，但标注过的数据量却很少。那些未标注的数据仍然可以使用。首先，你需要在已有的标注数据上训练一个模型。然后，你让该模型对你的未标注数据进行预测。你将这些预测当作真实标签，并在完整的伪标注数据集上训练你的模型。然而，实际的真实标签应该比伪标签使用得更频繁。
- en: The exact sampling rate for pseudo labels can vary for different circumstances.
    This works under the condition that errors are random. If they are biased, your
    model will be biased as well. This simple method is surprisingly effective and
    can greatly reduce labeling efforts.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 伪标签的具体采样率可以根据不同的情况有所变化。此方法适用于错误是随机的情况。如果错误存在偏差，那么你的模型也会有偏差。这种简单的方法出奇地有效，能够大大减少标注工作量。
- en: Using generative models
  id: totrans-415
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用生成模型
- en: As it turns out, GANs extend quite naturally to semi-supervised training. By
    giving the discriminator two outputs, we can train it to be a classifier as well.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，GAN在半监督训练中扩展得非常自然。通过给判别器两个输出，我们可以训练它同时成为一个分类器。
- en: The first output of the discriminator only classifies data as real or fake,
    just as it did for the GAN previously. The second output classifies the data by
    its class, for example, the digit an image represents, or an extra "is fake" class.
    In the MNIST example, the classifying output would have 11 classes, 10 digits
    plus the "is fake" class. The trick is that the generator is one model and only
    the output, that is, the last layer, is different. This forces the "real or not"
    classification to share weights with the "which digit" classifier.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的第一次输出仅将数据分类为真实或伪造，就像之前GAN的输出一样。第二次输出根据数据的类别进行分类，例如图像所表示的数字，或者一个额外的“是伪造”的类别。在MNIST示例中，分类输出将有11个类别，10个数字加上“是伪造”类别。关键在于生成器是一个模型，只有输出，即最后一层不同。这迫使“真实或伪造”分类与“哪一位数字”分类器共享权重。
- en: The idea is that to determine whether an image is real or fake, the classifier
    would have to figure out whether it can classify this image into one class. If
    it can, the image is probably real. This approach, called **semi-supervised generative
    adversarial network** (**SGAN**), has been shown to generate more realistic data
    and deliver better results on limited data than standard supervised learning.
    Of course, GANs can be applied to more than just images.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法的核心思想是，要判断一张图像是真实的还是伪造的，分类器需要判断它是否能将该图像归类到一个类别中。如果能，这张图像可能就是真的。这个方法叫做**半监督生成对抗网络**（**SGAN**），已被证明在有限数据上能比标准的监督学习生成更真实的数据，并提供更好的结果。当然，GAN不仅可以应用于图像。
- en: In the next section, we will apply them to our fraud detection task.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将把它们应用到我们的欺诈检测任务中。
- en: SGANs for fraud detection
  id: totrans-420
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于欺诈检测的SGAN
- en: 'As the final applied project of this chapter, let''s consider the credit card
    problem again. In this section, we will create an SGAN as follows:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本章的最终应用项目，我们再次考虑信用卡问题。在本节中，我们将创建一个SGAN，步骤如下：
- en: '![SGANs for fraud detection](img/B10354_06_17.jpg)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![用于欺诈检测的SGAN](img/B10354_06_17.jpg)'
- en: SGAN scheme
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: SGAN方案
- en: We will train this model on fewer than 1,000 transactions and still get a decent
    fraud detector.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在少于1,000个交易上训练该模型，并仍然能够得到一个合理的欺诈检测器。
- en: Note
  id: totrans-425
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can find the code for the SGAN on Kaggle under this link: [https://www.kaggle.com/jannesklaas/semi-supervised-gan-for-fraud-detection/code](https://www.kaggle.com/jannesklaas/semi-supervised-gan-for-fraud-detection/code).'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：你可以在Kaggle上找到SGAN的代码，链接如下：[https://www.kaggle.com/jannesklaas/semi-supervised-gan-for-fraud-detection/code](https://www.kaggle.com/jannesklaas/semi-supervised-gan-for-fraud-detection/code)。'
- en: 'In this case, our data has 29 dimensions. We set our latent vectors to have
    10 dimensions:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的数据有29个维度。我们将潜在向量的维度设置为10：
- en: '[PRE53]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The generator model is constructed as a fully connected network with `LeakyReLU`
    activations and batch normalization. The output activation is a `tanh` activation:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器模型构建为一个全连接网络，使用`LeakyReLU`激活函数和批量归一化。输出激活函数使用`tanh`：
- en: '[PRE54]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'To use the generator model better, we wrap the model we created into a functional
    API model that maps the noise vector to a generated transaction record. Since
    most GAN literature is about images, and "transaction record" is a bit of a mouthful,
    therefore we just name our transaction records as "images":'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地使用生成器模型，我们将创建的模型包装成一个函数式API模型，将噪声向量映射到生成的交易记录。由于大多数GAN文献都是关于图像的，而“交易记录”有些拗口，因此我们将交易记录称为“图像”：
- en: '[PRE55]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Just as we did with the generator, we build the discriminator in the sequential
    API. The discriminator has two output: one for the classes, and one for fake or
    not fake. We first only construct the base of the model:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们为生成器所做的那样，我们在顺序API中构建判别器。判别器有两个输出：一个用于类别，另一个用于真假分类。我们首先只构建模型的基础部分：
- en: '[PRE56]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Now we''ll map the input of the discriminator to its two heads using the functional API:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过函数式API将判别器的输入映射到它的两个输出：
- en: '[PRE57]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Let''s take a minute to look at the five key aspects of the preceding code:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间看看前面代码的五个关键点：
- en: We create an input placeholder for the noise vector
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为噪声向量创建一个输入占位符。
- en: We get the feature tensor from the discriminator base model
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从判别器基础模型中获取特征张量。
- en: We create a `Dense` layer for classifying a transaction as real or not and map
    it to the feature vector
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个`Dense`层，用于将交易分类为真实或假的，并将其映射到特征向量。
- en: We create a second `Dense` layer for classifying transactions as genuine or
    fake
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为交易的真假分类创建第二个`Dense`层。
- en: We create a model mapping the input to the two heads
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个模型，将输入映射到两个头部。
- en: 'To compile the discriminator with two heads, we need to use a few advanced
    model-compiling tricks:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 为了编译具有两个头部的判别器，我们需要使用一些高级模型编译技巧：
- en: '[PRE58]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Breaking that code down, we see five key elements:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 将代码拆解开来，我们看到五个关键元素：
- en: We define an `Adam` optimizer with a learning rate of `0.0002` and a momentum
    of `0.5`.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个`Adam`优化器，学习率为`0.0002`，动量为`0.5`。
- en: Since we have two model heads, we can specify two losses. Our fake or not head
    is a binary classifier, so we use `binary_crossentropy` for it. Our classifying
    head is a multi-class classifier, so we use `categorical_crossentropy` for the
    second head.
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们有两个模型头部，我们可以指定两个损失函数。我们的真假分类头部是一个二分类器，因此我们为其使用`binary_crossentropy`。我们的分类头部是一个多分类器，因此我们为第二个头部使用`categorical_crossentropy`。
- en: We can specify how we want to weight the two different losses. In this case,
    we give all losses a 50% weight.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以指定如何加权两个不同的损失函数。在这种情况下，我们为所有损失函数分配50%的权重。
- en: We optimize our predefined `Adam` optimizer.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们优化了我们预定义的`Adam`优化器。
- en: As long as we are not using soft labels, we can track progress using the accuracy
    metric.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只要我们没有使用软标签，就可以使用准确率指标来跟踪进度。
- en: 'Finally, we create our combined GAN model:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们创建我们的组合GAN模型：
- en: '[PRE59]'
  id: totrans-452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Again, looking at the code, we can see the following key points:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看代码，我们可以看到以下关键点：
- en: We create a placeholder for the noise vector input.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们为噪声向量输入创建一个占位符。
- en: We obtain a tensor representing the generated image by mapping the generator
    to the noise placeholder.
  id: totrans-455
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过将生成器映射到噪声占位符来获得表示生成图像的张量。
- en: We make sure we do not destroy the discriminator by setting it to not trainable.
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们确保通过将判别器设置为不可训练，避免破坏它。
- en: We only want the discriminator to believe the generated transactions are real,
    so we can discard the classification output tensor.
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只希望判别器相信生成的交易是真的，因此我们可以丢弃分类输出张量。
- en: We map the noise input to the "fake or not fake" output of the discriminator.
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将噪声输入映射到判别器的“真假分类”输出。
- en: 'For training, we define a `train` function, which handles all the training
    for us:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 对于训练，我们定义了一个`train`函数，它为我们处理所有的训练工作：
- en: '[PRE60]'
  id: totrans-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Take a minute to pause: that was a very long and complicated function to code.
    Before we summarize this chapter, let''s look at the 15 key elements of that code:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 稍作停顿：那是一个非常长且复杂的函数。在总结这一章之前，让我们看看那段代码的15个关键元素：
- en: We create an empty array to monitor the F1 score of the discriminator on the
    test set.
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个空数组来监控判别器在测试集上的F1得分。
- en: Since we use separate batch training steps for real and fake data, we effectively
    use a half batch for each of the training steps.
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们对真实数据和假数据使用独立的批量训练步骤，因此我们实际上为每个训练步骤使用了半批数据。
- en: The classification head of the discriminator has a class label for "this is
    fake." Since half of the images are fake, we want to give this class a higher
    weight.
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判别器的分类头部有一个“这是假的”类标签。由于一半的图像是假的，我们希望为这个类赋予更高的权重。
- en: We now draw a random sample of real data.
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在随机抽取一组真实数据。
- en: We generate some random noise vectors and use the generator to create some fake
    data.
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们生成一些随机噪声向量，并使用生成器创建一些假数据。
- en: For the "fake or not" head, we create labels. All of the real images have the
    label `1` (real), while all the fake images have the label `0` (fake).
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于“真假分类”头部，我们创建标签。所有真实图像的标签为`1`（真实），而所有假图像的标签为`0`（假）。
- en: We one-hot encode the labels of our real data. By specifying that our data has one
    more class than it actually has, we leave space for the "is fake" class.
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对真实数据的标签进行独热编码。通过指定我们的数据比实际数据多一个类，我们为“是假的”类留出了空间。
- en: Our fake data is all labeled with the "is fake" label. We create a vector of
    those labels, and one-hot encode them, too.
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的假数据都被标记为“是假的”标签。我们创建一个标签向量，并对其进行独热编码。
- en: First, we train the discriminator on the real data.
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们在真实数据上训练判别器。
- en: Then we train the discriminator on the fake data.
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们在假数据上训练判别器。
- en: The total loss of the discriminator for this epoch is the mean of the loss from
    the real and fake data.
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该轮判别器的总损失是来自真实数据和虚假数据损失的平均值。
- en: Now we train the generator. We generate a batch full of noise vectors as well
    as a batch full of labels saying, "this is real data."
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们开始训练生成器。我们生成一批噪声向量以及一批标签，标记为“这是实际数据”。
- en: With this data in hand, we train the generator.
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在拥有这些数据之后，我们开始训练生成器。
- en: To keep track of what is going on, we print out the progress. Remember that
    we do not want the losses to go down; we want them to stay roughly constant. If
    either the generator or discriminator starts performing much better than the other,
    then the equilibrium breaks.
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了跟踪进展，我们会打印输出进度。记住，我们不希望损失值下降；我们希望它们保持大致恒定。如果生成器或判别器的表现远好于另一个，那么平衡就会打破。
- en: Finally, we calculate and output the F1 score of using the discriminator as
    a fraud detection classifier for the data. This time, we only care about the classification
    data and discard the "real or fake" head. We classify the transactions by the
    highest value that is not the "is real" class of the classifier.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们计算并输出使用判别器作为欺诈检测分类器对数据进行处理时的F1得分。这次，我们只关心分类数据，并丢弃“真实或虚假”这一部分。我们通过分类器中不是“真实”的类别来分类交易。
- en: 'Now that we have everything set up, we are going to train our SGAN for 5,000
    epochs. This will take about 5 minutes on a GPU but could take much longer if
    you do not have a GPU:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已完成所有设置，将训练SGAN 5,000轮。这在GPU上大约需要5分钟，如果没有GPU，可能需要更长时间：
- en: '[PRE61]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Finally, we plot the F1 score of our semi-supervised fraud classifier over
    time:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们绘制了半监督欺诈分类器的F1得分随时间变化的图表：
- en: '[PRE62]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'This would output as the following graph:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出如下图表：
- en: '![SGANs for fraud detection](img/B10354_06_18.jpg)'
  id: totrans-482
  prefs: []
  type: TYPE_IMG
  zh: '![SGANs for fraud detection](img/B10354_06_18.jpg)'
- en: SGAN progress
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: SGAN进展
- en: As you can see, the model learns pretty quickly at first, but then collapses
    with its F1 score going to zero. This is a textbook example of a collapsing GAN.
    As mentioned previously, GANs are unstable. If the delicate balance between the
    generator and discriminator breaks, performance quickly deteriorates.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，模型一开始学习得非常快，但随后崩溃，F1得分降为零。这是一个典型的GAN崩溃例子。如前所述，GAN是非常不稳定的。如果生成器和判别器之间的微妙平衡打破，性能会迅速恶化。
- en: Making GANs more stable is an active area of research. So far, many practitioners
    will just attempt to try multiple runs with different hyperparameters and random
    seeds in a hope to get lucky. Another popular method is just to save the model
    every couple of epochs. The model seems to be a pretty decent fraud detector at
    around epoch 150 despite being trained on fewer than 1,000 transactions.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 使GAN更加稳定是一个活跃的研究领域。到目前为止，许多从业者通常会尝试使用不同的超参数和随机种子进行多次运行，希望能走运。另一种流行的方法是每隔几轮就保存一次模型。尽管训练样本少于1,000个交易数据，但该模型似乎在第150轮左右成为一个相当不错的欺诈检测器。
- en: Exercises
  id: totrans-486
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: 'To get more comfortable with generative models, try your hand at these exercises:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解生成模型，尝试完成以下练习：
- en: Create an SGAN in order to train an MNIST image classifier. How few images can
    you use to achieve over 90% classification accuracy?
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个SGAN来训练MNIST图像分类器。你能用多少的图像达到90%以上的分类准确率？
- en: 'Using LSTMs, you can build an autoencoder for stock price movements. Using
    a dataset such as the DJIA stock prices, build an autoencoder that encodes stock
    movements. Then visualize what happens to the outputs as you move through the
    latent space. You can find the dataset here: [https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231](https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231).'
  id: totrans-489
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用LSTM，你可以为股票价格波动构建一个自编码器。使用像DJIA股票价格这样的数据集，构建一个能够编码股票波动的自编码器。然后，观察在通过潜在空间时输出的变化。你可以在这里找到数据集：[https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231](https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231)。
- en: Summary
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you have learned about the two most important types of generative
    models: autoencoders and GANs. We first developed an autoencoder for MNIST images.
    We then used a similar architecture to encode credit card data and detect fraud.
    Afterward, we expanded the autoencoder to a VAE. This allowed us to learn distributions
    of encodings and generate new data that we could use for training.'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了两种最重要的生成模型：自编码器和GAN。我们首先为MNIST图像开发了一个自编码器。然后，我们使用类似的架构来编码信用卡数据并检测欺诈。随后，我们将自编码器扩展为VAE。这使我们能够学习编码的分布并生成新的数据，用于训练。
- en: Afterward, we learned about GANs, again first in the context of MNIST images
    and then in the context of credit card fraud. We used an SGAN to reduce the amount
    of data we needed to train our fraud detector. We used model outputs to reduce
    the amount of labeling necessary through active learning and smarter labeling
    interfaces.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，我们学习了生成对抗网络（GAN），首先是在MNIST图像的背景下，然后是信用卡欺诈的背景下。我们使用SGAN减少了训练欺诈检测器所需的数据量。我们通过主动学习和更智能的标注接口，利用模型输出减少了所需标注的数量。
- en: We've also discussed and learned about latent spaces and the use they have for
    financial analysis. We saw the t-SNE algorithm and how it can be used to visualize
    higher dimensional (latent) data. You also got a first impression of how machine
    learning can solve game-theoretic optimization problems. GANs solve a minimax
    problem, which is frequent in economics and finance.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论并学习了潜在空间及其在金融分析中的应用。我们了解了t-SNE算法，以及它如何用于可视化更高维度（潜在）数据。你们还初步了解了机器学习如何解决博弈论中的优化问题。GAN解决的是一种最小最大问题，这在经济学和金融学中非常常见。
- en: In the next chapter, we will deep dive into exactly that type of optimization
    as we cover reinforcement learning.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将深入探讨这种类型的优化问题，重点讲解强化学习。
