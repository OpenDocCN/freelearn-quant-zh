["```py\ninstall.packages('package name')\n\n```", "```py\nlibrary('package name')\n\n```", "```py\n> library('quantmod') \n>getSymbols(\"^DJI\",src=\"img/yahoo\") \n[1] \"DJI\" \n> head(DJI) \n\n```", "```py\n>dji<- DJI[,\"DJI.Close\"] \n> class(dji) \n[1] \"xts\" \"zoo\" \n\n```", "```py\n>dji<- dji[(index(dji) >= \"2010-01-01\" & index(dji) <= \"2015-12-31\"),] \n\n```", "```py\n>ret_dji<- Delt(dji,k=1) \n\n```", "```py\n>ret_dji<- Delt(dji,k=1:3)\n\n```", "```py\n> head(ret_dji) \n                 Delt.1        Delt.2               Delt.3 \n2010-01-04          NA           NA                   NA \n2010-01-05     -0.0011281628     NA                   NA \n2010-01-06      0.0001570331  -0.0009713069           NA \n2010-01-07      0.0031380432   0.0032955691      0.002163688 \n2010-01-08      0.0010681840   0.0042095792      0.004367273 \n2010-01-11      0.0043133342   0.0053861256      0.008541071 \n\n```", "```py\n> ? Delt\n\n```", "```py\n>in_sd<- \"2010-01-01\" \n>in_ed<- \"2014-12-31\" \n>out_sd<- \"2015-01-01\" \n>out_ed<- \"2015-12-31\" \n\n```", "```py\n>in_dji<- dji[(index(dji) >= in_sd& index(dji) <= in_ed),] \n>in_ret_dji<- ret_dji[(index(ret_dji) >= in_sd& index(ret_dji) <= in_ed),] \n>out_dji<- dji[(index(dji) >= out_sd& index(dji) <= out_ed),] \n>out_ret_dji<- ret_dji[(index(ret_dji) >= out_sd& index(ret_dji) <= out_ed),] \n\n```", "```py\n>macd<- MACD(in_dji, nFast =12, nSlow = 26, nSig = 9,maType=\"SMA\", percent = FALSE)    \n> bb <- BBands(in_dji, n = 20, maType=\"SMA\", sd = 2) \n\n```", "```py\n> signal <- NULL \n> signal <- ifelse(in_dji> bb[,'up'] &macd[,'macd'] >macd[,'signal'],1,ifelse(in_dji< bb[,'dn'] &macd[,'macd'] <macd[,'signal'],-1,0)) \n\n```", "```py\n>trade_return<- in_ret_dji*lag(signal) \n\n```", "```py\n> library(PerformanceAnalytics) \n>cumm_ret<- Return.cumulative(trade_return) \n>annual_ret<- Return.annualized(trade_return) \n\n```", "```py\n>charts.PerformanceSummary(trade_return) \n\n```", "```py\n> summary(as.ts(trade_return)) \n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's  \n-0.039770  0 0 0.000062  0 0.055460        20  \n\n```", "```py\n>maxDrawdown(trade_return) \n0.1173028 \n>StdDev(trade_return) \nStdDev0.00379632 \n>StdDev.annualized(trade_return) \nAnnualized Standard Deviation        0.06026471 \n>VaR(trade_return, p = 0.95) \n>SharpeRatio(as.ts(trade_return), Rf = 0, p = 0.95, FUN = \"StdDev\") \nStdDev Sharpe (Rf=0%, p=95%): 0.01621421 \n>SharpeRatio.annualized(trade_return, Rf = 0) \nAnnualized Sharpe Ratio (Rf=0%)         0.2289401 \n\n```", "```py\n>macd<- MACD(out_dji, nFast = 7, nSlow = 12, nSig = 15,maType=\"SMA\", percent = FALSE) \n> bb <- BBands(out_dji, n = 20, maType=\"SMA\", sd = 2) \n\n```", "```py\n>signal <- NULL \n> signal <- ifelse(out_dji> bb[,'up'] &macd[,'macd'] >macd[,'signal'],1,ifelse(out_dji< bb[,'dn'] &macd[,'macd'] <macd[,'signal'],-1,0)) \n\n```", "```py\n>trade_return<- out_ret_dji*lag(signal) \n>cumm_ret<- Return.cumulative(trade_return) \n>annual_ret<- Return.annualized(trade_return) \n>charts.PerformanceSummary(trade_return) \n>maxdd<- maxDrawdown(trade_return) \n>sd<- StdDev(trade_return) \n>sda<- StdDev.annualized(trade_return) \n>VaR(trade_return, p = 0.95)   \n>SharpeRatio(as.ts(trade_return), Rf = 0, p = 0.95, FUN = \"StdDev\") \n>SharpeRatio.annualized(trade_return, Rf = 0) \n\n```", "```py\n>var(ret_dji,na.rm=T) \nDelt.1.arithmetic      8.093402e-05 \n\n```", "```py\n>getSymbols(\"GSPC\",src=\"img/yahoo\") \n\n```", "```py\n>snp<- GSPC[,\"GSPC.Close\"] \n>snp<- snp[(index(snp) >= \"2010-01-01\" & index(snp) <= \"2015-12-31\"),] \n>ret_snp<- Delt(snp) \n\n```", "```py\n>var(ret_snp,na.rm=T) \nDelt.1.arithmetic      8.590805e-05 \n\n```", "```py\n>var(ret_dji + ret_snp,na.rm=T) \nDelt.1.arithmetic       0.000218383 \n\n```", "```py\nVariance(ret_dji + ret_snp) ≠ Variance(ret_dji) + Variance(ret_snp) \n\n```", "```py\nVariance (X + Y) = Variance(X) + Variance(Y) + 2  Covariance(X,Y)     .......... (5.1) \nVariance (X + Y) = Variance(X) + Variance(Y) + 2  ρσXσY................(5.2) \n\n```", "```py\n>sd(ret_dji,na.rm=T) \n[1] 0.00926866 \n>sd(ret_snp,na.rm=T) \n[1] 0.008996333 \n>cor(ret_dji[!is.na(ret_dji)],ret_snp[!is.na(ret_snp)]) \n                  Delt.1.arithmetic \nDelt.1.arithmetic         0.3090576 \n\n```", "```py\n>port_ret<- data.frame(matrix(NA,dim(ret_dji)[1],2)) \n\n```", "```py\n>port_ret[,1] <- ret_dji \n>port_ret[,2] <- ret_snp \n\n```", "```py\n>cor(port_ret) \n       X1           X2 \nX1     1            NA \nX2     NA           1 \n\n```", "```py\n>port_ret<- port_ret[!is.na(port_ret[,1]),] \n>cor(port_ret) \n\n             X1                  X2 \nX1        1.0000000           0.3090576 \nX2        0.3090576           1.0000000 \n\n```", "```py\nVariance (X -Y) = Variance(X) + Variance(Y) - 2 ρ σXσY................(5.3) \n\n```", "```py\n>ret_dji[1] <- 1\n>ret_snp[1] <- 1\n\n```", "```py\n>norm_dji<- apply(ret_dji,2,cumprod)\n>norm_snp<- apply(ret_snp,2,cumprod)\n\n```", "```py\n(Norm_dji)t =  (norm_dji)t-1 * (1 + rt) \n\n```", "```py\n>plot(norm_dji,type=\"l\",ylim=c(0.5,2) ,ylab=\"Normalized_Price\") \n>lines(norm_snp,col=\"red\") \n>legend('topright',c(\"DJI\",\"S&P 500\") ,  lty=1, col=c('black','red'), bty='o', cex=1) \n\n```", "```py\n> class(norm_xom)\n[1] \"matrix\"\n> class(norm_cvx)\n[1] \"matrix\"\n\n```", "```py\nnorm_xom<- xts(norm_xom,index(ret_xom)) \nnorm_cvx<- xts(norm_cvx,index(ret_cvx)) \n\n```", "```py\n>par(mfrow=c(3,1)) \n> plot(norm_xom,type=\"l\",ylim=c(0.5,2) ,ylab=\"Normalized_Price\") \n> lines(norm_cvx,col=\"red\") \n> legend('topright',c(\"XOM\",\"CVX\") ,  lty=1, col=c('black','red'), bty='o', cex=1) \n> diff = norm_xom - norm_cvx \n> plot(diff,type=\"l\",ylab=\"Normalized_Price_difference\") \n\n```", "```py\n> me <- mean(diff) \n>std<- sd(diff) \n\n```", "```py\n>ub<- me + n * std \n>lb<- me  - n*std \n\n```", "```py\n> n <- 1 \n> signal <- ifelse(diff > ub,1,ifelse(diff < lb,-1,0)) \n\n```", "```py\n>me_dynamic<-  rollapply(diff,10,mean) \n>std_dynamic<-  rollapply(diff,10,sd) \n\n```", "```py\n>plot(signal, type=\"l\") \n\n```", "```py\n>spread_return<- ret_xom - ret_cvx \n>trade_return<- spread_return*lag(signal) - cost \n\n```", "```py\n> summary(trade_return) \n      Min.    1st Qu.     Median       Mean    3rd Qu.       Max.  \n-0.0330000  0.0000000  0.0000000  0.0002135  0.0000000  0.0373400 \n\n```", "```py\n>cumm_ret<- Return.cumulative(trade_return) \n>annual_ret<- Return.annualized(trade_return) \n>charts.PerformanceSummary(trade_return) \n>maxdd<- maxDrawdown(trade_return) \n>sd<- StdDev(trade_return) \n>sda<- StdDev.annualized(trade_return) \n>VaR(trade_return, p = 0.95)   \n>SharpeRatio(as.ts(trade_return), Rf = 0, p = 0.95, FUN = \"StdDev\") \n>SharpeRatio.annualized(trade_return, Rf = 0) \n\n```", "```py\n>data <- data.frame(matrix(NA,dim(ret_xom)[1],2)) \n>data[,1] <- ret_xom \n>data[,2] <- ret_cvx \n> class(data) \n[1] \"data.frame\" \n\n```", "```py\n> data <- xts(data,index(ret_xom)) \n> class(data) \n[1] \"xts\" \"zoo\" \n\n```", "```py\n>correlation <- function(x)  \n{ \n         result <- cor(x[,1],x[,2]) \n         return (result) \n} \n\n```", "```py\n>corr<- rollapply(data,252,correlation ,by.column=FALSE)  \n\n```", "```py\n>hedge_ratio<-  xom  / cvx \n\n```", "```py\n>roll_me<- rollapply(hedge_ratio,14,mean)\n>roll_std<- rollapply(hedge_ratio,14,sd)\n> n <- 1\n>roll_ub<- roll_me + n * roll_std\n>roll_lb<- roll_me - n * roll_std\n\n```", "```py\n> signal <- NULL\n> signal <- ifelse(hedge_ratio> roll_ub,-1,ifelse(hedge_ratio< roll_lb,1,0))\n>lagsignal<- Lag(signal,1)\n> signal <- ifelse(lagsignal == -1 &hedge_ratio> roll_me,\n-1,ifelse(lagsignal == 1 &hedge_ratio< roll_me,1,0))\n\n```", "```py\n>spread_return<- ret_xom - ret_cvx\n>trade_return<- spread_return*lag(signal) - cost\n\n```", "```py\n> library(tseries)\n>adf.test(xom)\n\n```", "```py\ndata:  xom \nDickey-Fuller = -1.4326, Lag order = 11, p-value = 0.8185 \nalternative hypothesis: stationary \n\n```", "```py\n> diff <- xom - Lag(xom,1) \n>adf.test(diff[!is.na(diff)]) \n   Augmented Dickey-Fuller Test \ndata:  diff[!is.na(diff)] \nDickey-Fuller = -11.791, Lag order = 11, p-value = 0.01 \nalternative hypothesis: stationary \n\n```", "```py\n> model <- lm(xom ~ cvx + 0) \n> model \nCall: \nlm(formula = xom ~ cvx + 0) \nCoefficients: \ncvx \n0.8008   \n\n```", "```py\n> summary(model) \nCall: \nlm(formula = xom ~ cvx + 0) \nResiduals: \n     Min       1Q   Median       3Q      Max  \n-12.7667  -2.2833   0.4533   2.9224  13.9694  \nCoefficients: \nEstimate Std. Error t value Pr(>|t|)     \ncvx 0.800802   0.001123   713.4   <2e-16 *** \n--- \nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \nResidual standard error: 4.587 on 1509 degrees of freedom \nMultiple R-squared:  0.997,     Adjusted R-squared:  0.997  \nF-statistic: 5.09e+05 on 1 and 1509 DF,  p-value: < 2.2e-16> \n\n```", "```py\n>adf.test(as.ts(model$residuals))\nAugmented Dickey-Fuller Test\ndata:  as.ts(model$residuals)\nDickey-Fuller = -2.6088, Lag order = 11, p-value = 0.3206\nalternative hypothesis: stationary\n\n```", "```py\n> model <- lm(xom ~ bp + 0) \n>adf.test(as.ts(model$residuals)) \nAugmented Dickey-Fuller Test \ndata:  as.ts(model$residuals) \nDickey-Fuller = -3.9007, Lag order = 11, p-value = 0.01395 \nalternative hypothesis: stationary \n\n```", "```py\n> par(mfrow=c(2,1)) \n> plot(dji,type=\"l\") \n> lines(snp*model$coefficients,col=\"red\") \n> plot(model$residuals,type=\"l\") \n\n```", "```py\n>roll_me<- rollapply(model$residuals,14,mean)\n>roll_std<- rollapply(model$residuals,14,sd)\n> n <- 1\n>roll_ub<- roll_me + n * roll_std\n>roll_lb<- roll_me - n * roll_std\n\n```", "```py\n> signal <- NULL\n> signal <- ifelse(model$residuals> roll_ub,-1,ifelse(model$residuals< roll_lb,1,0))\n>lagsignal<- Lag(signal,1)\n>signal <- ifelse(lagsignal == -1 &model$residuals> roll_me,-1,ifelse(lagsignal == 1 &model$residuals< roll_me,1,0))\n\n```", "```py\n>rf<- rep(0,length(dji))\n>model <- lm((ret_cvx  -rf) ~ (ret_dji -rf) )\n> model\nCall:\nlm(formula = (ret_cvx - rf) ~ (ret_dji - rf))\nCoefficients:\n(Intercept)  ret_dji\n-0.0002013    1.1034521 \n\n```", "```py\n>CAPM.beta(ret_cvx,ret_dji)\n[1] 1.103452\n>CAPM.alpha(ret_cvx,ret_dji)\n[1] -0.0002013222\n\n```", "```py\n>plot(as.ts(ret_cvx),as.ts(ret_dji),xlab=\"CVX_ Return\",ylab=\"DJI_Return\")\n>abline(model,col=\"red\")\n\n```", "```py\n>cor(ret_cvx,ret_dji)\n Delt.1.arithmetic\nDelt.1.arithmetic         0.7881967\n\n```", "```py\n> con = gzcon(url('http://www.systematicportfolio.com/sit.gz', 'rb'))\n>  source(con)\n> close(con)\n\n```", "```py\n>dow.jones.components<- function(){\nurl = 'http://money.cnn.com/data/dow30/'\n txt = join(readLines(url))\n temp = gsub(pattern = '\">', replacement = '<td>', txt, perl = TRUE)\n temp = gsub(pattern = '</a>', replacement = '</td>', temp, perl = TRUE) \n temp = extract.table.from.webpage(temp, 'Volume', has.header = T)\n trim(temp[,'Company']) }\n\n```", "```py\n>tickers = dow.jones.components()\n\n```", "```py\n>data.fund<- new.env()\n>   temp = paste(iif( nchar(tickers) <= 3, 'NYSE:', 'NASDAQ:'), tickers, sep='')\n>for(i in 1:len(tickers)) data.fund[[tickers[i]]] = fund.data(temp[i], 80)\n>save(data.fund, file='data.fund.Rdata')\n# load(file='data.fund.Rdata')\n\n```", "```py\n# get pricing data\n>data <- new.env()\n>getSymbols(tickers, src = 'yahoo', from = '1970-01-01', env = data, auto.assign = T)\n>for(i in ls(data)) data[[i]] = adjustOHLC(data[[i]], use.Adjusted=T) \n>save(data, file='data.Rdata')\n#load(file='data.Rdata')\n\n```", "```py\n>date.fund.data<- function(data){\nquarter.end.date = as.Date(paste(data['quarter end date',], '/1', sep=''), '%Y/%m/%d') \nquarterly.indicator = data['quarterly indicator',]\ndate.preliminary.data.loaded = as.Date(data['date preliminary data loaded',], '%Y-%m-%d') + 1\nmonths = seq(quarter.end.date[1], tail(quarter.end.date,1)+365, by='1 month') \nindex = match(quarter.end.date, months)\nquarter.end.date = months[ iif(quarterly.indicator == '4', index+3, index+2) + 1 ] - 1\nfund.date = date.preliminary.data.loaded\nfund.date[is.na(fund.date)] = quarter.end.date[is.na(fund.date)] \nreturn(fund.date) }\n\n```", "```py\n> library(quantmod)\n>for(i in tickers) {\nfund = data.fund[[i]]\nfund.date = date.fund.data(fund) \n# Earnings per Share \nEPS = get.fund.data('Diluted EPS from Total Operations', fund, fund.date, is.12m.rolling=T) \n# Common Shares Outstanding\nCSHO = get.fund.data('total common shares out', fund, fund.date)\n# Common Equity\nCEQ = get.fund.data('total equity', fund, fund.date)\n# merge\ndata[[i]] = merge(data[[i]], EPS, CSHO, CEQ) }\n\n```", "```py\n>bt.prep(data, align='keep.all', dates='1995::2011')\n\n```", "```py\n>     prices = data$prices\n>     prices = bt.apply.matrix(prices, function(x) ifna.prev(x))\n\n```", "```py\n# Financial Ratios\n>factors$TV = list()\n# Market Value - capitalization\n> CSHO =  bt.apply(data, function(x) ifna.prev(x[, 'CSHO']))\n> MKVAL = prices * CSHO\n #  Earnings / Price\n> EPS = bt.apply(data, function(x) ifna.prev(x[, 'EPS']))\n>factors$TV$EP = EPS / prices\n#  Book Value / Price\n> CEQ = bt.apply(data, function(x) ifna.prev(x[, 'CEQ']))\n>factors$TV$BP = CEQ / MKVAL\n\n```", "```py\n# normalize (convert to z scores) cross sectional all Traditional Value factors\n>for(i in names(factors$TV)) {\nfactors$TV[[i]] = (factors$TV[[i]] - \ncap.weighted.mean(factors$TV[[i]], MKVAL)) / \n apply(factors$TV[[i]], 1, sd, na.rm=T)\n}\nThis is how we bind different data in multidimensional case\n# compute the overall Traditional Value factor\n>load.packages('abind') \n> temp = abind(factors$TV, along = 3)\n\n```", "```py\n>factors$TV$AVG = factors$TV[[1]]\n>factors$TV$AVG[] = apply(temp, c(1,2), mean, na.rm=T)\n\n```", "```py\n# find month ends\n>month.ends = endpoints(prices, 'months')\n> prices = prices[month.ends,]\n>     n = ncol(prices)\n>nperiods = nrow(prices)\n\n```", "```py\n> ret = prices / mlag(prices) - 1\n>next.month.ret = mlag(ret, -1)\n\n```", "```py\n> MKVAL = MKVAL[month.ends,]\n\n```", "```py\n>for(j in 1:len(factors)) { \nfor(i in 1:len(factors[[j]])) {\n factors[[j]][[i]] = factors[[j]][[i]][month.ends,] \n }}\n\n```", "```py\n> out = compute.quantiles(factors$TV$AVG, next.month.ret, plot=F) \n> models = list()\n>for(i in 1:5) {\ndata$weight[] = NA\ndata$weight[month.ends,] = iif(out$quantiles == i, out$weights, 0)\n capital = 100000\ndata$weight[] = (capital / prices) * (data$weight) \n models[[paste('Q',i,sep='')]] = bt.run(data, type='share', capital=capital) }\n\n```", "```py\n# spread\n>data$weight[] = NA\n>data$weight[month.ends,] = iif(out$quantiles == 5, out$weights, \niif(out$quantiles == 1, -out$weights, 0))\n>     capital = 100000\n>data$weight[] = (capital / prices) * (data$weight)\n> models$Q5_Q1 = bt.run(data, type='share', capital=capital)\n\n```", "```py\n>factors.avg = list()\n>for(j in names(factors)) factors.avg[[j]] = factors[[j]]$AVG\n>factors.avg = add.avg.factor(factors.avg)\n>nperiods = nrow(next.month.ret)\n> n =ncol(next.month.ret)\n# create matrix for each factor\n>factors.matrix = abind(factors.avg, along = 3) \n>all.data = factors.matrix\n> # betas\n> beta = all.data[,1,] * NA\n# append next.month.ret to all.data\n>all.data = abind(next.month.ret, all.data, along = 3)\n>dimnames(all.data)[[3]][1] = 'Ret'\n# estimate betas (factor returns)\n>for(t in 30:(nperiods-1)) {\n temp = all.data[t:t,,]\n x = temp[,-1]\n y = temp[,1]\n beta[(t+1),] = lm(y~x-1)$coefficients\n }\n # create Alpha return forecasts\n> alpha = next.month.ret * NA\n>for(t in 40:(nperiods-1)) {\n # average betas over the last 6 months\ncoef = colMeans(beta[(t-5):t,],na.rm=T)\n alpha[t,] = rowSums(all.data[t,,-1] * t(repmat(coef, 1,n)), na.rm=T)    }\n\n```", "```py\n>stockData<- new.env() \n> symbols <- c(\"MSFT\",\"FB\",\"GOOG\",\"AAPL\")\n>start_date<- as.Date(\"2014-01-01\")\n>getSymbols(symbols, src=\"img/yahoo\", env=stockData, from=start_date)\n> x <- list()\n\n```", "```py\n>for (i in 1:length(symbols)) {\n x[[i]] <- get(symbols[i], pos=stockData)  # get data from stockData environment\n x[[i]]$gl<-((Cl(x[[i]])-Op(x[[i]]))/Op(x[[i]]))*100 #Daily gain loss percentage \n if(i==1)\n data <- Cl(x[[i]])\n else \n data <- cbind(data,Cl(x[[i]])) }\n\n```", "```py\n>data_ret<- apply(data,2,Delt)\n>napos<- which(apply(data_ret,2,is.na))# Remove Na's\n>avg_ret<- apply(data_ret[-napos,],2,mean)\n>covariance_mat<- cov(data_ret,use='na')\n\n```", "```py\n> weights <- c(0.2,0.3,0.35,0.15)\n\n```", "```py\n> source(\"portfolio.R\")\n\n```", "```py\n>weightedport = getPortfolio(avg_ret,covariance_mat,weights)\n>weightedport\nCall:\ngetPortfolio(er = avg_ret, cov.mat = covariance_mat, weights = weights)\nPortfolio expected return:     0.0004109398 \nPortfolio standard deviation:  0.01525882 \nPortfolio weights:\nMSFT.CloseFB.CloseGOOG.CloseAAPL.Close\n 0.20       0.30       0.35       0.15\n\n```", "```py\n>minvar_port<- globalMin.portfolio(avg_ret, covariance_mat)\n>minvar_port\nCall:\nglobalMin.portfolio(er = avg_ret, cov.mat = covariance_mat)\nPortfolio expected return:     0.0007211767 \nPortfolio standard deviation:  0.01349528 \nPortfolio weights:\nMSFT.CloseFB.CloseGOOG.CloseAAPL.Close\n0.5889     0.2415     0.1001     0.0696\n\n```", "```py\n>rf<- 0.0002\n>effcient_port<- efficient.portfolio(avg_ret, covariance_mat,rf)\n>effcient_port\nCall:\nefficient.portfolio(er = avg_ret, cov.mat = covariance_mat, target.return = 2e-04)\nPortfolio expected return:     2e-04 \nPortfolio standard deviation:  0.0169678 \nPortfolio weights:\nMSFT.CloseFB.CloseGOOG.CloseAAPL.Close\n0.4626    -0.1292     0.4184     0.2482\n\n```", "```py\n>tangency_port<- tangency.portfolio(avg_ret,covariance_mat , rf)\n>tangency_port\nCall:\ntangency.portfolio(er = avg_ret, cov.mat = covariance_mat, risk.free = 2e-04)\nPortfolio expected return:     0.4942792 \nPortfolio standard deviation:  0.02226374 \nPortfolio weights:\nMSFT.CloseFB.CloseGOOG.CloseAAPL.Close\n0.8062     0.8797    -0.4480    -0.2378\n\n```", "```py\n>efficient_frontier<- efficient.frontier(avg_ret, covariance_mat, alpha.min=-2,alpha.max=2, nport=50)\n\n```", "```py\n>plot(efficient_frontier, plot.assets=T)\n>points(minvar_port$sd, minvar_port$er, col=\"blue\")\n>points(tangency_port$sd,tangency_port$er, col=\"red\")\n>tangenet_sharpe_ratio = (tangency_port$er - rf)/tangency_port$sd\n>abline(a=rf, b=tangenet_sharpe_ratio)\n\n```"]