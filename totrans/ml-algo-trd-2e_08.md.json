["```py\nsp500 = web.DataReader('SP500', 'fred', '2014', '2018').pct_change()\ndata = pd.read_hdf('00_data/backtest.h5', 'data')\ndata.info()\nMultiIndex: 187758 entries, ('AAL', Timestamp('2014-12-09 00:00:00')) to ('ZTS', Timestamp('2017-11-30 00:00:00'))\nData columns (total 6 columns):\n #   Column     Non-Null Count   Dtype  \n---  ------     --------------   -----  \n 0   predicted  74044 non-null   float64\n 1   open       187758 non-null  float64\n 2   high       187758 non-null  float64\n 3   low        187758 non-null  float64\n 4   close      187758 non-null  float64\n 5   volume     187758 non-null  float64 \n```", "```py\ndaily_returns = data.open.unstack('ticker').sort_index().pct_change()\nfwd_returns = daily_returns.shift(-1)\npredictions = data.predicted.unstack('ticker') \n```", "```py\nlong_signals = (predictions.where(predictions>0).rank(axis=1, ascending=False) > 10).astype(int)\nshort_signals = (predictions.where(predictions<0).rank(axis=1) > 10).astype(int) \n```", "```py\nlong_returns = long_signals.mul(fwd_returns).mean(axis=1)\nshort_returns = short_signals.mul(-fwd_returns).mean(axis=1)\nstrategy = long_returns.add(short_returns).to_frame('strategy') \n```", "```py\nclass SignalData(PandasData):\n    \"\"\"\n    Define pandas DataFrame structure\n    \"\"\"\n    cols = OHLCV + ['predicted']\n    # create lines\n    lines = tuple(cols)\n    # define parameters\n    params = {c: -1 for c in cols}\n    params.update({'datetime': None})\n    params = tuple(params.items()) \n```", "```py\ncerebro = bt.Cerebro()  # create a \"Cerebro\" instance\nidx = pd.IndexSlice\ndata = pd.read_hdf('00_data/backtest.h5', 'data').sort_index()\ntickers = data.index.get_level_values(0).unique()\nfor ticker in tickers:\n    df = data.loc[idx[ticker, :], :].droplevel('ticker', axis=0)\n    df.index.name = 'datetime'\n    bt_data = SignalData(dataname=df)\n    cerebro.adddata(bt_data, name=ticker) \n```", "```py\nclass MLStrategy(bt.Strategy):\n    params = (('n_positions', 10),\n              ('min_positions', 5),\n              ('verbose', False),\n              ('log_file', 'backtest.csv'))\n    def log(self, txt, dt=None):\n        \"\"\" Logger for the strategy\"\"\"\n        dt = dt or self.datas[0].datetime.datetime(0)\n        with Path(self.p.log_file).open('a') as f:\n            log_writer = csv.writer(f)\n            log_writer.writerow([dt.isoformat()] + txt.split(',')) \n```", "```py\n def prenext(self):\n        self.next()\n    def next(self):\n        today = self.datas[0].datetime.date()\n        positions = [d._name for d, pos in self.getpositions().items() if pos]\n        up, down = {}, {}\n        missing = not_missing = 0\n        for data in self.datas:\n            if data.datetime.date() == today:\n                if data.predicted[0] > 0:\n                    up[data._name] = data.predicted[0]\n                elif data.predicted[0] < 0:\n                    down[data._name] = data.predicted[0]\n        # sort dictionaries ascending/descending by value\n        # returns list of tuples\n        shorts = sorted(down, key=down.get)[:self.p.n_positions]\n        longs = sorted(up, key=up.get, reverse=True)[:self.p.n_positions]\n        n_shorts, n_longs = len(shorts), len(longs)\n        # only take positions if at least min_n longs and shorts\n        if n_shorts < self.p.min_positions or n_longs < self.p.min_positions:\n            longs, shorts = [], []\n        for ticker in positions:\n            if ticker not in longs + shorts:\n                self.order_target_percent(data=ticker, target=0)\n         short_target = -1 / max(self.p.n_positions, n_short)\n        long_target = 1 / max(self.p.top_positions, n_longs)\n        for ticker in shorts:\n            self.order_target_percent(data=ticker, target=short_target)\n        for ticker in longs:\n            self.order_target_percent(data=ticker, target=long_target) \n```", "```py\nclass FixedCommisionScheme(bt.CommInfoBase):\n    \"\"\"\n    Simple fixed commission scheme for demo\n    \"\"\"\n    params = (\n        ('commission', .02),\n        ('stocklike', True),\n        ('commtype', bt.CommInfoBase.COMM_FIXED),\n    )\n    def _getcommission(self, size, price, pseudoexec):\n        return abs(size) * self.p.commission \n```", "```py\ncash = 10000\ncerebro.broker.setcash(cash)\ncomminfo = FixedCommisionScheme()\ncerebro.broker.addcommissioninfo(comminfo) \n```", "```py\ncerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')\ncerebro.addstrategy(MLStrategy, n_positions=10, min_positions=5, \n                    verbose=True, log_file='bt_log.csv')\nresults = cerebro.run()\nending_value = cerebro.broker.getvalue()\nf'Final Portfolio Value: {ending_value:,.2f}'\nFinal Portfolio Value: 10,502.32 \n```", "```py\nregister('algoseek',\n        algoseek_to_bundle(),\n        calendar_name='AlgoSeek',\n        minutes_per_day=960\n        ) \n```", "```py\nclass AlgoSeekCalendar(XNYSExchangeCalendar):\n    \"\"\"\n    A calendar for trading assets before and after market hours\n    Open Time: 4AM, US/Eastern\n    Close Time: 19:59PM, US/Eastern\n    \"\"\"\n    @property\n    def name(self):\n        return \"AlgoSeek\"\n    @property\n    def open_time(self):\n        return time(4, 0)\n    @property\n    def close_time(self):\n        return time(19, 59) \n```", "```py\nregister_calendar(\n        'AlgoSeek',\n        AlgoSeekCalendar()) \n```", "```py\ndef load_predictions(bundle):\n    predictions = pd.read_hdf('../00_data/backtest.h5', 'data')[['predicted']].dropna()\n    tickers = predictions.index.get_level_values(0).unique().tolist()\n    assets = bundle.asset_finder.lookup_symbols(tickers, as_of_date=None)\n    predicted_sids = pd.Int64Index([asset.sid for asset in assets])\n    ticker_map = dict(zip(tickers, predicted_sids))\n    return (predictions\n            .unstack('ticker')\n            .rename(columns=ticker_map)\n            .predicted\n            .tz_localize('UTC')), assets\nbundle_data = bundles.load('quandl')\npredictions, assets = load_predictions(bundle_data) \n```", "```py\nclass SignalData(DataSet):\n    predictions = Column(dtype=float)\n    domain = US_EQUITIES \n```", "```py\nsignal_loader = {SignalData.predictions:\n                     DataFrameLoader(SignalData.predictions, predictions)} \n```", "```py\nclass MLSignal(CustomFactor):\n    \"\"\"Converting signals to Factor\n        so we can rank and filter in Pipeline\"\"\"\n    inputs = [SignalData.predictions]\n    window_length = 1\n    def compute(self, today, assets, out, preds):\n        out[:] = preds \n```", "```py\ndef compute_signals():\n    signals = MLSignal()\n    return Pipeline(columns={\n        'longs' : signals.top(N_LONGS, mask=signals > 0),\n        'shorts': signals.bottom(N_SHORTS, mask=signals < 0)},\n            screen=StaticAssets(assets)) \n```", "```py\ndef initialize(context):\n    \"\"\"\n    Called once at the start of the algorithm.\n    \"\"\"\n    context.n_longs = N_LONGS\n    context.n_shorts = N_SHORTS\n    context.min_positions = MIN_POSITIONS\n    context.universe = assets\n    set_slippage(slippage.FixedSlippage(spread=0.00))\n    set_commission(commission.PerShare(cost=0, min_trade_cost=0))\n    schedule_function(rebalance,\n                      date_rules.every_day(),\n                      time_rules.market_open(hours=1, minutes=30))\n    schedule_function(record_vars,\n                      date_rules.every_day(),\n                      time_rules.market_close())\n    pipeline = compute_signals()\n    attach_pipeline(pipeline, 'signals') \n```", "```py\ndef before_trading_start(context, data):\n    \"\"\"\n    Called every day before market open.\n    \"\"\"\n    output = pipeline_output('signals')\n    context.trades = (output['longs'].astype(int)\n                      .append(output['shorts'].astype(int).mul(-1))\n                      .reset_index()\n                      .drop_duplicates()\n                      .set_index('index')\n                      .squeeze()) \n```", "```py\ndef rebalance(context, data):\n    \"\"\"\n    Execute orders according to schedule_function() date & time rules.\n    \"\"\"\n    trades = defaultdict(list)\n    for stock, trade in context.trades.items():\n        if not trade:\n            order_target(stock, 0)\n        else:\n            trades[trade].append(stock)\n    context.longs, context.shorts = len(trades[1]), len(trades[-1])\n    if context.longs > context.min_positions and context.shorts > context.min_positions:\n        for stock in trades[-1]:\n            order_target_percent(stock, -1 / context.shorts)\n        for stock in trades[1]:\n            order_target_percent(stock, 1 / context.longs) \n```", "```py\nresults = run_algorithm(start=start_date,\n                       end=end_date,\n                       initialize=initialize,\n                       before_trading_start=before_trading_start,\n                       capital_base=1e6,\n                       data_frequency='daily',\n                       bundle='quandl',\n                       custom_loader=signal_loader) # need to modify zipline\nreturns, positions, transactions = pf.utils.extract_rets_pos_txn_from_zipline(results) \n```", "```py\nclass Trendline(CustomFactor):\n    # linear 12-month price trend regression\n    inputs = [USEquityPricing.close]\n    window_length = 252\n    def compute(self, today, assets, out, close):\n        X = np.arange(self.window_length).reshape(-1, 1).astype(float)\n        X -= X.mean()\n        Y = close - np.nanmean(close, axis=0)\n        out[:] = (X.T @ Y / np.var(X)) / self.window_length \n```", "```py\nclass LinearModel(CustomFactor):\n    \"\"\"Obtain model predictions\"\"\"\n    train_on_weekday = [0, 2, 4]\n    def __init__(self, *args, **kwargs):\n        super().__init__(self, *args, **kwargs)\n        self._scaler = StandardScaler()\n        self._model = SGDRegressor(penalty='L2')\n        self._trained = False \n```", "```py\n def _maybe_train_model(self, today, returns, inputs):\n        if (today.weekday() in self.train_on_weekday) or not self._trained:\n            self._train_model(today, returns, inputs)\n    def compute(self, today, assets, out, returns, *inputs):\n        self._maybe_train_model(today, returns, inputs)\n        # Predict most recent feature values\n        X = np.dstack(inputs)[-1]\n        missing = np.any(np.isnan(X), axis=1)\n        X[missing, :] = 0\n        X = self._scaler.transform(X)\n        preds = self._model.predict(X)\n        out[:] = np.where(missing, np.nan, preds) \n```", "```py\n def _train_model(self, today, returns, inputs):\n        scaler = self._scaler\n        model = self._model\n        shift_by = N_FORWARD_DAYS + 1\n        outcome = returns[shift_by:].flatten()\n        features = np.dstack(inputs)[:-shift_by]\n        n_days, n_stocks, n_features = features.shape\n        features = features.reshape(-1, n_features)\n        features = features[~np.isnan(outcome)]\n        outcome = outcome[~np.isnan(outcome)]\n        outcome = outcome[np.all(~np.isnan(features), axis=1)]\n        features = features[np.all(~np.isnan(features), axis=1)]\n        features = scaler.fit_transform(features)\n        model.fit(X=features, y=outcome)\n        self._trained = True \n```", "```py\ndef make_ml_pipeline(universe, window_length=21, n_forward_days=5):\n    pipeline_columns = OrderedDict()\n    # ensure that returns is the first input\n    pipeline_columns['Returns'] = Returns(inputs=[USEquityPricing.open],\n                                          mask=universe,\n                                          window_length=n_forward_days + 1)\n    # convert factors to ranks; append to pipeline\n    pipeline_columns.update({k: v.rank(mask=universe)\n                             for k, v in features.items()})\n    # Create ML pipeline factor.\n    # window_length = length of the training period\n    pipeline_columns['predictions'] = LinearModel(\n        inputs=pipeline_columns.values(),\n        window_length=window_length + n_forward_days,\n        mask=universe)\n    return Pipeline(screen=universe, columns=pipeline_columns) \n```", "```py\ndef before_trading_start(context, data):\n    output = pipeline_output('ml_model')\n    context.predicted_returns = output['predictions']\n    context.predicted_returns.index.rename(['date', 'equity'], inplace=True)\n    evaluate_predictions(output, context) \n```", "```py\ndef evaluate_predictions(output, context):\n    # Look at past predictions to evaluate model performance out-of-sample\n    # A day has passed, shift days and drop old ones\n    context.past_predictions = {\n        k - 1: v for k, v in context.past_predictions.items() if k > 0}\n    if 0 in context.past_predictions:\n        # Use today's forward returns to evaluate predictions\n        returns, predictions = (output['Returns'].dropna()\n                                .align(context.past_predictions[0].dropna(),\n                                       join='inner'))\n        if len(returns) > 0 and len(predictions) > 0:\n            context.ic = spearmanr(returns, predictions)[0]\n            context.rmse = np.sqrt(\n                mean_squared_error(returns, predictions))\n            context.mae = mean_absolute_error(returns, predictions)\n            long_rets = returns[predictions > 0].mean()\n            short_rets = returns[predictions < 0].mean()\n            context.returns_spread_bps = (\n                long_rets - short_rets) * 10000\n    # Store current predictions\n    context.past_predictions[N_FORWARD_DAYS] = context.predicted_returns \n```"]