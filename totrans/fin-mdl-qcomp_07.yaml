- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Simulators and HPC’s Role in the NISQ Era
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we know how to make quantum and classical computing resources available
    and have reviewed how to pose our problems in both domains, we should evaluate
    the available mechanisms and strategies for exploiting those resources efficiently.
    By that, we mean cost and time efficiency, given that those axes will also need
    to be considered when it comes to including these techniques in our company’s
    daily processes.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, the classical resources in most companies comprise a mixture of on-premises
    and cloud-enabled resources. This is the common case for most experimental projects
    aiming to improve operational processes using analytics. Ephemeral computing resources
    may have different needs, depending on the project or the nature of the technique
    we envision using. That is why the cloud-native pay-per-use model has become a
    good option for most companies.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the tasks, **graphical processing units** (**GPUs**) for machine
    learning activities or high-performance computing resources for optimization problems
    might be required. Purchasing those resources without knowing the initiative’s
    outcome might be too expensive. But it is also true that once those processes
    are operationalized, capitalizing costs on infrastructure and integrating those
    resources into more cost-efficient structures become crucial. Pay-per-use can
    become expensive if it’s not evaluated sensibly. In layman’s terms, there is a
    market for both renting and owning cars. It all gets reduced to usage.
  prefs: []
  type: TYPE_NORMAL
- en: Finding the right combination of resources from the beginning, even in a project
    life cycle, is key for quantum computing and overall business sustainability and
    competitiveness. Quantum computing goes beyond the quantum hardware itself, and
    many options can be used when adopting it. From quantum-inspired to fully quantum
    algorithms, as we have covered in previous chapters, we must find the right resources
    for those solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, this chapter will explore the variety of potential options within
    the quantum domain and how these can be used for cost-effective technology adoption.
    We will also try to outline a sensible adoption approach so that it serves those
    less familiar with the life cycle of analytics projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Local simulation of quantum hardware with noise
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed approaches to running local emulators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Local simulation of noise models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First, we must distinguish between the three naming conventions we will use
    during this chapter and the following ones. Previously, we talked about how quantum
    algorithms can be run on a classical device before being sent to a real quantum
    device, but there are some different ways in which this classical execution can
    be done. Problems such as the ones we have posed have been around for a while,
    and classical computing has evolved in many different ways to bring solutions
    to the technology at hand during this time. As we will see, this may also bring
    some challenges related to the specifics of the different classical setups we
    will cover. Mimicking quantum mechanical evolution is a non-trivial task; that
    was how quantum computing was proposed as a potential solution.
  prefs: []
  type: TYPE_NORMAL
- en: '*Simulators* are the classical means of processing information in the way an
    ideal quantum computer would do so. Recall that quantum information theory is
    not a new task brought about by the availability of quantum hardware. Lots of
    work was done even before the first quantum device was created (*Bennet and Shor,
    1998*). By defining the quantum information and determining the set of operations
    to be employed, the sequence that applies these operations to our quantum states
    is what we refer to as algorithms or circuits in the quantum domain. Simulators
    make the mathematical apparatus used in quantum computing computationally available.
    We have not discussed those terms much since [*Chapter 1*](B19146_01.xhtml#_idTextAnchor016),
    but remember that a quantum state is, in simple terms, a vector that encodes the
    wave function of a given system. As an example, we can represent the basic 0 state
    as a column vector, as shown in the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|0⟩ = ( 1   0 )'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, computationally, we could represent it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, operations, such as the CNOT or Hadamard gates, which are
    used to create superposed states, are nothing other than the matrices that perform
    the evolution from one state into its product state. A Hadamard gate, for example,
    is represented by the following matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: H =  1 _ √ _ 2  (1 1 1 − 1)
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code can express its coded version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Since each operator (quantum gate) can be represented as a matrix, it is simple
    to perform those operations with classical resources, so long as we have sufficient
    resources. Memory, in particular, becomes relevant as the system’s size grows.
    The representation for a quantum computer is two to the power of *N* matrices,
    and vectors will need to be handled to perform such computations. We can benefit
    from the work we’ve done on vectorization and sparse matrix handling, but at this
    point, our classical devices will reach their limits with these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, applying a Hadamard gate to our basic 0 state qubit would yield
    a state in a superposition of the 0 and 1 states. This action can be simulated
    by creating the dot product of the previously defined objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the superposed quantum state:'
  prefs: []
  type: TYPE_NORMAL
- en: '|ψ⟩ =  1 _ √ _ 2  (|0⟩ + |1⟩)'
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have performed our first simulation. Starting from the initial
    state, most devices are initialized with a Hadamard gate operator (*H*), producing
    the output state. We could extend it so that all basic gates and states can be
    represented and thus work at higher levels of abstraction. This is mostly what
    quantum simulators do when we use them to run an algorithm. Frameworks such as
    Qiskit or Pennylane offer this set of operations as abstractions to this matrix
    product of operations so that it is easy for us to use those by simply using those
    definitions.
  prefs: []
  type: TYPE_NORMAL
- en: How many classical resources are needed to simulate a quantum system? Well,
    this is where things become interesting – you can expect many qubits to be simulated
    on a normal laptop and many bit operations to be performed. But the truth is that
    16-qubit algorithms may already consume more than the available memory on a common
    laptop. As an example, 16 qubits would encode the available options for 16 assets
    of the portfolio optimization task we reviewed in [*Chapter 5*](B19146_05.xhtml#_idTextAnchor100).
    This is a small problem that can be easily solved using classical computers but
    that would, on its quantum version, consume up to the 16 GB available on a regular
    laptop using any of those previously mentioned frameworks. So, how can classical
    computers handle that, and how can quantum simulators get out of hand at the same
    size?
  prefs: []
  type: TYPE_NORMAL
- en: The amount of information you are processing when simulating quantum mechanical
    systems is much more than the simple sum of assets and derived information you
    could have encoded into those quantum objects. Quantum mechanical dynamics occur
    in more complex spaces, which require many more resources to reproduce whole system
    dynamics faithfully. But that also means fewer quantum resources are necessary
    to encode larger pieces of classical information (*Bowen, 2001*). Hopefully, thanks
    to this very same fact, we can compute things differently, and that is when the
    advantage arises. Making use of quantum domain characteristics such as superposition
    or entanglement, we can do things a little bit differently, such as evaluating
    all potential combinations via single-step operations (*Brassard et al. 2002*)
    or making solutions cancel out between them, amplifying the best candidates, as
    we did in the examples in *Chapters 4*, *5*, and *6*.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we have covered the basics of how different quantum computing is
    from classical computing. Therefore, you must know that classical systems have
    limitations when it comes to mimicking those dynamics. That is why so much effort
    has been put into creating computers that work at a quantum mechanical level so
    that there is no loss due to the classical “emulation” of those effects.
  prefs: []
  type: TYPE_NORMAL
- en: While mimicking real quantum devices, we can take things one step further and
    allow our classical simulations not only to work as an ideal quantum computer
    but also as a specific device. When simulating specific devices, we would like
    to mimic all their restrictions regarding connectivity or error statistics. In
    the current state of the NISQ era (*Preskill, 2021*), it is important that we
    faithfully characterize the specifics of our target device.
  prefs: []
  type: TYPE_NORMAL
- en: '*Emulator* is the word used when simulators mimic quantum dynamics within a
    given set of restrictions associated with specific quantum hardware. In the case
    of IBM’s superconducting chips, for example, we can retrieve their model from
    Qiskit and use existing local simulators limited to the functioning of the real
    device. This means that not all possible two-qubit gate operations can be performed
    between any two qubits, plus operations will fail sometimes, with what we call
    errors, thus producing noise (inaccuracies):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '*Figure 8**.1* is a representation of the error map for the fake Vigo.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – IBM Vigo chip description highlighting qubit connectivity and
    error upon H, CNOT, or measurement operations](img/B19146_08_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – IBM Vigo chip description highlighting qubit connectivity and error
    upon H, CNOT, or measurement operations
  prefs: []
  type: TYPE_NORMAL
- en: By running our circuits against this fake instance instead of a simulator, we
    will face the same issues as we would when using the real device and obtain results
    closer to the ones obtained with it without waiting in the actual device queue.
    That is why, when a quantum circuit needs to be sent to an actual device (or an
    emulator mimicking the real hardware), a transpilation step is needed. We need
    a step that translates our theoretical and device-agnostic algorithm into the
    available gates and provides connectivity to the hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we take the example of the two-qubit bell state we presented in [*Chapter
    1*](B19146_01.xhtml#_idTextAnchor016), as shown in *Figure 8**.2*, we could add
    a transpilation step to that `fake_vigo` device and see what is drawn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The last line of code outputs the circuit shown in *Figure 8**.2*. It represents
    one of the Bell states.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Bell state circuit](img/B19146_08_002.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Bell state circuit
  prefs: []
  type: TYPE_NORMAL
- en: 'The circuit needs to be broken into gates implemented on the quantum computer.
    To do that, the circuit needs to be transpiled:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 8.3 – Circuit transpiled based on the Bell state with the emulator
    configuration](img/B19146_08_003.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Circuit transpiled based on the Bell state with the emulator configuration
  prefs: []
  type: TYPE_NORMAL
- en: These discrepancies come from the fact that the Hadamard gate is not a native
    operation in the device, even though its error is shown in *Figure 8**.1*. We
    need to transform the circuit into native gate operations so that their combination
    produces the same effect as an H gate would. We also need to specify what will
    happen to the rest of the qubits that are part of the hardware specification but
    not of the circuit.
  prefs: []
  type: TYPE_NORMAL
- en: This fact, of course, extends to all devices, not only IBM’s, as each manufacturer
    and the underlying technology are different. Moreover, each chip will show different
    error statistics at different moments in time, and this is because they are being
    worked on and improved upon. Therefore, device models may need to be updated every
    once in a while, so the last snapshot of the device is used.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, we have quantum *devices*, the actual services we showed in [*Chapter
    7*](B19146_07.xhtml#_idTextAnchor145), which can ultimately be used to run our
    algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Like in any sensible project development, it is relevant to understand the difference
    between the three options and know when it makes sense to leverage each one.
  prefs: []
  type: TYPE_NORMAL
- en: Simulators help us conceptualize algorithms and particular implementations so
    that we can envision the expected outcome for a given use case. The classical
    resources will limit us, but, as we will see, there are plenty of options for
    squeezing these resources as much as possible before moving forward.
  prefs: []
  type: TYPE_NORMAL
- en: The ultimate goal of a quantum algorithm is for it to be run on quantum hardware.
    As much as we could work on classical resources, we would find limitations as
    we moved forward at the scale of our problems. Quantum devices are scarce, and
    we may need to adapt a theoretical algorithm to the specific hardware. But given
    that these are scarce and are doing that work locally, emulating a device is a
    suitable option before moving forward.
  prefs: []
  type: TYPE_NORMAL
- en: Device emulation makes us aware of the changes our theoretical algorithm will
    face, and the results will be much closer to the actual expected outcome when
    it’s run on the device. For variational approaches and QML, which not only require
    many iterations to fit parameters also but where the parameter fitting may substantially
    change due to device behavior, these are really valuable resources. Having a faithful
    representation or model of the device is also key. Even though some providers
    will charge for the emulator, most can be accessed freely or mimicked using some
    of the software we have explored so far. Some of the devices shown in [*Chapter
    7*](B19146_07.xhtml#_idTextAnchor145) are classically emulated quantum device
    representations. Providers such as Quantinuum offer access to their devices and
    emulators, often offering less waiting time so that researchers can balance their
    workload between the emulator and the actual device.
  prefs: []
  type: TYPE_NORMAL
- en: Most libraries and frameworks offer resources to create noise models to be added
    to standard simulators ([https://qiskit.org/documentation/tutorials/simulators/3_building_noise_models.html](https://qiskit.org/documentation/tutorials/simulators/3_building_noise_models.html)).
    But what if our algorithm requires more classical resources than the ones we can
    provide on our laptops? Next, we will explore some interesting options we may
    need to consider from the range of available classical resources to get the most
    out of those devices.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed computing approaches to quantum simulation
  prefs: []
  type: TYPE_NORMAL
- en: One way we could get the most classical resources is by leveraging distributed
    frameworks for quantum computing.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, they are omnipresent in all large organizations. Some distributed
    computing frameworks, such as Apache Spark and Ray, have been extensively used
    for large dataset wrangling or deep learning model training (*Meng et al. 2016,
    Moritz et al. 2018*). Not far from it, quantum computing simulators can leverage
    the distributed ecosystem by splitting the mathematical operations that need to
    be performed. Splitting a system that should operate as a whole as a set of independent
    operations requires us to understand how splittable our problem at hand is.
  prefs: []
  type: TYPE_NORMAL
- en: This is why most of the frameworks that deal with distributed quantum computing
    simulation come from research teams, even in large organizations such as Intel
    (*Guerreschi et al. 2020*) and Baidu (*Zhao et* *al. 2021*).
  prefs: []
  type: TYPE_NORMAL
- en: As quantum hardware matures, device-independent frameworks will likely proliferate,
    but there is still a lack of consensus that renders into isolated or hardware-specific
    frameworks for distributed computation. This is the reason why Microsoft researchers
    have created **Quantum Intermediate Representation** (**QIR**) and the QIR Alliance
    ([https://www.qir-alliance.org/](https://www.qir-alliance.org/)) is to help deliver
    an industry standard that can help boost that interoperability between hardware
    providers and quantum computing scientists.
  prefs: []
  type: TYPE_NORMAL
- en: The creation of an industry-wide standard will also help boost work done on
    cloud-based quantum computation for quantum deep learning (*Kwak et al., 2022*)
    and emerging quantum versions for federated learning (*Li et al, 2021*), which
    is already present as a solution for fighting against organized crime and collaborative
    financial crime detection (*Suzumura et* *al., 2021*).
  prefs: []
  type: TYPE_NORMAL
- en: While these standards and distributed frameworks evolve at the maturity of their
    classical counterparts, there is still room for computational efficiency in simulating
    complex systems, which is what we will dig into in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Tensor networks for simulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Tensor networks are new to many people approaching quantum computation but were
    created a while back. Even though initial steps were made in the early 90s to
    help deal with large systems in the field of condensed matter physics, this rapidly
    extended to other fields, such as high-energy and many-body physics. This exploded
    during the early 2000s as a whole family of methods and algorithms suited to particular
    use cases of studying entanglement at many different levels (*Biamonte and Bergholm,
    2017;* *Órus, 2019*).
  prefs: []
  type: TYPE_NORMAL
- en: Entanglement is one of the key properties that makes quantum computing highly
    intriguing, powerful, and challenging to comprehend and develop intuition about.
    Tensors, as mathematical objects, provide a consistent framework for handling
    relationships between sets of objects related to an *N*-dimensional vector space.
    Due to the dimensionality that some problems in certain areas of physics pose,
    the tensor network framework allows researchers to decompose these complex structures
    into tensor products, which can be contracted and expanded so that they can be
    handled more efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Knowing the relevance of tensor networks in the field of quantum computing,
    some providers have already taken a step forward and developed their frameworks
    so that researchers can leverage them. This is the case of the Pennylane creators,
    Xanadu, and their Jet framework (*Vincent et* *al. 2022*).
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will simulate a two-qubit circuit producing a Bell state using the
    Jet framework as an exercise. The resemblance between the circuit and the tensorial
    representation, as can be seen in the following figure, should help you envision
    the similarity between both approaches. The efficiency of computing will become
    apparent when the scale of the circuit is increased:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – A quantum circuit producing a two-qubit entangled bell state
    (left); tensor network representation highlighting the indexes to be used in the
    following code example (right)](img/B19146_08_004.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – A quantum circuit producing a two-qubit entangled bell state (left);
    tensor network representation highlighting the indexes to be used in the following
    code example (right)
  prefs: []
  type: TYPE_NORMAL
- en: 'As we did previously, we will need to create the two 0 states that will kickstart
    our circuit state (initialization). In this case, we will need to indicate the
    index and dimensionality of our states:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, the Hadamard gate is represented by the matrix operator, and the
    indexes indicate where it is placed for our initial states:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'It does not matter if the *k* index has not appeared before, as it will be
    the link to further actions. The last action will be the **Control NOT** (**CNOT**)
    operation, which acts on the second qubit only if the first one (also called the
    control qubit) is in state |1>. It is characterized by the following matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: CNOT = ⎡ ⎢ ⎣1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0⎤ ⎥ ⎦
  prefs: []
  type: TYPE_NORMAL
- en: 'So, we can compose it by selecting which elements of the matrix are the ones
    that should be replaced with a value of 1, given that the matrix is initialized
    with 0 values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'With these four elements, we can compose our tensor network, linking each element
    by the indexes that are common to the rest. We could, for example, simply impose
    the Hadamard action on the first qubit (similar to what we did in the first exercise)
    and ask for its contraction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'This will yield an equal superposition of |0> and |1> states:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see how the obtained tensor is the one referenced by the *k* index.
    Just by concatenating further actions and asking for the final contraction, we
    can effectively simulate the full chain of actions until the circuit produces
    the final state:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'In the two-qubit case, we can see how the first (|00>) and last (|11>) are
    states with probability amplitudes above zero and of equal value. They should
    coincide with the Bell state encoded by the circuit in *Figure 8**.3*, which can
    be represented in Dirac notation, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Quantum circuit producing an entangled bell state (source: Wikipedia)](img/B19146_08_005.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.5 – Quantum circuit producing an entangled bell state (source: Wikipedia)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to its fundamental functioning, many providers already offer the fundamentals
    of it as a simulator so that users can work at higher abstraction levels. We can
    find it as an option with some cloud vendors, as in the case of AWS cloud devices,
    as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – AWS TN1 tensor network simulator description page](img/B19146_08_006.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – AWS TN1 tensor network simulator description page
  prefs: []
  type: TYPE_NORMAL
- en: It costs up to 0.275 dollars per minute but can perform on up to 50 qubits and
    100 gate circuit instances. Both SV1 and DM1 devices, which can classically simulate
    circuits as well, are limited to up to 34 qubits and 17 qubit circuits, respectively
    (also being cheaper options).
  prefs: []
  type: TYPE_NORMAL
- en: Given that it all seems to boil down to tensor multiplications (vectors for
    states and matrices for operators in general), there is an evident step to squeeze
    our classical resources up to their limit, which is done by exploiting all available
    classical resources when performing those computations. Tensor networks are great
    for simplifying the required computation, but still, the hardware needs to be
    provided. This is when classical resources for vector and matrix computation join
    the quantum computing party.
  prefs: []
  type: TYPE_NORMAL
- en: GPUs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously, GPUs also play a key role in short-term quantum computing.
    Initially, GPUs were designed for matrix operations, which are required when rendering
    images on a computer. Mid-90s manufacturers such as Nvidia ([https://en.wikipedia.org/wiki/NV1](https://en.wikipedia.org/wiki/NV1))
    released their first working cards and have been actively innovating since then.
    The gaming industry made sure GPU manufacturers had continuous improvements to
    be delivered both software and hardware-wise, making those devices more and more
    performant for their main tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at adjacent fields, GPU manufacturers realized that it was becoming
    more and more difficult to train models on a CPU for machine learning specialists,
    particularly in computer vision. And with the explosion of large-scale models
    and the deep learning era, it was obvious that there was a niche market to exploit
    for their product. Their ability to boost deep learning tasks comes from the fact
    that performing matrix operations efficiently is their main purpose. In general,
    computers process images as tensors, performing convolutions on them to identify
    cats or dogs (for example), detect objects in the image, or segment the objects
    on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given that matrix operations are at the core of the mathematical concept of
    quantum computing, a few providers such as Nvidia focused on how they could help
    boost this field, which later released an SDK specialized for quantum computing
    that leverages the usage of its card architectures ([https://docs.nvidia.com/cuda/cuquantum/](https://docs.nvidia.com/cuda/cuquantum/)).
    Not only that, but it also provided specialized frameworks for previously highlighted
    techniques and mathematical frameworks, making its GPU cards the cornerstone for
    current quantum computing research:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Architecture for the GPU-based simulation framework described
    by NVIDIA](img/B19146_08_007.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Architecture for the GPU-based simulation framework described by
    NVIDIA
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to its abstractions, most hardware providers and cloud computing vendors
    can seamlessly integrate state-of-the-art quantum simulation and emulation technology
    on its stack, making it available to the general public.
  prefs: []
  type: TYPE_NORMAL
- en: For those interested in diving a little bit deeper into the technology, frameworks
    such as Baidu’s PaddlePaddle and Xanadu’s Pennylane offer the option to run their
    simulations on top of Nvidia cards by allowing Python-intermediate libraries to
    interact with native CUDA libraries acting on the hardware. Even if it sounds
    complicated, it just takes a few lines of code to enable this boosting.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, when using Qiskit as the main framework, you can install the Aer
    simulator’s version with GPU support:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It will overwrite the standard `qiskit-aer` library, and all simulations will
    utilize GPU-backed processing for state vector simulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Xanadu and its QML framework, Pennylane, went in a different direction. It
    released a completely separate library called Lightning that, once installed with
    GPU support, allows users to invoke a GPU device so that all required calculations
    are sent to the GPU instead of the default CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Google went on a different journey, defining its specific hardware as optimized
    for low-dimensional matrices and the broader definition of tensors. These devices
    are called *tensor processing units* ([https://cloud.google.com/tpu/docs/tpus](https://cloud.google.com/tpu/docs/tpus))
    and are the natural evolution of this abstraction; they are particularly suited
    for AI and will most likely boost some of the workloads of its cloud-provided
    quantum computing service ([https://quantumai.google/cirq/google/concepts](https://quantumai.google/cirq/google/concepts)).
    Thanks to the cloud’s abstraction, it would most likely be hard to tell where
    our circuits were running if it was not for their price.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we saw that there are many ways to simulate a quantum computer
    before running it on an actual device. We saw that there are also some implications
    regarding the limited availability, errors, and specific characteristics of the
    real hardware to be considered and that classical computers are not yet done when
    it comes to quantum computing.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing a strategy to validate our circuits, evaluate their potential,
    and decide where those algorithms will run requires understanding the set of options
    provided by almost all quantum companies.
  prefs: []
  type: TYPE_NORMAL
- en: Tensor networks provide a powerful mathematical framework to simulate complex
    systems efficiently. GPUs have also placed their bet. Even combining both has
    proven to be a valid approach for simulating large devices.
  prefs: []
  type: TYPE_NORMAL
- en: Distributed computation is anticipated to be the next hurdle to overcome, necessitating
    a certain level of technical expertise to harness its potential efficiently. Similar
    to the trajectory followed by tensor networks and GPUs, simplified approaches
    have emerged to exploit classical computing resources at various levels.
  prefs: []
  type: TYPE_NORMAL
- en: Vendors such as Nvidia already provide a distributed framework for data science
    called RAPIDS, which simplifies the end-to-end work, boosting the core activities
    related to data cleaning, transformation, and model training. It allows us to
    imagine a future where distributed GPU-enabled tensor network-rooted quantum computing
    simulators and emulators will be integrated within the actual ecosystem for end-to-end
    data-driven use case exploitation. Even when fault-tolerant quantum devices are
    available to the open public, this type of setting will provide a cost-efficient
    way to tackle some of the most complicated problems companies face nowadays.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid quantum computation will make use of all the research that has been developed
    so that meaningful advances in science and business will be accelerated in the
    near future.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For those interested in diving deeper into some of the techniques mentioned
    in this chapter, here are some recommendations that should help you understand
    the basics.
  prefs: []
  type: TYPE_NORMAL
- en: One of the most interesting and challenging frameworks we have discussed is
    tensor networks. Many resources can be found in the literature. Still, two that
    we can recommend are the work by Biamonte and Bergholm from 2017, which provides
    a solid foundation to understand its potential better. For those more hands-on
    engineers, the Quimb (*Gray, 2018*) and Jet (*Vincent et al., 2022*) Python packages
    provide a fun way to learn and experiment.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, distributed computation has a path, and works by Zaharia et al. (2010)
    on Apache Spark and Moritz et al. (2018) on Ray are leading the path toward easy-to-implement
    distributed solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Something particularly interesting is the contribution of the Baidu team to
    the existing PaddlePaddle framework (*Ma et al., 2020*). Not only have they provided
    an industrial-level framework for deep learning but they have also adapted part
    of it to include QML-related works, extending it to one of the most interesting
    hybrid QML platforms that’s openly available: [https://github.com/PaddlePaddle/Quantum](https://github.com/PaddlePaddle/Quantum).'
  prefs: []
  type: TYPE_NORMAL
- en: It also specifies the possibility of performing said calculation on GPUs so
    that users get the most out of classical resources.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Bennett, C. H., & Shor, P. W. (1998). Quantum information theory. IEEE transactions
    on information theory,* *44(6), 2,724-2,742.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Biamonte, J., & Bergholm, V. (2017). Tensor networks in a nutshell. arXiv*
    *preprint arXiv:1708.00006.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Brassard, G., Hoyer, P., Mosca, M., & Tapp, A. (2002). Quantum amplitude amplification
    and estimation. Contemporary Mathematics,* *305, 53-74.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Bowen, G. (2001). Classical information capacity of superdense coding. Physical
    Review A,* *63(2), 022302.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Guerreschi, G. G., Hogaboam, J., Baruffa, F., & Sawaya, N. P. (2020). Intel
    Quantum Simulator: A cloud-ready high-performance simulator of quantum circuits.
    Quantum Science and Technology,* *5(3), 034007.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Gray, J. (2018). quimb: A Python package for quantum information and many-body
    calculations. Journal of Open Source Software,* *3(29), 819.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Kwak, Y., Yun, W. J., Kim, J. P., Cho, H., Park, J., Choi, M., ... & Kim,
    J. (2022). Quantum distributed deep learning architectures: Models, discussions,
    and applications.* *ICT Express.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Li, W., Lu, S., & Deng, D. L. (2021). Quantum federated learning through blind
    quantum computing. Science China Physics, Mechanics & Astronomy,* *64(10), 1-8.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Ma, Y., Yu, D., Wu, T., & Wang, H. (2019). PaddlePaddle: An open-source deep
    learning platform from industrial practice. Frontiers of Data and Computing,*
    *1(1), 105-115.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Meng, X., Bradley, J., Yavuz, B., Sparks, E., Venkataraman, S., Liu, D., ...
    & Talwalkar, A. (2016). Mllib: Machine learning in apache spark. The Journal of
    Machine Learning Research,* *17(1), 1,235-1,241.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., ...
    & Stoica, I. (2018). Ray: A distributed framework for emerging {AI} applications.
    In the 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    18) (**pp. 561-577).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Orús, R. (2019). Tensor networks for complex quantum systems. Nature Reviews
    Physics,* *1(9), 538-550.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Preskill, J. (2021). Quantum computing 40 years later. arXiv* *preprint arXiv:2106.10522.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Suzumura, T., Zhou, Y., Kawahara, R., Baracaldo, N., & Ludwig, H. (2022).
    Federated Learning for Collaborative Financial Crimes Detection. In Federated
    Learning (pp. 455-466).* *Springer, Cham.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Vincent, T., O’Riordan, L. J., Andrenkov, M., Brown, J., Killoran, N., Qi,
    H., & Dhand, I. (2022). Jet: Fast quantum circuit simulations with parallel task-based
    tensor-network contraction. Quantum,* *6, 709.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Zaharia, M., Chowdhury, M., Franklin, M. J., Shenker, S., & Stoica, I. (2010).
    Spark: Cluster computing with working sets. In the 2nd USENIX Workshop on Hot
    Topics in Cloud Computing (**HotCloud 10).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Zhao, X., Zhao, B., Wang, Z., Song, Z., & Wang, X. (2021). Practical distributed
    quantum information processing with LOCCNet. npj Quantum Information,* *7(1),
    1-7.*'
  prefs: []
  type: TYPE_NORMAL
