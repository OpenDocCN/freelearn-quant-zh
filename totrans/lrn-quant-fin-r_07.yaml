- en: Chapter 6.  Trading Using Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第六章 使用机器学习进行交易
- en: In the capital market, machine learning-based algorithmic trading is quite popular
    these days and many companies are putting a lot of effort into machine learning-based
    algorithms which are either proprietary or for clients. Machine learning algorithms
    are programmed in such a way that they learn continuously and change their behavior
    automatically. This helps to identify new patterns when they emerge in the market.
    Sometimes patterns in the capital market are so complex they cannot be captured
    by humans. Even if humans somehow managed to find one pattern, humans do not have
    the tendency to find it efficiently. Complexity in patterns forces people to look
    for alternative mechanisms which identify such complex patterns accurately and
    efficiently.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在资本市场，基于机器学习的算法交易如今非常流行，许多公司正在投入大量精力研发机器学习算法，这些算法要么是专有的，要么是为客户提供的。机器学习算法是以一种能够不断学习并自动改变其行为的方式编写的。这有助于在市场中出现新模式时及时识别。有时候，资本市场中的模式是如此复杂，以至于人类无法捕捉到。即使人类设法找到了某个模式，也无法高效地识别它。模式的复杂性迫使人们寻求其他机制，以准确高效地识别这些复杂的模式。
- en: 'In the previous chapter, you got the feel of momentum, pairs-trading-based
    algorithmic trading, and portfolio construction. In this chapter, I will explain
    step by step a few supervised and unsupervised machine learning algorithms which
    are being used in algorithm trading:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你了解了动量、基于配对交易的算法交易和投资组合构建。在本章中，我将一步步解释一些在算法交易中使用的有监督和无监督的机器学习算法：
- en: Logistic regression neural network
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归神经网络
- en: Neural network
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: Deep neural network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: K means algorithm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K均值算法
- en: K nearest neighborhood
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K最近邻算法
- en: Support vector machine
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: Decision tree
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树
- en: Random forest
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: A few of the packages used in this chapter are `quantmod`, `nnet`, `genalg`,
    `caret`, `PerformanceAnalytics`, `deepnet`, `h2o`, `clue`, `e1071`, `randomForest`,
    and `party`.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的几个包包括`quantmod`、`nnet`、`genalg`、`caret`、`PerformanceAnalytics`、`deepnet`、`h2o`、`clue`、`e1071`、`randomForest`和`party`。
- en: Logistic regression neural network
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归神经网络
- en: 'Market direction is very important for investors or traders. Predicting market
    direction is quite a challenging task as market data involves lots of noise. The
    market moves either upward or downward and the nature of market movement is binary.
    A logistic regression model help us to fit a model using binary behavior and forecast
    market direction. Logistic regression is one of the probabilistic models which
    assigns probability to each event. I am assuming you are well versed with extracting
    data from Yahoo as you have studied this in previous chapters. Here again, I am
    going to use the `quantmod` package. The next three commands are used for loading
    the package into the workspace, importing data into R from the `yahoo` repository
    and extracting only the closing price from the data:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 市场方向对于投资者或交易者来说非常重要。预测市场方向是一项非常具有挑战性的任务，因为市场数据充满了噪声。市场要么上涨，要么下跌，市场运动的性质是二元的。逻辑回归模型帮助我们通过二元行为拟合模型，并预测市场方向。逻辑回归是一种概率模型，它为每个事件分配概率。我假设你已经熟悉从Yahoo提取数据，因为你在前面的章节中已经学习过这一部分。这里我仍将使用`quantmod`包。接下来的三条命令用于将该包加载到工作空间中，从`yahoo`库导入数据，并仅提取数据中的收盘价：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The input data to the logistic regression is constructed using different indicators,
    such as moving average, standard deviation, RSI, MACD, Bollinger Bands, and so
    on, which has some predictive power in market direction, that is, `Up` or `Down.`
    These indicators can be constructed using the following commands:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的输入数据是通过不同的指标构建的，如移动平均、标准差、相对强弱指数（RSI）、平滑异同移动平均线（MACD）、布林带等，这些指标在市场方向上具有一定的预测能力，即`Up`（上涨）或`Down`（下跌）。这些指标可以通过以下命令构建：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following commands are to create variable direction with either `Up` direction
    (`1`) or `Down` direction (`0`). `Up` direction is created when the current price
    is greater than the 20 days previous price and `Down` direction is created when
    the current price is less than the 20 days previous price:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于创建方向变量，方向可以是`Up`（上涨，`1`）或`Down`（下跌，`0`）。当当前价格大于20天前的价格时，创建`Up`方向；当当前价格小于20天前的价格时，创建`Down`方向：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we have to bind all columns consisting of price and indicators, which is
    shown in the following command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要绑定所有包含价格和指标的列，以下命令展示了如何操作：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The dimension of the `dji` object can be calculated using `dim()`. I used `dim()`
    over `dji` and saved the output in `dm()`. `dm()` has two values stored: the first
    value is the number of rows and the second value is the number of columns in `dji`.
    Column names can be extracted using `colnames()`. The third command is used to
    extract the name for the last column. Next I replaced the column name with a particular
    name, `Direction`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`dim()`计算`dji`对象的维度。我对`dji`使用了`dim()`并将输出保存到`dm()`中。`dm()`存储了两个值：第一个值是行数，第二个值是列数。列名可以通过`colnames()`提取。第三个命令用于提取最后一列的名称。接下来，我将列名替换为特定的名称`Direction`：
- en: '[PRE4]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We have extracted the **Dow Jones Index** (**DJI**) data into the R workspace.
    Now, to implement logistic regression, we should divide the data into two parts.
    The first part is in-sample data and the second part is out-sample data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将**道琼斯指数**（**DJI**）数据提取到 R 工作空间中。现在，为了实现逻辑回归，我们应该将数据分为两部分。第一部分是样本内数据，第二部分是样本外数据。
- en: 'In-sample data is used for the model building process and out-sample data is
    used for evaluation purposes. This process also helps to control the variance
    and bias in the model. The next four lines are for in-sample start, in-sample
    end, out-sample start, and out-sample end dates:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 样本内数据用于模型构建过程，样本外数据用于评估目的。这个过程还有助于控制模型中的方差和偏差。接下来的四行是样本内开始、样本内结束、样本外开始和样本外结束日期：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following two commands are to get the row number for the dates, that is,
    the variable `isrow` extracts row numbers for the in-sample date range and `osrow`
    extracts the row numbers for the out-sample date range:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下两个命令用于获取日期的行号，即变量`isrow`提取样本内日期范围的行号，`osrow`提取样本外日期范围的行号：
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The variables `isdji` and `osdji` are the in-sample and out-sample datasets
    respectively:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`isdji`和`osdji`分别是样本内和样本外数据集：
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you look at the in-sample data, that is, `isdji`, you will realize that
    the scaling of each column is different: a few columns are in the scale of 100,
    a few others are in the scale of 10,000, and a few others are in the scale of
    1\. Difference in scaling can put your results in trouble as higher weights are
    being assigned to higher scaled variables. So before moving ahead, you should
    consider standardizing the dataset. I will use the following formula:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看样本内数据，即`isdji`，你会发现每一列的尺度不同：有些列的尺度是100，有些列的尺度是10,000，还有些列的尺度是1。尺度的不同可能会导致结果出现问题，因为较高尺度的变量会被赋予更高的权重。因此，在继续之前，你应该考虑对数据集进行标准化。我将使用以下公式：
- en: '![Logistic regression neural network](img/00088.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归神经网络](img/00088.jpeg)'
- en: 'The mean and standard deviation of each column using `apply()` can be seen
    here:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`apply()`可以查看每列的均值和标准差：
- en: '[PRE8]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'An identity matrix of dimension equal to the in-sample data is generated using
    the following command, which is going to be used for normalization:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令生成一个维度与样本内数据相同的单位矩阵，该矩阵将用于标准化：
- en: '[PRE9]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Use formula 6.1 to standardize the data:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公式 6.1 来标准化数据：
- en: '[PRE10]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The preceding line also standardizes the `direction` column, that is, the last
    column. We don''t want direction to be standardized so I replace the last column
    again with variable direction for the in-sample data range:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的行也标准化了`direction`列，即最后一列。我们不希望方向被标准化，所以我再次将最后一列替换为变量方向，适用于样本内数据范围：
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now we have created all the data required for model building. You should build
    a logistic regression model and it will help you to predict market direction based
    on in-sample data. First, in this step, I created a formula which has direction
    as dependent and all other columns as independent variables. Then I used a generalized
    linear model, that is, `glm()`, to fit a model which has formula, family, and
    dataset:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了构建模型所需的所有数据。你应该建立一个逻辑回归模型，它将帮助你根据样本内数据预测市场方向。首先，在这一步中，我创建了一个公式，其中方向作为因变量，所有其他列作为自变量。然后，我使用了广义线性模型，即`glm()`，来拟合一个包含公式、族和数据集的模型：
- en: '[PRE12]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'A summary of the model can be viewed using the following command:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令查看模型的摘要：
- en: '[PRE13]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next use `predict()` to fit values on the same dataset to estimate the best
    fitted value:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来使用`predict()`在相同的数据集上拟合值，以估计最佳拟合值：
- en: '[PRE14]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once you have fitted the values, you should try to convert it to probability
    using the following command. This will convert the output into probabilistic form
    and the output will be in the range [0,1]:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你拟合了这些值，你应该尝试使用以下命令将其转换为概率。这将把输出转换为概率形式，且输出值将在[0,1]的范围内：
- en: '[PRE15]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Figure 6.1* is plotted using the following commands. The first line of the
    code shows that we divide the figure into two rows and one column, where the first
    figure is for prediction of the model and the second figure is for probability:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.1*是使用以下命令绘制的。代码的第一行显示我们将图形分为两行一列，第一张图是模型预测结果，第二张图是概率：'
- en: '[PRE16]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`head()` can be used to look at the first few values of the variable:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`head()`查看变量的前几个值：
- en: '[PRE17]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following figure shows the above-defined variable `pred`, which is a real
    number, and its conversion between `0` and `1`, which represents probability,
    that is, `prob`, using the preceding transformation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了上述定义的变量`pred`，它是一个实数，并且它在`0`和`1`之间的转换，表示概率，即`prob`，使用之前的变换：
- en: '![Logistic regression neural network](img/00089.jpeg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![逻辑回归神经网络](img/00089.jpeg)'
- en: 'Figure 6.1: Prediction and probability distribution of DJI'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1：DJI的预测与概率分布
- en: 'As probabilities are in the range of (0,1) so is our vector `prob`. Now, to
    classify them as one of the two classes, I considered `Up` direction (`1`) when
    `prob` is greater than `0.5` and `Down` direction (`0`) when `prob` is less than
    `0.5`. This assignment can be done using the following commands. `prob> 0.5` generate
    true for points where it is greater and `pred_direction[prob> 0.5`] assigns `1`
    to all such points. Similarly, the next statement shows assignment `0` when probability
    is less than or equal to `0.5`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于概率值在（0,1）范围内，所以我们的向量`prob`也是如此。现在，为了将其分类为两个类别之一，我考虑了当`prob`大于`0.5`时为`Up`方向（`1`），而当`prob`小于`0.5`时为`Down`方向（`0`）。这个赋值可以通过以下命令完成。`prob
    > 0.5`生成一个布尔值，表示`prob`大于`0.5`的点，`pred_direction[prob > 0.5]`将`1`赋给所有这些点。类似地，接下来的语句展示了当概率小于或等于`0.5`时赋值`0`：
- en: '[PRE18]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once we have figured out the predicted direction, we should check model accuracy:
    how much our model has predicted `Up` direction as `Up` direction and `Down` as
    `Down.` There might be some scenarios where it predicted the opposite of what
    it is, such as predicting down when it is actually `Up` and vice versa. We can
    use the `caret` package to calculate `confusionMatrix()`, which gives a matrix
    as an output. All diagonal elements are correctly predicted and off-diagonal elements
    are errors or wrongly predicted. One should aim to reduce the off-diagonal elements
    in a confusion matrix:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定了预测方向，我们应该检查模型的准确性：我们的模型将`Up`方向预测为`Up`方向和`Down`方向预测为`Down`的准确程度。可能会出现一些情况，模型预测的方向与实际方向相反，例如预测为`Down`时实际上是`Up`，反之亦然。我们可以使用`caret`包来计算`confusionMatrix()`，它会输出一个矩阵。所有对角线上的元素是正确预测的，非对角线元素则是错误的或预测错的。我们应该尽量减少混淆矩阵中的非对角线元素：
- en: '[PRE19]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The preceding table shows we have got 94% correct prediction, as 362+819 =
    1181 are correct predictions out of 1258 (sum of all four values). Prediction
    above 80% over in-sample data is generally assumed good prediction; however, 80%
    is not fixed, one has to figure out this value based on the dataset and industry.
    Now you have implemented the logistic regression model, which has predicted 94%
    correctly, and need to test it for generalization power. One should test this
    model using out-sample data and test its accuracy. The first step is to standardize
    the out-sample data using formula (6.1). Here mean and standard deviations should
    be the same as those used for in-sample normalization:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的表格显示我们得到了94%的正确预测，因为362+819 = 1181个正确预测占总数1258（所有四个值的和）。在样本内数据上预测超过80%通常被认为是好的预测；然而，80%并不是固定的，具体数值需要根据数据集和行业来决定。现在你已经实现了逻辑回归模型，并且预测了94%的正确率，需要测试其泛化能力。应该使用样本外数据来测试这个模型的准确性。第一步是使用公式（6.1）标准化样本外数据。这里的均值和标准差应与样本内归一化时使用的相同：
- en: '[PRE20]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next we use `predict()` on the out-sample data and use this value to calculate
    probability:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们在样本外数据上使用`predict()`并利用这个值计算概率：
- en: '[PRE21]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once probabilities are determined for the out-sample data, you should put it
    into either `Up` or `Down` classes using the following commands. `ConfusionMatrix()`
    here will generate a matrix for the out-sample data:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦为样本外数据确定了概率，你应该使用以下命令将其划分到`Up`或`Down`类别中。这里的`ConfusionMatrix()`将为样本外数据生成一个矩阵：
- en: '[PRE22]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This shows 85% accuracy on the out-sample data. Quality of accuracy is beyond
    the scope of the book so I am not going to cover whether out-sample accuracy is
    good or bad and what the techniques are to improve this performance. A realistic
    trading model also accounts for trading cost and market slippage, which decrease
    the winning odds significantly. The next thing to be done is to devise a trading
    strategy using predicted directions. I will explain how to implement an automated
    trading strategy using predicted signals in the next section.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在外样本数据上显示了85%的准确率。准确率的质量超出了本书的讨论范围，因此我不会讨论外样本准确率是否良好，或者改进此性能的技术。一个现实的交易模型还需要考虑交易成本和市场滑点，这会显著降低胜率。接下来要做的是利用预测的方向设计交易策略。我将在下一节中解释如何使用预测信号实现自动化交易策略。
- en: Neural network
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络
- en: 'In the previous section, I implemented a model using two classes. In reality,
    it might be possible that traders do not want to enter trade when the market is
    range-bound. That is to say, we have to add one more class, `Nowhere`, to the
    existing two classes. Now we have three classes: `Up`, `Down`, and `Nowhere`.
    I will be using an artificial neural network to predict `Up`, `Down`, or `Nowhere`
    direction. Traders buy (sell) when they anticipate a bullish (bearish) trend in
    some time and no investment when the market is moving `Nowhere.` An artificial
    neural network with feedforward backpropagation will be implemented in this section.
    A neural network requires input and output data to the neural network. Closing
    prices and indicators derived from closing prices are input layer nodes and three
    classes (`Up`, `Down`, and `Nowhere`) are output layer nodes. However, there is
    no limit on the number of nodes in the input layer. I will use a dataset consisting
    of prices and indicators used in the logistic regression. However, it is not mandatory
    to use same dataset. If you would like to use different indicators, you can do
    so. You can also increase or decrease the number of indicators in the dataset;
    it is left to the reader to construct a dataset of their choice. I will continue
    this section using the same the dataset that is used in logistic regression except
    direction. In this section, we have `Nowhere` as the third dimension in the direction
    so I have to calculate the direction parameter again to train the neural network:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我使用了两个类别实现了一个模型。实际上，可能有交易者不愿意在市场处于震荡区间时进行交易。也就是说，我们必须在现有的两个类别基础上再添加一个类别，`Nowhere`。现在我们有三个类别：`Up`、`Down`和`Nowhere`。我将使用人工神经网络来预测`Up`、`Down`或`Nowhere`方向。当交易者预测某一时刻会有看涨（看跌）趋势时，他们会买入（卖出），而在市场处于`Nowhere`时则不会投资。本节将实现一个具有前馈反向传播的人工神经网络。神经网络需要输入和输出数据。收盘价以及从收盘价衍生出的指标是输入层节点，三个类别（`Up`、`Down`和`Nowhere`）是输出层节点。然而，输入层节点的数量没有限制。我将使用一个包含价格和在逻辑回归中使用的指标的数据集。不过，使用相同的数据集并非强制要求。如果你想使用不同的指标，完全可以这么做。你还可以增加或减少数据集中的指标数量；这部分留给读者自行构建自己选择的数据集。我将继续使用与逻辑回归中相同的数据集，唯一不同的是方向。在本节中，我们将`Nowhere`作为方向中的第三个维度，因此我必须重新计算方向参数，以便训练神经网络：
- en: '[PRE23]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: I will generate `Up` (`Down`) direction when the return over the last 20 days
    is greater (less) than 2% (-2%), and `Nowhere` when the return over the last 20
    days is between -2% and 2%.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当过去20天的收益率大于（小于）2%（-2%）时，我将生成`Up`（`Down`）方向；当过去20天的收益率在-2%和2%之间时，我将生成`Nowhere`方向。
- en: 'The first line generates a data frame named direction which consists of NA
    and a number of rows the same as the number of rows in `dji` and one column. The
    second command is the return over the last 20 days. The parameter value 20 is
    sacrosanct; however, you can choose any value you wish to. The third, fourth,
    and fifth commands are basically the assignment of `Up`, `Down` and `NoWhere`
    direction as per the condition:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行生成一个名为direction的数据框，该数据框包含NA值，行数与`dji`的行数相同，并且只有一列。第二个命令是过去20天的收益率。参数值20是神圣不可侵犯的；不过，你可以选择任何你想要的值。第三、第四和第五个命令基本上是根据条件分配`Up`、`Down`和`NoWhere`方向：
- en: '[PRE24]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Closing price and indicators are clubbed into one variable called `dji` using
    the following command line:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 收盘价和指标通过以下命令行合并成一个变量，命名为`dji`：
- en: '[PRE25]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Data for the neural network is divided into three parts, that is, training
    dataset, validating dataset, and testing dataset. Training data should be used
    for training the neural network; however, validating data should be used for validating
    estimated parameters and testing dataset to measure the accuracy of the prediction.
    I have used the following `date` variables to define the date range and extract
    data as per the date range:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的数据被分为三部分，即训练数据集、验证数据集和测试数据集。训练数据应用于训练神经网络；然而，验证数据应用于验证估计的参数，测试数据集则用于测量预测的准确性。我使用了以下`date`变量来定义日期范围，并根据该范围提取数据：
- en: '[PRE26]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Date ranges for the three datasets can be constructed using the following commands,
    where `train_sdate` and `train_edate` define training period start and end dates
    respectively. Similarly, validating and testing period dates are also used.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令构建三个数据集的日期范围，其中`train_sdate`和`train_edate`分别定义训练期的开始和结束日期。同样，验证期和测试期的日期也需要使用。
- en: 'The function `which()` is used to generate row numbers where the date is greater
    than and equal to the start date and less than and equal to the end date:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`which()`用于生成行号，其中日期大于等于开始日期并且小于等于结束日期：
- en: '[PRE27]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, using the preceding row numbers, you should extract data for training,
    validating, and testing periods:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用前面的行号，你应该提取训练、验证和测试期间的数据：
- en: '[PRE28]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following commands are used to calculate the mean and standard deviations
    of training data column wise. The function `apply()` uses data as the first parameter,
    direction as the second parameter, in which we would like to apply a certain function,
    and function is provided as the third parameter:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于计算训练数据按列的均值和标准差。函数`apply()`将数据作为第一个参数，方向作为第二个参数，表示我们希望应用某个特定函数，函数作为第三个参数提供：
- en: '[PRE29]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: To normalize the three datasets, we have to create three identity matrices of
    dimensions equal to the training, validating, and testing data dimensions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了规范化三个数据集，我们需要创建三个单位矩阵，其维度与训练、验证和测试数据的维度相等。
- en: 'The following commands do this nicely:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令能够很好地完成此任务：
- en: '[PRE30]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Training, validating, and testing data is normalized using the following commands.
    `t()` is used for transposing of the data frame, matrix, or vector:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 训练、验证和测试数据可以使用以下命令进行规范化。`t()`用于转置数据框、矩阵或向量：
- en: '[PRE31]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The previously defined normalized data consists of price and indicator values.
    We should also define training, validating, and testing period direction using
    the following commands:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 先前定义的规范化数据包含价格和指标值。我们还应使用以下命令定义训练、验证和测试期间的方向：
- en: '[PRE32]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, I assume the package `nnet()` is installed on your machine. If not, you
    should `install.package()` to install it. Once installed, you should use the following
    line to load this into the workspace:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我假设你的机器上已经安装了`nnet()`包。如果没有，你应该使用`install.package()`进行安装。安装完成后，应该使用以下命令将其加载到工作空间中：
- en: '[PRE33]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following line sets the seed for the neural network, otherwise every time
    the neural network will start with some random weights and output will differ.
    We should use `set.seed()` to get the same output every time you run this command.
    The next line explains neural network fitting, where the first parameter is the
    set of all normalized columns, the second parameter is the target vector for training
    period dates which consist of directions, the third parameter is the number of
    neurons in the hidden layer, and the fourth parameter is the trace, which prints
    output at the end of execution. I used hidden layer neurons as `4`; however, you
    should optimize this parameter. I do not want output to get printed at the end
    of the execution unless I explicitly want it so I use `trade=F`:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码行用于设置神经网络的种子，否则每次神经网络将以随机权重开始，输出结果会有所不同。我们应使用`set.seed()`来确保每次运行此命令时输出相同。下一行解释了神经网络的拟合，其中第一个参数是所有规范化列的集合，第二个参数是训练期日期的目标向量，其中包含方向，第三个参数是隐藏层中的神经元数量，第四个参数是`trace`，它在执行结束时打印输出。我将隐藏层神经元数设置为`4`；但是，你应该优化此参数。我不希望在执行结束时打印输出，除非我明确要求，因此我使用`trade=F`：
- en: '[PRE34]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: In the second parameter, you must have observed the use of the `class.ind()`
    function. This function converts three classes to three columns where every column
    corresponds to each class and each column has `1` at the place where it has the
    same class, otherwise `0`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个参数中，您必须已经注意到使用了`class.ind()`函数。该函数将三个类别转换为三列，每列对应一个类别，每列中相同类别的位置为`1`，其他位置为`0`。
- en: 'You can see the model output using the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下方式查看模型输出：
- en: '[PRE35]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'There are a few more parameters in `nnet()` which you can set as per your requirement.
    For more information on `nnet()`, you should type the following command on the
    command prompt:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`nnet()`中有一些额外的参数，您可以根据需要进行设置。有关`nnet()`的更多信息，您应该在命令提示符下输入以下命令：'
- en: '[PRE36]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This explains the neural network architecture, which is `15-4-3`. This shows
    three layers; the first layer (input layer), second layer (hidden layer), and
    third layer (output layer) have `15`, `4`, and `3` neurons respectively, and `79`
    generated weight parameters. You can see that the number of neurons in the first
    layer is equal to the number of columns in `norm_traindji`:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这解释了神经网络架构，`15-4-3`表示三层结构；第一层（输入层）、第二层（隐藏层）和第三层（输出层）分别有`15`、`4`和`3`个神经元，生成了`79`个权重参数。您可以看到第一层的神经元数量等于`norm_traindji`中的列数：
- en: '[PRE37]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You can see that output has 15 columns, which is the same as the number of
    input data features. That number of columns are 15 so does the number of neuron
    in input layer. The second parameter is the number of neurons in the hidden layer,
    which is provided as input in `nnet()` (in our case, this is `4`), and the final
    parameter is the number of neurons in the output layer, which is `3`, the same
    as the number of directions (`Up`, `Down` and `NoWhere`). You must use `predict()`
    using the trained neural network over the validating dataset:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到输出包含15列，这与输入数据特征的数量相同。这15列的数量与输入层的神经元数量相同。第二个参数是隐藏层中的神经元数量，这个数量作为输入提供给`nnet()`（在我们的例子中是`4`），最终参数是输出层中的神经元数量，它是`3`，与方向（`Up`、`Down`和`NoWhere`）的数量相同。您必须使用`predict()`对验证数据集应用训练后的神经网络：
- en: '[PRE38]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, we have to figure out the predicted direction using the above information.
    I define `0.5` as the threshold and pick directions which have a value greater
    than `0.5`. The first line creates a data frame of length equal to the `vali_pred`
    length. The next commands are used for each class one by one; it checks condition
    and writes the name of class where `vali_pred` is greater than `0.5`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要根据上述信息确定预测的方向。我定义`0.5`作为阈值，并选择值大于`0.5`的方向。第一行创建了一个长度与`vali_pred`相同的数据框。接下来的命令逐一对每个类别进行检查，并在`vali_pred`大于`0.5`的位置写入类别名称：
- en: '[PRE39]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now we are going to create a confusion matrix to check for its accuracy. First
    of all, load the caret package into the workspace and use `confusionMatrix()`
    over the predicted class and original class for the validating dataset:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建一个混淆矩阵来检查其准确性。首先，加载caret包到工作空间，并对验证数据集的预测类别和原始类别使用`confusionMatrix()`：
- en: '[PRE40]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If you look at the accuracy level in the result output, you can see accuracy
    is 87% and this level of accuracy is quite good. This 87% accuracy for a model
    trained on training data and accuracy is tested on validating data. Now we should
    also check accuracy on testing data and check its generalization power. Normalization
    of the testing dataset is already above so I go to the `predict()` command right
    away:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看结果输出中的准确率水平，可以看到准确率为87%，这个准确率相当不错。这87%的准确率是针对在训练数据上训练的模型，且在验证数据上进行了测试。现在，我们还应该检查测试数据上的准确率，验证它的泛化能力。测试数据集的归一化已经完成，因此我直接进入`predict()`命令：
- en: '[PRE41]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Classes for the testing data are defined as the same as the validating data:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据的类别与验证数据相同：
- en: '[PRE42]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '`ConfusionMatrix()` is generated for testing data using the following command
    and accuracy on testing dataset is 82% as can be seen here; this prediction accuracy
    is very similar to the prediction accuracy on the validating dataset. We found
    results are consistently good as compared to the validating data:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令生成用于测试数据的`ConfusionMatrix()`，可以看到测试数据集上的准确率为82%；这一预测准确率与验证数据集上的预测准确率非常相似。与验证数据相比，结果始终保持良好：
- en: '[PRE43]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Consistency in accuracy across validating and testing datasets shows its generalization
    power and this model got good generalization power. Now, as we have got classes,
    the next thing is we should use these classes for signal generation. People buy
    when they anticipate Up direction and sell when they anticipate `Down` direction.
    So I generate signals using the same human psychology and the following command
    does that for you:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证数据集和测试数据集中的准确性一致性表明其泛化能力，该模型具有较好的泛化能力。现在，既然我们已经得到了类别，接下来我们应该使用这些类别来生成信号。当人们预测上涨方向时，他们会买入；而当他们预测`下跌`方向时，他们会卖出。所以，我根据相同的人类心理生成信号，以下命令为你完成了这一操作：
- en: '[PRE44]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Trade return is calculated as defined here. `Lag()` is used over signal as
    the signal generated in the previous session contributes to trade return. I am
    assuming cost as `0`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 交易收益按此处定义的方式计算。`Lag()`函数应用于信号，因为上一时段生成的信号对交易收益有贡献。我假设成本为`0`：
- en: '[PRE45]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'To evaluate the performance of the strategy, we have to load the package and
    use all relevant commands defined in the following section:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估该策略的表现，我们需要加载相关包，并使用以下部分中定义的所有相关命令：
- en: '[PRE46]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The following commands generate *Figure 6.2*, which shows cumulative return,
    daily return, and drawdown. We can see the cumulative return of the strategy is
    negative. Generating profitable strategy is beyond the scope of this book. This
    book only explains how one should go about implementing strategy using R:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令生成*图6.2*，展示了累计收益、每日收益和回撤。我们可以看到该策略的累计收益为负值。生成盈利策略超出了本书的范围。本书仅解释了如何使用R实现策略：
- en: '[PRE47]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Neural network](img/00090.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![神经网络](img/00090.jpeg)'
- en: 'Figure 6.2: Cumulative return, daily return, and drawdown for DJI'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：DJI的累计收益、每日收益和回撤
- en: Deep neural network
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络
- en: 'Deep neural networks are under the broad category of deep learning. In contrast
    to neural networks, deep neural networks contain multiple hidden layers. The number
    of hidden layers can vary from problem to problem and needs to be optimized. R
    has many packages, such as `darch`, `deepnet`, `deeplearning`, and `h20`, which
    can create deep networks. However, I will use the `deepnet` package in particular
    and apply a deep neural network on **DJI** data. The package `deepnet` can be
    installed and loaded to the workspace using the following commands:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络属于深度学习的广泛类别。与神经网络不同，深度神经网络包含多个隐藏层。隐藏层的数量因问题而异，需要进行优化。R语言有许多包，如`darch`、`deepnet`、`deeplearning`和`h20`，可以创建深度网络。然而，我将特别使用`deepnet`包，并应用于**DJI**数据。可以使用以下命令安装并加载`deepnet`包：
- en: '[PRE48]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: I will use `set.seed()` to generate uniform output and `dbn.dnn.train()` is
    used for training deep neural networks. The parameter `hidden` is used for the
    number of hidden layers and the number of neurons in each layer.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用`set.seed()`来生成均匀输出，`dbn.dnn.train()`用于训练深度神经网络。参数`hidden`用于设置隐藏层的数量以及每层的神经元数量。
- en: 'In the below example, I have used a three hidden layer structure and `3`, `4`,
    and `6` neurons in the first, second, and third hidden layers respectively. `class.ind()`
    is again used to convert three directions into column vector, where each column
    represents one direction:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我使用了一个包含三个隐藏层的结构，并在第一、第二和第三个隐藏层中分别使用了`3`、`4`和`6`个神经元。`class.ind()`再次用于将三个方向转换为列向量，每一列表示一个方向：
- en: '[PRE49]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The following command is to generate the output of three classes using the
    normalization validation dataset:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令用于生成使用归一化验证数据集的三个类别的输出：
- en: '[PRE50]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'To obtain the accuracy of the model over the validation dataset, you can also
    use following command. I chose `t=0.4` just for the purpose of showing results.
    You should use a value as per your requirement. It will create each column of
    output to certain direction if its value is greater than `0.4`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得模型在验证数据集上的准确度，你还可以使用以下命令。我选择`t=0.4`仅仅是为了展示结果。你应根据实际需求选择合适的值。如果其值大于`0.4`，将会生成每一列对应某一方向的输出：
- en: '[PRE51]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '`H2o` is another package which can be used for deep neural network learning.
    It is implemented in Java and can use multithreads and multinodes of the CPU;
    however, `deepnet` is implemented in R itself and uses only a single thread and
    doesn''t have the flexibility to use multithreads and multinodes of the CPU. The
    following commands install and load it into the workspace:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`H2o`是另一个可以用于深度神经网络学习的包。它是用Java实现的，能够利用CPU的多线程和多节点；然而，`deepnet`是用R本身实现的，只使用单线程，并且没有灵活性来使用CPU的多线程和多节点。以下命令会安装并将其加载到工作空间：'
- en: '[PRE52]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next I combined the normalized training data and direction into one variable.
    I converted the normalized data into a data frame as the original data in `xts`,
    `zoo` format. As the normalized training data is numeric, if I had not converted
    it into a data frame then adding `traindir`, which is character, would have converted
    `traindir` to NAs. To avoid this, I used a data frame in the following commands
    and the class of the input variables can be verified using the next two commands:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将标准化的训练数据和方向结合成一个变量。我将标准化数据转换为数据框架，格式与原始数据的`xts`、`zoo`格式一致。由于标准化的训练数据是数值型的，如果我没有将其转换为数据框，那么添加字符型的`traindir`会将`traindir`转换为NAs。为了避免这种情况，我在以下命令中使用了数据框，可以使用接下来的两个命令验证输入变量的类别：
- en: '[PRE53]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Once I am done with creating a variable then I convert it into an `h2o` object
    because model fitting requires input data to be in `h2o` format. In the following
    command, the first parameter is the variable which I would like to be converted
    and the second parameter is the name of the class in which we would like the first
    parameter to be converted.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我完成了变量的创建，我就将其转换为`h2o`对象，因为模型拟合需要输入数据是`h2o`格式。在以下命令中，第一个参数是我要转换的变量，第二个参数是我们希望第一个参数转换成的类名称。
- en: 'In the following command, I would like to convert data into `h2o` type. This
    can also be verified using the second command:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下命令中，我希望将数据转换为`h2o`类型。也可以使用第二个命令进行验证：
- en: '[PRE54]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We looked into the dimension of the `h2o` class object which I just created,
    where the last column is the direction vector and the remaining columns are normalized
    data columns:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们查看了刚刚创建的`h2o`类对象的维度，其中最后一列是方向向量，剩余的列是标准化的数据列：
- en: '[PRE55]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Below, `h2o.deeplearning()` trains a deep neural network with a four hidden
    layer architecture and the number of neurons is `4`,`5`,`2`, and `7` respectively
    in each hidden layer. The first parameter is the vector of column number 1 to
    15 assumed as input data and the second parameter 16 implies the 16th column as
    output supplied to the deep neural network for training. The third parameter is
    datah2o, which is supplied for deep neural network fitting, and the fourth parameter
    is hidden. The parameter hidden has important significance here, which shows the
    total number of hidden layers, and the following example shows four hidden layers:
    the first hidden layer has 4 neurons, the second has 5 hidden neurons, and the
    third and fourth layers have 2 and 7 neurons:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`h2o.deeplearning()`，它训练一个具有四个隐藏层架构的深度神经网络，每个隐藏层的神经元数分别为`4`、`5`、`2`和`7`。第一个参数是1到15列的向量，假设为输入数据，第二个参数16表示第16列作为输出，供深度神经网络进行训练。第三个参数是datah2o，用于深度神经网络的拟合，第四个参数是hidden。参数hidden在这里具有重要意义，表示隐藏层的总数，以下示例显示了四个隐藏层：第一个隐藏层有4个神经元，第二个隐藏层有5个神经元，第三个和第四个隐藏层分别有2和7个神经元：
- en: '[PRE56]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'As `vali_pred` is of `H2OFrame`, we should convert it to a data frame to apply
    the following operations:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`vali_pred`是`H2OFrame`格式，我们应该将其转换为数据框，以便应用以下操作：
- en: '[PRE57]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'I used the caret package and `confusionMatrix()` to create a misclassification
    matrix:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了caret包和`confusionMatrix()`来创建误分类矩阵：
- en: '[PRE58]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: As we have done this for validation dataset, if accuracy percentage is within
    desired limit. We should go ahead and predict directions using the testing data
    and use those predicted directions to generate trading signals as generated in
    the *Neural network* section. To generate signal and performance of strategy,
    you should use the command mentioned in the *Neural network* section.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如同我们在验证数据集上所做的那样，如果准确率在期望的范围内，我们应该继续使用测试数据预测方向，并使用这些预测的方向生成交易信号，正如在*神经网络*部分中所生成的那样。为了生成信号和策略的表现，你应该使用*神经网络*部分中提到的命令。
- en: K means algorithm
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K均值算法
- en: The K means algorithm is an unsupervised machine learning algorithm. Unsupervised
    learning is another way of classifying the data as it does not require labeling
    of the data. In reality, there are many instances where labeling of the data is
    not possible, so we require them to classify data based on unsupervised learning.
    Unsupervised learning uses the similarity between data elements and assigns each
    data point to its relevant cluster. Each cluster has a set of data points which
    are similar in nature. The K means algorithm is the most basic unsupervised learning
    algorithm and it just requires data to plug into the algorithm along with the
    number of clusters we would like it to cluster returning the vector of cluster
    labeling for each data point. I used normalized data along with the number of
    clusters. I used the in-sample data which was used during logistic regression,
    to be divided into three clusters.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: K-means 算法是一种无监督机器学习算法。无监督学习是另一种数据分类方式，因为它不需要数据的标签。实际上，很多情况下数据无法被标注，因此我们需要基于无监督学习来分类数据。无监督学习通过数据元素之间的相似性，将每个数据点分配到相应的聚类中。每个聚类包含一组在性质上相似的数据点。K-means
    算法是最基本的无监督学习算法，它只需要输入数据和我们希望聚类的数量，并返回每个数据点的聚类标签向量。我使用了标准化数据和聚类数量。我使用了在逻辑回归中使用的内样本数据，将其分为三个聚类。
- en: '`set.seed()` is used to have the same output in every iteration; without using
    `set.seed()`, the output changes every time:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`set.seed()` 用于确保每次迭代输出相同；如果不使用 `set.seed()`，输出会在每次运行时变化：'
- en: '[PRE59]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Normalized in-sample and out-sample data has direction (labels) as the last
    column, which is not required for unsupervised learning. So I removed the last
    column in both of these datasets using the following command:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化后的内样本和外样本数据将方向（标签）作为最后一列，而无监督学习不需要这些标签。因此，我通过以下命令删除了这两个数据集中的最后一列：
- en: '[PRE60]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now I do not have any labeling for this data and run `kmeans()`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我没有这些数据的标签，并运行 `kmeans()`：
- en: '[PRE61]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '`model$cluser` returns the relevant cluster number corresponding to each data
    point and `head()` is used to print out the first few:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`model$cluser` 返回每个数据点对应的聚类编号，`head()` 用于输出前几个数据点的聚类编号：'
- en: '[PRE62]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The preceding command shows the first few data points belong to cluster number
    3\. Similarly, centers of final clusters can be extracted using the following
    command:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令显示前几个数据点属于聚类编号 3。同样，最终聚类的中心可以通过以下命令提取：
- en: '[PRE63]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The number of data points in each cluster can be extracted using the following
    line of command:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 每个聚类中的数据点数量可以通过以下命令提取：
- en: '[PRE64]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'As we are using k means to cluster, which is unsupervised learning, performance
    or accuracy can be calculated using the ratio of the sum of squares to the total
    sum of squares. The sum of squares between clusters and the total sum of squares
    can be extracted using the following commands:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是 k-means 聚类算法，它是无监督学习，性能或准确性可以通过平方和与总平方和的比值来计算。聚类间的平方和与总平方和可以通过以下命令提取：
- en: '[PRE65]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The ratio of these values indicates the sum of squares within clusters with
    respect to the total sum of squares. In our case, it is around 50.7%, as is shown
    below, which shows the sum of squares within cluster is almost half of the total
    sum of squares. The model which minimizes this ratio is chosen over a range of
    models. This is a minimization problem:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值的比率表示聚类内的平方和与总平方和的比率。在我们的例子中，这个比率大约是 50.7%，如下所示，表示聚类内的平方和几乎占总平方和的一半。在一系列模型中，选择最小化该比率的模型。这是一个最小化问题：
- en: '[PRE66]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'If we are satisfied with the accuracy of the algorithm, we will go ahead and
    use this fitted model to predict clusters for the out-sample dataset, which can
    be done using the `predict()` command:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对算法的准确性满意，我们将继续使用这个拟合模型来预测外样本数据集的聚类，这可以通过 `predict()` 命令来实现：
- en: '[PRE67]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The next line extracts the first few predicted cluster numbers for the out-sample
    data using `head()`:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 下一行使用 `head()` 提取外样本数据的前几个预测聚类编号：
- en: '[PRE68]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: This algorithm assigns each data point from the out-sample dataset into any
    one of the clusters, where each cluster belongs to one of the market directions,
    that is, `Up`, `Down`, and `Nowhere`. It is very important to figure out upfront
    which cluster represents `Up` and which ones represent `Down` and `Nowhere.` Once
    you recognize each cluster as either `Up`, `Down`, or `Nowhere`, we can enter
    a relevant trade when a data point falls in the relevant cluster. For example,
    in the preceding case, the output is two for the first six data points, which
    implies that these data points lie in the same cluster, but we do not know whether
    this is the `Up` cluster, `Down` cluster, or `Nowhere` cluster. You can figure
    out this using the average price of data points in one cluster and if the average
    is greater than a certain threshold from the first data point then you can consider
    it as the `Up` cluster; if the average price is less than a certain threshold
    from the first data point then this is the `Down` cluster; and it is the `Nowhere`
    cluster if the average price is within a certain threshold above and below the
    first data point. There are other techniques as well to figure out the class of
    the cluster; you can use any technique, whichever you would like to use. When
    a data point falls in the `Up` cluster, we enter long trade; it happens for the
    other two clusters as well. We should design a trading strategy by looking into
    each cluster. Behavior recognition is critical as this will help us design a trading
    strategy. We should know which cluster represents the `Up`, `Down`, or `Nowhere`
    direction. We should generate a trading signal and return using the example mentioned
    in the *Neural network* section.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法将每个来自外部样本数据集的数据点分配到任一簇中，每个簇属于一个市场方向，即`Up`（上涨）、`Down`（下跌）和`Nowhere`（无方向）。在开始之前，弄清楚哪个簇代表`Up`，哪个代表`Down`和`Nowhere`非常重要。一旦你识别出每个簇是`Up`、`Down`还是`Nowhere`，当数据点落入相关簇时，我们就可以进行相关交易。例如，在前述的情况下，前六个数据点的输出是2，这意味着这些数据点位于同一个簇中，但我们不知道这是否是`Up`簇、`Down`簇，还是`Nowhere`簇。你可以通过计算一个簇中数据点的平均价格来弄清楚这一点，如果平均值高于某个阈值，则可以将其视为`Up`簇；如果平均价格低于某个阈值，则为`Down`簇；如果平均价格位于第一个数据点的上下某个阈值范围内，则为`Nowhere`簇。还有其他技术可以用来确定簇的类别；你可以使用任何你喜欢的方法。当数据点落入`Up`簇时，我们进入多头交易；对于其他两个簇也是如此。我们应该通过研究每个簇来设计交易策略。行为识别至关重要，因为这将帮助我们设计交易策略。我们应该知道哪个簇代表`Up`、`Down`或`Nowhere`方向。我们应该基于*神经网络*部分中提到的例子生成交易信号并返回。
- en: K nearest neighborhood
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K 最近邻算法
- en: 'K nearest neighborhood is another supervised learning algorithm which helps
    us to figure out the class of the out-sample data among k classes. K has to be
    chosen appropriately, otherwise it might increase variance or bias, which reduces
    the generalization capacity of the algorithm. I am considering `Up`, `Down`, and
    `Nowhere` as three classes which have to be recognized on the out-sample data.
    This is based on Euclidian distance. For each data point in the out-sample data,
    we calculate its distance from all data points in the in-sample data. Each data
    point has a vector of distances and the K distance which is close enough will be
    selected and the final decision about the class of the data point is based on
    a weighted combination of all k neighborhoods:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: K 最近邻是另一种监督学习算法，帮助我们在 k 个类别中确定外样本数据的类别。K 值必须适当选择，否则可能增加方差或偏差，降低算法的泛化能力。我将`Up`、`Down`和`Nowhere`作为需要在外样本数据中识别的三个类别。这是基于欧几里得距离的。对于外样本数据中的每个数据点，我们计算它与内样本数据中所有数据点的距离。每个数据点都有一个距离向量，选择与其足够接近的
    K 个距离，并根据所有 K 个邻域的加权组合来决定数据点的最终类别：
- en: '[PRE69]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The K nearest neighborhood function in R does not need labeled values in the
    training data. So I am going to use the normalized in-sample and normalized out-sample
    data created in the *Logistic regression* section and remove the last column in
    the normalized in-sample and normalized out-sample data:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: R 中的 K 最近邻函数不需要训练数据中的标签值。因此，我将使用在*逻辑回归*部分创建的标准化内样本和标准化外样本数据，并删除标准化内样本和标准化外样本数据中的最后一列：
- en: '[PRE70]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Labeling of the training data is a vector of three directions, that is, `Up`,
    `Down`, and `Nowhere`, which is constructed using the following command:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的标签是一个包含三个方向的向量，即`Up`、`Down`和`Nowhere`，通过以下命令构造：
- en: '[PRE71]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '`lagret` is the return over the last 20 data points and is used to generate
    three directions as in the *Neural network* section:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`lagret`是过去 20 个数据点的回报，并用于生成如*神经网络*部分中的三种方向：'
- en: '[PRE72]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'I choose three neighborhoods and fix the `set.seed()` value to generate the
    same output every time:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了三个邻域，并固定了`set.seed()`值，以便每次生成相同的输出：
- en: '[PRE73]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The `knn()` model has the first three mandatory parameters which are the normalized
    in-sample data, the normalized out-sample data, and the training labeled data
    in our case. The fourth parameter is optional; I supplied 3 as input here. If
    this is not supplied by the user, R will consider the default value, which is
    1\. However, 3 is not fixed; it needs to be optimized using multiple values of
    neighborhood. The `knn()` function returns classes over the out-sample data which
    can be checked using the following command:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`knn()`模型有前三个必填参数，分别是归一化的样本内数据、归一化的样本外数据以及我们案例中的训练标签数据。第四个参数是可选的；我在此输入了 3。如果用户没有提供该值，R
    将使用默认值 1。不过，3 并不是固定的，它需要通过多个邻域值进行优化。`knn()`函数返回样本外数据的类别，可以通过以下命令检查：'
- en: '[PRE74]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '`Summary()` over the model generates the total number of data points in each
    class, as you can see in the following command. It has generated `44`, `172`,
    and `36` data points into the `Down`, `Nowhere`, and `Up` classes respectively:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 对模型使用`Summary()`会生成每个类别中的数据点总数，正如以下命令所示。它分别生成了`44`、`172`和`36`个数据点，分别对应`Down`、`Nowhere`和`Up`类别：
- en: '[PRE75]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'We are not sure about the accuracy. We have to test it for accuracy using the
    following commands. `confusionMatrix()` generates a matrix of counts for correct
    and wrong predictions:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不确定准确度如何。我们需要通过以下命令进行准确度测试。`confusionMatrix()`会生成正确和错误预测的计数矩阵：
- en: '[PRE76]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'We also have to minimize off-diagonal elements as these are wrong classified
    classes. Diagonal elements can be extracted using the following command:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要最小化非对角线元素，因为这些是错误分类的类别。可以通过以下命令提取对角线元素：
- en: '[PRE77]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: We can use a `for` loop over the neighborhood varying from 1 to 30 and find
    the accuracy at each value. We can pick the optimal value of k, which has the
    highest and consistent accuracy in its neighborhood.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一个`for`循环，遍历从 1 到 30 的邻域，并找到每个值对应的准确度。我们可以选择最佳的 k 值，该值在其邻域中具有最高且一致的准确度。
- en: 'The following few lines of codes explain this. The `For` loop is used for values
    from 1 to 30\. Inside the `for` loop, I fit model for every value of, that is,
    `confusionMatrix()` calculate matrix for every `i` followed by calculation of
    elements as diagonal and total number of elements in out-sample data. The sum
    of all elements of `matrix$table` is equal to the number of data points in the
    out-sample data. The misclassification number is calculated by subtracting `diag`
    from the total number of points and accuracy is calculated by dividing it by the
    total number of data points:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几行代码做了说明。`For`循环用于遍历从 1 到 30 的值。在`for`循环内部，我为每个值拟合模型，即`confusionMatrix()`为每个`i`计算矩阵，并计算对角线元素和样本外数据中的总元素数。`matrix$table`的所有元素之和等于样本外数据中的数据点数。错误分类数是通过从总点数中减去`diag`来计算的，而准确度则通过将其除以数据点总数来得出：
- en: '[PRE78]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'We can check the variable `accuracy` output using `head()`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`head()`检查变量`accuracy`的输出：
- en: '[PRE79]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The following command `plot()` generates *Figure 6.3*, which explain accuracy
    variation across the value of neighborhood. *Figure 6.3* clearly explains the
    importance of neighborhood, as error is minimum for **k=14** which is assumed
    to be the optimal value. However, **k=15** spike the error which means **k=14**
    is not stable in its neighborhood. The value **k=12** is considered stable in
    its neighborhood as well, so it is left to the reader, how you would like to pick
    the optimal value:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令`plot()`生成*图 6.3*，解释了邻域值变化对准确度的影响。*图 6.3*清楚地解释了邻域的重要性，因为错误在**k=14**时最小，这被认为是最佳值。然而，**k=15**使错误激增，这意味着**k=14**在其邻域中并不稳定。**k=12**在其邻域中也被认为是稳定的，因此如何选择最佳值留给读者自行决定：
- en: '[PRE80]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '![K nearest neighborhood](img/00091.jpeg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![K 最近邻](img/00091.jpeg)'
- en: 'Figure 6.3: Accuracy level for KNN classifier'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3：KNN 分类器的准确度水平
- en: Support vector machine
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机
- en: 'Support vector machine is another supervised learning algorithm that can be
    used for classification and regression. It is able to classify data linearly and
    nonlinearly using kernel methods. Each data point in the training dataset is labeled,
    as it is supervised learning, and mapped to the input feature space, and the aim
    is to classify every point of new data to one of the classes. A data point is
    an *N* dimension number, as *N* is the number of features, and the problem is
    to separate this data using *N-1* dimensional hyperplane and this is considered
    to be a linear classifier. There might be many classifiers which segregate the
    data; however, the optimal classifier is one which has the maximum margin between
    classes. The maximum margin hyperplane is one which has the maximum distance from
    the closest point in each size and the corresponding classifier is called the
    maximum margin classifier. Package `e1071` has all functionalities related to
    the support vector machine so I am going to install it first using the following
    command:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机是另一种可以用于分类和回归的监督学习算法。它能够通过核方法对数据进行线性和非线性分类。训练数据集中的每个数据点都有标签，因为它是监督学习，并且映射到输入特征空间，目的是将每个新数据点分类到某一类别。数据点是一个*N*维数，其中*N*是特征的数量，问题是使用*N-1*维超平面将这些数据分开，这被认为是一个线性分类器。可能有许多分类器可以分隔数据；然而，最佳分类器是那个在类别之间具有最大间隔的分类器。最大间隔超平面是指与每一侧最近的点具有最大距离的超平面，且对应的分类器称为最大间隔分类器。`e1071`包具有与支持向量机相关的所有功能，因此我将首先使用以下命令安装它：
- en: '[PRE81]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Once it is installed, I am going to load it into the workspace using the following
    command:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我将使用以下命令将其加载到工作区：
- en: '[PRE82]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'I am going to use the same normalized in-sample and out-sample data that was
    used in the previous `section.` The `svm()` function takes a few more parameters,
    such as type of support vector machine, kernel type, and a few more. The type
    parameter has the option to train the support vector machine with respect to a
    classification or regression problem; by default, it considers classification
    problems. The kernel type has many options to choose from, such as linear, polynomial,
    radial, and sigmoid, and the linear kernel type is set as the default parameter.
    The following command explains the use of support vector machine using only the
    first two parameters and the remaining default parameters:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用与之前“章节”中相同的归一化内样本和外样本数据。`svm()`函数还需要一些其他参数，例如支持向量机类型、核类型等。类型参数可以选择训练支持向量机以解决分类或回归问题；默认情况下，它会考虑分类问题。核类型有多种选择，如线性、多项式、径向和
    sigmoid，线性核类型是默认参数。以下命令说明了仅使用前两个参数和剩余默认参数的支持向量机的使用：
- en: '[PRE83]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The output of the `svm()` function is saved in the variable model and can be
    seen by typing the variable name `model` on the command prompt:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`svm()`函数的输出保存在变量`model`中，可以通过在命令提示符中输入变量名`model`来查看：'
- en: '[PRE84]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'The preceding results show the type of fitted support vector machine, and the
    kernel type which is used to fit the model. `predict()` helps to predict direction
    for the out-sample data:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的结果显示了拟合的支持向量机类型，以及用于拟合模型的核类型。`predict()`帮助预测外部样本数据的方向：
- en: '[PRE85]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The first few predicted directions can be seen using the following line of
    command:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令查看前几个预测方向：
- en: '[PRE86]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The `table()` command generates a misclassification matrix and clearly shows
    45 misclassified data points in total:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '`table()`命令生成一个误分类矩阵，并清楚地显示总共45个误分类的数据点：'
- en: '[PRE87]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'If you would like to see the vectors generated by support vector machine, you
    can do so using the following command:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看支持向量机生成的向量，可以使用以下命令：
- en: '[PRE88]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'You can also see the corresponding index values using the following command:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用以下命令查看相应的索引值：
- en: '[PRE89]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The first few index values can be seen using the following command:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令查看前几个索引值：
- en: '[PRE90]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The corresponding coefficients can be accessed using the following command:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令访问相应的系数：
- en: '[PRE91]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Decision tree
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策树
- en: 'Tree-based learning algorithms are one of the best supervised learning methods.
    They generally have stability over results, and great accuracy and generalization
    capacity to the out-sample dataset. They can map linear and nonlinear relationships
    quite well. It is generally represented in the form of a tree of variables and
    its results. The nodes in a tree are variables and end values are decision rules.
    I am going to use the package `party` to implement a decision tree. This package
    first need to be installed and loaded into the workspace using the following commands:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的学习算法是最好的监督学习方法之一。它们通常对结果具有稳定性，并且对样本外数据集具有很好的准确性和泛化能力。它们能够很好地映射线性和非线性关系。通常以变量树的形式表示，其结果为树中的节点变量，终端值则是决策规则。我将使用
    `party` 包来实现决策树。首先需要安装并使用以下命令加载该包：
- en: '[PRE92]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: The `ctree()` function is the function to fit the decision tree and it requires
    a formula and data as mandatory parameters and it has a few more optional variables.
    The normalized in-sample and normalized out-sample data does not have labels in
    the data so we have to merge labels in the data.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`ctree()` 函数是用于拟合决策树的函数，它需要公式和数据作为必需参数，并且还有一些可选变量。标准化的样本内数据和标准化的样本外数据没有标签，所以我们必须将标签合并到数据中。'
- en: 'The following commands bind labels into the normalized in-sample and normalized
    out-sample data and add a column name to the last column for both datasets:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将标签绑定到标准化的样本内和样本外数据中，并为两个数据集的最后一列添加列名：
- en: '[PRE93]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Now both datasets have labeled data in the dataset and we now choose to fit
    the decision tree using `ctree()`.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在两个数据集都包含了标签数据，我们现在选择使用 `ctree()` 来拟合决策树。
- en: The first parameter is the formula which has `Direction`, that is, labels as
    dependent variable and dot (`.`) on the other side of the formula, which means
    we are considering all other variables as independent variables.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是公式，公式中包含 `Direction`，即标签作为因变量，公式另一边的点号（`.`）表示我们将所有其他变量视为自变量。
- en: 'The second parameter is the normalized in-sample data:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数是标准化的样本内数据：
- en: '[PRE94]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'You can use `print()` to see the fitted model output. The variable model is
    the output of the model so use the following command to see what it contains:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `print()` 来查看拟合模型的输出。变量 model 是模型的输出，因此使用以下命令查看它包含的内容：
- en: '[PRE95]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'If you would like to plot the model, this can be done using `plot()`:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想绘制模型，可以使用 `plot()` 来完成：
- en: '[PRE96]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'You can also use `summary()` to get the output in summarized form:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用 `summary()` 获取总结形式的输出：
- en: '[PRE97]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '`predict()` can be used to estimate the labels using the fitted model and out-sample
    data. I calculated the dimension of the normalized out-sample data and plugged
    this data, except the last column, into `predict()`:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict()` 可以用于使用拟合的模型和样本外数据来估计标签。我计算了标准化样本外数据的维度，并将该数据（除了最后一列）传入 `predict()`：'
- en: '[PRE98]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The first few values of `pred` can be seen using `head()` as shown here:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `head()` 可以查看 `pred` 的前几个值，如下所示：
- en: '[PRE99]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'The command `plot()` generates a graph for the predicted variable `pred`, which
    is shown in the figure which follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 命令 `plot()` 为预测变量 `pred` 生成一个图表，如下图所示：
- en: '[PRE100]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'The following figure clearly shows three classes: one class is between **1.0**
    and **1.5**, the second class around **2.0,** and the third class around **3.0**.
    Data points are clearly distinguished based on the clustered and separation criteria:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表清楚地显示了三类数据：第一类位于 **1.0** 和 **1.5** 之间，第二类在 **2.0** 附近，第三类在 **3.0** 附近。数据点根据聚类和分离标准被清晰区分：
- en: '![Decision tree](img/00092.jpeg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![决策树](img/00092.jpeg)'
- en: 'Figure 6.4: Predicted values for normalized out-sample data'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4：标准化样本外数据的预测值
- en: Random forest
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机森林
- en: 'Random forest is one of the best tree-based methods. Random forest is an ensemble
    of decision trees and each decision tree has certain weights associated with it.
    A decision of the random forest is decided like voting, as the majority of decision
    tree outcomes decide the outcome of the random forest. So we start using the `randomForest`
    package and this can be installed and loaded using the following commands:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是最好的基于树的方法之一。随机森林是多个决策树的集合，每个决策树都有一定的权重。随机森林的决策是通过类似投票的方式决定的，大多数决策树的结果决定随机森林的结果。因此，我们开始使用
    `randomForest` 包，可以使用以下命令进行安装并加载：
- en: '[PRE101]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'We can also use the following command to know more about this `randomForest`
    package, including version, date of release, URL, set of functions implemented
    in this package, and much more:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用以下命令了解更多关于这个`randomForest`包的信息，包括版本、发布日期、网址、包中实现的函数集等：
- en: '[PRE102]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Random forest works best for any type of problem and handles classification,
    regression, and unsupervised problems quite well. Depending upon the type of labeled
    variable, it will implement relevant decision trees; for example, it uses classification
    for factor target variables, regression for numeric or integer type target variables,
    and unsupervised decision tree when the target vector is not defined or completely
    unknown. I will use the labeled data which I have used throughout this chapter:
    the normalized in-sample data for model building and normalized out-sample data
    for model validation. You can see the column names of the input data using the
    following commands:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林适用于任何类型的问题，并且能很好地处理分类、回归和无监督问题。根据标签变量的类型，它会实现相关的决策树；例如，对于因子目标变量，它使用分类；对于数值型或整数型目标变量，它使用回归；当目标向量未定义或完全未知时，它使用无监督决策树。我将使用本章中使用的标签数据：用于模型构建的归一化内样本数据和用于模型验证的归一化外样本数据。你可以使用以下命令查看输入数据的列名：
- en: '[PRE103]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'The following command helps you to know the number of independent variables
    in the input data. It shows our input dataset is going to have 15 independent
    variables which can be seen previously:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令帮助你了解输入数据中独立变量的数量。它显示我们的输入数据集将有15个独立变量，如之前所示：
- en: '[PRE104]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'As the labeled data has three classes, `Up`, `Down`, and `Nowhere`, we should
    build a classification random forest. For classification, the `randomForest()`
    function accepts labeled data as a factor so the first thing is we should check
    the labeled data type, which can be done using the following command and it shows
    the labeled data is character:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 由于标签数据有三个类别：`Up`、`Down`和`Nowhere`，我们应该构建一个分类随机森林。对于分类问题，`randomForest()`函数将标签数据作为因子，因此首先我们应该检查标签数据的类型，可以使用以下命令进行检查，它显示标签数据是字符类型：
- en: '[PRE105]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'The next thing is we should convert the labeled data into factors as `randomForest()`
    accepts factor labeled data for classification problems. The following two lines
    convert character data into factors:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们应该将标签数据转换为因子类型，因为`randomForest()`接受因子类型的标签数据来解决分类问题。以下两行代码将字符数据转换为因子：
- en: '[PRE106]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Now, if we check the class of the labeled data, we can use the `class()` function
    again and the following command shows we have converted character data type to
    factor:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们检查标签数据的类别，可以再次使用`class()`函数，以下命令显示我们已将字符数据类型转换为因子：
- en: '[PRE107]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Now we are set with the in-sample and out-sample datasets and plug these datasets
    into `randomForest()` using the following command. The first parameter in the
    function is the normalized in-sample independent variables data frame, the second
    parameter is in-sample labels, the third parameter is the out-sample independent
    variables data frame, the fourth parameter is out-sample labels, and the fifth
    parameter is the number of trees to be used for random forest model building and
    I used this equal to `500`:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好内样本和外样本数据集，并将这些数据集输入到`randomForest()`中，使用以下命令。函数中的第一个参数是归一化的内样本独立变量数据框，第二个参数是内样本标签，第三个参数是外样本独立变量数据框，第四个参数是外样本标签，第五个参数是用于随机森林模型构建的树木数量，我设置为`500`：
- en: '[PRE108]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'However, there many more parameters which one can use if required. If you want
    to know more about the other parameters, the following single line of code will
    open a new window which explains everything for the `randomForest` function, including
    input variables, input variables type, output variables, examples, and so on:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有许多其他参数可以根据需要使用。如果你想了解更多关于其他参数的信息，下面这行代码将打开一个新窗口，详细解释`randomForest`函数的所有内容，包括输入变量、输入变量类型、输出变量、示例等：
- en: '[PRE109]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'You can look at the model output using the following command. First it shows
    the command which is used to fit the model, then the type of forest, which is
    classification in our case as the labeled data was factor or consisted of three
    classes, and next the number of trees, as we provided `500` as parameter in the
    previous command. It also calculates a confusion matrix for the in-sample as well
    as for out-sample data. The error rate for the in-sample data is `11.76%` and
    `21.03%` for the out-sample data, which is assumed to be quite good. If you look
    deep into the in-sample and out-sample confusion matrix, you can also find the
    error rate for each class separately. In the case of the in-sample confusion matrix,
    the fourth column contains errors which are `11.34%`. `14.40%`, and `9.55%` for
    `Down`, `NoWhere`, and `Up` classes respectively. Similarly, you can also interpret
    the out-sample confusion matrix:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令查看模型输出。首先显示用于拟合模型的命令，然后是森林的类型，在我们的例子中是分类，因为标记数据是因子类型或由三类组成，接下来是树的数量，因为我们在先前的命令中提供了`500`作为参数。它还计算了样本内和样本外的数据的混淆矩阵。样本内数据的错误率为`11.76%`，样本外数据的错误率为`21.03%`，这被认为是相当不错的。如果深入查看样本内和样本外的混淆矩阵，你还可以找到每个类别的单独误差率。在样本内混淆矩阵中，第四列包含的错误率分别是`11.34%`、`14.40%`和`9.55%`，对应`Down`、`NoWhere`和`Up`类别。同样，你也可以解释样本外的混淆矩阵：
- en: '[PRE110]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'The fitted model generates errors in matrix form and if you would like to dive
    deep into error matrices, you can look into the matrix format using `head()`.
    The following matrix shows the error rate for the in-sample data and the next
    three columns for each class separately across 500 decision trees:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型以矩阵形式生成误差，如果你想深入了解错误矩阵，可以使用`head()`查看矩阵格式。以下矩阵显示了样本内数据的错误率，接下来的三列分别显示了每个类别在500棵决策树中的误差：
- en: '[PRE111]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'The following commands plot the overall in-sample and three classes errors
    for all `500` decision trees and you can see in *Figure 6.5* that after 100 decision
    trees, there is no significant decrease in the error:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令绘制了所有`500`棵决策树的总体样本内和三类误差，你可以在*图 6.5*中看到，经过100棵决策树后，错误率没有显著下降：
- en: '[PRE112]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'The plot looks as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图如下：
- en: '![Random forest](img/00093.jpeg)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![随机森林](img/00093.jpeg)'
- en: 'Figure 6.5: Error rate for 500 decision trees'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.5：500棵决策树的错误率
- en: 'If you want to extract variables which help to control error, you can choose
    those variables depending upon `MeanDecreaseGinni`. `MeanDecreaseGinni` can be
    accessed using the following lines of code:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想提取有助于控制误差的变量，可以根据`MeanDecreaseGinni`选择这些变量。`MeanDecreaseGinni`可以通过以下代码访问：
- en: '[PRE113]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: Questions
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is machine learning and how it being used in the capital market? Explain
    in brief.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是机器学习，它在资本市场中是如何应用的？简要说明。
- en: What is logistic regression and in which form does it generate its output?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是逻辑回归，它以何种形式生成输出？
- en: Write a small piece of code to use a neural network for any stock time series.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一小段代码，使用神经网络处理任何股票的时间序列数据。
- en: How does a confusion matrix explain the accuracy of a model?
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混淆矩阵如何解释模型的准确性？
- en: How do you standardize data and why is it important in the model building process?
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何标准化数据，为什么它在模型构建过程中很重要？
- en: How is support vector machine different from logistic regression?
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 支持向量机与逻辑回归有何不同？
- en: Explain supervised and unsupervised learning and how to use these techniques
    in algorithmic trading.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释监督学习和无监督学习，并说明如何在算法交易中使用这些技术。
- en: Write a small piece of code for the k means algorithm using any one stock closing
    price.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一小段代码，使用任意一个股票的收盘价实现k均值算法。
- en: Apart from `confusionMatrix()`, what is the other function to calculate classification
    and misclassification matrices?
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了`confusionMatrix()`，还有什么函数可以计算分类和误分类矩阵？
- en: What is the difference between decision tree and random forest and how are features
    selected from random forest?
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决策树和随机森林有什么区别，如何从随机森林中选择特征？
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter presents advanced techniques which are implemented for capital
    markets. I have presented various supervised and unsupervised learning in detail
    along with examples. This chapter particularly used Dow Jones Index closing price
    as dataset, which was divided into in-sample and out-sample data. The in-sample
    data was used for model building and the out-sample data for validation of the
    model. Overfitting and underfitting generally questions the generalization capacity
    of the model which can be understand using confusion matrix. The accuracy of the
    model was defined using `confusionMatrix()` or `table()`.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了针对资本市场实施的高级技术。我详细介绍了各种有监督和无监督学习，并附带了实例。本章特别使用了道琼斯指数的收盘价作为数据集，该数据集被划分为样本内数据和样本外数据。样本内数据用于模型构建，样本外数据用于模型验证。过拟合和欠拟合通常会质疑模型的泛化能力，可以通过混淆矩阵来理解。模型的准确性是通过`confusionMatrix()`或`table()`来定义的。
- en: There are various types of risks that exists in the market and in the next chapter,
    I will explain how to calculate risk associated with various investments, in particular
    market risk, portfolio risk, and so on. I will also explain Monte Carlo simulation
    for risk, hedging techniques, and credit risk, along with Basel regulations.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 市场中存在各种类型的风险，在下一章中，我将解释如何计算与各种投资相关的风险，特别是市场风险、投资组合风险等。我还将解释蒙特卡洛模拟在风险计算中的应用、对冲技术以及信用风险，同时介绍巴塞尔协议的相关规定。
