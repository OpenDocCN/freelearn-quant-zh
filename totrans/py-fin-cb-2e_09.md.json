["```py\n    import pandas as pd \n    import yfinance as yf \n    from arch import arch_model \n    ```", "```py\n    RISKY_ASSET = \"GOOG\"\n    START_DATE = \"2015-01-01\"\n    END_DATE = \"2021-12-31\" \n    ```", "```py\n    df = yf.download(RISKY_ASSET, \n                     start=START_DATE, \n                     end=END_DATE, \n                     adjusted=True) \n    ```", "```py\n    returns = 100 * df[\"Adj Close\"].pct_change().dropna()\n    returns.name = \"asset_returns\"\n    returns.plot(\n        title=f\"{RISKY_ASSET} returns: {START_DATE} - {END_DATE}\"\n    ) \n    ```", "```py\n    model = arch_model(returns, mean=\"Zero\", vol=\"ARCH\", p=1, q=0) \n    ```", "```py\n    fitted_model = model.fit(disp=\"off\")\n    print(fitted_model.summary()) \n    ```", "```py\n     Zero Mean - ARCH Model Results                        \n    ===================================================================\n    Dep. Variable:      asset_returns   R-squared:                 0.000\n    Mean Model:         Zero Mean       Adj. R-squared:             .001\n    Vol Model:          ARCH            Log-Likelihood:         -3302.93\n    Distribution:       Normal          AIC:                     6609.85\n    Method:             Maximum         BIC:                     6620.80\n                        Likelihood\n                                        No. Observations:        1762\n    Date:           Wed, Jun 08 2022    Df Residuals:            1762\n    Time:                   22:25:16    Df Model:                0\n                            Volatility Model\n    ===================================================================\n                 coef      std err        t      P>|t|  95.0% Conf. Int.\n    -------------------------------------------------------------------\n    omega        1.8625    0.166      11.248  2.359e-29 [ 1.538, 2.187]\n    alpha[1]     0.3788    0.112       3.374  7.421e-04 [ 0.159, 0.599]\n    =================================================================== \n    ```", "```py\n    fitted_model.plot(annualize=\"D\") \n    ```", "```py\nfrom statsmodels.stats.diagnostic import het_arch\nhet_arch(fitted_model.resid) \n```", "```py\n(98.10927835448403,\n 1.3015895084238874e-16,\n 10.327662606705564,\n 4.2124269229123006e-17) \n```", "```py\n    model = arch_model(returns, mean=\"Zero\", vol=\"GARCH\", p=1, q=1) \n    ```", "```py\n    fitted_model = model.fit(disp=\"off\")\n    print(fitted_model.summary()) \n    ```", "```py\n     Zero Mean - GARCH Model Results                        \n    ====================================================================\n    Dep. Variable:      asset_returns   R-squared:                 0.000\n    Mean Model:         Zero Mean       Adj. R-squared:            0.001\n    Vol Model:          GARCH           Log-Likelihood:         -3246.71\n    Distribution:       Normal          AIC:                     6499.42\n    Method:             Maximum         BIC:                     6515.84\n                        Likelihood\n                                        No. Observations:        1762\n    Date:           Wed, Jun 08 2022    Df Residuals:            1762\n    Time:                   22:37:27    Df Model:                0\n                              Volatility Model\n    ===================================================================\n                 coef      std err     t      P>|t|     95.0% Conf. Int.\n    -------------------------------------------------------------------\n    omega        0.2864    0.186     1.539   0.124   [-7.844e-02, 0.651]\n    alpha[1]     0.1697  9.007e-02   1.884 5.962e-02 [-6.879e-03, 0.346]\n    beta[1]      0.7346    0.128     5.757  8.538e-09    [ 0.485, 0.985]\n    =================================================================== \n    ```", "```py\n    fitted_model.plot(annualize=\"D\") \n    ```", "```py\n    import pandas as pd\n    import yfinance as yf\n    from datetime import datetime\n    from arch import arch_model \n    ```", "```py\n    df = yf.download(\"MSFT\",\n                     start=\"2015-01-01\",\n                     end=\"2021-12-31\",\n                     adjusted=True)\n    returns = 100 * df[\"Adj Close\"].pct_change().dropna()\n    returns.name = \"asset_returns\" \n    ```", "```py\n    model = arch_model(returns, mean=\"Zero\", vol=\"GARCH\", dist=\"t\",\n                       p=1, q=1) \n    ```", "```py\n    SPLIT_DATE = datetime(2021, 1, 1)\n    fitted_model = model.fit(last_obs=SPLIT_DATE, disp=\"off\") \n    ```", "```py\n    forecasts_analytical = fitted_model.forecast(horizon=3,\n                                                 start=SPLIT_DATE,\n                                                 reindex=False)\n    forecasts_analytical.variance.plot(\n        title=\"Analytical forecasts for different horizons\"\n    ) \n    ```", "```py\n    forecasts_analytical.variance \n    ```", "```py\n    forecasts_simulation = fitted_model.forecast(\n        horizon=3, \n        start=SPLIT_DATE, \n        method=\"simulation\", \n        reindex=False\n    ) \n\n    forecasts_simulation.variance.plot( \n        title=\"Simulation forecasts for different horizons\" \n    ) \n    ```", "```py\n    forecasts_bootstrap = fitted_model.forecast(horizon=3,\n                                                start=SPLIT_DATE,\n                                                method=\"bootstrap\",\n                                                reindex=False)\n    forecasts_bootstrap.variance.plot(\n        title=\"Bootstrap forecasts for different horizons\"\n    ) \n    ```", "```py\n    import numpy as np \n    ```", "```py\n    FCST_HORIZON = 10\n    vol_analytic = (\n        fitted_model.forecast(horizon=FCST_HORIZON,\n                              start=datetime(2020, 1, 1),\n                              reindex=False)\n        .residual_variance[\"2020\"]\n        .apply(np.sqrt)\n    )\n    vol_bootstrap = (\n        fitted_model.forecast(horizon=FCST_HORIZON,\n                              start=datetime(2020, 1, 1),\n                              method=\"bootstrap\",\n                              reindex=False)\n        .residual_variance[\"2020\"]\n        .apply(np.sqrt)\n    ) \n    ```", "```py\n    vol = fitted_model.conditional_volatility[\"2020\"] \n    ```", "```py\n    ax = vol.plot(\n        title=\"Comparison of analytical vs bootstrap volatility forecasts\",\n        alpha=0.5\n    )\n    ind = vol.index\n    for i in range(0, 240, 10):\n        vol_a = vol_analytic.iloc[i]\n        vol_b = vol_bootstrap.iloc[i]\n        start_loc = ind.get_loc(vol_a.name)\n        new_ind = ind[(start_loc+1):(start_loc+FCST_HORIZON+1)]\n        vol_a.index = new_ind\n        vol_b.index = new_ind\n        ax.plot(vol_a, color=\"r\")\n        ax.plot(vol_b, color=\"g\")\n\n    labels = [\"Volatility\", \"Analytical Forecast\", \n              \"Bootstrap Forecast\"]\n    legend = ax.legend(labels) \n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    import yfinance as yf\n    from arch import arch_model \n    ```", "```py\n    RISKY_ASSETS = [\"GOOG\", \"MSFT\", \"AAPL\"]\n    START_DATE = \"2015-01-01\"\n    END_DATE = \"2021-12-31\" \n    ```", "```py\n    df = yf.download(RISKY_ASSETS, \n                     start=START_DATE, \n                     end=END_DATE, \n                     adjusted=True) \n    ```", "```py\n    returns = 100 * df[\"Adj Close\"].pct_change().dropna()\n    returns.plot(\n        subplots=True, \n        title=f\"Stock returns: {START_DATE} - {END_DATE}\"\n    ) \n    ```", "```py\n    coeffs = [] \n    cond_vol = [] \n    std_resids = [] \n    models = [] \n    ```", "```py\n    for asset in returns.columns:\n        model = arch_model(returns[asset], mean=\"Constant\", \n                           vol=\"GARCH\", p=1, q=1)\n        model = model.fit(update_freq=0, disp=\"off\");\n        coeffs.append(model.params)\n        cond_vol.append(model.conditional_volatility)\n        std_resids.append(model.std_resid)\n        models.append(model) \n    ```", "```py\n    coeffs_df = pd.DataFrame(coeffs, index=returns.columns)\n    cond_vol_df = (\n        pd.DataFrame(cond_vol)\n        .transpose()\n        .set_axis(returns.columns,\n                  axis=\"columns\")\n    )\n    std_resids_df = (\n        pd.DataFrame(std_resids)\n        .transpose()\n        .set_axis(returns.columns\n                  axis=\"columns\")\n    ) \n    ```", "```py\n    R = (\n        std_resids_df\n        .transpose()\n        .dot(std_resids_df)\n        .div(len(std_resids_df))\n    ) \n    ```", "```py\n    # define objects\n    diag = []\n    D = np.zeros((len(RISKY_ASSETS), len(RISKY_ASSETS)))\n\n    # populate the list with conditional variances\n    for model in models:\n        diag.append(model.forecast(horizon=1).variance.iloc[-1, 0])\n    # take the square root to obtain volatility from variance\n    diag = np.sqrt(diag)\n    # fill the diagonal of D with values from diag\n    np.fill_diagonal(D, diag)\n\n    # calculate the conditional covariance matrix\n    H = np.matmul(np.matmul(D, R.values), D) \n    ```", "```py\narray([[2.39962391, 1.00627878, 1.19839517],\n       [1.00627878, 1.51608369, 1.12048865],\n       [1.19839517, 1.12048865, 1.87399738]]) \n```", "```py\n    %load_ext rpy2.ipython \n    ```", "```py\n    %%R \n\n    install.packages('rmgarch', repos = \"http://cran.us.r-project.org\") \n    library(rmgarch) \n    ```", "```py\n    %%R -i returns\n    print(head(returns)) \n    ```", "```py\n     AAPL       GOOG       MSFT\n    2015-01-02 00:00:00 -0.951253138 -0.3020489  0.6673615\n    2015-01-05 00:00:00 -2.817148406 -2.0845731 -0.9195739\n    2015-01-06 00:00:00  0.009416247 -2.3177049 -1.4677364\n    2015-01-07 00:00:00  1.402220689 -0.1713264  1.2705295\n    2015-01-08 00:00:00  3.842214047  0.3153082  2.9418228 \n    ```", "```py\n    %%R\n\n    # define GARCH(1,1) model\n    univariate_spec <- ugarchspec(\n        mean.model = list(armaOrder = c(0,0)),\n        variance.model = list(garchOrder = c(1,1), \n                              model = \"sGARCH\"),\n        distribution.model = \"norm\"\n    )\n\n    # define DCC(1,1) model\n    n <- dim(returns)[2]\n    dcc_spec <- dccspec(\n        uspec = multispec(replicate(n, univariate_spec)),\n        dccOrder = c(1,1),\n        distribution = \"mvnorm\"\n    ) \n    ```", "```py\n    %%R \n    dcc_fit <- dccfit(dcc_spec, data=returns) \n    dcc_fit \n    ```", "```py\n    *---------------------------------*\n    *          DCC GARCH Fit          *\n    *---------------------------------*\n    Distribution         :  mvnorm\n    Model                :  DCC(1,1)\n    No. Parameters       :  17\n    [VAR GARCH DCC UncQ] : [0+12+2+3]\n    No. Series           :  3\n    No. Obs.             :  1762\n    Log-Likelihood       :  -8818.787\n    Av.Log-Likelihood    :  -5 \n    Optimal Parameters\n    --------------------------------------------------------------------\n                   Estimate  Std. Error  t value Pr(>|t|)\n    [AAPL].mu      0.189285    0.037040   5.1102 0.000000\n    [AAPL].omega   0.176370    0.051204   3.4445 0.000572\n    [AAPL].alpha1  0.134726    0.026084   5.1651 0.000000\n    [AAPL].beta1   0.811601    0.029763  27.2691 0.000000\n    [GOOG].mu      0.125177    0.040152   3.1176 0.001823\n    [GOOG].omega   0.305000    0.163809   1.8619 0.062614\n    [GOOG].alpha1  0.183387    0.089046   2.0595 0.039449\n    [GOOG].beta1   0.715766    0.112531   6.3606 0.000000\n    [MSFT].mu      0.149371    0.030686   4.8677 0.000001\n    [MSFT].omega   0.269463    0.086732   3.1068 0.001891\n    [MSFT].alpha1  0.214566    0.052722   4.0698 0.000047\n    [MSFT].beta1   0.698830    0.055597  12.5695 0.000000\n    [Joint]dcca1   0.060145    0.016934   3.5518 0.000383\n    [Joint]dccb1   0.793072    0.059999  13.2180 0.000000\n    Information Criteria\n    ---------------------\n\n    Akaike       10.029\n    Bayes        10.082\n    Shibata      10.029\n    Hannan-Quinn 10.049 \n    ```", "```py\n    forecasts <- dccforecast(dcc_fit, n.ahead = 5) \n    ```", "```py\n    %%R \n\n    # conditional covariance matrix \n    forecasts@mforecast$H \n    # conditional correlation matrix \n    forecasts@mforecast$R \n    # proxy correlation process \n    forecasts@mforecast$Q \n    # conditional mean forecasts \n    forecasts@mforecast$mu \n    ```", "```py\n[[1]]\n, , 1\n\n         [,1]     [,2]     [,3]\n[1,] 2.397337 1.086898 1.337702\n[2,] 1.086898 1.515434 1.145010\n[3,] 1.337702 1.145010 1.874023\n\n, , 2\n\n         [,1]     [,2]     [,3]\n[1,] 2.445035 1.138809 1.367728\n[2,] 1.138809 1.667607 1.231062\n[3,] 1.367728 1.231062 1.981190\n\n, , 3\n\n         [,1]     [,2]     [,3]\n[1,] 2.490173 1.184169 1.395189\n[2,] 1.184169 1.804434 1.308254\n[3,] 1.395189 1.308254 2.079076\n, , 4\n         [,1]     [,2]     [,3]\n[1,] 2.532888 1.224255 1.420526\n[2,] 1.224255 1.927462 1.377669\n[3,] 1.420526 1.377669 2.168484\n\n, , 5\n\n         [,1]     [,2]     [,3]\n[1,] 2.573311 1.259997 1.444060\n[2,] 1.259997 2.038083 1.440206\n[3,] 1.444060 1.440206 2.250150 \n```", "```py\n%%R\n# parallelized DCC-GARCH(1,1)\nlibrary(\"parallel\")\n# set up the cluster\ncl <- makePSOCKcluster(3)\n# define parallelizable specification\nparallel_fit <- multifit(multispec(replicate(n, univariate_spec)),\n                         returns,\n                         cluster = cl)\n# fit the DCC-GARCH model\ndcc_fit <- dccfit(dcc_spec,\n                  data = returns,\n                  fit.control = list(eval.se = TRUE),\n                  fit = parallel_fit,\n                  cluster = cl)\n# stop the cluster\nstopCluster(cl) \n```"]