- en: Chapter 4. Big Data – Advanced Analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 大数据——高级分析
- en: In this chapter, we will deal with one of the biggest challenges of high-performance
    financial analytics and data management; that is, how to handle large datasets
    efficiently and flawlessly in R.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将处理高性能金融分析和数据管理的最大挑战之一；即如何在 R 中高效且无误地处理大数据集。
- en: Our main objective is to give a practical introduction on how to access and
    manage large datasets in R. This chapter does not focus on any particular financial
    theorem, but it aims to give practical, hands-on examples to researchers and professionals
    on how to implement computationally - intensive analyses and models that leverage
    large datasets in the R environment.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要目标是提供一个关于如何在 R 中访问和管理大数据集的实际介绍。本章并不专注于任何特定的金融理论，而是旨在为研究人员和专业人士提供实际的操作示例，教他们如何在
    R 环境中实现计算密集型的分析和模型，利用大数据集。
- en: In the first part of this chapter, we explained how to access data directly
    for multiple open sources. R offers various tools and options to load data into
    the R environment without any prior data-management requirements. This part of
    the chapter will guide you through practical examples on how to access data using
    the `Quandl` and `qualtmod` packages. The examples presented here will be a useful
    reference for the other chapters of this book. In the second part of this chapter,
    we will highlight the limitation of R to handle big data and show practical examples
    on how to load a large amount of data in R with the help of big memory and `ff`
    packages. We will also show how to perform essential statistical analyses, such
    as K-mean clustering and linear regression, using large datasets.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一部分，我们解释了如何直接访问多个开放源的数据。R 提供了各种工具和选项，可以将数据加载到 R 环境中，而无需任何事先的数据管理要求。本章的这一部分将通过实际示例指导你如何使用
    `Quandl` 和 `qualtmod` 包来访问数据。这里展示的示例将为本书的其他章节提供有用的参考。在本章的第二部分，我们将强调 R 在处理大数据时的局限性，并展示如何在大内存和
    `ff` 包的帮助下将大量数据加载到 R 中的实际示例。我们还将展示如何使用大数据集执行基本的统计分析，如 K-means 聚类和线性回归。
- en: Getting data from open sources
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从开放源获取数据
- en: Extraction of financial time series or cross-sectional data from open sources
    is one of the challenges of any academic analysis. While several years ago, the
    accessibility of public data for financial analysis was very limited, in recent
    years, more and more open access databases are available, providing huge opportunities
    for quantitative analysts in any field.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 从开放源提取金融时间序列或横截面数据是任何学术分析中的挑战之一。虽然几年前，公开数据对金融分析的可访问性非常有限，但近年来，越来越多的开放获取数据库已可用，为各个领域的定量分析师提供了巨大的机会。
- en: In this section, we will present the `Quandl` and `quantmod` packages, two specific
    tools that can be used to seamlessly access and load financial data in the R environment.
    We will lead you through two examples to showcase how these tools can help financial
    analysts to integrate data directly from sources without any prior data management.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍 `Quandl` 和 `quantmod` 包，这两个特定工具可以无缝地访问和加载 R 环境中的金融数据。我们将通过两个示例，展示这些工具如何帮助金融分析师直接从数据源整合数据，无需事先进行数据管理。
- en: Quandl is an open source website for financial time series, indexing over millions
    of financial, economic, and social datasets from 500 sources. The `Quandl` package
    interacts directly with the `Quandl` API to offer data in a number of formats
    usable in R. Besides downloading data, users can also upload and edit their own
    data, as well as search in any of the data sources directly from R.upload and
    search for any data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Quandl 是一个开源网站，提供金融时间序列数据，索引来自500个来源的数百万个金融、经济和社会数据集。`Quandl` 包与 `Quandl` API
    直接交互，提供多种格式的数据，可供 R 使用。除了下载数据，用户还可以上传和编辑自己的数据，并且可以直接从 R 中在任何数据源中进行搜索。
- en: 'In the first simple example, we will show you how to retrieve and plot exchange
    rate time series with Quandl in an easy way. Before we can access any data from
    Quandl, we need to install and load the `Quandl` package using the following commands:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个简单的示例中，我们将展示如何使用 Quandl 轻松地获取并绘制汇率时间序列。在访问 Quandl 上的任何数据之前，我们需要使用以下命令安装并加载
    `Quandl` 包：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will download the currency exchange rates in EUR for USD, CHF, GBP, JPY,
    RUB, CAD, and AUD between January 01, 2005 and May 30, 2014\. The following command
    specifies how to select a particular time series and period for the analysis:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将下载2005年1月1日至2014年5月30日之间EUR汇率下的美元、瑞士法郎、英镑、日元、俄罗斯卢布、加元和澳元的汇率。以下命令指定了如何选择特定的时间序列和分析周期：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As the next step, we will visualize the exchange rate evolution of four selected
    exchange rates, USD, GBP, CAD, and AUD, using the `matplot()` function:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，我们将使用`matplot()`函数可视化四个选定汇率（美元、英镑、加元和澳元）的汇率变化：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following screenshot displays the output of the preceding code:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出：
- en: '![Getting data from open sources](img/2078OT_04_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![从开放源获取数据](img/2078OT_04_01.jpg)'
- en: 'Figure 4.1: Exchange rate plot of USD, GBP, CAD, and AUD'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：美元、英镑、加元和澳元的汇率图
- en: In the second example, we will demonstrate the usage of the `quantmod` package
    to access, load, and investigate data from open sources. One of the huge advantages
    of the quantmod package is that it works with a variety of sources and accesses
    data directly for Yahoo! Finance, Google Finance, **Federal Reserve Economic Data**
    (**FRED**), or the Oanda website.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个示例中，我们将演示如何使用`quantmod`包来访问、加载并调查开放来源的数据。`quantmod`包的一个巨大优势是它可以与多种数据源兼容，并直接从Yahoo!
    Finance、Google Finance、**联邦储备经济数据**（**FRED**）或Oanda网站获取数据。
- en: 'In this example, we will access the stock price information of BMW and analyze
    the performance of the car-manufacturing company since 2010:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将访问宝马股票价格信息，并分析这家汽车制造公司自2010年以来的表现：
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'From the Web, we will obtain the price data of BMW stock from Yahoo! Finance
    for the given time period. The `quantmod` package provides an easy-to-use function,
    `getSymbols()`, to download data from local or remote sources. As the first argument
    of the function, we need to define the character vector by specifying the name
    of the symbol loaded. The second one specifies the environment where the object
    is created:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从网络上获取宝马股票的价格数据，数据来源于Yahoo! Finance，涵盖给定的时间段。`quantmod`包提供了一个易于使用的函数`getSymbols()`，用于从本地或远程来源下载数据。作为该函数的第一个参数，我们需要通过指定符号的名称来定义字符向量。第二个参数指定对象创建的环境：
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As the next step, we need to load the `BMW.DE` variable from the `bmw_stock`
    environment to a vector. With the help of the `head()` function, we can also show
    the first six rows of the data:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步，我们需要将`bmw_stock`环境中的`BMW.DE`变量加载到一个向量中。借助`head()`函数，我们还可以显示数据的前六行：
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `quantmod` package is also equipped with a finance charting ability. The
    `chartSeries()` function allows us to not only visualize but also interact with
    the charts. With its expanded functionality, we can also add a wide range of technical
    and trading indicators to a basic chart; this is a very useful functionality for
    technical analysis.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`quantmod`包还具备财务图表功能。`chartSeries()`函数不仅允许我们可视化图表，还能与图表进行交互。借助其扩展功能，我们还可以将多种技术和交易指标添加到基本图表中；这对于技术分析来说是非常有用的功能。'
- en: 'In our example, we will add the Bollinger Bands using the `addBBands()` command
    and the MACD trend-following momentum indicator using the `addMACD()` command
    to get more insights on the stock price evolution:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将使用`addBBands()`命令添加布林带，并使用`addMACD()`命令添加MACD趋势跟踪动量指标，以获得有关股票价格变化的更多见解：
- en: '[PRE6]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following screenshot displays the output of the preceding code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出：
- en: '![Getting data from open sources](img/2078OT_04_02.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![从开放源获取数据](img/2078OT_04_02.jpg)'
- en: 'Figure 4.2: BMW stock price evolution with technical indicators'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：宝马股票价格变化与技术指标
- en: 'Finally, we will calculate the daily log return of the BMW stock for the given
    period. We would also like to investigate whether the returns have normal distribution.
    The following figure shows the daily log returns of the BMW stock in the form
    of a normal Q-Q plot:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将计算宝马股票在给定期间的日常对数收益。同时，我们还希望调查这些收益是否符合正态分布。下图展示了宝马股票的日常对数收益，并以正常Q-Q图的形式呈现：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following screenshot displays the output of the preceding code. It shows
    the daily log returns of the BMW stock in the form of a normal Q-Q plot:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出。它以正常Q-Q图的形式展示了宝马股票的日常对数收益：
- en: '![Getting data from open sources](img/2078OT_04_03.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![从开放源获取数据](img/2078OT_04_03.jpg)'
- en: 'Figure 4.3: Q-Q Plot of the daily return of BMW'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：宝马股票日常收益的Q-Q图
- en: Introduction to big data analysis in R
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R中的大数据分析简介
- en: Big data refers to the situations when volume, velocity, or a variety of data
    exceeds the abilities of our computation capacity to process, store, and analyze
    them. Big data analysis has to deal not only with large datasets but also with
    computationally intensive analyses, simulations, and models with many parameters.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据指的是当数据的体积、速度或种类超过我们的计算能力以处理、存储和分析它们时的情况。大数据分析不仅需要处理庞大的数据集，还需要应对计算密集型分析、模拟和具有大量参数的模型。
- en: Leveraging large data samples can provide significant advantages in the field
    of quantitative finance; we can relax the assumption of linearity and normality,
    generate better perdition models, or identify low-frequency events.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 利用大数据样本可以在量化金融领域提供显著优势；我们可以放宽线性和正态性假设，生成更好的预测模型，或者识别低频事件。
- en: However, the analysis of large datasets raises two challenges. First, most of
    the tools of quantitative analysis have limited capacity to handle massive data,
    and even simple calculations and data-management tasks can be challenging to perform.
    Second, even without the capacity limit, computation on large datasets may be
    extremely time consuming.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大数据集的分析提出了两个挑战。首先，大多数定量分析工具处理庞大数据的能力有限，即使是简单的计算和数据管理任务也可能变得难以执行。其次，即使没有容量限制，对大数据集的计算也可能极其耗时。
- en: Although R is a powerful and robust program with a rich set of statistical algorithms
    and capabilities, one of the biggest shortcomings is its limited potential to
    scale to large data sizes. The reason for this is that R requires the data that
    it operates on to be first loaded into memory. However, the operating system and
    system architecture can only access approximately 4 GB of memory. If the dataset
    reaches the RAM threshold of the computer, it can literally become impossible
    to work with on a standard computer with a standard algorithm. Sometimes, even
    small datasets can cause serious computation problems in R, as R has to store
    the biggest object created during the analysis process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管R是一个功能强大且稳定的程序，拥有丰富的统计算法和能力，但它的一个最大缺点是其在处理大数据集时的扩展能力有限。其原因在于R要求其操作的数据首先被加载到内存中。然而，操作系统和系统架构只能访问大约4
    GB的内存。如果数据集超过计算机的RAM阈值，它就几乎不可能在标准计算机和标准算法上进行处理。有时，即使是较小的数据集也可能在R中引发严重的计算问题，因为R必须存储分析过程中创建的最大对象。
- en: R, however, has a few packages to bridge the gap to provide efficient support
    for big data analysis. In this section, we will introduce two particular packages
    that can be useful tools to create, store, access, and manipulate massive data.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，R有一些包可以弥补这一差距，为大数据分析提供高效支持。在本节中，我们将介绍两个特别的包，它们是创建、存储、访问和操作海量数据的有用工具。
- en: 'First, we will introduce the `bigmemory` package that is a widely used option
    for large-scale statistical computing. The package and its sister packages (`biganalytics`,
    `bigtabulate`, and `bigalgebra`) address two challenges in handling and analyzing
    massive datasets: data management and statistical analysis. The tools are able
    to implement massive matrices that do not fit in the R runtime environment and
    support their manipulation and exploration.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍`bigmemory`包，这是一个广泛用于大规模统计计算的选项。该包及其姐妹包（`biganalytics`、`bigtabulate`和`bigalgebra`）解决了处理和分析海量数据集时的两个挑战：数据管理和统计分析。这些工具能够实现超出R运行环境的巨大矩阵，并支持它们的操作和探索。
- en: An alternative for the bigmemory package is the `ff` package. This package allows
    R users to handle large vectors and matrices and work with several large data
    files simultaneously. The big advantage of `ff` objects is that they behave as
    ordinary R vectors. However, the data is not stored in the memory; it is a resident
    on the disk.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`bigmemory`包的替代方案是`ff`包。这个包允许R用户处理大向量和矩阵，并同时处理多个大型数据文件。`ff`对象的一个巨大优势是，它们表现得像普通的R向量。然而，数据并不存储在内存中；它驻留在磁盘上。'
- en: In this section, we will showcase how these packages can help R users overcome
    the limitations of R to cope with very large datasets. Although the datasets we
    use here are simple in size, they effectively shows the power of big data packages.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示这些包如何帮助R用户克服R的局限性，处理非常大的数据集。尽管我们在这里使用的数据集在规模上相对简单，但它们有效地展示了大数据包的强大功能。
- en: K-means clustering on big data
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在大数据上的K-means聚类
- en: Data frames and matrices are easy-to-use objects in R, with typical manipulations
    that execute quickly on datasets with a reasonable size. However, problems can
    arise when the user needs to handle larger data sets. In this section, we will
    illustrate how the `bigmemory` and `biganalytics` packages can solve the problem
    of too large datasets, which is impossible to handle by data frames or data tables.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框和矩阵是 R 中易于使用的对象，对于大小适中的数据集，常见的操作可以迅速执行。然而，当用户需要处理更大的数据集时，可能会出现问题。在本节中，我们将说明如何使用
    `bigmemory` 和 `biganalytics` 包来解决数据框或数据表无法处理的超大数据集问题。
- en: Note
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The latest updates of `bigmemory`, `biganalytics`, and `biglm` packages are
    not available on Windows at time of writing this chapter. The examples shown here
    assume that R Version 2.15.3 is the current state-of-the-art version of R for
    Windows.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本章撰写时，`bigmemory`、`biganalytics` 和 `biglm` 包的最新更新在 Windows 上不可用。这里展示的示例假设
    R 版本 2.15.3 是 Windows 上当前的先进版本。
- en: In the following example, we will perform K-means clustering on large datasets.
    For illustrative purposes, we will use the Airline Origin and Destination Survey
    data of the U.S. Bureau of Transportation Statistics. The datasets contain the
    summary characteristics of more than 3 million domestic flights, including the
    itinerary fare, number of passengers, originating airport, roundtrip indicator,
    and miles flown, in a `csv` format.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将对大数据集执行 K-means 聚类分析。为了便于说明，我们将使用美国交通统计局的航空公司出发地和目的地调查数据集。该数据集包含超过
    300 万个国内航班的汇总特征，包括行程票价、乘客人数、起始机场、往返指示符和飞行里程，数据以`csv`格式呈现。
- en: Loading big matrices
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载大矩阵
- en: Reading dataset from `csv` files can be easily executed by the `read.csv()`
    file. However, when we have to handle larger datasets, the reading time of any
    file can become quite substantial. With some careful options, however, the data-loading
    functionality of R can be significantly improved.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 从 `csv` 文件中读取数据集可以通过 `read.csv()` 函数轻松实现。然而，当我们需要处理更大的数据集时，任何文件的读取时间都可能变得相当长。然而，通过一些细致的选项，R
    的数据加载功能可以得到显著提升。
- en: One option is to specify correct types in `colClasses = argument` when loading
    data to R; this will result in a faster conversion of external data. Also, the
    `NULL` specification of columns that are not needed for the analysis can significantly
    decrease the time and memory consumed to load the data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一个选项是在加载数据到 R 时，通过 `colClasses = argument` 指定正确的数据类型；这将导致外部数据的转换速度更快。此外，指定不需要进行分析的列为
    `NULL` 可以显著减少加载数据时所消耗的时间和内存。
- en: However, if the dataset reaches the RAM threshold of the computer, we need to
    adopt more memory-efficient data-leading options. In the following example, we
    will show how the bigmemory package can handle this task.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果数据集达到了计算机的 RAM 阈值，我们需要采用更节省内存的数据加载选项。在以下示例中，我们将展示如何使用 `bigmemory` 包来处理此任务。
- en: 'First of all, we will install and load the required `bigmemory` and `biganalytics`
    packages to perform the K-means cluster analysis on big data:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将安装并加载所需的 `bigmemory` 和 `biganalytics` 包，以执行大数据的 K-means 聚类分析：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We used the `read.big.matrix` function to import the downloaded dataset in
    R from the local system. The function handles data not as a data frame but as
    matrix-like objects, which we need to turn into a matrix with the `as.matrix`
    function:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`read.big.matrix`函数将从本地系统下载的数据集导入到 R 中。该函数将数据处理为类似矩阵的对象，而不是数据框，我们需要通过 `as.matrix`
    函数将其转换为矩阵：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Big data K-means clustering analysis
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大数据 K-means 聚类分析
- en: The format of the big data K-means function in R is `bigkmeans` (*x*, *centers*),
    where *x* is a numeric dataset (big data matrix object), and centers is the number
    of clusters to extract. The function returns the cluster memberships, centroids,
    **within cluster sum of squares** (**WCSS**), and cluster sizes. The `bigkmeans()`
    function works either on regular R matrix objects or on `big.matrix` objects.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中，处理大数据 K-means 聚类的函数格式是`bigkmeans` (*x*, *centers*)，其中 *x* 是一个数值数据集（大数据矩阵对象），centers
    是提取的聚类数。该函数返回聚类成员、中心点、**聚类内平方和**（**WCSS**）和聚类大小。`bigkmeans()`函数可以处理常规 R 矩阵对象或
    `big.matrix` 对象。
- en: 'We will determine the number of clusters based on the percentage of variance
    explained by each cluster; therefore, we will plot the percentage of variance
    explained by the clusters versus the number of clusters:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将根据每个聚类所解释的方差百分比来确定聚类数量；因此，我们将绘制聚类所解释的方差百分比与聚类数量之间的关系：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following screenshot displays the output of the preceding code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出：
- en: '![Big data K-means clustering analysis](img/2078OT_04_04.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![大数据K-means聚类分析](img/2078OT_04_04.jpg)'
- en: 'Figure 4.4: Plot the within cluser sums of squares versus the number of clusters
    extracted'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：绘制聚类内平方和与提取的聚类数量的关系
- en: 'The sharp decrease from 1 to 3 clusters (with little decrease thereafter) suggests
    a three-cluster solution. Therefore, we will perform the big data K-means cluster
    analysis with three clusters:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从1到3个聚类的急剧下降（之后几乎没有下降）表明了三聚类解决方案。因此，我们将执行具有三个聚类的大数据K-means聚类分析：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `bigkmeans()` function also works with ordinary matrix objects, offering
    a faster calculation than the `kmeans()` function.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`bigkmeans()`函数也可以与普通矩阵对象一起使用，比`kmeans()`函数提供更快的计算速度。'
- en: 'To test this hypothesis, we will measure the average execution time of the
    `bigkmeans()` and `kmeans()` functions with different dataset sizes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这个假设，我们将测量不同数据集大小下，`bigkmeans()`和`kmeans()`函数的平均执行时间：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following screenshot displays the output of the preceding code:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出：
- en: '![Big data K-means clustering analysis](img/2078OT_04_05.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![大数据K-means聚类分析](img/2078OT_04_05.jpg)'
- en: 'Figure 4.5: Execution time of the kmeans() and bigkmeans() function according
    to the size of the dataset'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5：根据数据集大小，kmeans()和bigkmeans()函数的执行时间
- en: Calculating the average execution time of the two functions takes substantial
    time. The preceding figure, however, reveals that `bigkmeans()` works more efficiently
    with larger datasets than the `kmeans()` function, thus reducing the calculation
    time of R in the analysis.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 计算这两个函数的平均执行时间需要相当长的时间。然而，从前述图表可以看出，`bigkmeans()`在处理较大数据集时比`kmeans()`函数更高效，从而减少了R在分析中的计算时间。
- en: Big data linear regression analysis
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大数据线性回归分析
- en: In this section, we will illustrate how to load large datasets directly from
    a URL with the help of the `ff` package and how to interact with a `biglm` package
    to fit a general linear regression model to the datasets that are larger than
    the memory. The `biglm` package can effectively handle datasets even if they overload
    the RAM of the computer, as it loads data into memory in chunks. It processes
    the last chunk and updates the sufficient statistics required for the model. It
    then disposes the chunk and loads the next one. This process is repeated until
    all the data is processed in the calculation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将展示如何借助`ff`包直接从URL加载大数据集，以及如何与`biglm`包交互，为大于内存的数据集拟合一个通用的线性回归模型。`biglm`包可以有效地处理超出计算机内存的数据集，因为它将数据分块加载到内存中。它处理最后一个数据块并更新模型所需的充分统计数据，然后丢弃该数据块并加载下一个。这个过程一直重复，直到所有数据都被处理完。
- en: The following example examines the unemployment compensation amount as a linear
    function of a few social-economic data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例考察了失业补偿金额作为几个社会经济数据的线性函数。
- en: Loading big data
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载大数据
- en: 'To perform a big data linear regression analysis, we first need to install
    and load the `ff` packages, which we will use to open large files in R, and the
    `biglm` package, which we will use to fit the linear regression model on our data:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行大数据线性回归分析，我们首先需要安装并加载`ff`包，使用该包在R中打开大文件；以及`biglm`包，用来拟合我们的数据上的线性回归模型：
- en: '[PRE13]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For the big data linear regression analysis, we used the Individual Income Tax
    ZIP Code Data provided by the U.S government agency, **Internal Revenue Service
    (IRS)**. ZIP code-level data shows selected income and tax items classified by
    the state, ZIP code, and income classes. We used the 2012 data of the database;
    this database is reasonable in size but allows us to highlight the functionality
    of the big data packages.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大数据线性回归分析，我们使用了美国政府机构**国税局（IRS）**提供的个人所得税邮政编码数据。邮政编码级别的数据展示了按州、邮政编码和收入类别分类的选定收入和税务项目。我们使用了该数据库的2012年数据；该数据库数据量适中，但足以展示大数据包的功能。
- en: 'We will directly load the required dataset into R from the URL with the following
    command:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将直接通过以下命令从URL加载所需的数据集到R中：
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once we have downloaded the data, we will use the `read.table.ffdf` function
    that reads the files into an `ffdf` object that is supported by the `ff` package.
    The `read.table.ffdf` function works very much like the `read.table` function.
    It also provides convenient options to read other file formats, such as `csv`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下载数据后，我们将使用`read.table.ffdf`函数将文件读取为`ffdf`对象，该对象由`ff`包支持。`read.table.ffdf`函数的工作方式与`read.table`函数非常相似。它还提供了便捷的选项来读取其他文件格式，例如`csv`：
- en: '[PRE15]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: After we have converted the dataset into an `ff` object, we will load the `biglm`
    package to perform the linear regression analysis.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据集转换为`ff`对象后，我们将加载`biglm`包以执行线性回归分析。
- en: Leveraging the dataset of almost 1,67,000 observations along 77 different variables,
    we will investigate whether the location-level amount of unemployment compensation
    (defined as variable `A02300`) can be explained by the total salary and wages
    amount (A00200), the number of residents by income category (AGI_STUB), the number
    of dependents (the NUMDEP variable), and the number of married people (MARS2)
    in the given location.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 利用包含大约167,000个观测值和77个不同变量的数据集，我们将调查是否可以通过总薪资和工资金额（A00200）、按收入类别划分的居民数量（AGI_STUB）、被抚养人数（NUMDEP变量）以及已婚人数（MARS2）来解释某一地区的失业补偿金额（定义为变量`A02300`）。
- en: Fitting a linear regression model on large datasets
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在大型数据集上拟合线性回归模型
- en: 'For the linear regression analysis, we will use the `biglm` function; therefore,
    before we specify our model, we need to load the package:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归分析，我们将使用`biglm`函数；因此，在指定模型之前，我们需要加载该包：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As the next step, we will define the formula and fit the model on our data.
    With the summary function, we can obtain the coefficients and the significance
    level of the variable of the fitted model. As the model output does not include
    the R-square value, we need to load the R-square value of the model with a separate
    command:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 作为下一步，我们将定义公式并在我们的数据上拟合模型。通过summary函数，我们可以获得拟合模型的系数及其显著性水平。由于模型输出不包括R平方值，我们需要使用单独的命令加载模型的R平方值：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can conclude from the regression model coefficient output that all the variables
    contribute significantly to the model. The independent variables explain 86.09
    percent of the total variance of the unemployment compensation amount, indicating
    a good fit of the model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从回归模型的系数输出中得出结论，所有变量对模型都有显著贡献。独立变量解释了86.09%的失业补偿总方差，表明该模型拟合良好。
- en: Summary
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we applied R to access data from open sources and perform various
    analyses on large datasets. The examples presented here aimed to be a practical
    guide to empirical researchers who handle a large amount of data.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们应用R来访问开放源数据，并对大型数据集进行各种分析。这里展示的示例旨在为处理大量数据的经验研究人员提供实用指南。
- en: First, we introduced useful methods for open source data integration. R has
    powerful options to directly access data for financial analysis without any prior
    data-management requirement. Second, we discussed how to handle big data in an
    R environment. Although R has fundamental limitations in handling large datasets
    and performing computationally intensive analyses and simulations, we introduced
    specific tools and packages that can bridge this gap. We presented two examples
    on how to perform K-means clustering and how to fit linear regression models on
    big data. This is the last chapter of the first part in this book. Next we will
    look at FX derivatives.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们介绍了开放源数据整合的实用方法。R具有强大的选项，可以直接访问金融分析所需的数据，无需任何先前的数据管理要求。其次，我们讨论了如何在R环境中处理大数据。尽管R在处理大型数据集和执行计算密集型分析与仿真方面有基本的局限性，但我们介绍了一些特定的工具和包来弥补这一差距。我们展示了两个示例，说明如何在大数据上执行K均值聚类以及如何拟合线性回归模型。这是本书第一部分的最后一章。接下来，我们将探讨外汇衍生品。
- en: References
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '**Adler, D., Nenadic, O., Zucchini, W.,Gläser, C. (2007)**: The ff package:
    Handling Large Data Sets in R with Memory Mapped Pages of Binary Flat Files'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Adler, D., Nenadic, O., Zucchini, W., Gläser, C. (2007)**：The ff包：使用二进制平面文件的内存映射页面在R中处理大数据集'
- en: '**Enea, M. (2009)**: Fitting Linear Models and Generalized Linear Models with
    large data sets in R. In book of short papers, conference on "Statistical Methods
    for the analysis of large data-sets", Italian Statistical Society, Chieti-Pescara,
    23-25 September 2009, 411-414.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Enea, M. (2009)**: 使用 R 在大数据集上拟合线性模型和广义线性模型。短篇论文集，《大数据集分析的统计方法》会议，意大利统计学会，基耶蒂-佩斯卡拉，2009年9月23-25日，411-414。'
- en: '**Kane, M.,Emerson, JW., Weston (2010)**: The Bigmemory Project, Yale University'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kane, M., Emerson, JW., Weston (2010)**: 大记忆项目，耶鲁大学'
- en: '**Kane, M.,Emerson, JW., Weston, S. (2013)**: Scalable Strategies for Computing
    with Massive Data. Journal of Statistical Software , Vol. 55, Issue 14'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kane, M., Emerson, JW., Weston, S. (2013)**: 处理海量数据的可扩展计算策略。统计软件杂志，第55卷，第14期'
- en: '**Lumley, T. (2009) biglm**: bounded memory linear and generalized linear models.
    R package version 0.7'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lumley, T. (2009) biglm**: 有界内存线性和广义线性模型。R 包版本 0.7'
