- en: Chapter 12. Capital Adequacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we learned in the previous chapter, banking is a specifically risky industry
    and the safety of the clients' money is a top priority. In order to ensure that
    banks meet this primary objective, the industry is under strict regulation. It
    has always been a very important task for supervisors to build rules to avoid
    the collapsing of banks and to protect clients' wealth. Capital adequacy or capital
    requirement is one of, if not, the most, important regulatory tool to serve this
    goal. Given the high leverage in the financial sector, banks and other financial
    institutions are not allowed to freely use all their assets. These firms need
    to hold enough capital to ensure safe operation and solvency even if things turn
    bad.
  prefs: []
  type: TYPE_NORMAL
- en: Different countries have different banking supervisory bodies (financial watchdog,
    central bank, and so on) and regulation standards. However, as the banking system
    became more and more globalized, a common worldwide standard became necessary.
    In 1974, the **Basel Committee on Banking Supervision** (**BCBS**) was set up
    by the G-10 central banks to provide banking regulatory standards that can be
    applied to different countries around the globe.
  prefs: []
  type: TYPE_NORMAL
- en: This area of economics has developed quite fast since then, and more and more
    complex mathematical methods are used in risk management and capital adequacy
    calculation. R is such a powerful tool that it is perfectly capable of solving
    these complex mathematical and analytical problems. Therefore, it is not surprising
    that many banks use this as an important tool for risk management.
  prefs: []
  type: TYPE_NORMAL
- en: Principles of the Basel Accords
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 1988, the BCBS published a regulatory framework in Basel, Switzerland, to
    set the minimum capital that a bank needs to hold to minimize the risk of insolvency.
    The so-called First Basel Accord, which is now referred to as Basel I, was enforced
    by the law in all of the G-10 countries by 1992\. By 2009, 27 jurisdictions were
    involved in the Basel Regulatory Framework (the history of the Basel Committee
    can be read at [http://www.bis.org/bcbs/history.htm](http://www.bis.org/bcbs/history.htm)).
  prefs: []
  type: TYPE_NORMAL
- en: Basel I
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first Basel Accord mainly focuses on credit risk, and formalizes the appropriate
    risk weighting considering different asset classes. Based on the Accord, the assets
    of banks should be classified into categories regarding credit risk, and the exposure
    of each category should be weighted with the defined measures (0 percent, 20 percent,
    50 percent, and 100 percent). The resulted value of **risk-weighted assets** (**RWA**)
    is used for the determination of capital adequacy. According to the Basel I legislation,
    banks that are present on international markets are required to hold capital of
    at least 8 percent of their RWA. This is called the minimum capital ratio (refer
    to *Basel Committee on Banking Supervision (Charter)* [http://www.bis.org/bcbs/charter.htm](http://www.bis.org/bcbs/charter.htm)).
  prefs: []
  type: TYPE_NORMAL
- en: The so-called off-balance sheet items such as derivatives, unused commitments,
    and credit letters are included in RWA, and should be reported as well.
  prefs: []
  type: TYPE_NORMAL
- en: The Accord was intended to amend and refine over time in order to address risks
    other than credit risk as well. Furthermore, it was revised to give more appropriate
    definitions to certain asset classes included in the capital adequacy calculation
    and to recognize subsequently identified effects.
  prefs: []
  type: TYPE_NORMAL
- en: Basel I defines other capital ratios as well, in order to quantify the banks'
    capital adequacy. The capital ratios are considered as certain so-called tier-capital
    elements relative to all RWA. Tier-capital elements include types of capital grouped
    based on the definition of Basel I. However, each country's banking regulator
    might revise the classification of the financial instruments considered in capital
    calculation due to the different legal frameworks of the countries.
  prefs: []
  type: TYPE_NORMAL
- en: 'The tier 1 capital includes core capital, which is composed of common stock,
    retained earnings, and certain preferred stocks, which meet the defined requirements.
    Tier 2 is considered supplementary capital, which involves supplementary debts,
    undisclosed reserves, revaluation reserves, general loan-loss reserves, and hybrid
    capital instruments, while tier 3 is deemed as the short-term additional capital.
    (*Committee on Banking Regulations and Supervisory Practices (1987): Proposals
    for international convergence of capital measurement and capital standards, Consultative
    paper, December 1987*, [http://www.bis.org/publ/bcbs03a.pdf](http://www.bis.org/publ/bcbs03a.pdf).)'
  prefs: []
  type: TYPE_NORMAL
- en: Basel II
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Basel II was issued in 1999 as a new capital adequacy framework proposed to
    succeed Basel I, and was published in 2004 in order to ensure resolutions to certain
    issues, which was slightly regulated by the former Basel Accord.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main objectives of Basel II were to:'
  prefs: []
  type: TYPE_NORMAL
- en: Provide more risk-sensitive capital allocation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement appropriate calculation methods for not only credit risk but market
    risk and operational risk as well
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improve the disclosure requirement in order to make capital adequacy more perceptible
    for market participants
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid regulatory arbitrage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The framework of Basel II is based on the three following pillars:'
  prefs: []
  type: TYPE_NORMAL
- en: The minimum capital requirements by which the Committee intended to develop
    and expand the standardized capital adequacy calculations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A supervisory review of a financial institute's capital adequacy and internal
    assessment process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effective disclosure to enhance market discipline
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimum capital requirements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The required capital on credit risk can be calculated according to the standardized
    approach. Based on this method, credit exposures should be weighted by measures
    considering primarily the related ratings by **External Credit Assessment Institutions**
    (**ECAI**). Claims on sovereigns, corporates, and banks or securities companies
    can be weighted by 0 percent, 20 percent, 50 percent, 100 percent, or 150 percent
    according to their ratings; however, based on the claims by international associations
    such as IMF, BIS, or EC, the risk weight should consistently be 0 percent.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding secured claims, cash, and other assets, there are constant weights
    defined by the Committee and implemented by local regulators who are considering
    risk mitigation techniques. Eligibility can be considered on different levels
    regarding the different asset classes, and is regulated in local acts and decrees
    of the countries. Furthermore, real estate is not deemed as cover but as exposure
    according to the standard approach; therefore, it is included in the regulation
    on asset classes as well.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum capital requirement is defined as 8 percent of the RWA, considering
    conversion factors in case of off-balance sheet items. Capital requirement determined
    by this method should be appropriate to cover credit risk, market risk, and operational
    risk as well.
  prefs: []
  type: TYPE_NORMAL
- en: Other methods for the calculation of credit risk are the so-called **Internal
    Ratings-Based** (**IRB**) approaches, including Foundation IRB and Advanced IRB.
    IRB approaches are allowed to use only the approved banks by their local regulator.
  prefs: []
  type: TYPE_NORMAL
- en: IRB approaches apply a capital function to determine the required capital. There
    are key parameters that influence the capital function, such as **probability
    of default** (**PD**), **loss given default** (**LGD**), **exposure at default**
    (**EAD**), and **maturity** (**M**).
  prefs: []
  type: TYPE_NORMAL
- en: Probability of default is considered the likelihood that the client will not
    (entirely) meet its debt obligation over a particular time horizon. By IRB methods,
    the bank is allowed to estimate the PD of its clients based on either own developed
    models or by applying the ratings of ECAI.
  prefs: []
  type: TYPE_NORMAL
- en: Loss given default is the percentage of a relating asset when the client defaults.
    LGD is related tightly to EAD. Exposure at default is the value of the outstanding
    liability towards the client at the time of the event of its default. Applying
    Foundation IRB, the calculation method of EAD is determined by the local regulator;
    however, by Advanced IRB, the banks are allowed to develop their own methodology.
  prefs: []
  type: TYPE_NORMAL
- en: Maturity is a duration type parameter, which indicates the average remaining
    part of the credit period.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced IRB enables another classification of exposures and assets, which may
    reflect more on the characteristics of the bank's portfolio. Furthermore, the
    range of the possibly applied credit risk mitigation actions expands as well.
  prefs: []
  type: TYPE_NORMAL
- en: Although RWA can be determined by various methods by applying either Foundation
    IRB or Advanced IRB, according to Basel II, the minimum capital requirement is
    the 8 percent of RWA in both cases.
  prefs: []
  type: TYPE_NORMAL
- en: Determination of the operational risk can be executed by different methods.
    The simplest way of the calculation is the so-called **Basic Indicator Approach**
    (**BIA**). Based on this approach, the capital requirement is defined as the average
    of **gross incomes** (**GI**) of the previous 3 years of the bank multiplied by
    a given measure, Alpha, which is determined as 15 percent by the legislation.
  prefs: []
  type: TYPE_NORMAL
- en: The **Standardized Approach** (**STA**) is a little bit more complex. This approach
    adopts certain methods of BIA; however, using STA, it is required to determine
    the gross income regarding the **lines of** **business** (**LoB**). The GI of
    each LoB should be multiplied by a fixed measure, Beta (12 percent, 15 percent,
    or 18 percent, depending on the LoB). The capital requirement is the sum of the
    products of GIs and betas that refer to the LoBs.
  prefs: []
  type: TYPE_NORMAL
- en: The aim of the **Alternative Standard Approach** (**ASTA**) is to avoid double
    imposition due to credit risk. ASTA adopts the methodology of STA; however, in
    the case of two LoBs (Retail and Commercial banking), the calculation differs
    from the standardized approach. Regarding these LoBs, GI is replaced by the product
    of the value of loans and advances (LA) and a fixed factor (m is equal to 0,035).
  prefs: []
  type: TYPE_NORMAL
- en: The most complex methodology of the determination of operational risk is the
    **Advanced Measurement Approach** (**AMA**). This approach has both quantitative
    and qualitative requirements, which should be met. The internal model developed
    for the estimation of the operational risk has to correspond to the standards
    of safe operation, such as risk measurement on 99.9 percent possibility regarding
    the period of 1 year. Furthermore, banks that apply the AMA have to provide data
    of the past 5 years in relation to their losses.
  prefs: []
  type: TYPE_NORMAL
- en: Risk-mitigation techniques can be applied for up to 20 percent of the capital
    requirement only by banks that use the advanced measurement approach. The banks
    also have to meet certain strict requirements to be allowed to adopt the risk-mitigation
    effects.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the calculation of capital requirement for market risk, the standardized
    approach is based on the measures and techniques defined by regulators. For more
    advanced approaches, determination of **Value at Risk** (**VaR**) is considered
    the preferred methodology.
  prefs: []
  type: TYPE_NORMAL
- en: Supervisory review
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Basel II defines the supervisory and interventional responsibilities of local
    regulators. It enables them to prescribe a higher capital requirement than what
    is determined in Pillar I. Furthermore, it allows regulating and managing the
    remaining risks that are not described in Pillar I, such as liquidity, concentration,
    strategic, and systemic risks.
  prefs: []
  type: TYPE_NORMAL
- en: The **International Capital Adequacy** **Assessment Process** (**ICAAP**) is
    meant to ensure that the bank operates an appropriately sophisticated risk management
    system, which measures, quantifies, summarizes, and monitors all the potentially
    occurring risks. Furthermore, it should oversee whether the banks have enough
    capital determined, based on internal methods, to cover all the mentioned risks.
  prefs: []
  type: TYPE_NORMAL
- en: The **Supervisory Review Evaluation Process** (**SREP**) is defined as the procedure
    for the examination of risk and capital adequacy of the institutes executed by
    the local regulator. Moreover, considering Pillar II, the regulator has to regularly
    monitor the capital adequacy according to Pillar I, and intervene in order to
    ensure the sustainable level of capital.
  prefs: []
  type: TYPE_NORMAL
- en: Transparency
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Pillar III of Basel II focuses on the disclosure requirements of banks. It
    refers mainly to the listed institutes, which are required to share information
    regarding the scope of application of Pillar I-II, risk assessment processes,
    risk exposure, and capital adequacy. (*Basel Committee on Banking Supervisions
    (1999): A New Capital Adequacy Framework; Consultative paper; June 1999*; [http://www.bis.org/publ/bcbs50.pdf](http://www.bis.org/publ/bcbs50.pdf).)'
  prefs: []
  type: TYPE_NORMAL
- en: Basel III
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Even before the financial crisis, the need for review and the fundamental strengthening
    of Basel II framework became evident. During the crisis, it was apparent that
    the banks had inadequate liquidity position and too much leverage. Risk management
    should have been more significant, while credit and liquidity risks have usually
    been mispriced.
  prefs: []
  type: TYPE_NORMAL
- en: The third installment of Basel Accords was developed in 2010 with the aim of
    providing a more stable and safe operation framework for the financial sector.
    Basel III and the relating Capital Requirements Directive (CRD IV) are supposed
    to be implemented into the local legislation by 2019.
  prefs: []
  type: TYPE_NORMAL
- en: Although the implementation will be executed in several steps, the financial
    institutions are required to commence the preparation for the application of new
    capital standards even years before the deadline.
  prefs: []
  type: TYPE_NORMAL
- en: 'The areas concerned in the regulation of Basel III are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The elements of the required capital—implementing a capital conservation buffer
    and a counter-cyclical buffer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction of leverage ratio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of liquidity indicators
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Measurement of the counterparty risk
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capital requirement of credit institutions and investment companies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of global prudential standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In order to improve the quality of capital, Basel III regulates the composite
    of required capital. Core Tier 1 is defined within Tier 1 capital, and a so-called
    capital conservation buffer is implemented with the constant measure of 2.5 percent.
    A discretionary counter-cyclical buffer is introduced as well, which is considered
    an additional 2.5 percent of capital during periods of high-credit growth.
  prefs: []
  type: TYPE_NORMAL
- en: A leverage ratio was also defined by Basel III, as a minimum amount of loss-absorbing
    capital compared to all assets and off-balance sheet items regardless of risk
    weighting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most significant provision of Basel III is the introduction of two liquidity
    indicators. The first one, considered on a short-term horizon, is the **liquidity
    coverage ratio** (**LCR**), which should be implemented in 2015\. LCR is the value
    of liquid assets relative to the cumulated net cash flow within a 30-day period.
    At the beginning, the minimum value of LCR should be 60 percent; however, it is
    intended to be raised to 100 percent by 2019\. The formula for the LCR is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Basel III](img/2078OT_12_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The **Net stable funding ratio** (**NSFR**) is going to be implemented in 2018\.
    The aim of this indicator is to avoid maturity gaps between the assets and liabilities
    of financial institutions. The objective is to provide financing of long-term
    assets that concern the stability of liabilities. Consequently, NSFR is defined
    as the stable liabilities on stable assets to be financed. The measure of NSFR
    should be a minimum 100 percent in 2019 as well.
  prefs: []
  type: TYPE_NORMAL
- en: '![Basel III](img/2078OT_12_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To avoid systemic risks, capital requirement is implemented also with regard
    to counterparty risk. Expectations regarding the capital adequacy and liquidity
    position of counterparties are framed according to the Basel III regulation. Regarding
    the capital adequacy, institutes that mainly apply internal calculation methods
    are involved in the new regulation, since the regulation takes into consideration
    the more detailed examination of potential risks that occur and the exposures
    towards Systematically Important Financial Institutions (SIFI). Based on the third
    installment of Basel Accords, the institutions should identify the SIFI based
    on an indicator than apply the requirements determined by the regulator regarding
    them (refer to *History of the Basel Committee*).
  prefs: []
  type: TYPE_NORMAL
- en: 'The main measures and phase-in arrangements of Basel III are included in the
    following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Basel III](img/2078OT_12_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Risk measures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Financial risk is a tangible and quantifiable concept, a value that you can
    lose on a certain financial investment. Note that here, we strictly differentiate
    between uncertainty and risk, where the latter is measurable with mathematical-statistical
    methods with exact probabilities of the different outcomes. However, there are
    various kinds of measures for financial risks. The most common risk measure is
    the standard deviation of the returns of a certain financial instrument. Although
    it is very widespread and easy to use, it has some major disadvantages. One of
    the most important problems of the standard deviation as a risk measurement is
    that it treats upside potential the same way as downside risk. In other words,
    it also punishes a financial instrument that might bring huge positive returns
    and little negative ones than a less volatile asset.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the following extreme example. Let's assume that we have two stocks
    on the stock market and we can exactly measure the stocks' yields in three different
    macroeconomic events. Next year for stock A, a share of a mature corporation brings
    5 percent yield if the economy grows, 0 percent if there is stagnation, and loses
    5 percent if there's a recession. Stock B is a share of a promising start-up firm;
    it skyrockets (+ 50 percent) when there's a good economic environment, brings
    30 percent if there's stagnation, and has a 20 percent annual yield even if the
    economy contracts. The statistical standard deviations of stock A and B's returns
    are 4.1 percent and 12.5 percent respectively. Therefore, it is riskier to pick
    stock A than stock B if we make our choice based on the standard deviation. However,
    using our common sense, it is obvious that stock B is better in every case than
    stock A as it gives a better yield in all different macroeconomic situations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our short example perfectly showed the biggest problem with standard deviation
    as a risk measure. The standard deviation does not meet the most simple condition
    of a coherent risk measure, the monotonicity. We call the σ risk measure coherent
    if it is normalized and meets the following criteria. See the work of Artzner
    and Delbaen for further information on coherent risk measures:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monotonicity**: If portfolio *X[1]* has no lower values than portfolio *X[2]*
    under all scenarios, then the risk of *X[1]* should be lower than *X[2]*. In other
    words, if an instrument pays more than another one in every case, it should have
    a lower risk.![Risk measures](img/2078OT_12_04.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sub-additivity**: The risk of two portfolios together should be less than
    the sum of the risks of the two portfolios separately. This criterion represents
    the principle of diversification.![Risk measures](img/2078OT_12_05.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Positive homogeneity**: Multiplying the portfolio values by a constant multiplies
    the risk by the same extent.![Risk measures](img/2078OT_12_06.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Translation invariance**: Adding a constant value to the portfolio decreases
    the risk by the same amount. See the following formula:![Risk measures](img/2078OT_12_07.jpg)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the standard deviation is not a reliable risk measure, then what can we use?
    This question popped up at J.P. Morgan by CEO Dennis Weatherstone in the early
    1990s. He called the firm's departments for the famous 4:15 report, in which they
    aggregated the so-called values at risk 15 minutes before the market closed. The
    CEO wanted an aggregated measure that showed what amount the firm might lose in
    the next trading day. As this cannot be calculated with full certainty, especially
    in the light of the 1987 Black Monday, the analysts added a probability of 95
    percent.
  prefs: []
  type: TYPE_NORMAL
- en: The figure that shows what a position might lose in a specified time period
    with a specified probability (significance level) is called the Value at Risk
    (VaR). Although it is quite new, it is widely used both by risk departments and
    financial regulators. There are several ways to calculate value at risk, which
    can be categorized into three different methods. Under the analytical VaR calculation,
    we assume that we know the probability distribution of the underlying asset or
    return. If we do not want to make such assumptions, we can use the historical
    VaR calculation using the returns or asset values realized in the past. In this
    case, the implicit assumption is that the past development of the given instrument
    is a good estimator for the future distribution. If we would like to use a more
    complex distribution function that is hard to tackle by analytics, a Monte-Carlo
    simulation could be the best choice to calculate VaR. This can be used by either
    assuming an analytical distribution of the instrument or by using past values.
    The latter is called historic simulation.
  prefs: []
  type: TYPE_NORMAL
- en: Analytical VaR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When calculating Value at Risk (VaR) in an analytical approach, we need to
    assume that the return of a financial instrument follows a certain mathematical
    probability distribution. The normal distribution is used most commonly; that
    is why we usually call it the delta-normal method for VaR calculation. Mathematically,
    *X ~ N (μ,σ)*, where *μ* and *σ* are the mean and the standard deviation parameters
    of the distribution. To calculate the value at risk, we need to find a threshold
    (T) that has the ability that the probability of all data bigger than this is
    *α* (*α* is the level of significance that can be 95 percent, 99 percent, 99.9
    percent, and so on). Using the standard normal cumulative distribution for function
    F:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analytical VaR](img/2078OT_12_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'This indicates that we need to apply the inverse cumulative distribution function
    to *1- α*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analytical VaR](img/2078OT_12_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Although we do not know the closed mathematical formula of neither the cumulative
    function of normal distribution nor its inverse, we can solve this by using a
    computer.
  prefs: []
  type: TYPE_NORMAL
- en: We use R to calculate the 95 percent, 1 day VaR of the Apple stocks using the
    delta normal method, based on a two-year dataset. The estimated mean and standard
    deviation of Apple returns are 0.13 percent and 1.36 percent.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code calculates that VaR for Apple stocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The threshold, which is equal to the VaR if we apply it to the returns, can
    be seen in the following formula. Note that we always take the absolute value
    of the result, as VaR is interpreted as a positive number:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analytical VaR](img/2078OT_12_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The VaR (95 percent, 1 day) is 2.11 percent. This means that it has 95 percent
    probability that Apple shares will not lose more than 2.11 percent in one day.
    We can also interpret this with an opposite approach. An Apple share will only
    lose more than 2.11 percent in one day with 5 percent probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chart shown in the following figure depicts the actual distribution of
    Apple returns with the historic value at risk on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Analytical VaR](img/2078OT_12_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Historical VaR
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The simplest way of calculating the value at risk is by using the historical
    approach. Here, we assume that the past distribution of the financial instrument''s
    return represents the future too. Therefore, we need to find the threshold above
    which the *α* portion of the values can be found. In statistics, this is called
    the percentile. If we use a VaR with a 95- percent level of significance, for
    instance, then it will imply the lower fifth percentile of the dataset. The following
    code shows how to calculate the percentile in R:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Applying this to the Apple shares, we get a lower fifth percentile of 1.57 percent.
    The value at risk is the absolute value of this percentile. Therefore, we can
    either say that it has only 5 percent probability that Apple shares lose more
    than 1.57 percent in a day, or the stock will lose less than 1.57 percent with
    95 percent likelihood.
  prefs: []
  type: TYPE_NORMAL
- en: Monte-Carlo simulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most sophisticated approach to calculate the value at risk is the Monte-Carlo
    simulation. However, it is only worth using if other methods cannot be used. These
    reasons can be the complexity of the problem or the assumption of a difficult
    probability distribution. Nevertheless, this is the best method to show the powerful
    capabilities of R that can support risk management.
  prefs: []
  type: TYPE_NORMAL
- en: A Monte-Carlo simulation can be used in many different fields of finance and
    other sciences as well. The basic approach is to set up a model and to assume
    an analytic distribution of the exogenous variable The next step is to randomly
    generate the input data to the model in accordance with the assumed distribution.
    Then, the outcomes are collected and used to gather the result and draw the conclusion.
    When the simulated output data is ready, we can follow the same procedure as we
    would do if we used the historical approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using a 10,000 step Monte-Carlo simulation to calculate the value at risk of
    Apple shares may seem to be an overkill, but it serves for the demonstration.
    The related R code is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: We get a result of 2.06 percent for the value at risk as a lower fifth percentile
    of the simulated returns. This is very close to the 2.11 percent estimated with
    the delta-normal method, which is not a coincidence. The basic assumption that
    the yield follows a normal distribution is the same; thus, the minor difference
    is only a result of the randomness of the simulation. The more steps the simulation
    takes, the closer the result is to the delta-normal estimation.
  prefs: []
  type: TYPE_NORMAL
- en: A modification of the Monte-Carlo method is the historical simulation when the
    assumed distribution is based on the past data of the financial instrument. The
    generation of the data here is not based on an analytical mathematical function
    but the historical values are selected randomly, preferably via an independent
    identical distribution method.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also use a 10,000 element simulation for the Apple stock returns. In order
    to select the values from the past randomly, we assign numbers to them. The next
    step is to simulate a random integer between 1 and 251 (the number of historic
    data) and then use a function to find the associated yield. The R code can be
    seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The result for the VaR is 1.58 percent, which is not surprisingly close to the
    value derived from the original historic method.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, value at risk is a common measure for risk in many fields of finance.
    However, in general, it still does not fulfill the criteria of a coherent risk
    measure as it fails to meet sub-additivity. In other words, it might discourage
    diversification in certain cases. However, if we assume an elliptically distributed
    function for the returns, the VaR proves to be a coherent risk measure. This essentially
    means that the normal distribution suits the estimation of VaR perfectly. The
    only problem is that the stock returns in real life are rather leptokurtic (heavy-tailed)
    compared to the Gaussian curve as it is experienced as a stylized fact of finance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Monte-Carlo simulation](img/2078OT_12_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In other words, the stocks in real life tend to show more extreme losses and
    profits than it would be explained by the normal distribution. Therefore, a developed
    analysis of risk assumes more complex distributions to cope with the heavy-tailed
    stock returns, the heteroskedasticity, and other imperfections of the real-life
    yields.
  prefs: []
  type: TYPE_NORMAL
- en: The use of **Expected Shortfall** (**ES**) is also included in the developed
    analysis of risk, which is, in fact, a coherent risk measure, no matter what distribution
    we assume. The expected shortfall concentrates on the tail of the distribution.
    It measures the expected value of the distribution beyond the value at risk. In
    other words, the expected shortfall at *α* significance level is the expected
    value of the worst *α* percent of the cases. Mathematically, ![Monte-Carlo simulation](img/2078OT_12_13.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: Here, *VaRγ* is the value at risk of the distribution of returns.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, an expected shortfall is called **conditional value at risk** (**CVaR**).
    However, the two terminologies do not exactly mean the same thing; they can be
    used as synonyms if continuous distribution functions are used for the risk analysis.
    Although R is capable of dealing with such complex issues as the expected shortfall,
    it goes beyond the goals of this book. For further information on this topic,
    see the work of *Acerbi, C.; Tasche, D. (2002)*.
  prefs: []
  type: TYPE_NORMAL
- en: Risk categories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Banks face various kinds of risks, for example, client default, changes in the
    market environment, troubles in refinancing, and fraud. These risks are categorized
    into credit risk, market risk, and operational risk.
  prefs: []
  type: TYPE_NORMAL
- en: Market risk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Losses realized from the movements of the market prices are covered by the market
    risk. It may include the losses on the trading book positions of a bank or financial
    institution, but the losses realized on interest rate or currency that may be
    in connection with the core business of a bank also belong to market risk. Market
    risk can include several subcategories such as equity risk, interest rate risk,
    currency risk, and commodity risk. Liquidity risk is also covered in this topic.
    Based on the advanced approach of the Basel II directive, the capital needed to
    cover these risks is mostly based on value at risk calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Currency risk refers to the possible loss on the movements of the foreign exchange
    rates (for example, EUR/USD) or on its derivative products, while commodity risk
    covers the losses on the movements of commodity prices (for example, gold, crude
    oil, wheat, copper, and so on). Currency risk can also affect the core business
    of a bank if there is a mismatch between the FX exposure in funding and lending.
    FX mismatch can lead to a serious risk in a bank; thus, regulators usually have
    strict limitations on the maximum amount of the so-called open FX positions. This
    results in a mismatch of the FX exposure between the liability and the asset side
    of the bank. This can be tackled by certain hedging deals (such as cross-currency
    swaps, currency futures, forwards, FX options, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Equity risk is the possible loss on stocks, stock indices, or derivative products
    with equity underlying. We saw examples on how to measure the equity risk using
    either the standard deviation or the value at risk. Now, we will show examples
    on how the risk of the equity derivative portfolio can be measured using the already
    mentioned techniques. First, we look at a single call option's value at risk,
    and we then analyze how a portfolio of a call and a put option can be dealt by
    this method.
  prefs: []
  type: TYPE_NORMAL
- en: First, let's assume that all the conditions of the Black-Scholes model consist
    of the market. For more information on the Black-Scholes model and its condition,
    refer to the book of *John. C. Hull [9]*. A stock is currently traded at S = USD
    100, which pays no dividend and follows a geometric Brownian motion with *μ* equal
    to 20 percent (drift) and *σ* equal to 30 percent (volatility) parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'An ATM (at-the-money) call option on this stock matures in two years from now,
    and we would like to determine the 95 percent one year value at risk of this option.
    We know that the stock price follows a lognormal distribution, while the logarithmic
    rate of return follows a normal distribution with the following *m* and *s* parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_14.jpg)![Market risk](img/2078OT_12_15.jpg)![Market
    risk](img/2078OT_12_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, let''s calculate the current price of the derivative given that the Black-Scholes
    conditions exist. Using the Black-Scholes formula, the two-year option is trading
    at USD 25.98:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Note that the price of the call option is a monotone-growing function of the
    spot price of the underlying.
  prefs: []
  type: TYPE_NORMAL
- en: 'This characteristic helps us a lot in solving this problem. What we need is
    a threshold of the option price below which it goes with only a 5-percent probability.
    However, because it is a monotone growing function of *S*, we only need to know
    where this threshold is for the stock price. Given the *m* and *s* parameters,
    we can easily find this value using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, we now know that there is only a 5 percent chance that the stock
    price goes below USD 71.29 in one year (the time period for *m* and *s* parameters
    is one year). If we apply the Black-Scholes formula on this price and with a one
    year less maturity of the option, we get the threshold for the call option price.
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we know that there is a 95 percent likelihood that the option price goes
    above USD 2.90 in one year. So the value that we lose at most with 95 percent
    probability is the difference between the actual option price and the threshold.
    So the call option''s 95 percent VaR for one year is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_21.jpg)![Market risk](img/2078OT_12_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Therefore, the call option on the given stock may only lose more than USD `23.08`
    or `88.82` percent with 5 percent probability in one year.
  prefs: []
  type: TYPE_NORMAL
- en: 'The calculations can be seen below in the following R codes. Note that before
    running the code, we need to install the `fOptions` library using this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot is the result of the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The situation is not that simple if we would like to find the value at risk
    of a certain portfolio of call and put options. Let's use the previous example
    with the stock trading at USD 100\. Now, we add an ATM put option to the portfolio
    besides the ATM call option to form a complex position known as straddle in finance.
    From our point of view, the problem with this portfolio is the non-monotonicity
    of the function of the stock price. As seen in the chart shown in the next image,
    the value of this portfolio as a function of the stock price is a parabola or
    is similar to a V if the option is just before its maturity.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the previous logic of finding the appropriate stock price threshold
    to calculate the option price threshold does not work here. However, we can call
    the Monte-Carlo simulation method to derive the desired value.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s use the so-called put-call parity to gather the put option''s
    value using the call price that has been calculated previously. The put-call parity
    is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_25.jpg)![Market risk](img/2078OT_12_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Here, *c* and *p* is the call and put option prices, both with a strike price
    of *X*, and *S* is the actual stock price *Hull (2002)*. The value of the full
    portfolio is USD 33.82 as a consequence.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we use the simulation to gather 10,000 realizations of a possible portfolio
    value derived from a randomly generated set of input data. We ensure that the
    stock follows a geometric Brownian motion and that the logarithmic rate of return
    follows a normal distribution with the *m* and *s* parameters (15.5 percent and
    30 percent). Applying the generated logarithmic return on the original stock price
    (USD 100), we will reach a simulated stock price for 1 year from now. This can
    be used to recalculate the value of both the call and put options using the Black-Scholes
    formula. Note that here, we replace the original stock price with the simulated
    one, while we also use a one year less maturity for the calculations. As the last
    step, we create 10,000 realizations of the simulated portfolio value (c + p),
    and then find the lower fifth percentile. This will be the threshold below which
    the option portfolio value goes only in 5 percent of the cases. The steps can
    be seen in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command yields the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Market risk](img/2078OT_12_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The desired threshold came out at USD 21.45; thus, the value at risk of the
    portfolio is 33.82 - 21.45 = USD 12.37\. Therefore, the probability that the portfolio
    loses more than 12.37 in one year is only 5 percent.
  prefs: []
  type: TYPE_NORMAL
- en: Interest rate risk arises from the core business, that is, the lending and refinancing
    activity of a bank. However, it also includes the possible losses on bonds or
    fixed income derivatives due to unfavorable changes in interest rates. The interest
    rate risk is the most important market risk for a bank, given the fact that it
    mostly uses short-term funding (client deposits, interbank loans, and so on) to
    refinance long-term assets (such as mortgage loans, government bonds, and so on).
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the value at risk of a position or the whole portfolio can be a
    useful tool to measure the market risk of a bank or financial institution. However,
    several other tools are also available to measure and to cope with the interest
    rate risk for example. Such a tool can be the analysis of the mismatch of the
    interest-sensitivity gap between assets and liabilities. This method was among
    the first techniques in asset liability management to measure and tackle interest-rate
    risk, but it is much less accurate than the modern risk measurement methods. In
    the interest-sensitivity gap analysis, asset and liability elements are classified
    by the average maturity or the timing of interest-rate reset in case the asset
    or liability is a floater. Then, the asset and liability elements are compared
    in each time period class to give a detailed view on the interest-rate sensitivity
    mismatch.
  prefs: []
  type: TYPE_NORMAL
- en: The VaR-based approach is a much more developed and accurate measure for the
    interest rate risk of a bank or financial institution. This method is also based
    on the interest rate sensitivity and is represented by the duration (and convexity)
    of a fixed income portfolio rather than the maturity mismatch of asset and liability
    elements.
  prefs: []
  type: TYPE_NORMAL
- en: Credit risk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The primary risk that a bank faces is the possible default of the borrower,
    where the required payment is failed to be made. Here, the risk is that the lender
    loses the principal, the interest, and all related payments. The loss can be partial
    or complete depending on the collateral and other mitigating factors. The default
    can be a consequence of a number of different circumstances such as payment failure
    from a retail borrower on mortgage, a credit card, or a personal loan; the insolvency
    of a company, bank, or insurance firm; a failed payment on an invoice due; the
    failure of payment by the issuer on debt securities, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expected loss from credit risk can be represented as a multiple of three
    different factors: the PD, LGD, and EAD:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Credit risk](img/2078OT_12_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Probability of default (PD) is the likelihood that the event of failed payment
    happens. This is the key factor of all credit risk models, and there are several
    types of approaches to estimate this value. The loss given default (LGD) is the
    proportion that is lost in percentage of the claimed par value. The **recovery
    rate** (**RR**) is the inverse of LGD and shows the amount that can be collected
    (recovered) even if the borrower defaults. This is affected by the collaterals
    and other mitigating factors used in lending. The exposure at the default (EAD)
    is the claimed value that is exposed to the certain credit risk.
  prefs: []
  type: TYPE_NORMAL
- en: Banks and financial institutions use different methods to measure and handle
    credit risk. In order to reduce it, all the three factors of the multiple can
    be in focus. To keep the exposure under control, banks may use limits and restrictions
    in lending towards certain groups of clients (consumers, companies, and sovereigns).
    Loss given default can be lowered by using collaterals such as mortgage rights
    on properties, securities, and guarantees. Collaterals provide security to the
    lenders and ensure that they get back at least some of their money. Other tools
    are also available to reduce loss given default, such as credit derivatives and
    credit insurance.
  prefs: []
  type: TYPE_NORMAL
- en: A **credit default swap** (**CDS**) is a financial swap agreement that works
    as insurance against the default of a third party. The issuer or seller of the
    CDS agrees to compensate the buyer in an event that the debt holder defaults.
    The buyer pays a periodical fee for the seller set in percentage of the par value
    of the bond or other debt security. The seller pays the par value to the buyer
    and receives the bond in the case of a credit event. If there is no default by
    the debtor, the CDS deal terminates at maturity without any payment from the seller.
  prefs: []
  type: TYPE_NORMAL
- en: '![Credit risk](img/2078OT_12_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The probability of default can be mitigated by due diligence of the business
    partners and the borrowers, using covenants and strict policies. Banks use a broad
    variety of due diligence, ranging from the standardized scoring processes to more
    complex in-depth research on clients. By applying these methods, banks can screen
    out those clients who have too high probability of default and would therefore
    hit the capital position. Credit risk can also be mitigated by risk-based pricing.
    Higher probability of default leads to a higher expected loss on credit risk that
    has to be covered by the interest rate spread applied to the specific client.
    Banks need to tackle this in their normal course of business and only need to
    form capital to the unexpected loss. Therefore, the expected loss on credit risk
    should be a basic part of product pricing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Estimating the probability of default is a very important issue for all banks
    and financial institutions. There are several approaches, of which we examine
    three different ones:'
  prefs: []
  type: TYPE_NORMAL
- en: An implicit probability is derived from the market pricing of risky bonds or
    credit default swaps (for example, the Hull-White method)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Structural models (for example, the KMV model)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current and historic movements of credit ratings (for example, CreditMetrics)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first approach assumes that there are traded products on the market related
    to the instruments as an underlying that have credit risk. It is also assumed
    that the risk is perfectly shown in the market pricing of such instruments. For
    example, if a bond of a risky company is traded on the market, the price of the
    bond will be lower than the price of a risk-free security. If a credit default
    swap is traded on the market on a certain bond, then, it also reflects the market's
    evaluation of the risk on that security. If there is enough liquidity on the market,
    the expected credit risk loss should be equal to the observed price of the risk.
    If we know this price, we can determine the implicit probability of the default
    price.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at a short example. Let's assume that a 1 year maturity zero-coupon
    bond with a par value of USD 1,000 issued by a BBB-rated corporation trades at
    a YTM (yield-to-maturity) of 5 percent. An AAA-rated government T-Bill with similar
    characteristics but without credit risk trades at 3 percent. We know that if the
    corporate bond defaults, 30 percent of the par value will be recovered. What is
    the probability of the bond defaulting if the market prices properly?
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to calculate the current market price of both the corporate and
    the government bond. The corporate bond should trade at ![Credit risk](img/2078OT_12_29.jpg).
    Similarly, the government bond should trade at ![Credit risk](img/2078OT_12_30.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: The price difference between the two bonds is USD 18.5\. The expected credit
    loss is PD∙LGD∙EAD in one year. If we wanted to take a hedge against the credit
    loss through insurance or CDS, the present value of this amount would be the maximum
    that we would pay. As a consequence, the price difference of the two bonds should
    equal to the present value of the expected credit loss. The LGD is 70 percent
    as 30 percent of the par value is recovered in the case of a default.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, ![Credit risk](img/2078OT_12_31.jpg) or ![Credit risk](img/2078OT_12_32.jpg).
  prefs: []
  type: TYPE_NORMAL
- en: So the implicit probability of default is 2.72 percent during the next year,
    if the market prices are proper. This method can also be used if there is a credit
    derivative traded on the market related to the specific bond.
  prefs: []
  type: TYPE_NORMAL
- en: Structural methods create a mathematical model based on the characteristics
    of the financial instrument that is exposed to the credit risk. A common example
    is the KMV model created by the joint company founded by three mathematicians,
    Stephen Kealhofer, John McQuown, and Oldřich Vašíček. Currently, this company
    runs under the name of Moody's Analytics after having been acquired by Moody's
    rating agency in 2002.
  prefs: []
  type: TYPE_NORMAL
- en: The KMV model is based on Merton's credit model (1974), which regards both the
    debt and equity securities of a corporation with credit risk as derivatives similar
    to options. The basic idea is that if a company is solvent, then the market value
    of its assets (or enterprise value) should exceed the par value of the debts it
    holds. Therefore, just before the maturity of the corporate bonds, they estimate
    their par value and the value of the equity (market capitalization of a public
    company). However, if the value of assets misses the par value of debt at maturity,
    the owners might decide to raise the capital or go bankrupt. If the latter is
    the case, the market value of corporate bonds will equal the asset value, and
    the equity holders will get nothing during liquidation.
  prefs: []
  type: TYPE_NORMAL
- en: The choice between the bankruptcy and capital raising is called the bankruptcy
    option, which has the characteristics of a put option. This exists because the
    equity holders have no more responsibility on the company than the value they
    invested (the share price cannot go to negative). More specifically, the value
    of the corporate bond is the combination of a bond without credit risk and a bankruptcy
    option, which is a short put option from the point of view of the bondholder (long
    bond + short put).
  prefs: []
  type: TYPE_NORMAL
- en: 'The equity of the company can be treated as a call option (long call). The
    asset value of the company is the sum of all the equations, as shown in this formula:
    ![Credit risk](img/2078OT_12_33.jpg), where *D* is the par value of the corporate
    debt, *V* is the asset value, *c* is the market value of the equity (the call
    option in this regard), and *p* is the value of the bankruptcy option.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Credit risk](img/2078OT_12_34.jpg)'
  prefs: []
  type: TYPE_IMG
- en: The KMV model
  prefs: []
  type: TYPE_NORMAL
- en: In practice, the volatility of both the asset value and the equity is necessary
    to calculate the actual value of the risky corporate bond. A public company's
    equity volatility can easily be estimated from stock price movements, but the
    asset volatility is not available as real economy goods are usually not traded
    publicly. The market value of assets is also a tricky one due to the same reason.
    Therefore, the KMV has two equations and two unknown variables. The two equations
    are the conditions of the Black-Scholes theory ![Credit risk](img/2078OT_12_35.jpg),
    which is based on the Black-Scholes equation, and ![Credit risk](img/2078OT_12_36.jpg),
    which is based on Itō's lemma, where *E* and *V* are the market values of equity
    and assets, *D* is the par value of the bond, *σ[E]* and *σ[V]* are the volatilities
    of the equity and the assets. The ![Credit risk](img/2078OT_12_37.jpg) is the
    derivative of *E* with respect to *V*, and it equals to *N(d[1])*, based on the
    Black-Scholes theory. The two unknown variables are *V* and *σ[V]*.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's take a look at an example where the market value of a company's equity
    (market capitalization) is USD 3 billion with 80 percent volatility. The company
    has a single series of zero-coupon bonds with a par value of USD 10 billion, which
    matures exactly in one year. The risk-free logarithmic rate of return is 5 percent
    for one year.
  prefs: []
  type: TYPE_NORMAL
- en: 'The solution of the preceding equation in R can be seen as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The value of the aggregate of the corporate bonds is USD 9.40 billion with a
    logarithmic of yield to maturity at 6.44 percent, and the value of the assets
    are USD 12.40 billion with 21.2 percent volatility.
  prefs: []
  type: TYPE_NORMAL
- en: The third way of estimating the probability of default is the rating-based approach.
    This method of estimation starts from the credit rating of different financial
    instruments or economic entities (companies, sovereigns, and institutions). CreditMetrics
    analytics was originally developed by JP Morgan's risk management division in
    1997\. Since then, it has evolved further, and now, it is widely used among other
    risk management tools. The basic idea of CreditMetrics is to estimate probabilities
    on how the credit rating of an entity can change over time and what effect it
    can have on the value of the securities issued by the same entity. It starts with
    the analysis of the rating history and then creates a so-called transition matrix
    that contains the probabilities of how the credit rating might develop. For further
    information on CreditMetrics, see the technical book published by MSCI (*Committee
    on Banking Regulations and Supervisory Practices (1987)*).
  prefs: []
  type: TYPE_NORMAL
- en: Operational risk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The third major risk category is the operational risk. This refers to all the
    possible losses that can arise during the operation of a bank, financial institution,
    or another company. It includes losses from natural disasters, internal or external
    fraud (for example, bank robbery), system faults or failures, and inadequate working
    processes. These risks can be categorized into four different groups seen below:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Low impact with low probability**: If the risk as well as its potential impact
    on the operation is low, then it is not worth the effort to handle it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low impact with high probability**: If a risk event happens too often, it
    means that some processes of the company should be restructured, or it should
    be included in the pricing of a certain operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High impact with low probability**: If the probability of a high-impact event
    is low, the most suitable method to mitigate the risk is to take insurance on
    such events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High impact with high probability**: If both the impact and the probability
    of such a risk are high, then it''s better to shut down that operation. Here,
    neither the restructuring nor the insurance works.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This part of the risk management belongs rather to the actuarial sciences than
    financial analysis. However, the tools provided by R are also capable of handling
    such problems as well. Let''s take an example of the possible operational losses
    on the failures of an IT system. The number of failures follow a Poisson distribution
    with λ = 20 parameter, while the magnitude of each loss follows a lognormal distribution
    with *m* equal to 5 and *s* equal to 2 parameters. The average number of failures
    in a year is 20 based on the Poisson distribution, while the expected value of
    the magnitude of a loss is: ![Operational risk](img/2078OT_12_38.jpg).'
  prefs: []
  type: TYPE_NORMAL
- en: However, we need to determine the joint distribution, the expected value, and
    the quantile of 99.9 percent of the aggregate annual loss. The latter will be
    used to determine the necessary capital set by the advanced measurement approach
    (AMA) of Basel II. We use a 10,000 element Monte-Carlo simulation. The first step
    is to generate a discrete random variable that follows a Poisson distribution.
    Then, we generate independent variables with lognormal distribution in the number
    of the previously generated integers, and we aggregate them. We can create the
    distribution of the aggregated losses by repeating this process 10,000 times.
    The expected value of the aggregate losses is USD 21,694, and the quantile of
    99.9 percent is USD 382,247.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we will only lose more than USD 382 thousand in a year by the failure
    of the IT system in 0.1 percent of the cases. The calculations can be seen in
    R here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the screenshot of the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Operational risk](img/2078OT_12_39.jpg)'
  prefs: []
  type: TYPE_IMG
- en: We see the distribution of the aggregated losses in the chart shown in the preceding
    figure, which is similar to a lognormal distribution but is not necessarily lognormal.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the basic principles of the Basel Accords, the capital
    adequacy requirements in banking regulation, the risk measures and different risk
    types, and most importantly, the powerful tools of R used in risk management.
  prefs: []
  type: TYPE_NORMAL
- en: We saw that the Basel Accords are a world wide harmonized banking regulatory
    framework, and we learned the ongoing development and more sophisticated approaches
    of the financial regulations. Furthermore, we provided insights on risk measures,
    starting from the most simple standard deviation of returns to the more sophisticated
    ones, most importantly, Value at Risk (VaR). However, we saw that VaR is not necessarily
    a coherent risk measure, but it is still one of the most widely used figures in
    both regulation and risk management.
  prefs: []
  type: TYPE_NORMAL
- en: We went through the main risk types a bank or financial institution faces, that
    is, the credit risk, the market risk, and the operational risk. You can see how
    the different risk management approaches can be used to calculate the possible
    losses of the different risk types and the related capital adequacy. Finally,
    we presented several examples to show how R can be used to easily solve complex
    problems in risk management.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] History of the Basel Committee'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] Basel Committee on Banking Supervision (Charter)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] Committee on Banking Regulations and Supervisory Practices (1987): Proposals
    for international convergence of capital measurement and capital standards; Consultative
    paper; December 1987'
  prefs: []
  type: TYPE_NORMAL
- en: '[4] Basel Committee on Banking Supervisions (1999): A New Capital Adequacy
    Framework; Consultative paper; June 1999'
  prefs: []
  type: TYPE_NORMAL
- en: '[5] Artzner, P.; Delbaen, F.; Eber, J. M.; Heath, D. (1999). *Coherent Measures
    of Risk*. Mathematical Finance, 9 (3 ed.): p. 203'
  prefs: []
  type: TYPE_NORMAL
- en: '[6] Wilmott, P. (2006). *Quantitative Finance 1* (2 ed.): p. 342'
  prefs: []
  type: TYPE_NORMAL
- en: '[7] Acerbi, C.; Tasche, D. (2002). *Expected Shortfall: a natural coherent
    alternative to Value at Risk*. Economic Notes 31: p. 379–388'
  prefs: []
  type: TYPE_NORMAL
- en: '[8] Basel II Comprehensive Version'
  prefs: []
  type: TYPE_NORMAL
- en: '[9] Hull, J. C. (2002). *Options, Futures and Other Derivatives* (5th ed.)'
  prefs: []
  type: TYPE_NORMAL
- en: '[10] *Principles for the Management of Credit Risk - final document*. Basel
    Committee on Banking Supervision. BIS. (2000)'
  prefs: []
  type: TYPE_NORMAL
- en: '[11] Crosbie, P., Bohn, J. (2003): *Modeling default risk. Technical Report,
    Moody''s KMV*'
  prefs: []
  type: TYPE_NORMAL
- en: '[12] Crouhy, M., Galai, D., Mark, R. (2000): *A comparative analysis of current
    credit risk models*. Journal of Banking & Finance, 24:59–117'
  prefs: []
  type: TYPE_NORMAL
- en: '[13] MSCI CreditMetrics Technical Book'
  prefs: []
  type: TYPE_NORMAL
