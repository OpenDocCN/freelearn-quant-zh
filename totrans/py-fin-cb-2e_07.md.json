["```py\n    import pandas as pd\n    import numpy as np\n    from sklearn.model_selection import TimeSeriesSplit, cross_validate\n    from sklearn.linear_model import LinearRegression\n    from sklearn.metrics import mean_absolute_percentage_error\n    import nasdaqdatalink\n    nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\" \n    ```", "```py\n    df = (\n        nasdaqdatalink.get(dataset=\"FRED/UNRATENSA\",\n                           start_date=\"2010-01-01\",\n                           end_date=\"2019-12-31\")\n        .rename(columns={\"Value\": \"unemp_rate\"})\n    )\n    df.plot(title=\"Unemployment rate (US) - monthly\") \n    ```", "```py\n    df[\"linear_trend\"] = range(len(df))\n    df[\"month\"] = df.index.month \n    ```", "```py\n    month_dummies = pd.get_dummies(\n        df[\"month\"], drop_first=True, prefix=\"month\"\n    )\n    df = df.join(month_dummies) \\\n           .drop(columns=[\"month\"]) \n    ```", "```py\n    X = df.copy()\n    y = X.pop(\"unemp_rate\") \n    ```", "```py\n    expanding_cv = TimeSeriesSplit(n_splits=5, test_size=12)\n\n    for fold, (train_ind, valid_ind) in enumerate(expanding_cv.split(X)):\n        print(f\"Fold {fold} ----\")\n        print(f\"Train indices: {train_ind}\")\n        print(f\"Valid indices: {valid_ind}\") \n    ```", "```py\n    Fold 0 ----\n    Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 \n                    12 13 14 15 16 17 18 19 20 21 22 23 \n                    24 25 26 27 28 29 30 31 32 33 34 35 \n                    36 37 38 39 40 41 42 43 44 45 46 47 \n                    48 49 50 51 52 53 54 55 56 57 58 59]\n    Valid indices: [60 61 62 63 64 65 66 67 68 69 70 71]\n    Fold 1 ----\n    Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 \n                    12 13 14 15 16 17 18 19 20 21 22 23\n                    24 25 26 27 28 29 30 31 32 33 34 35 \n                    36 37 38 39 40 41 42 43 44 45 46 47\n                    48 49 50 51 52 53 54 55 56 57 58 59 \n                    60 61 62 63 64 65 66 67 68 69 70 71]\n    Valid indices: [72 73 74 75 76 77 78 79 80 81 82 83]\n    Fold 2 ----\n    Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 \n                    12 13 14 15 16 17 18 19 20 21 22 23\n                    24 25 26 27 28 29 30 31 32 33 34 35 \n                    36 37 38 39 40 41 42 43 44 45 46 47\n                    48 49 50 51 52 53 54 55 56 57 58 59 \n                    60 61 62 63 64 65 66 67 68 69 70 71\n                    72 73 74 75 76 77 78 79 80 81 82 83]\n    Valid indices: [84 85 86 87 88 89 90 91 92 93 94 95]\n    Fold 3 ----\n    Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 \n                    12 13 14 15 16 17 18 19 20 21 22 23\n                    24 25 26 27 28 29 30 31 32 33 34 35 \n                    36 37 38 39 40 41 42 43 44 45 46 47\n                    48 49 50 51 52 53 54 55 56 57 58 59 \n                    60 61 62 63 64 65 66 67 68 69 70 71\n                    72 73 74 75 76 77 78 79 80 81 82 83 \n                    84 85 86 87 88 89 90 91 92 93 94 95]\n    Valid indices: [96 97 98 99 100 101 102 103 104 105 106 107]\n    Fold 4 ----\n    Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11  \n                    12 13 14 15 16 17 18 19 20 21 22 23\n                    24 25 26 27 28 29 30 31 32 33 34 35\n                    36 37 38 39 40 41 42 43 44 45 46 47  \n                    48 49 50 51 52 53 54 55 56 57 58 59  \n                    60 61 62 63 64 65 66 67 68 69 70 71\n                    72 73 74 75 76 77 78 79 80 81 82 83  \n                    84 85 86 87 88 89 90 91 92 93 94 95  \n                    96 97 98 99 100 101 102 103 104 105 106 107]\n    Valid indices: [108 109 110 111 112 113 114 115 116 117 118 119] \n    ```", "```py\n    scores = []\n    for train_ind, valid_ind in expanding_cv.split(X):\n        lr = LinearRegression()\n        lr.fit(X.iloc[train_ind], y.iloc[train_ind])\n        y_pred = lr.predict(X.iloc[valid_ind])\n        scores.append(\n            mean_absolute_percentage_error(y.iloc[valid_ind], y_pred)\n        )\n    print(f\"Scores: {scores}\")\n    print(f\"Avg. score: {np.mean(scores)}\") \n    ```", "```py\n    Scores: [0.03705079312389441, 0.07828415627306308, 0.11981060282173006, 0.16829494012910876, 0.25460459651634165]\n    Avg. score: 0.1316090177728276 \n    ```", "```py\n    cv_scores = cross_validate(\n        LinearRegression(),\n        X, y,\n        cv=expanding_cv,\n        scoring=[\"neg_mean_absolute_percentage_error\",\n                 \"neg_root_mean_squared_error\"]\n    )\n    pd.DataFrame(cv_scores) \n    ```", "```py\n    sliding_cv = TimeSeriesSplit(\n        n_splits=5, test_size=12, max_train_size=60\n    )\n\n    for fold, (train_ind, valid_ind) in enumerate(sliding_cv.split(X)):\n        print(f\"Fold {fold} ----\")\n        print(f\"Train indices: {train_ind}\")\n        print(f\"Valid indices: {valid_ind}\") \n    ```", "```py\n    Fold 0 ----\n    Train indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 \n                    12 13 14 15 16 17 18 19 20 21 22 23\n                    24 25 26 27 28 29 30 31 32 33 34 35 \n                    36 37 38 39 40 41 42 43 44 45 46 47\n                    48 49 50 51 52 53 54 55 56 57 58 59]\n    Valid indices: [60 61 62 63 64 65 66 67 68 69 70 71]\n    Fold 1 ----\n    Train indices: [12 13 14 15 16 17 18 19 20 21 22 23 \n                    24 25 26 27 28 29 30 31 32 33 34 35\n                    36 37 38 39 40 41 42 43 44 45 46 47 \n                    48 49 50 51 52 53 54 55 56 57 58 59\n                    60 61 62 63 64 65 66 67 68 69 70 71]\n    Valid indices: [72 73 74 75 76 77 78 79 80 81 82 83]\n    Fold 2 ----\n    Train indices: [24 25 26 27 28 29 30 31 32 33 34 35 \n                    36 37 38 39 40 41 42 43 44 45 46 47\n                    48 49 50 51 52 53 54 55 56 57 58 59 \n                    60 61 62 63 64 65 66 67 68 69 70 71\n                    72 73 74 75 76 77 78 79 80 81 82 83]\n    Valid indices: [84 85 86 87 88 89 90 91 92 93 94 95]\n    Fold 3 ----\n    Train indices: [36 37 38 39 40 41 42 43 44 45 46 47 \n                    48 49 50 51 52 53 54 55 56 57 58 59\n                    60 61 62 63 64 65 66 67 68 69 70 71 \n                    72 73 74 75 76 77 78 79 80 81 82 83\n                    84 85 86 87 88 89 90 91 92 93 94 95]\n    Valid indices: [96 97 98 99 100 101 102 103 104 105 106 107]\n    Fold 4 ----\n    Train indices: [48 49 50 51 52 53 54 55 56 57 58 59 \n                    60 61 62 63 64 65 66 67 68 69 70 71 \n                    72 73 74 75 76 77 78 79 80 81 82 83\n                    84 85 86 87 88 89 90 91 92 93 94 95 \n                    96 97 98 99 100 101 102 103 104 105 106 107]\n    Valid indices: [108 109 110 111 112 113 114 115 116 117 118 119] \n    ```", "```py\n    cv_scores = cross_validate(\n        LinearRegression(),\n        X, y,\n        cv=sliding_cv,\n        scoring=[\"neg_mean_absolute_percentage_error\",\n                 \"neg_root_mean_squared_error\"]\n    )\n    pd.DataFrame(cv_scores) \n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    from datetime import date\n    from sklearn.linear_model import LinearRegression\n    from sklearn.preprocessing import FunctionTransformer\n    from sklego.preprocessing import RepeatingBasisFunction \n    ```", "```py\n    np.random.seed(42)\n    range_of_dates = pd.date_range(start=\"2017-01-01\",\n                                   end=\"2019-12-31\")\n    X = pd.DataFrame(index=range_of_dates)\n    X[\"day_nr\"] = range(len(X))\n    X[\"day_of_year\"] = X.index.day_of_year\n    signal_1 = 2 + 3 * np.sin(X[\"day_nr\"] / 365 * 2 * np.pi)\n    signal_2 = 2 * np.sin(X[\"day_nr\"] / 365 * 4 * np.pi + 365/2)\n    noise = np.random.normal(0, 0.81, len(X))\n    y = signal_1 + signal_2 + noise\n    y.name = \"y\"\n    y.plot(title=\"Generated time series\") \n    ```", "```py\n    results_df = y.to_frame()\n    results_df.columns = [\"y_true\"] \n    ```", "```py\n    X_1 = pd.get_dummies(\n        X.index.month, drop_first=True, prefix=\"month\"\n    )\n    X_1.index = X.index\n    X_1 \n    ```", "```py\n    model_1 = LinearRegression().fit(X_1, y)\n    results_df[\"y_pred_1\"] = model_1.predict(X_1)\n    (\n        results_df[[\"y_true\", \"y_pred_1\"]]\n        .plot(title=\"Fit using month dummies\")\n    ) \n    ```", "```py\n    def sin_transformer(period):\n        return FunctionTransformer(lambda x: np.sin(x / period * 2 * np.pi))\n    def cos_transformer(period):\n        return FunctionTransformer(lambda x: np.cos(x / period * 2 * np.pi)) \n    ```", "```py\n    X_2 = X.copy()\n    X_2[\"month\"] = X_2.index.month\n    X_2[\"month_sin\"] = sin_transformer(12).fit_transform(X_2)[\"month\"]\n    X_2[\"month_cos\"] = cos_transformer(12).fit_transform(X_2)[\"month\"]\n    X_2[\"day_sin\"] = (\n        sin_transformer(365).fit_transform(X_2)[\"day_of_year\"]\n    )\n    X_2[\"day_cos\"] = (\n        cos_transformer(365).fit_transform(X_2)[\"day_of_year\"]\n    )\n    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(16,8))\n    X_2[[\"month_sin\", \"month_cos\"]].plot(ax=ax[0])\n    ax[0].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n    X_2[[\"day_sin\", \"day_cos\"]].plot(ax=ax[1])\n    ax[1].legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n    plt.suptitle(\"Cyclical encoding with sine/cosine transformation\") \n    ```", "```py\n    (\n        X_2[X_2.index.year == 2017]\n        .plot(\n            kind=\"scatter\",\n            x=\"month_sin\",\n            y=\"month_cos\",\n            figsize=(8, 8),\n            title=\"Cyclical encoding using sine/cosine transformations\"\n      )\n    ) \n    ```", "```py\n    X_2 = X_2[[\"day_sin\", \"day_cos\"]]\n    model_2 = LinearRegression().fit(X_2, y)\n    results_df[\"y_pred_2\"] = model_2.predict(X_2)\n    (\n        results_df[[\"y_true\", \"y_pred_2\"]]\n        .plot(title=\"Fit using sine/cosine features\")\n    ) \n    ```", "```py\n    rbf = RepeatingBasisFunction(n_periods=12,\n                                 column=\"day_of_year\",\n                                 input_range=(1,365),\n                                 remainder=\"drop\")\n    rbf.fit(X)\n    X_3 = pd.DataFrame(index=X.index,\n                       data=rbf.transform(X))\n    X_3.plot(subplots=True, sharex=True,\n             title=\"Radial Basis Functions\",\n             legend=False, figsize=(14, 10)) \n    ```", "```py\n    model_3 = LinearRegression().fit(X_3, y)\n    results_df[\"y_pred_3\"] = model_3.predict(X_3)\n    (\n        results_df[[\"y_true\", \"y_pred_3\"]]\n        .plot(title=\"Fit using RBF features\")\n    ) \n    ```", "```py\n    from sktime.transformations.series.date import DateTimeFeatures\n    from tsfresh import extract_features\n    from tsfresh.feature_extraction import settings\n    from tsfresh.utilities.dataframe_functions import roll_time_series \n    ```", "```py\n    dt_features = DateTimeFeatures(\n        ts_freq=\"D\", feature_scope=\"comprehensive\"\n    )\n    features_df_1 = dt_features.fit_transform(y)\n    features_df_1.head() \n    ```", "```py\n    df = y.to_frame().reset_index(drop=False)\n    df.columns = [\"date\", \"y\"]\n    df[\"series_id\"] = \"a\" \n    ```", "```py\n    df_rolled = roll_time_series(\n        df, column_id=\"series_id\", column_sort=\"date\",\n        max_timeshift=30, min_timeshift=7\n    ).drop(columns=[\"series_id\"])\n    df_rolled \n    ```", "```py\n    settings_minimal = settings.MinimalFCParameters()\n    settings_minimal \n    ```", "```py\n    {'sum_values': None,\n     'median': None,\n     'mean': None,\n     'length': None,\n     'standard_deviation': None,\n     'variance': None,\n     'maximum': None,\n     'minimum': None} \n    ```", "```py\n    features_df_2 = extract_features(\n        df_rolled, column_id=\"id\",\n        column_sort=\"date\",\n        default_fc_parameters=settings_minimal\n    ) \n    ```", "```py\n    features_df_2 = (\n        features_df_2\n        .set_index(\n            features_df_2.index.map(lambda x: x[1]), drop=True\n        )\n    )\n    features_df_2.index.name = \"last_date\"\n    features_df_2.head(25) \n    ```", "```py\n    from sktime.utils.plotting import plot_series\n    from sktime.forecasting.model_selection import (\n        temporal_train_test_split, ExpandingWindowSplitter\n    )\n    from sktime.forecasting.base import ForecastingHorizon\n    from sktime.forecasting.compose import (\n        make_reduction, TransformedTargetForecaster, EnsembleForecaster\n    )\n    from sktime.performance_metrics.forecasting import (\n        mean_absolute_percentage_error\n    )\n    from sktime.transformations.series.detrend import (\n        Deseasonalizer, Detrender\n    )\n    from sktime.forecasting.trend import PolynomialTrendForecaster\n    from sktime.forecasting.model_evaluation import evaluate\n    from sktime.forecasting.arima import AutoARIMA\n    from sklearn.ensemble import RandomForestRegressor \n    ```", "```py\n    y_train, y_test = temporal_train_test_split(\n        y, test_size=12\n    )\n    plot_series(\n        y_train, y_test,\n        labels=[\"y_train\", \"y_test\"]\n    ) \n    ```", "```py\n    fh = ForecastingHorizon(y_test.index, is_relative=False)\n    fh \n    ```", "```py\n    ForecastingHorizon(['2019-01', '2019-02', '2019-03', '2019-04', '2019-05', '2019-06', '2019-07', '2019-08', '2019-09', '2019-10', '2019-11', '2019-12'], dtype='period[M]', is_relative=False) \n    ```", "```py\n    regressor = RandomForestRegressor(random_state=42)\n    rf_forecaster = make_reduction(\n        estimator=regressor,\n        strategy=\"recursive\",\n        window_length=12\n    )\n    rf_forecaster.fit(y_train)\n    y_pred_1 = rf_forecaster.predict(fh) \n    ```", "```py\n    mape_1 = mean_absolute_percentage_error(\n        y_test, y_pred_1, symmetric=False\n    )\n    fig, ax = plot_series(\n        y_train[\"2016\":], y_test, y_pred_1,\n        labels=[\"y_train\", \"y_test\", \"y_pred\"]\n    )\n    ax.set_title(f\"MAPE: {100*mape_1:.2f}%\") \n    ```", "```py\n    deseasonalizer = Deseasonalizer(model=\"additive\", sp=12)\n    y_deseas = deseasonalizer.fit_transform(y_train)\n    plot_series(\n        y_train, y_deseas,\n        labels=[\"y_train\", \"y_deseas\"]\n    ) \n    ```", "```py\n    plot_series(\n        deseasonalizer.seasonal_,\n        labels=[\"seasonal_component\"]\n    ) \n    ```", "```py\n    forecaster = PolynomialTrendForecaster(degree=1)\n    transformer = Detrender(forecaster=forecaster)\n    y_detrend = transformer.fit_transform(y_deseas)\n    # in-sample predictions\n    forecaster = PolynomialTrendForecaster(degree=1)\n    y_in_sample = (\n        forecaster\n        .fit(y_deseas)\n        .predict(fh=-np.arange(len(y_deseas)))\n    )\n    plot_series(\n        y_deseas, y_in_sample, y_detrend,\n        labels=[\"y_deseas\", \"linear trend\", \"resids\"]\n    ) \n    ```", "```py\n    rf_pipe = TransformedTargetForecaster(\n        steps = [\n            (\"deseasonalize\", Deseasonalizer(model=\"additive\", sp=12)),\n            (\"detrend\", Detrender(\n                forecaster=PolynomialTrendForecaster(degree=1)\n            )),\n            (\"forecast\", rf_forecaster),\n        ]\n    )\n    rf_pipe.fit(y_train)\n    y_pred_2 = rf_pipe.predict(fh) \n    ```", "```py\n    mape_2 = mean_absolute_percentage_error(\n        y_test, y_pred_2, symmetric=False\n    )\n    fig, ax = plot_series(\n        y_train[\"2016\":], y_test, y_pred_2,\n        labels=[\"y_train\", \"y_test\", \"y_pred\"]\n    )\n    ax.set_title(f\"MAPE: {100*mape_2:.2f}%\") \n    ```", "```py\n    cv = ExpandingWindowSplitter(\n        fh=list(range(1,13)),\n        initial_window=12*5,\n        step_length=12\n    )\n    cv_df = evaluate(\n        forecaster=rf_pipe,\n        y=y,\n        cv=cv,\n        strategy=\"refit\",\n        return_data=True\n    )\n    cv_df \n    ```", "```py\n    for ind, row in cv_df.iterrows():\n        print(f\"Fold {ind} ----\")\n        print(f\"Training: {row['y_train'].index.min()} - {row['y_train'].index.max()}\")\n        print(f\"Training: {row['y_test'].index.min()} - {row['y_test'].index.max()}\") \n    ```", "```py\n    Fold 0 ----\n    Training: 2010-01 - 2014-12\n    Training: 2015-01 - 2015-12\n    Fold 1 ----\n    Training: 2010-01 - 2015-12\n    Training: 2016-01 - 2016-12\n    Fold 2 ----\n    Training: 2010-01 - 2016-12\n    Training: 2017-01 - 2017-12\n    Fold 3 ----\n    Training: 2010-01 - 2017-12\n    Training: 2018-01 - 2018-12\n    Fold 4 ----\n    Training: 2010-01 - 2018-12\n    Training: 2019-01 - 2019-12 \n    ```", "```py\n    n_fold = len(cv_df)\n    plot_series(\n        y,\n        *[cv_df[\"y_pred\"].iloc[x] for x in range(n_fold)],\n        markers=[\"o\", *[\".\"] * n_fold],\n        labels=[\"y_true\"] + [f\"cv: {x}\" for x in range(n_fold)]\n    ) \n    ```", "```py\n    ensemble = EnsembleForecaster(\n        forecasters = [\n            (\"autoarima\", AutoARIMA(sp=12)),\n            (\"rf_pipe\", rf_pipe)\n        ]\n    )\n    ensemble.fit(y_train)\n    y_pred_3 = ensemble.predict(fh) \n    ```", "```py\n    mape_3 = mean_absolute_percentage_error(\n        y_test, y_pred_3, symmetric=False\n    )\n    fig, ax = plot_series(\n        y_train[\"2016\":], y_test, y_pred_3,\n        labels=[\"y_train\", \"y_test\", \"y_pred\"]\n    )\n    ax.set_title(f\"MAPE: {100*mape_3:.2f}%\") \n    ```", "```py\n    import pandas as pd\n    import nasdaqdatalink\n    from prophet import Prophet\n    from prophet.plot import add_changepoints_to_plot\n    nasdaqdatalink.ApiConfig.api_key = \"YOUR_KEY_HERE\" \n    ```", "```py\n    df = nasdaqdatalink.get(\n        dataset=\"WGC/GOLD_DAILY_USD\",\n        start_date=\"2015-01-01\",\n        end_date=\"2019-12-31\"\n    )\n    df.plot(title=\"Daily gold prices (2015-2019)\") \n    ```", "```py\n    df = df.reset_index(drop=False)\n    df.columns = [\"ds\", \"y\"] \n    ```", "```py\n    train_indices = df[\"ds\"] < \"2019-10-01\"\n    df_train = df.loc[train_indices].dropna()\n    df_test = (\n        df\n        .loc[~train_indices]\n        .reset_index(drop=True)\n    ) \n    ```", "```py\n    prophet = Prophet(changepoint_range=0.9)\n    prophet.add_country_holidays(country_name=\"US\")\n    prophet.add_seasonality(\n        name=\"monthly\", period=30.5, fourier_order=5\n    )\n    prophet.fit(df_train) \n    ```", "```py\n    df_future = prophet.make_future_dataframe(\n        periods=len(df_test), freq=\"B\"\n    )\n    df_pred = prophet.predict(df_future)\n    prophet.plot(df_pred) \n    ```", "```py\n    df_pred.columns \n    ```", "```py\n    ['ds', 'trend', 'yhat_lower', 'yhat_upper', 'trend_lower', \n    'trend_upper', 'Christmas Day', 'Christmas Day_lower', \n    'Christmas Day_upper', 'Christmas Day (Observed)', \n    'Christmas Day (Observed)_lower', 'Christmas Day (Observed)_upper', \n    'Columbus Day', 'Columbus Day_lower', 'Columbus Day_upper', \n    'Independence Day', 'Independence Day_lower', \n    'Independence Day_upper', 'Independence Day (Observed)',\n    'Independence Day (Observed)_lower', \n    'Independence Day (Observed)_upper', 'Labor Day', 'Labor Day_lower',\n    'Labor Day_upper', 'Martin Luther King Jr. Day',\n    'Martin Luther King Jr. Day_lower', \n    'Martin Luther King Jr. Day_upper',\n    'Memorial Day', 'Memorial Day_lower', 'Memorial Day_upper',\n    'New Year's Day', 'New Year's Day_lower', 'New Year's Day_upper',\n    'New Year's Day (Observed)', 'New Year's Day (Observed)_lower',\n    'New Year's Day (Observed)_upper', 'Thanksgiving', \n    'Thanksgiving_lower', 'Thanksgiving_upper', 'Veterans Day',\n    'Veterans Day_lower', 'Veterans Day_upper', \n    'Veterans Day (Observed)', 'Veterans Day (Observed)_lower',\n    'Veterans Day (Observed)_upper', 'Washington's Birthday',\n    'Washington's Birthday_lower', 'Washington's Birthday_upper',\n    'additive_terms', 'additive_terms_lower', 'additive_terms_upper',\n    'holidays', 'holidays_lower', 'holidays_upper', 'monthly',\n    'monthly_lower', 'monthly_upper', 'weekly', 'weekly_lower',\n    'weekly_upper', 'yearly', 'yearly_lower', 'yearly_upper',\n    'multiplicative_terms', 'multiplicative_terms_lower',\n    'multiplicative_terms_upper', 'yhat'] \n    ```", "```py\n    fig = prophet.plot(df_pred)\n    a = add_changepoints_to_plot(\n        fig.gca(), prophet, df_pred\n    ) \n    ```", "```py\n    prophet.plot_components(df_pred) \n    ```", "```py\n    SELECTED_COLS = [\n        \"ds\", \"yhat\", \"yhat_lower\", \"yhat_upper\"\n    ]\n    df_pred = (\n        df_pred\n        .loc[:, SELECTED_COLS]\n        .reset_index(drop=True)\n    )\n    df_test = df_test.merge(df_pred, on=[\"ds\"], how=\"left\")\n    df_test[\"ds\"] = pd.to_datetime(df_test[\"ds\"])\n    df_test = df_test.set_index(\"ds\") \n    ```", "```py\n    fig, ax = plt.subplots(1, 1)\n    PLOT_COLS = [\n        \"y\", \"yhat\", \"yhat_lower\", \"yhat_upper\"\n    ]\n    ax = sns.lineplot(data=df_test[PLOT_COLS])\n    ax.fill_between(\n        df_test.index,\n        df_test[\"yhat_lower\"],\n        df_test[\"yhat_upper\"],\n        alpha=0.3\n    )\n    ax.set(\n        title=\"Gold Price - actual vs. predicted\",\n        xlabel=\"Date\",\n        ylabel=\"Gold Price ($)\"\n    ) \n    ```", "```py\n    from prophet.diagnostics import (cross_validation, \n                                     performance_metrics)\n    from prophet.plot import plot_cross_validation_metric \n    ```", "```py\n    df_cv = cross_validation(\n        prophet,\n        initial=\"756 days\",\n        period=\"60 days\",\n        horizon = \"60 days\"\n    )\n    df_cv \n    ```", "```py\n    Making 16 forecasts with cutoffs between 2017-02-12 00:00:00 and 2019-08-01 00:00:00 \n    ```", "```py\n    df_p = performance_metrics(df_cv)\n    df_p \n    ```", "```py\n    plot_cross_validation_metric(df_cv, metric=\"mape\") \n    ```", "```py\n    from pycaret.datasets import get_data\n    from pycaret.time_series import TSForecastingExperiment \n    ```", "```py\n    exp = TSForecastingExperiment()\n    exp.setup(df, fh=6, fold=5, session_id=42) \n    ```", "```py\n    exp.plot_model(\n        plot=\"diagnostics\",\n        fig_kwargs={\"height\": 800, \"width\": 1000}\n    ) \n    ```", "```py\n    exp.plot_model(plot=\"cv\") \n    ```", "```py\n    exp.check_stats() \n    ```", "```py\n    exp.check_stats(test=\"summary\") \n    ```", "```py\n    best_pipelines = exp.compare_models(\n        sort=\"MAPE\", turbo=False, n_select=5\n    ) \n    ```", "```py\n    [BATS(show_warnings=False, sp=12, use_box_cox=True),\n     TBATS(show_warnings=False, sp=[12], use_box_cox=True),\n     AutoARIMA(random_state=42, sp=12, suppress_warnings=True),\n     ProphetPeriodPatched(), \n    ThetaForecaster(sp=12)] \n    ```", "```py\n    best_pipelines_tuned = [\n        exp.tune_model(model) for model in best_pipelines\n    ]\n    best_pipelines_tuned \n    ```", "```py\n    [BATS(show_warnings=False, sp=12, use_box_cox=True),\n     TBATS(show_warnings=False, sp=[12], use_box_cox=True,  \n           use_damped_trend=True, use_trend=True),\n     AutoARIMA(random_state=42, sp=12, suppress_warnings=True),\n     ProphetPeriodPatched(changepoint_prior_scale=0.016439324494196616,\n                          holidays_prior_scale=0.01095960453692584,\n                          seasonality_prior_scale=7.886714129990491),\n     ThetaForecaster(sp=12)] \n    ```", "```py\n    blended_model = exp.blend_models(\n        best_pipelines_tuned, method=\"mean\"\n    ) \n    ```", "```py\n    y_pred = exp.predict_model(blended_model) \n    ```", "```py\n    exp.plot_model(estimator=blended_model) \n    ```", "```py\n    final_model = exp.finalize_model(blended_model)\n    exp.plot_model(final_model) \n    ```", "```py\ny_pred = exp.predict_model(final_model)\nprint(y_pred) \n```", "```py\ny_pred\n2020-01  3.8437\n2020-02  3.6852\n2020-03  3.4731\n2020-04  3.0444\n2020-05  3.0711\n2020-06  3.4585 \n```"]