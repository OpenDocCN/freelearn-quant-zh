["```py\n>>>sqrt(3)\nSyntaxError: invalid syntax\n>>>\n```", "```py\n>>>import math\n>>>x=math.sqrt(3)\n>>>round(x,4)\n1.7321\n```", "```py\n>>>dir()\n['__builtins__', '__doc__', '__name__', '__package__', 'math']\n```", "```py\n>>> dir(__builtins__)\n['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException', 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning', 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError', 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning', 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False', 'FileExistsError', 'FileNotFoundError', 'FloatingPointError', 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError', 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError', 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError', 'MemoryError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented', 'NotImplementedError', 'OSError', 'OverflowError', 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError', 'RecursionError', 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning', 'StopAsyncIteration', 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError', 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError', 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError', 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning', 'ValueError', 'Warning', 'WindowsError', 'ZeroDivisionError', '_', '__build_class__', '__debug__', '__doc__', '__import__', '__loader__', '__name__', '__package__', '__spec__', 'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits', 'debugfile', 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'evalsc', 'exec', 'exit', 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass', 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview', 'min', 'next', 'object', 'oct', 'open', 'open_in_spyder', 'ord', 'pow', 'print', 'property', 'quit', 'range', 'repr', 'reversed', 'round', 'runfile', 'set', 'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars', 'zip']\n```", "```py\n>>> help(pow)\nHelp on built-in function pow in module builtins:\npow(x, y, z=None, /)\nEquivalent to x**y (with two arguments) or x**y % z \n(with three arguments) \nSome types, such as ints, are able to use a more \nefficient algorithm when invoked using the three argument form.\n>> > \n```", "```py\n>>>import sys as s\n>>>import time as tt\n>>>import numpy as np\n>>>import matplotlib as mp\n```", "```py\n>>> import time as tt\n>>> tt.localtime()\ntime.struct_time(tm_year=2016, tm_mon=11, tm_mday=21, tm_hour=10, tm_min=58, tm_sec=33, tm_wday=0, tm_yday=326, tm_isdst=0)\n>>>\n```", "```py\n>>>import math\n>>>dir(math)\n['__doc__', '__loader__', '__name__', '__package__', 'acos', 'acosh',\n'asin', 'asinh', 'atan', 'atan2', 'atanh', 'ceil', 'copysign', 'cos',\n'cosh', 'degrees', 'e', 'erf', 'erfc', 'exp', 'expm1', 'fabs',\n'factorial', 'floor', 'fmod', 'frexp', 'fsum', 'gamma', 'hypot',\n'isfinite', 'isinf', 'isnan', 'ldexp', 'lgamma', 'log', 'log10', 'log1p', 'log2', 'modf', 'pi', 'pow', 'radians', 'sin', 'sinh', 'sqrt', 'tan', 'tanh', 'trunc']\n>>>\n```", "```py\n>>>from math import *\n>>>sqrt(3)\n   1.7320508075688772\n```", "```py\n    >>>import math\n    >>>math.sqrt(3)\n        1.7320508075688772\n    ```", "```py\n>>>import math\n>>>dir()\n['__builtins__', '__doc__', '__loader__', '__name__', '__package__', 'math']\n>>>del math\n>>>dir()\n['__builtins__', '__doc__', '__loader__', '__name__', '__package__']\n```", "```py\n>>>from math import *\n>>>del math\nTraceback (most recent call last):\nFile \"<pyshell#23>\", line 1, in <module>\ndel math NameError: name 'math' is not defined\n```", "```py\nFrom scipy import log,exp,sqrt,stats\n```", "```py\ndef bsCall(S,X,T,r,sigma):\n    from scipy import log,exp,sqrt,stats\n    d1=(log(S/X)+(r+sigma*sigma/2.)*T)/(sigma*sqrt(T))\n    d2 = d1-sigma*sqrt(T)\n    return S*stats.norm.cdf(d1)-X*exp(-r*T)*stats.norm.cdf(d2) \n```", "```py\n>>> bsCall(40,40,0.1,0.05,0.2)\n1.1094616585675574\n```", "```py\n>>> help()\n>>> \nWelcome to Python 3.5's help utility!\n```", "```py\nhelp>\n```", "```py\n>>>import numpy as np\n>>>x= np.array([[1,2,3],[3,4,6]])     # 2 by 3 matrix\n>>>np.size(x)                         # number of data items\n6\n>>>np.size(x,1)                       # show number of columns\n3\n>>>np.std(x)\n1.5723301886761005\n>>>np.std(x,1)\nArray([ 0.81649658, 1.24721913]\n>>>total=x.sum()                      # attention to the format\n>>>z=np.random.rand(50)               #50 random obs from [0.0, 1)\n>>>y=np.random.normal(size=100)       # from standard normal\n>>>r=np.array(range(0,100),float)/100 # from 0, .01,to .99\n```", "```py\n>>>np.array([100,0.1,2],float)\n```", "```py\n>>>x=[1,2,3,20]\n>>>y=np.array(x1,dtype=float)\n>>>y\narray([ 1., 2., 3., 20.])\n```", "```py\n>>>x2=[1,2,3,\"good\"]\n>>>x2\n[1, 2, 3, 'good']\n>>>y3=np.array(x2,float)\nTraceback (most recent call last):\nFile \"<pyshell#25>\", line 1, in <module>\ny3=np.array(x2,float)\nValueError: could not convert string to float: 'good'\n. ]])\n```", "```py\n>>> import numpy as np\n>>> dir(np)\n['ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'ComplexWarning', 'DataSource', 'ERR_CALL', 'ERR_DEFAULT', 'ERR_IGNORE', 'ERR_LOG', 'ERR_PRINT', 'ERR_RAISE', 'ERR_WARN', 'FLOATING_POINT_SUPPORT', 'FPE_DIVIDEBYZERO', 'FPE_INVALID', 'FPE_OVERFLOW', 'FPE_UNDERFLOW', 'False_', 'Inf', 'Infinity', 'MAXDIMS', 'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'MachAr', 'ModuleDeprecationWarning', 'NAN', 'NINF', 'NZERO', 'NaN', 'PINF', 'PZERO', 'PackageLoader', 'RAISE', 'RankWarning', 'SHIFT_DIVIDEBYZERO', 'SHIFT_INVALID', 'SHIFT_OVERFLOW', 'SHIFT_UNDERFLOW', 'ScalarType', 'Tester', 'TooHardError', 'True_', 'UFUNC_BUFSIZE_DEFAULT', 'UFUNC_PYVALS_NAME', 'VisibleDeprecationWarning', 'WRAP', '_NoValue', '__NUMPY_SETUP__', '__all__', '__builtins__', '__cached__', '__config__', '__doc__', '__file__', '__git_revision__', '__loader__', '__mkl_version__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_import_tools', '_mat', 'abs', 'absolute', 'absolute_import', 'add', 'add_docstring', 'add_newdoc', 'add_newdoc_ufunc', 'add_newdocs', 'alen', 'all', 'allclose', 'alltrue', 'alterdot', 'amax', 'amin', 'angle', 'any', 'append', 'apply_along_axis', 'apply_over_axes', 'arange', 'arccos', 'arccosh', 'arcsin', 'arcsinh', 'arctan', 'arctan2', 'arctanh', 'argmax', 'argmin', 'argpartition', 'argsort', 'argwhere', 'around', 'array', 'array2string', 'array_equal', 'array_equiv', 'array_repr', 'array_split', 'array_str', 'asanyarray',\n```", "```py\n>>> x=np.array(dir(np))\n>>> len(x)\n598\n```", "```py\n>>> x[200:250]\narray(['disp', 'divide', 'division', 'dot', 'double', 'dsplit', 'dstack',\n       'dtype', 'e', 'ediff1d', 'einsum', 'emath', 'empty', 'empty_like',\n       'equal', 'errstate', 'euler_gamma', 'exp', 'exp2', 'expand_dims',\n       'expm1', 'extract', 'eye', 'fabs', 'fastCopyAndTranspose', 'fft',\n       'fill_diagonal', 'find_common_type', 'finfo', 'fix', 'flatiter',\n       'flatnonzero', 'flexible', 'fliplr', 'flipud', 'float', 'float16',\n       'float32', 'float64', 'float_', 'floating', 'floor', 'floor_divide',\n       'fmax', 'fmin', 'fmod', 'format_parser', 'frexp', 'frombuffer',\n       'fromfile'], \n      dtype='<U25')\n>> > \n```", "```py\n>>>import numpy as np\n>>>help(np.std)\nHelp on function std in module numpy.core.fromnumeric:\n\nstd(a, axis=None, dtype=None, out=None, ddof=0, keepdims=False)\n    Compute the standard deviation along the specified axis.\n```", "```py\n\n    Parameters\n    ----------\n   a : array_like\n      Calculate the standard deviation of these values.\n   axis : None or int or tuple of ints, optional\nAxis or axes along which the standard deviation is computed. The\ndefault is to compute the standard deviation of the flattened array.\n\n        .. versionadded: 1.7.0\n```", "```py\n>>>import scipy as sp\n>>>cashflows=[-100,50,40,20,10,50]\n>>>x=sp.npv(0.1,cashflows)\n>>>round(x,2)\n>>>31.41\n```", "```py\n>>>payment=sp.pmt(0.045/12,30*12,250000)\n>>>round(payment,2)\n-1266.71\n```", "```py\n>>>pv1=sp.pv(0.1,5,0,100) # pv of one future cash flow\n>>>round(pv1,2)\n-92.09\n>>>pv2=sp.pv(0.1,5,100)   # pv of annuity\n>>>round(pv2,2)\n-379.08\n```", "```py\n>>>(2+3+4)/3.\n>>>3.0\n>>>geo_mean=(2*3*4)**(1./3)\n>>>round(geo_mean,4)\n2.8845\n```", "```py\n>>>import scipy as sp\n>>>ret=sp.array([0.1,0.05,-0.02])\n>>>sp.mean(ret)                      # arithmetic mean\n0.04333\n>>>pow(sp.prod(ret+1),1./len(ret))-1 # geometric mean\n0.04216\n```", "```py\ndef geoMeanReturn(ret):\n    return pow(sp.prod(ret+1),1./len(ret))-1\n```", "```py\n>>> import scipy as sp\n>>> ret=sp.array([0.1,0.05,-0.02])\n>>> geoMeanReturn(ret)\n0.042163887067679262\n```", "```py\n>>>sp.unique([2,3,4,6,6,4,4])\nArray([2,3,4,6])\n>>>sp.median([1,2,3,4,5])\n3.0\n```", "```py\n>>>import scipy as sp\n>>>round(sp.pv(0.1,5,0,100),2)\n>>>-62.09\n>>>round(sp.pv(0.1,5,0,-100),2)\n>>>62.09\n```", "```py\n>>>import numpy as np\n>>>dir(np)\n```", "```py\n>>> import scipy as sp\n>>> dir(sp)\n['ALLOW_THREADS', 'BUFSIZE', 'CLIP', 'ComplexWarning', 'DataSource', 'ERR_CALL', 'ERR_DEFAULT', 'ERR_IGNORE', 'ERR_LOG', 'ERR_PRINT', 'ERR_RAISE', 'ERR_WARN', 'FLOATING_POINT_SUPPORT', 'FPE_DIVIDEBYZERO', 'FPE_INVALID', 'FPE_OVERFLOW', 'FPE_UNDERFLOW', 'False_', 'Inf', 'Infinity', 'MAXDIMS', 'MAY_SHARE_BOUNDS', 'MAY_SHARE_EXACT', 'MachAr', 'ModuleDeprecationWarning', 'NAN', 'NINF', 'NZERO', 'NaN', 'PINF', 'PZERO', 'PackageLoader', 'RAISE', 'RankWarning', 'SHIFT_DIVIDEBYZERO', 'SHIFT_INVALID', 'SHIFT_OVERFLOW', 'SHIFT_UNDERFLOW', 'ScalarType', 'Tester', 'TooHardError', 'True_', 'UFUNC_BUFSIZE_DEFAULT', 'UFUNC_PYVALS_NAME', 'VisibleDeprecationWarning', 'WRAP', '__SCIPY_SETUP__', '__all__', '__builtins__', '__cached__', '__config__', '__doc__', '__file__', '__loader__', '__name__', '__numpy_version__', '__package__', '__path__', '__spec__', '__version__', '_lib', 'absolute', 'absolute_import', 'add', 'add_docstring', 'add_newdoc', 'add_newdoc_ufunc', 'add_newdocs', 'alen', 'all', 'allclose', 'alltrue', 'alterdot', 'amax', 'amin', 'angle', 'any', 'append', 'apply_along_axis', 'apply_over_axes', 'arange', 'arccos', 'arccosh', 'arcsin', 'arcsinh', 'arctan', 'arctan2', 'arctanh', 'argmax', 'argmin', 'argpartition', 'argsort', 'argwhere', 'around', 'array', 'array2string', 'array_equal', 'array_equiv', 'array_repr', 'array_split', 'array_str', 'asanyarray', 'asarray', 'asarray_chkfinite', 'ascontiguousarray', 'asfarray', 'asfortranarray', 'asmatrix', 'asscalar', 'atleast_1d', 'atleast_2d', 'atleast_3d', 'average', 'bartlett',\n```", "```py\n>>>import scipy as sp\n>>> x=dir(sp)\n>>> len(x)\n588\n>>>\n```", "```py\n>>> import matplotlib\n```", "```py\nimport datetime\nimport matplotlib.pyplot as plt\nfrom matplotlib.finance import quotes_historical_yahoo_ochl\nfrom matplotlib.dates import MonthLocator,DateFormatter\nticker='AAPL'\nbegdate= datetime.date( 2012, 1, 2 )\nenddate = datetime.date( 2013, 12,5)\nmonths = MonthLocator(range(1,13), bymonthday=1, interval=3) # every 3rd month\nmonthsFmt = DateFormatter(\"%b '%Y\")\nx = quotes_historical_yahoo_ochl(ticker, begdate, enddate)\nif len(x) == 0:\n    print ('Found no quotes')\n    raise SystemExit\ndates = [q[0] for q in x]\ncloses = [q[4] for q in x]\nfig, ax = plt.subplots()\nax.plot_date(dates, closes, '-')\nax.xaxis.set_major_locator(months)\nax.xaxis.set_major_formatter(monthsFmt)\nax.xaxis.set_minor_locator(mondays)\nax.autoscale_view()\nax.grid(True)\nfig.autofmt_xdate()\n```", "```py\n>>> import numpy as np\n>>> import statsmodels.api as sm\n>>> y=[1,2,3,4,2,3,4]\n>>> x=range(1,8)\n>>> x=sm.add_constant(x)\n>>> results=sm.OLS(y,x).fit()\n>>> print(results.params)\n     [ 1.28571429  0.35714286]\n```", "```py\n>>> import statsmodels as sm\n>>> dir(sm)\n['CacheWriteWarning', 'ConvergenceWarning', 'InvalidTestWarning', 'IterationLimitWarning', 'NoseWrapper', 'Tester', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__init__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'api', 'base', 'compat', 'datasets', 'discrete', 'distributions', 'duration', 'emplike', 'errstate', 'formula', 'genmod', 'graphics', 'info', 'iolib', 'nonparametric', 'print_function', 'regression', 'robust', 'sandbox', 'simplefilter', 'stats', 'test', 'tools', 'tsa', 'version']\n```", "```py\n>>> import statsmodels.api as api\n>>> dir(api)               \n['Categorical', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'ExcelFile', 'ExcelWriter', 'Expr', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int64Index', 'MultiIndex', 'NaT', 'Panel', 'Panel4D', 'Period', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseArray', 'SparseDataFrame', 'SparseList', 'SparsePanel', 'SparseSeries', 'SparseTimeSeries', 'Term', 'TimeGrouper', 'TimeSeries', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'WidePanel', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_np_version_under1p10', '_np_version_under1p11', '_np_version_under1p12', '_np_version_under1p8', '_np_version_under1p9', '_period', '_sparse', '_testing', '_version', 'algos', 'bdate_range', 'compat', 'computation', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'datetime', 'datetools', 'dependency', 'describe_option', 'eval', 'ewma', 'ewmcorr', 'ewmcov', 'ewmstd', 'ewmvar', 'ewmvol', 'expanding_apply', 'expanding_corr', 'expanding_count', 'expanding_cov', 'expanding_kurt', 'expanding_max', 'expanding_mean', 'expanding_median', 'expanding_min', 'expanding_quantile', 'expanding_skew', 'expanding_std', 'expanding_sum', 'expanding_var', 'factorize', 'fama_macbeth', 'formats', 'get_dummies', 'get_option', 'get_store', 'groupby', 'hard_dependencies', 'hashtable', 'index', 'indexes', 'infer_freq', 'info', 'io', 'isnull', 'json', 'lib', 'lreshape', 'match', 'melt', 'merge', 'missing_dependencies', 'msgpack', 'notnull', 'np', 'offsets', 'ols', 'option_context', 'options', 'ordered_merge', 'pandas', 'parser', 'period_range', 'pivot', 'pivot_table', 'plot_params', 'pnow', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_msgpack', 'read_pickle', 'read_sas', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'reset_option', 'rolling_apply', 'rolling_corr', 'rolling_count', 'rolling_cov', 'rolling_kurt', 'rolling_max', 'rolling_mean', 'rolling_median', 'rolling_min', 'rolling_quantile', 'rolling_skew', 'rolling_std', 'rolling_sum', 'rolling_var', 'rolling_window', 'scatter_matrix', 'set_eng_float_format', 'set_option', 'show_versions', 'sparse', 'stats', 'test', 'timedelta_range', 'to_datetime', 'to_msgpack', 'to_numeric', 'to_pickle', 'to_timedelta', 'tools', 'tseries', 'tslib', 'types', 'unique', 'util', 'value_counts', 'wide_to_long']\n```", "```py\n>>>import pandas as pd\n```", "```py\nimport numpy as np\nimport pandas as pd\ndates=pd.date_range('20160101',periods=5)\nnp.random.seed(12345)\nx=pd.DataFrame(np.random.rand(5,2),index=dates,columns=('A','B'))\n```", "```py\n>>> x\n                   A         B\n2016-01-01  0.929616  0.316376\n2016-01-02  0.183919  0.204560\n2016-01-03  0.567725  0.595545\n2016-01-04  0.964515  0.653177\n2016-01-05  0.748907  0.653570\n>>>\n>>> x.describe()\n              A         B\ncount  5.000000  5.000000\nmean   0.678936  0.484646\nstd    0.318866  0.209761\nmin    0.183919  0.204560\n25%    0.567725  0.316376\n50%    0.748907  0.595545\n75%    0.929616  0.653177\nmax    0.964515  0.653570\n>>>\n```", "```py\n>>> import pandas as pd\n>>> dir(pd)\n['Categorical', 'CategoricalIndex', 'DataFrame', 'DateOffset', 'DatetimeIndex', 'ExcelFile', 'ExcelWriter', 'Expr', 'Float64Index', 'Grouper', 'HDFStore', 'Index', 'IndexSlice', 'Int64Index', 'MultiIndex', 'NaT', 'Panel', 'Panel4D', 'Period', 'PeriodIndex', 'RangeIndex', 'Series', 'SparseArray', 'SparseDataFrame', 'SparseList', 'SparsePanel', 'SparseSeries', 'SparseTimeSeries', 'Term', 'TimeGrouper', 'TimeSeries', 'Timedelta', 'TimedeltaIndex', 'Timestamp', 'WidePanel', '__builtins__', '__cached__', '__doc__', '__docformat__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_np_version_under1p10', '_np_version_under1p11', '_np_version_under1p12', '_np_version_under1p8', '_np_version_under1p9', '_period', '_sparse', '_testing', '_version', 'algos', 'bdate_range', 'compat', 'computation', 'concat', 'core', 'crosstab', 'cut', 'date_range', 'datetime', 'datetools', 'dependency', 'describe_option', 'eval', 'ewma', 'ewmcorr', 'ewmcov', 'ewmstd', 'ewmvar', 'ewmvol', 'expanding_apply', 'expanding_corr', 'expanding_count', 'expanding_cov', 'expanding_kurt', 'expanding_max', 'expanding_mean', 'expanding_median', 'expanding_min', 'expanding_quantile', 'expanding_skew', 'expanding_std', 'expanding_sum', 'expanding_var', 'factorize', 'fama_macbeth', 'formats', 'get_dummies', 'get_option', 'get_store', 'groupby', 'hard_dependencies', 'hashtable', 'index', 'indexes', 'infer_freq', 'info', 'io', 'isnull', 'json', 'lib', 'lreshape', 'match', 'melt', 'merge', 'missing_dependencies', 'msgpack', 'notnull', 'np', 'offsets', 'ols', 'option_context', 'options', 'ordered_merge', 'pandas', 'parser', 'period_range', 'pivot', 'pivot_table', 'plot_params', 'pnow', 'qcut', 'read_clipboard', 'read_csv', 'read_excel', 'read_fwf', 'read_gbq', 'read_hdf', 'read_html', 'read_json', 'read_msgpack', 'read_pickle', 'read_sas', 'read_sql', 'read_sql_query', 'read_sql_table', 'read_stata', 'read_table', 'reset_option', 'rolling_apply', 'rolling_corr', 'rolling_count', 'rolling_cov', 'rolling_kurt', 'rolling_max', 'rolling_mean', 'rolling_median', 'rolling_min', 'rolling_quantile', 'rolling_skew', 'rolling_std', 'rolling_sum', 'rolling_var', 'rolling_window', 'scatter_matrix', 'set_eng_float_format', 'set_option', 'show_versions', 'sparse', 'stats', 'test', 'timedelta_range', 'to_datetime', 'to_msgpack', 'to_numeric', 'to_pickle', 'to_timedelta', 'tools', 'tseries', 'tslib', 'types', 'unique', 'util', 'value_counts', 'wide_to_long']\n```", "```py\n>>> import pandas as pd\n>>> import numpy as np\n>>> x=pd.Series([1,4,-3,np.nan,5])\n>>> x\n0    1.0\n1    4.0\n2   -3.0\n3    NaN\n4    5.0\ndtype: float64\n>>> m=np.mean(x)\n>>> m\n1.75\n>>> x.fillna(m)\n0    1.00\n1    4.00\n2   -3.00\n3    1.75\n4    5.00\ndtype: float64>> >\n```", "```py\nimport pandas as pd\nimport numpy as np\nnp.random.seed(123)\ndf = pd.DataFrame(np.random.randn(10, 4))\n```", "```py\n>>> df\n>>> \n          0         1         2         3\n0 -1.085631  0.997345  0.282978 -1.506295\n1 -0.578600  1.651437 -2.426679 -0.428913\n2  1.265936 -0.866740 -0.678886 -0.094709\n3  1.491390 -0.638902 -0.443982 -0.434351\n4  2.205930  2.186786  1.004054  0.386186\n5  0.737369  1.490732 -0.935834  1.175829\n6 -1.253881 -0.637752  0.907105 -1.428681\n7 -0.140069 -0.861755 -0.255619 -2.798589\n8 -1.771533 -0.699877  0.927462 -0.173636\n9  0.002846  0.688223 -0.879536  0.283627\n>>>\n```", "```py\nimport pandas as pd\nimport numpy as np\nnp.random.seed(123)                   # fix the random numbers \nx=np.arange(1, 10.1, .25)**2      \nn=np.size(x)\ny = pd.Series(x + np.random.randn(n))\nbad=np.array([4,13,14,15,16,20,30])   # generate a few missing values\nx[bad] = np.nan                       # missing code is np.nan\nmethods = ['linear', 'quadratic', 'cubic']\ndf = pd.DataFrame({m: x.interpolate(method=m) for m in methods})\ndf.plot()\n```", "```py\nimport numpy as np\nimport pandas as pd\nnp.random.seed(123)\ndf=pd.Series(np.random.randn(100))\ndf.to_pickle('test.pkl')\n```", "```py\ndf.to_pickle('test.pkl')\n```", "```py\n>>>import pandas as pd\n>>>x=pd.read_pickle(\"c:/temp/test.pkl\")\n>>>x[:5]\n>>> \n>>> \n0   -1.085631\n1    0.997345\n2    0.282978\n3   -1.506295\n4   -0.578600\ndtype: float64\n>>>\n```", "```py\nimport numpy as np\nimport pandas as pd\nx = pd.DataFrame({'key':['A','B','C','D'],'value': [0.1,0.2,-0.5,0.9]})\ny = pd.DataFrame({'key':['B','D','D','E'],'value': [2, 3, 4, 6]})\nz=pd.merge(x, y, on='key')\n```", "```py\n>>> x\n  key  value\n0   A    0.1\n1   B    0.2\n2   C   -0.5\n3   D    0.9\n>>> y\n  key  value\n0   B      2\n1   D      3\n2   D      4\n3   E      6numpy as np\n>>>z\n  key  value_x  value_y\n0   B      0.2        2\n1   D      0.9        3\n2   D      0.9        4\n>>>\n```", "```py\n>>> date1=pd.datetime(2010,2,3)\n>>> date1\ndatetime.datetime(2010, 2, 3, 0, 0)\n```", "```py\n>>>date1=pd.datetime(2010,2,3)\n>>>date2=pd.datetime(2010,3,31)\n>>> date2-date1\ndatetime.timedelta(56)\n```", "```py\n>>> dir(pd.datetools)\n>>> \n['ABCDataFrame', 'ABCIndexClass', 'ABCSeries', 'AmbiguousTimeError', 'BDay', 'BMonthBegin', 'BMonthEnd', 'BQuarterBegin', 'BQuarterEnd', 'BYearBegin', 'BYearEnd', 'BusinessDay', 'BusinessHour', 'CBMonthBegin', 'CBMonthEnd', 'CDay', 'CustomBusinessDay', 'CustomBusinessHour', 'DAYS', 'D_RESO', 'DateOffset', 'DateParseError', 'Day', 'Easter', 'FY5253', 'FY5253Quarter', 'FreqGroup', 'H_RESO', 'Hour', 'LastWeekOfMonth', 'MONTHS', 'MS_RESO', 'Micro', 'Milli', 'Minute', 'MonthBegin', 'MonthEnd', 'MutableMapping', 'Nano', 'OLE_TIME_ZERO', 'QuarterBegin', 'QuarterEnd', 'Resolution', 'S_RESO', 'Second', 'T_RESO', 'Timedelta', 'US_RESO', 'Week', 'WeekOfMonth', 'YearBegin', 'YearEnd', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'algos', 'bday', 'bmonthBegin', 'bmonthEnd', 'bquarterEnd', 'businessDay', 'byearEnd', 'cache_readonly', 'cbmonthBegin', 'cbmonthEnd', 'cday', 'com', 'compat', 'customBusinessDay', 'customBusinessMonthBegin', 'customBusinessMonthEnd', 'datetime', 'day', 'deprecate_kwarg', 'format', 'getOffset', 'get_base_alias', 'get_freq', 'get_freq_code', 'get_freq_group', 'get_legacy_offset_name', 'get_offset', 'get_offset_name', 'get_period_alias', 'get_standard_freq', 'get_to_timestamp_base', 'infer_freq', 'isBMonthEnd', 'isBusinessDay', 'isMonthEnd', 'is_subperiod', 'is_superperiod', 'lib', 'long', 'monthEnd', 'need_suffix', 'normalize_date', 'np', 'offsets', 'ole2datetime', 'opattern', 'parse_time_string', 'prefix_mapping', 'quarterEnd', 'range', 're', 'thisBMonthEnd', 'thisBQuarterEnd', 'thisMonthEnd', 'thisQuarterEnd', 'thisYearBegin', 'thisYearEnd', 'time', 'timedelta', 'to_datetime', 'to_offset', 'to_time', 'tslib', 'unique', 'warnings', 'week', 'yearBegin', 'yearEnd', 'zip']\n>>>\n```", "```py\n>>import pandas as pd\n>>>date1=pd.datetime(2010,10,10)\n>>>date1.weekday()\n6\n```", "```py\nimport pandas as pd\nimport numpy as np\nnp.random.seed(1256)\ndf=pd.DataFrame(np.random.randn(4,2),columns=['Stock A','Stock B'])\ndf2=df.stack()\n```", "```py\n>>> df\n    Stock A   Stock B\n0  0.452820 -0.892822\n1 -0.476880  0.393239\n2  0.961438 -1.797336\n3 -1.168289  0.187016\n>>>\n>>> df2\n>>> \n0  Stock A    0.452820\n   Stock B   -0.892822\n1  Stock A   -0.476880\n   Stock B    0.393239\n2  Stock A    0.961438\n   Stock B   -1.797336\n3  Stock A   -1.168289\n   Stock B    0.187016\ndtype: float64>> >\n```", "```py\n>>> k=df2.unstack()\n>>> k\n    Stock A   Stock B\n0  0.452820 -0.892822\n1 -0.476880  0.393239\n2  0.961438 -1.797336\n3 -1.168289  0.187016\n```", "```py\nimport pandas_datareader.data as web\ndf=web.get_data_google(\"ibm\")\n```", "```py\n>>> df.head()\n>>> \n                  Open        High         Low       Close   Volume  \nDate                                                                  \n2010-01-04  131.179993  132.970001  130.850006  132.449997  6155300   \n2010-01-05  131.679993  131.850006  130.100006  130.850006  6841400   \n2010-01-06  130.679993  131.490005  129.809998  130.000000  5605300   \n2010-01-07  129.869995  130.250000  128.910004  129.550003  5840600   \n2010-01-08  129.070007  130.919998  129.050003  130.850006  4197200   \n\n             Adj Close  \nDate                    \n2010-01-04  112.285875  \n2010-01-05  110.929466  \n2010-01-06  110.208865  \n2010-01-07  109.827375  \n2010-01-08  110.929466 \n >> >df.tail()\n>>> \n                  Open        High         Low       Close   Volume  \nDate                                                                  \n2016-11-16  158.460007  159.550003  158.029999  159.289993  2244100   \n2016-11-17  159.220001  159.929993  158.850006  159.800003  2256400   \n2016-11-18  159.800003  160.720001  159.210007  160.389999  2958700   \n2016-11-21  160.690002  163.000000  160.369995  162.770004  4601900   \n2016-11-22  163.000000  163.000000  161.949997  162.669998  2707900   \n\n             Adj Close  \nDate                    \n2016-11-16  159.289993  \n2016-11-17  159.800003  \n2016-11-18  160.389999  \n2016-11-21  162.770004  \n2016-11-22  162.669998  \n>>>\n```", "```py\n>>> import numpy.lib.financial as fin\n>>> dir(fin)\n['__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_convert_when', '_g_div_gp', '_rbl', '_when_to_num', 'absolute_import', 'division', 'fv', 'ipmt', 'irr', 'mirr', 'np', 'nper', 'npv', 'pmt', 'ppmt', 'print_function', 'pv', 'rate']\n>>>\n```", "```py\n>>> import numpy.lib.financial as fin\n>>> fin.pv(0.1,1,0,100)\n-90.909090909090907\n>>>\n```", "```py\n>>>import fincal\n>>>dir(fincal)\n['CND', 'EBITDA_value', 'IRR_f', 'IRRs_f', 'NPER', 'PMT', 'Rc_f', 'Rm_f', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__request', '__spec__', 'bondPrice', 'bsCall', 'convert_B_M', 'duration', 'exp', 'fincalHelp', 'fvAnnuity', 'fv_f', 'get_200day_moving_avg', 'get_50day_moving_avg', 'get_52week_high', 'get_52week_low', 'get_EBITDA', 'get_all', 'get_avg_daily_volume', 'get_book_value', 'get_change', 'get_dividend_per_share', 'get_dividend_yield', 'get_earnings_per_share', 'get_historical_prices', 'get_market_cap', 'get_price', 'get_price_book_ratio', 'get_price_earnings_growth_ratio', 'get_price_earnings_ratio', 'get_price_sales_ratio', 'get_short_ratio', 'get_stock_exchange', 'get_volume', 'log', 'market_cap', 'mean', 'modified_duration', 'n_annuity', 'npv_f', 'payback_', 'payback_period', 'pi', 'pvAnnuity', 'pvAnnuity_k_period_from_today', 'pvGrowPerpetuity', 'pvGrowingAnnuity', 'pvPerpetuity', 'pvPerpetuityDue', 'pv_excel', 'pv_f', 'r_continuous', 're', 'sign', 'sqrt', 'urllib']\n```", "```py\n>>> import fincal\n>>> help(fincal.pv_f)\nHelp on function pv_f in module fincal:\n\npv_f(fv, r, n)\n    Objective: estimate present value\n           fv: fture value\n           r : discount period rate\n           n : number of periods\n     formula : fv/(1+r)**n      \n         e.g.,\n         >>>pv_f(100,0.1,1)\n         90.9090909090909\n         >>>pv_f(r=0.1,fv=100,n=1)\n         90.9090909090909\n         >>>pv_f(n=1,fv=100,r=0.1)\n         90.9090909090909\n>>>\n```", "```py\npython -m pip install -U pip numpy\n```", "```py\npython –m pip install –upgrade pip\n```", "```py\npip install -U pip numpy\n```", "```py\n>>>import numpy as np\n>>> np.__version__\n'1.11.1'\n>>> import scipy as sp\n>>> sp.__version__\n'0.18.1'\n>>>import pandas as pd\n>>> pd.__version__\n'0.18.1'\n```", "```py\n    >>>x=[1,2,3]\n    >>>x.sum()\n    ```", "```py\n    >>>import np\n    >>>x=np.array([True,false,true,false],bool)\n    ```", "```py\n    >>>import scipy as sp\n    >>>ret=np.array([0.05,0.11,-0.03])\n    >>>pow(np.prod(ret+1),1/len(ret))-1\n    ```", "```py\n    >>>c=20\n    >>>npv=np.npv(0.1,c)\n    ```"]