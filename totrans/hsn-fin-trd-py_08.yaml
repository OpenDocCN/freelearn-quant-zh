- en: '*Chapter 6*: Statistical Estimation, Inference, and Prediction'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduce four key statistical libraries in Python—`statsmodels`,
    `pmdarima`, `fbprophet`, and `scikitlearn`—by outlining key examples. These libraries
    are used to model time series and provide their forecast values, along with confidence
    intervals. In addition, we demonstrate how to use a classification model to predict
    percentage changes of a time series.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, we are going to cover the following use cases:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to statsmodels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a **Seasonal Auto-Regressive Integrated Moving Average with eXogenous
    factors** (**SARIMAX**) time-series model with pmdarima
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series forecasting with Facebook's Prophet library
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to scikit-learn regression and classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Python code used in this chapter is available in the `Chapter06 folder`
    in the book's code repository.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to statsmodels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: statsmodels is a Python library that allows us to explore data, perform statistical
    tests, and estimate statistical models.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter focuses on statsmodels' modeling, analysis, and forecasting of
    time series.
  prefs: []
  type: TYPE_NORMAL
- en: Normal distribution test with Q-Q plots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An underlying assumption of many statistical learning techniques is that the
    observations/fields are normally distributed.
  prefs: []
  type: TYPE_NORMAL
- en: While there are many robust statistical tests for normal distributions, an intuitive
    visual method is known as a **quantile-quantile plot** (**Q-Q plot**). If a sample
    is normally distributed, its Q-Q plot is a straight line.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code block, the `statsmodels.graphics.api.qqplot(...)` method
    is used to check if a `numpy.random.uniform(...)` distribution is normally distributed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting plot depicted in the following screenshot shows a non-linear
    relationship between the two distributions, which was expected since we used a
    uniform distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Q-Q plot for a dataset generated from a uniform distribution](img/Figure_6.1_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – Q-Q plot for a dataset generated from a uniform distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code block, we repeat the test, but this time with a `numpy.random.exponential(...)`
    distribution as our sample distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting Q-Q plot again confirms a non-normal relationship between the
    two distributions, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Q-Q plot for a dataset generated from an exponential distribution](img/Figure_6.2_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Q-Q plot for a dataset generated from an exponential distribution
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will pick out 10,000 samples from a normal distribution using the
    `numpy.random.normal(...)` method and use `qqplot(...)` to observe them, as illustrated
    in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a plot with a linear relationship as expected, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – Q-Q plot for 10,000 samples sampled from a standard normal distribution](img/Figure_6.3_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – Q-Q plot for 10,000 samples sampled from a standard normal distribution
  prefs: []
  type: TYPE_NORMAL
- en: Q-Q plots are used for comparison between two probability distributions—with
    one of them most often being a normal distribution—by plotting their quantiles
    against one another. The preceding examples demonstrate how easy it is to test
    visually for normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Time series modeling with statsmodels
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A time series is a sequence of numerical data points in time order.
  prefs: []
  type: TYPE_NORMAL
- en: A crucial part of working with time series data involves working with dates
    and times.
  prefs: []
  type: TYPE_NORMAL
- en: The `statsmodels.api.tsa.datetools` model provides some basic methods for generating
    and parsing dates and date ranges, such as `dates_from_range(...)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following code snippet, we generate 12 `datetime.datetime` objects using
    a `length=12` parameter and starting from `2010` with a yearly frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'That yields the following list of `datetime` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The frequency of dates in the `dates_from_range(...)` method can be specified
    by the start date and a special format, where the `m1` suffix means first month
    and monthly frequency, and `q1` means first quarter and quarterly frequency, as
    illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'That yields the following list of `datetime` objects with monthly frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Let's now perform an **Error, Trend, Seasonality** (**ETS**) analysis of a time
    series.
  prefs: []
  type: TYPE_NORMAL
- en: ETS analysis of a time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ETS analysis of a time series breaks down the data into three different
    components, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The **trend** component captures the overall trend of the time series.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **seasonality** component captures cyclical/seasonal changes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **error** component captures noise in the data that could not be captured
    with the other two components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s generate 20 years of monthly dates as an index to the Pandas DataFrame
    dataset using the `datetools.dates_from_range(...)` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the following DataFrame with a `Price` field that is composed
    of ETS components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s visualize the time series dataset that we generated, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The resulting time series dataset has an apparent linearly increasing trend
    with seasonal components mixed in, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Plot displaying synthetic prices with ETS components](img/Figure_6.4_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Plot displaying synthetic prices with ETS components
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we do see the seasonality component very clearly—the
    oscillation up and down from the median value. We also see the error noise since
    the oscillations are not perfect. Finally, we see that the values are increasing—the
    trend component.
  prefs: []
  type: TYPE_NORMAL
- en: The Hodrick-Prescott filter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The `statsmodels`, this is implemented as `statsmodels.api.tsa.filters.hpfilter(...)`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use it with a `lamb=129600` smoothing parameter to perform the decomposition
    (the value `129600` is the recommended value for monthly data). We use a pair
    of series values returned to generate a DataFrame with `Price`, `hp_cycle`, and
    `hp_trend` fields to represent the price, the seasonal component, and the trend
    components, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The `decomp` DataFrame contains the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will look at the `UnobservedComponents` model.
  prefs: []
  type: TYPE_NORMAL
- en: UnobservedComponents model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way of breaking down a time series into ETS components is to use a `statsmodels.api.tsa.UnobservedComponents`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `UnobservedComponentsResults.summary(...)` method generates statistics
    for the model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output contains details about the model, as illustrated in the following
    code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access the ETS/cyclical components using the `resid`, `cycle.smoothed`,
    and `level.smoothed` attributes and add them to the `decomp` DataFrame, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `decomp` DataFrame has the following new columns containing the `Cycle`,
    `Trend`, and `Error` terms from the `UnobservedComponents` model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will look at the `statsmodel.tsa.seasonal.seasonal_decompose(…)` method.
  prefs: []
  type: TYPE_NORMAL
- en: statsmodels.tsa.seasonal.seasonal_decompose(...) method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to perform ETS decomposition is by using the `statsmodels.tsa.seasonal.seasonal_decompose(...)`
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block uses an additive model by specifying a `model=''additive''`
    parameter and adds `SDC_Cycle`, `SDC_Trend`, and `SDC_Error` columns to the `decomp`
    DataFrame by accessing the `season`, `trend`, and `resid` attributes in the `DecomposeResult`
    object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The `decomp` DataFrame now has three additional fields with values, as shown
    in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Next, we will plot the various results we got from the preceding sections.
  prefs: []
  type: TYPE_NORMAL
- en: Plotting of the results of HP filter, the UnobservedComponents model, and the
    seasonal_decompose method
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s plot the trend components extracted from the `HP` filter, the `UnobservedComponents`
    model, and the `seasonal_decompose` method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'That gives us the following plot, with the trend components plotted next to
    the original price. All three models did a good job in identifying the overall
    increasing trend, with the `seasonal_decompose(...)` method capturing some non-linear/cyclical
    trend components, in addition to the overall linearly increasing trend:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Plot showing trend components extracted from different ETS decomposition
    methods](img/Figure_6.5_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Plot showing trend components extracted from different ETS decomposition
    methods
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block plots the cycle/seasonal components obtained from
    the three models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following result shows that the `seasonal_decompose(...)` method generates
    seasonal components with very small fluctuations, and that is because some part
    of the seasonal components was built into the trend plot we saw before:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – Plot showing cyclical/seasonal components extracted by different
    ETS decomposition methods](img/Figure_6.6_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – Plot showing cyclical/seasonal components extracted by different
    ETS decomposition methods
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we will visualize the error terms in the `UnobservedComponents` and
    `seasonal_decompose` methods, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Plot displaying error terms from different ETS decomposition
    models](img/Figure_6.7_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Plot displaying error terms from different ETS decomposition models
  prefs: []
  type: TYPE_NORMAL
- en: The plot shown in the preceding screenshot demonstrates that the error terms
    oscillate around `0` and that they have no clear trend.
  prefs: []
  type: TYPE_NORMAL
- en: Augmented Dickey-Fuller test for stationarity of a time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stationary time series are time series whose statistical properties such as
    mean, variance, and autocorrelation are constant over time. Many statistical forecasting
    models assume that time series datasets can be transformed into stationary datasets
    by some mathematical operations, such as differencing.
  prefs: []
  type: TYPE_NORMAL
- en: An **Augmented Dickey-Fuller** (**ADF**) test is used to check if a dataset
    is stationary or not—it computes the likelihood that a dataset is not stationary,
    and when that probability (*p-value*) is very low, we can conclude that the dataset
    is stationary. We will look at the detailed steps in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – ADF test on the prices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s check for stationarity, as well as converting our dataset into a stationary
    dataset by using a differencing method. We start with the `statsmodels.tsa.stattools.adfuller(...)`
    method, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'That outputs the following values when applied to the `Price` field. The `Test`
    statistic is a positive value and the p-value is 98%, meaning there is strong
    evidence that the `Price` field is not stationary. We knew this was expected,
    since the `Price` field has strong trend and seasonality components in it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Step 2 – First differencing on prices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, we apply a **first differencing** transformation; this finds the first
    difference from one observation to the next one. If we difference the differenced
    dataset again, that yields a **second difference**, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'We store the first-differenced `pandas.Series` dataset in the `price_diff`
    variable, as shown in the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'That dataset contains the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Step 3 – ADF test on the differenced prices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now, we rerun the ADF test on this transformed dataset to check for stationarity,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The test statistic now has a large negative value (values under -4 have a very
    high likelihood of being stationary). The probability of not being stationary
    now reduces to an extremely low value, indicating that the transformed dataset
    is stationary, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Autocorrelation and partial autocorrelation of a time series
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Autocorrelation or serial correlation is the correlation of an observation—a
    delayed copy of itself—as a function of delay. It measures if the currently observed
    value has any relationship to the value in the future/past.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our dataset with a clear linear trend and some seasonal components, the
    autocorrelation slowly decreases as the number of lags increases, but for smaller
    lag values the dataset has high autocorrelation values due to the large overall
    linear trend. The `statsmodels.graphics.tsaplots.plot_acf(...)` method plots the
    autocorrelation of the `Price` field with lag values ranging from `0` to `100`,
    as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The result indicates that autocorrelation remains relatively strong up to lag
    values of around 36, where it dips below 0.5\. This is illustrated in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Autocorrelation plot showing autocorrelation against different
    lag values](img/Figure_6.8_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Autocorrelation plot showing autocorrelation against different
    lag values
  prefs: []
  type: TYPE_NORMAL
- en: 'The `statsmodels.graphics.tsaplots.plot_pacf(…)` method lets us plot the partial
    autocorrelation values against different lag values. The difference between autocorrelation
    and partial autocorrelation is that with partial autocorrelation, only the correlation
    between that observation and the previous observation that lag periods is used,
    and correlation effects from lower lag-value terms are removed. This method is
    shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The output can be seen in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Partial autocorrelation plot showing partial autocorrelations
    against lag values](img/Figure_6.9_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Partial autocorrelation plot showing partial autocorrelations against
    lag values
  prefs: []
  type: TYPE_NORMAL
- en: The plot shown in the preceding screenshot drops in autocorrelation sharply
    after the first two lag terms and then seasonally varies from positive to negative
    values every 10 lag terms.
  prefs: []
  type: TYPE_NORMAL
- en: ARIMA time series model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Auto-Regressive Integrated Moving Average** (**ARIMA**) model is one of
    the most well-known time series modeling and forecasting models available. It
    is used to predict time series data for time series with correlated data points.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ARIMA model is composed of three components, outlined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`p` parameter, specifying the number of lags to use. For our case based on
    the autocorrelation plots, we will specify `p=36` when modeling the `Price` series
    with ARIMA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`d` parameter, specifying the order of differencing to perform, which in our
    case will be `d=1`. As we saw in the *Augmented Dickey-Fuller test for stationarity
    of a time series* section, the first-order differencing led to a stationary dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`q`, which is the size of the MA window. In our case, we will set this parameter
    based on the partial autocorrelation plots and use a value of `q=2` because of
    the sharp drop-off in partial autocorrelation past the lag value of `1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In statsmodels, the `statsmodels.tsa.arima.model.ARIMA` model builds a time
    series as an ARIMA model. Using an `order=(36, 1, 2)` parameter, we specify `p=36`,
    `d=1`, and `q=2`. Then, we call the `ARIMA.fit(...)` method to fit the model to
    our `Price` series, and call the `ARIMA.summary(...)` method to output information
    about the fitted ARIMA model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some other packages—for example, `pmdarima`—offer `auto_arima` methods that
    find the ARIMA models by themselves, as illustrated in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output describes fitting parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the `statsmodels.tsa.arima.ARIMAResults.predict(...)` method, we can
    use the fitted model to predict values over the specified start and end datetime
    indices (in this case, the entire dataset). We will save the predicted prices
    in the `PredPrice` field for comparison later. The code can be seen in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The result adds the new column with the predicted prices, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we will plot the original `Price` and the `PredPrice` fields in the following
    code block to visually compare the two:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The predicted prices are quite accurate, and that is because the specified
    parameters (`p`, `d`, `q`) were precise. The result can be seen in the following
    screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Plot comparing the original price and the price predicted by
    an ARIMA (36, 1, 2) model](img/Figure_6.10_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Plot comparing the original price and the price predicted by an
    ARIMA (36, 1, 2) model
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s use this fitted model to forecast values for dates out in the future.
    First, we build an `extended_dataset` DataFrame with another 4 years'' worth of
    datetime indices and no data (which will be filled in with `NaN` values) using
    the `datetools.dates_from_range(...)` method and the `pandas.DataFrame.append(...)`
    method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can call the `ARIMAResults.predict(...)` method again to generate
    predicted prices for the entire time series and thus forecast onto the new dates
    we added, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code block plots the last 100 observations from the `extended_dataset`
    DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'And that yields a plot with the forecasted `PredPrice` values, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Historical and predicted prices forecasted by the ARIMA model](img/Figure_6.11_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – Historical and predicted prices forecasted by the ARIMA model
  prefs: []
  type: TYPE_NORMAL
- en: In the plot shown in the preceding screenshot, the predicted prices visibly
    follow the trend of past prices.
  prefs: []
  type: TYPE_NORMAL
- en: Using a SARIMAX time series model with pmdarima
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**SARIMA** is an extension of the ARIMA model for univariate time series with
    a seasonal component.'
  prefs: []
  type: TYPE_NORMAL
- en: '**SARIMAX** is, then, the name of the model, which also supports **exogenous**
    variables.'
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the three ARIMA parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`p` = trend auto-regressive order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`d` = trend difference order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`q` = trend MA order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition to the preceding parameters, SARIMA introduces four more, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`P` = seasonal auto-regressive order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`D` = seasonal difference order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Q` = seasonal MA order'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`m` = the length of a single seasonal period in the number of time steps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To find these parameters manually can be time-consuming, and it may be advantageous
    to use an auto-ARIMA model.
  prefs: []
  type: TYPE_NORMAL
- en: In Python, auto-ARIMA modeling is provided by the `pmdarima` library. Its documentation
    is available at [http://alkaline-ml.com/pmdarima/index.html](http://alkaline-ml.com/pmdarima/index.html).
  prefs: []
  type: TYPE_NORMAL
- en: 'The installation is straightforward, as can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The auto-ARIMA model attempts to automatically discover the SARIMAX parameters
    by conducting various statistical tests, as illustrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Table of the various statistical tests](img/Figure_6.12_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Table of the various statistical tests
  prefs: []
  type: TYPE_NORMAL
- en: Once we find the optimal `d` value, the auto-ARIMA model searches for the best
    fitting model within the ranges defined by `start_p`, `max_p`, `start_q`, and
    `max_q`. If the `seasonal` parameter is enabled, once we determine the optimal
    `D` value we use a similar procedure to find `P` and `Q`.
  prefs: []
  type: TYPE_NORMAL
- en: The best model is determined by minimizing the value of the information criterion
    (**Akaike information criterion** (**AIC**), **Corrected AIC**, **Bayesian information
    criterion** (**BIC**), **Hannan-Quinn information criterion** (**HQC**), or **out-of-bag**
    (**OOB**)—for validation scoring—respectively).
  prefs: []
  type: TYPE_NORMAL
- en: If no suitable model is found, auto-ARIMA returns a `ValueError` output.
  prefs: []
  type: TYPE_NORMAL
- en: Let's use auto-ARIMA with the previous dataset. The time series has a clear
    seasonality component with a periodicity of 12.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice in the following code block that we generate 95% confidence intervals
    for the predicted values, which is very useful for trading rules—for example,
    sell if the price is above the upper confidence interval value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.13 – SARIMAX result statistics from auto-ARIMA](img/Figure_6.13_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 – SARIMAX result statistics from auto-ARIMA
  prefs: []
  type: TYPE_NORMAL
- en: 'The plot is shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Historical and predicted price forecasted by the auto-ARIMA
    model](img/Figure_6.14_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 – Historical and predicted price forecasted by the auto-ARIMA model
  prefs: []
  type: TYPE_NORMAL
- en: 'The output also includes the predicted prices, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, the output provides the confidence intervals for each predicted
    price, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: We will now see time series forecasting with Facebook's Prophet library.
  prefs: []
  type: TYPE_NORMAL
- en: Time series forecasting with Facebook's Prophet library
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Facebook Prophet is a Python library used for forecasting univariate time series
    with strong support for seasonality and holiday effects. It is especially suitable
    for time series with frequent changes of trends and is robust enough to handle
    outliers.
  prefs: []
  type: TYPE_NORMAL
- en: 'More specifically, the `Prophet` model is an additive regression model with
    the following attributes:'
  prefs: []
  type: TYPE_NORMAL
- en: Piecewise linear or logistic growth trend
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yearly seasonal component modeled with a Fourier series
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weekly seasonal component modeled with dummy variables
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A user-provided list of holidays
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Installation of `Prophet` is more complicated, since it requires a compiler.
    The easiest way to install it is by using Anaconda, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: The accompanying Git repository contains the `conda` environment set up with
    `Prophet`.
  prefs: []
  type: TYPE_NORMAL
- en: The `Prophet` library requires the input DataFrame to include two columns—`ds`
    for date, and `y` for the value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s fit the `Prophet` model onto the previous dataset. Notice in the following
    code snippet that we explicitly tell `Prophet` we wish to receive monthly predictions
    (`freq=''M''`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The predicted values are very similar to the SARIMAX model, as can be seen
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – The Prophet library''s output includes prediction values, along
    with the model components'' values](img/Figure_6.15_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 – The Prophet library's output includes prediction values, along
    with the model components' values
  prefs: []
  type: TYPE_NORMAL
- en: The predicted values are stored in the `yhat` column with the `yhat_lower` and
    `yhat_upper` confidence intervals.
  prefs: []
  type: TYPE_NORMAL
- en: '`Prophet` does produce charts of Prophet components, which is useful for understanding
    the model''s prediction powers. A trend component chart can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – The trend component chart of the Prophet model](img/Figure_6.16_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 – The trend component chart of the Prophet model
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows the yearly seasonality output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.17 – The yearly seasonality component chart of the Prophet model](img/Figure_6.17_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – The yearly seasonality component chart of the Prophet model
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the output of the forecast chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – The forecast chart of the Prophet model along with the confidence
    intervals](img/Figure_6.18_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 – The forecast chart of the Prophet model along with the confidence
    intervals
  prefs: []
  type: TYPE_NORMAL
- en: Each time series model is slightly different and is best suited for different
    classes of time series. In general, however, the `Prophet` model is very robust
    and easiest to use in most scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to scikit-learn regression and classification
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: scikit-learn is a Python *supervised* and *unsupervised* machine learning library
    built on top of the `numpy` and `scipy` libraries.
  prefs: []
  type: TYPE_NORMAL
- en: Let's demonstrate how to forecast price changes on a dataset with `RidgeCV`
    regression and classification using scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: Generating the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s start by generating the dataset for the following examples—a Pandas
    DataFrame containing daily data for 20 years with `BookPressure`, `TradePressure`,
    `RelativeValue`, and `Microstructure` fields to represent some synthetic trading
    signals built on this dataset (also known as `PriceChange` field represents the
    daily change in prices that we are trying to predict (also known as `PriceChange`
    field a linear function of our predictors with random weights and some random
    noise. The `Price` field represents the actual price of the instrument generated
    using the `pandas.Series.cumsum(...)` method. The code can be seen in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s quickly inspect the true weights assigned to our four features, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s also inspect the DataFrame containing all the data, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s visually inspect the `Price` field, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot shows the following realistic-looking price evolution over 20 years:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – Price plot for the synthetically generated dataset](img/Figure_6.19_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.19 – Price plot for the synthetically generated dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s display a scatter matrix of all columns but the `Price` column, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The output is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Scatter matrix for the synthetically generated dataset](img/Figure_6.20_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.20 – Scatter matrix for the synthetically generated dataset
  prefs: []
  type: TYPE_NORMAL
- en: The scatter matrix shows that there is a strong relationship between `PriceChange`
    and `TradePressure`.
  prefs: []
  type: TYPE_NORMAL
- en: Running RidgeCV regression on the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's use a scikit-learn regression method to fit a linear regression model
    to our dataset. We will use the four features to try to fit to and predict the
    `PriceChange` field.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we collect the features and target into a DataFrame and a Series, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We will use `sklearn.linear_model.RidgeCV`, a linear regression model with
    L2 regularization (an L2 norm penalty factor to avoid overfitting) that uses cross-validation
    to learn the optimal coefficients. We will use the `sklearn.linear_model.RidgeCV.fit(...)`
    method to fit the target values using the features. The code is shown in the following
    snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a `RidgeCV` object, as can be seen here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'We can access the weights/coefficients learned by the `Ridge` model using the
    `RidgeCV.coef_` attribute and compare it with the actual coefficients, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'It seems the coefficients learned by the model are very close to the true weights,
    with some errors on each one of them, as can be seen in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'The `RidgeCV.score(...)` method returns the R2 score, representing the accuracy
    of a fitted model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'That returns the following R2 score with a maximum value of 1, so this model
    fits the data quite well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The `RidgeCV.predict(...)` method outputs the predicted price change values,
    which we combine with the `pandas.Series.cumsum(...)` method to generate the predicted
    price series, and then save it in the `PredPrice` field, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'That adds a new column to our DataFrame, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following code block, the true `Price` field is plotted alongside the
    predicted `PredPrice` field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The plot generated, as shown in the following screenshot, reveals that `PredPrice`
    mostly tracks `Price`, with some prediction errors during some time periods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Plot comparing the original price and the predicted price from
    a Ridge regression model](img/Figure_6.21_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.21 – Plot comparing the original price and the predicted price from
    a Ridge regression model
  prefs: []
  type: TYPE_NORMAL
- en: 'We can zoom in to the first quarter of 2010 to inspect the prediction errors,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following plot, displaying the differences between `Price`
    and `PredPrice` for that period:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.22 – Plot comparing the original and predicted price from a Ridge
    regression model for 2010 Q1](img/Figure_6.22_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.22 – Plot comparing the original and predicted price from a Ridge regression
    model for 2010 Q1
  prefs: []
  type: TYPE_NORMAL
- en: 'We can compute the prediction errors and plot them using a density plot, as
    shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'This generates the plot shown in the following screenshot, displaying the distribution
    of errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.23 – Plot displaying the distribution of prediction errors for the
    Ridge regression model](img/Figure_6.23_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.23 – Plot displaying the distribution of prediction errors for the
    Ridge regression model
  prefs: []
  type: TYPE_NORMAL
- en: The error plot displayed in the preceding screenshot shows that there is no
    strong bias in the errors.
  prefs: []
  type: TYPE_NORMAL
- en: Running a classification method on the dataset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let's demonstrate scikit-learn's classification methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create discrete categorical target labels for the classification
    model to predict. We assign `-2`, `-1`, `0`, `1`, and `2` numeric labels to these
    conditions respectively and save the discrete target labels in the `target_discrete
    pandas.Series` object, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'We can visualize the distribution of the five labels by using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a plot of frequency of occurrence of the five labels, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24 – Frequency distribution of our discrete target-price change-label
    values [-2, -1, 0, 1, 2]](img/Figure_6.24_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.24 – Frequency distribution of our discrete target-price change-label
    values [-2, -1, 0, 1, 2]
  prefs: []
  type: TYPE_NORMAL
- en: 'For the classification, we use an ensemble of decision tree classifiers provided
    by `sklearn.ensemble.RandomForestClassifier`. Random forest is a classifier that
    uses the bagging ensemble method and builds a forest of decision trees by training
    each tree on datasets generated by random sampling with replacements from the
    original dataset. Using a `max_depth=5` parameter, we limit the height of each
    tree to reduce overfitting and then call the `RandomForestClassifier.fit(...)`
    method to fit the model, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'This builds the following `RandomForestClassifier` fitted model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'The `RandomForestClassifier.score(...)` method returns the mean accuracy of
    the predictions compared to the `True` labels, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'As we can see here, the accuracy score is 83.5%, which is excellent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'We add the `DiscretePriceChange` and `PredDiscretePriceChange` fields to the
    DataFrame to hold the true labels and the predicted labels using the `RandomForestClassifier.predict(...)`
    method, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is the following DataFrame with the two additional fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following code block, we plot two fields for the first quarter of 2010:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'That yields a plot, as shown in the following screenshot, with some dislocations
    between the `True` and predicted labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.25 – Comparison of original and predicted discrete price-change
    labels from the RandomForest classification model for 2010 Q1](img/Figure_6.25_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.25 – Comparison of original and predicted discrete price-change labels
    from the RandomForest classification model for 2010 Q1
  prefs: []
  type: TYPE_NORMAL
- en: 'We can compute and plot the distribution of the `ClassificationErrors` DataFrame
    with the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'This yields the following error distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26 – Plot of distribution of classification errors from the RandomForest
    classifier model](img/Figure_6.26_B15029.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.26 – Plot of distribution of classification errors from the RandomForest
    classifier model
  prefs: []
  type: TYPE_NORMAL
- en: The classification errors are again without bias and are negligible.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All advanced trading algorithms use statistical models, whether for a direct
    trading rule or just for deciding when to enter/leave trading. In this chapter,
    we have covered the four key statistical libraries for Python—`statsmodels`, `pmdarima`,
    `fbprophet`, and `scikitlearn`.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we discuss how to import key financial and economic data
    into Python.
  prefs: []
  type: TYPE_NORMAL
