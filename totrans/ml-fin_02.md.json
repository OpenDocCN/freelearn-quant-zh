["```py\ndf['Fraud_Heuristic '] = np.where(((df['type'] == 'TRANSFER') &(df['amount'] > 200000)),1,0)\n```", "```py\nfrom sklearn.metrics import f1_score\n```", "```py\nf1_score(y_pred=df['Fraud_Heuristic '],y_true=df['isFraud'])\n```", "```py\nout: 0.013131315551742895\n\n```", "```py\nfrom sklearn.metrics import confusion_matrix cm = confusion_matrix(\n    y_pred=df['Fraud_Heuristic '],y_true=df['isFraud']) \nplot_confusion_matrix(cm,['Genuine','Fraud'])\n```", "```py\ndf['hour'] = df['step'] % 24\n```", "```py\nfrauds = []\ngenuine = []\nfor i in range(24):\n    f = len(df[(df['hour'] == i) & (df['isFraud'] == 1)])\n    g = len(df[(df['hour'] == i) & (df['isFraud'] == 0)])\n    frauds.append(f)\n    genuine.append(g)\n```", "```py\nfig, ax = plt.subplots(figsize=(10,6)) \nax.plot(genuine/np.sum(genuine), label='Genuine') \nax.plot(frauds/np.sum(frauds),dashes=[5, 2], label='Fraud') \nplt.xticks(np.arange(24))\nlegend = ax.legend(loc='upper center', shadow=True)\n```", "```py\nfig, ax = plt.subplots(figsize=(10,6))\nax.plot(np.divide(frauds,np.add(genuine,frauds)), label='Share of fraud')\nplt.xticks(np.arange(24))\nlegend = ax.legend(loc='upper center', shadow=True)\n```", "```py\ndfFraudTransfer = df[(df.isFraud == 1) & (df.type == 'TRANSFER')]\ndfFraudCashOut = df[(df.isFraud == 1) & (df.type == 'CASH_OUT')]\ndfFraudTransfer.nameDest.isin(dfFraudCashOut.nameOrig).any()\n```", "```py\nout: False\n\n```", "```py\ndfOdd = df[(df.oldBalanceDest == 0) &\n           (df.newBalanceDest == 0) & \n           (df.amount)]\nlen(dfOdd[(df.isFraud == 1)]) / len(dfOdd)\n```", "```py\nout: 0.7046398891966759\n\n```", "```py\nlen(dfOdd[(dfOdd.oldBalanceOrig <= dfOdd.amount)]) / len(dfOdd)\n```", "```py\nout: 0.8966412742382271\n\n```", "```py\ndf['type'] = 'Type_' + df['type'].astype(str)\n```", "```py\ndummies = pd.get_dummies(df['type'])\n```", "```py\ndf = pd.concat([df,dummies],axis=1)\n```", "```py\ndel df['type']\n```", "```py\nmap_dict = {}\nfor token, value in enumerate(df['type'].unique()):\n    map_dict[value] = token\n```", "```py\n{'CASH_IN': 4, 'CASH_OUT': 2, 'DEBIT': 3, 'PAYMENT': 0, 'TRANSFER': 1}\n\n```", "```py\ndf[\"type\"].replace(map_dict, inplace=True)\n```", "```py\nother_cols = [c for c in df.columns if ((c != 'type') and (c != 'isFraud'))]\n```", "```py\ninputs = []\noutputs = []\n```", "```py\nnum_types = len(df['type'].unique()) \ntype_embedding_dim = 3\n\ntype_in = Input(shape=(1,))\ntype_embedding = Embedding(num_types,type_embedding_dim,input_ length=1)(type_in)\ntype_out = Reshape(target_shape=(type_embedding_dim,))(type_embedding)\n\ntype_model = Model(type_in,type_out)\n\ninputs.append(type_in)\noutputs.append(type_out)\n```", "```py\nnum_rest = len(other_cols)\n\nrest_in = Input(shape = (num_rest,)) \nrest_out = Dense(16)(rest_in)\n\nrest_model = Model(rest_in,rest_out)\n\ninputs.append(rest_in)\noutputs.append(rest_out)\n```", "```py\nconcatenated = Concatenate()(outputs)\n```", "```py\nx = Dense(16)(concatenated)\nx = Activation('sigmoid')(x)\nx = Dense(1)(concatenated)\nmodel_out = Activation('sigmoid')(x)\n\nmerged_model = Model(inputs, model_out)\nmerged_model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n```", "```py\ntypes = df['type']\nrest = df[other_cols]\ntarget = df['isFraud']\n```", "```py\nhistory = merged_model.fit([types.values,rest.values],target.values, epochs = 1, batch_size = 128)\n```", "```py\nout:\nEpoch 1/1\n6362620/6362620 [==============================] - 78s 12us/step - loss: 0.0208 - acc: 0.9987\n\n```", "```py\namount, \noldBalanceOrig, \nnewBalanceOrig, \noldBalanceDest, \nnewBalanceDest, \nisFraud, \nisFlaggedFraud, \ntype_CASH_OUT, \ntype_TRANSFER, isNight\n```", "```py\ny_df = df['isFraud']\nx_df = df.drop('isFraud',axis=1)\n```", "```py\ny = y_df.values\nX = x_df.values\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n```", "```py\nFrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=42)\nX_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation\n```", "```py\nfrom keras.optimizers import SGD\n```", "```py\nmodel = Sequential()\nmodel.add(Dense(1, input_dim=9))\nmodel.add(Activation('sigmoid'))\n```", "```py\nmodel.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-5), metrics=['acc'])\n```", "```py\nmodel.fit(X_train_res,y_train_res, epochs=5, batch_size=256, validation_data=(X_val,y_val))\n```", "```py\nTrain on 3331258 samples, validate on 185618 samples Epoch 1/5\n3331258/3331258 [==============================] - 20s 6us/step - loss: \n3.3568 - acc: 0.7900 - val_loss: 3.4959 - val_acc: 0.7807 Epoch 2/5\n3331258/3331258 [==============================] - 20s 6us/step - loss: \n3.0356 - acc: 0.8103 - val_loss: 2.9473 - val_acc: 0.8151 Epoch 3/5\n3331258/3331258 [==============================] - 20s 6us/step - loss: \n2.4450 - acc: 0.8475 - val_loss: 0.9431 - val_acc: 0.9408 Epoch 4/5\n3331258/3331258 [==============================] - 20s 6us/step - loss: \n2.3416 - acc: 0.8541 - val_loss: 1.0552 - val_acc: 0.9338 Epoch 5/5\n3331258/3331258 [==============================] - 20s 6us/step - loss: \n2.3336 - acc: 0.8546 - val_loss: 0.8829 - val_acc: 0.9446\n\n```", "```py\ny_pred = model.predict(X_test)\n```", "```py\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred < 0.5] = 0\n```", "```py\nf1_score(y_pred=y_pred,y_true=y_test)\n```", "```py\nout: 0.054384286716408395\n\n```", "```py\ncm = confusion_matrix(y_pred=y_pred,y_true=y_test)\nplot_confusion_matrix(cm,['Genuine','Fraud'], normalize=False)\n```", "```py\nmodel = Sequential() \nmodel.add(Dense(16,input_dim=9)) \nmodel.add(Activation('tanh')) \nmodel.add(Dense(1)) \nmodel.add(Activation('sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer=SGD(lr=1e-5), metrics=['acc'])\n\nmodel.fit(X_train_res,y_train_res, epochs=5, batch_size=256, validation_data=(X_val,y_val))\n\ny_pred = model.predict(X_test)\ny_pred[y_pred > 0.5] = 1\ny_pred[y_pred < 0.5] = 0\n```", "```py\nf1_score(y_pred=y_pred,y_true=y_test)\n```", "```py\nout: 0.087220701988752675\n\n```", "```py\nfrom sklearn.tree import DecisionTreeClassifier\ndtree=DecisionTreeClassifier()\ndtree.fit(X_train,y_train)\n```", "```py\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=10,n_jobs=-1)\nrf.fit(X_train_res,y_train_res)\n```", "```py\ny_pred = rf.predict(X_test)\nf1_score(y_pred=y_pred,y_true=y_test)\n```", "```py\nout: 0.8749502190362406\n\n```", "```py\nimport xgboost as xgb\nbooster = xgb.XGBClassifier(n_jobs=-1)\nbooster = booster.fit(X_train,y_train)\ny_pred = booster.predict(X_test)\nf1_score(y_pred=y_pred,y_true=y_test)\n```", "```py\nout: 0.85572959604286891\n\n```"]