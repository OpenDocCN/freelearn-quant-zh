["```py\nn_days = [0, 1, 3, 5, 10, 25, 50, 100, 500]\noutcomes = sp500_binary.sample(n_days[-1])\np = np.linspace(0, 1, 100)\n\n# uniform (uninformative) prior\na = b = 1\nfor i, days in enumerate(n_days):\n    up = outcomes.iloc[:days].sum()\n    down = days - up\n    update = stats.beta.pdf(p, a + up , b + down)\n```", "```py\nwith pm.Model() as manual_logistic_model:\n    # coefficients as rvs with uninformative priors\n    intercept = pm.Normal('intercept', 0, sd=100)\n    b1 = pm.Normal('beta_1', 0, sd=100)\n    b2 = pm.Normal('beta_2', 0, sd=100)\n\n    # Likelihood transforms rvs into probabilities p(y=1)\n    # according to logistic regression model.    \n    likelihood = pm.invlogit(intercept + b1 * data.hours + b2 * data.educ)\n\n    # Outcome as Bernoulli rv with success probability \n    # given by sigmoid function conditioned on actual data \n    pm.Bernoulli(name='logit', p=likelihood, observed=data.income)\n```", "```py\nwith pm.Model() as logistic_model:  \n    pm.glm.GLM.from_formula('income ~ hours + educ', \n                            data, \n                            family=pm.glm.families.Binomial())\n```", "```py\nwith logistic_model:\n    map_estimate = pm.find_MAP()\nprint_map(map_estimate)\nIntercept   -6.561862\nhours        0.040681\neduc         0.350390\n```", "```py\nformula = 'income ~ sex + age+ I(age ** 2) + hours + educ'\n```", "```py\nwith logistic_model:\n    trace = pm.sample(draws=100, tune=1000,\n                      init='adapt_diag', # alternative initialization\n                      chains=4, cores=2,\n                      random_seed=42)\n```", "```py\nwith logistic_model:\n    callback = CheckParametersConvergence(diff='absolute')\n    approx = pm.fit(n=100000, \n                    callbacks=[callback])\n```", "```py\ntrace_advi = approx.sample(10000)\n```", "```py\nppc = pm.sample_ppc(trace_NUTS, samples=500, model=logistic_model)\nppc['y'].shape\n(500, 29170)\n```", "```py\nroc_auc_score(y_score=np.mean(ppc['y'], axis=0), \n              y_true=data.income)\n0.8294958565103577\n\n```", "```py\nX_shared = theano.shared(X_train.values\nwith pm.Model() as logistic_model_pred:\n    pm.glm.GLM(x=X_shared, labels=labels,\n               y=y_train, family=pm.glm.families.Binomial())\n```", "```py\nX_shared.set_value(X_test)\nppc = pm.sample_ppc(pred_trace, model=logistic_model_pred,\n                    samples=100)\n```", "```py\nmean_prior = data.stock.mean()\nstd_prior = data.stock.std()\nstd_low = std_prior / 1000\nstd_high = std_prior * 1000\n\nwith pm.Model() as sharpe_model:\n    mean = pm.Normal('mean', mu=mean_prior, sd=std_prior)\n    std = pm.Uniform('std', lower=std_low, upper=std_high)\n    nu = pm.Exponential('nu_minus_two', 1 / 29, testval=4) + 2.\n    returns = pm.StudentT('returns', nu=nu, mu=mean, sd=std, observed=data.stock)\n\n    sharpe = returns.distribution.mean / returns.distribution.variance ** .5 * np.sqrt(252)\n    pm.Deterministic('sharpe', sharpe)\n```"]