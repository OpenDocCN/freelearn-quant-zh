# 5

# Salesforce 的重塑：导航软件和大型语言模型（LLMs）

在*第四章*中，我们通过*约翰·迪尔*的财务景观深入探索了农业世界，运用了先进的财务分析技巧和创新的 AI 工具，如 ChatGPT 和 AutoGPT。这次探讨让我们通过复杂的财务比率、指标和估值方法，结合 Power BI 强大的数据可视化功能生动呈现了这一过程。同时，我们还涉及了 AI“幻觉”这一有趣的概念，揭示了如何在语言模型的背景下理解和应对这些现象。

在本章中，我们将通过 Salesforce 从面临挑战的公司到成为 AI 革命的领跑者的变革故事展开。这一过程将通过市场情感的视角进行讲解，而市场情感是投资者武器库中一项极为强大的工具。

本章从 Salesforce 的下滑开始，紧接着是激进投资者的果断干预。你将亲眼见证战略方向如何恢复信心并带来巨大的变化。情感分析的变革力量也将显现，揭示其在塑造并确认 Salesforce 复兴中的作用。

更重要的是，本章还将深入探索现代投资策略的世界。在这一部分，我们将介绍一项突破性的基于 AI 的期权交易策略，结合情感分析和 40 法则。在此过程中，我们将揭示如何利用这些方法优化你的交易决策。

你将学习如何使用 LangChain、ChatGPT 和 Streamlit 构建一个自主的激进 AI 代理。这将为你提供一个独特的视角，展示先进的 AI 工具如何重新塑造投资激进主义，提供的见解无疑将重新定义未来的投资方式。

本章的高潮是对**语言学习模型**（**LLMs**）的批判性评估。在这里，你将比较专有、开源和专门化的 LLMs 的格局。此探讨将帮助你了解适用于特定使用场景的理想选择，特别是与金融和投资相关的场景。

本章将涵盖以下主要内容：

+   Salesforce 的转机——市场情感视角

+   对 Salesforce 的深入分析——优势、劣势与竞争态势

+   Salesforce 的战略转折点和创新战略

+   基于 AI 的期权和股票交易策略——**软件即服务**（**SAAS**）的 40 法则和情感分析

+   用于情感期权跨期策略和 Salesforce 40 法则股票交易的 Power BI 可视化

+   ActivistGPT——使用 LangChain、ChatGPT 和 Streamlit 构建自主的激进 AI 代理，比较专有、开源和专门化的 LLMs

+   **开源与专有** **LLM 模型**

接下来的部分讲述了这家 CRM 巨头从 2022 年底增长停滞和投资者怀疑的黑暗时期，到 2023 年中期的非凡复兴，这一切都由一群精明的激进投资者精心策划。故事探索了市场情绪、战略转型以及最重要的，**人工智能**（**AI**）的创新应用在其中的决定性作用，生动地描绘了 Salesforce 如何转型为 AI 驱动销售解决方案的领导者。

# Salesforce 的逆转——从市场情绪的角度

在市场动态的引人入胜的故事中，很少有比逆袭的黑马更鼓舞人心的故事了。Salesforce，作为**客户关系管理**（**CRM**）领域的主导者，在 2022 年底和 2023 年初遇到了这样的困境。面对艰难的道路，Salesforce 的命运发生了戏剧性的转变，它从一个落后的企业变成了市场的领导者，这一切都归功于市场情绪和五位激进投资者的大胆策略。

故事始于市场季节的核心。曾经是华尔街之王的 Salesforce，发现自己在 2022 年底面临增长缓慢、竞争加剧和投资者信心下降的局面。市场对 Salesforce 的情绪非常低迷，其股价也反映了这一点。此时，市场情绪在交易中的艺术作用开始发挥作用。

## 凤凰的第一次飞行——识别下行趋势

通过使用先进的情绪分析工具，投资者可以从各种数据源中获取见解，包括新闻文章、社交媒体帖子、分析师报告，甚至财报电话会议的记录。尽管市场前景黯淡，我们的五位激进投资者看到了机会。他们明白，市场情绪往往会遮蔽公司内在价值，制造出可以被利用的不平衡。

## 战略计划——激进投资者出手

我们的激进投资者团队（*Elliott Management*、*Starboard Value*、*ValueAct*、*Inclusive Capital*和*Third Point*）在推动变革方面经验丰富，开始采取行动。他们购买了 Salesforce 的重大股份，反其道而行之，押注于市场情绪的逆转。他们有一个计划，通过发挥影响力改变公司的发展方向，重塑其战略。

## 恢复信心——一个大胆的新方向

激进投资者提出了战略转型的建议，专注于创新 Salesforce 的产品套件，并简化运营以降低成本。这些建议结合积极的沟通策略，开始创造积极的舆论。媒体开始讨论 Salesforce 的可能反转，逐步将市场情绪从负面转变为谨慎乐观。

## 看见变化——情绪分析的作用

随着潮流的转变，这一变化在情绪分析指标中得到了反映。赛富时相关的新闻头条开始出现诸如“改善”、“增长”和“潜力”等词汇。关于该股票的社交媒体讨论显示出越来越积极的趋势。这些信号为积极投资者的努力取得进展提供了定量证据，也表明情绪正在发生转变。

## 回报——扭转乾坤

快进到 2023 年 3 月，赛富时重新聚焦于创新，振兴了其产品套件，精简的运营提高了利润率，战略转型也重新点燃了其增长引擎。因此，赛富时不仅重新找回了立足之地，还变得更加强大，乘着积极的市场情绪和出色的财务业绩扬帆前行。

在这一令人激动的转机中，我们的五位积极投资者凭借他们对市场情绪的理解，看到了其他人未曾察觉的东西：赛富时在困境中的隐藏潜力。他们利用情绪分析的力量来把握时机、推动变革，并最终获得了丰厚的回报。

这个赛富时的故事是市场情绪在交易中力量的见证。它不仅是一个公司复兴的故事，更是创新、数据驱动的投资策略实力的展示。随着科技和金融的边界日益模糊，从市场情绪分析中汲取的见解，已经成为现代投资者的宝贵工具。

## 点燃 AI 革命——赛富时迈入下一个时代

随着赛富时（Salesforce）在 2022 年濒临崩溃后到 2023 年中期的惊人复兴大幕落下，舞台已经为更为激动人心的剧目——AI 革命——做好了准备。

销售，由于其重复性特征，成为了 AI 驱动颠覆的沃土。但 AI 不仅不会让销售人员变得过时，反而有望让其中最优秀的人才得到强化，而让其他人变得多余。到 2030 年，我们可能会看到一个大中型企业裁减销售人员达 50-70%的世界，而我们现在所熟知的销售经理职位可能不复存在。

对赛富时而言，在这个环境中生存并发展，关键在于一个重要方面——转型为一个以 AI 为中心的销售解决方案实体。新的赛富时需要将营销、数据和 CRM 任务融合为一个强大的 AI 驱动 UI/UX，帮助用户提升生产力、增强收入生成能力，并更有效地管理账户关系。

到目前为止，赛富时一直在积极表达其 AI 雄心，将 AI 为核心的论述贯穿其中。他们的 CRM 系统在行业领导者中占据重要地位，提供的解决方案通常优于如 HubSpot 等竞争对手，并与微软动态（Microsoft Dynamics）的产品高度契合，后者通过收购 LinkedIn 等战略性举措得到增强。

Salesforce CEO *马克·贝尼奥夫* 反复强调的 Einstein GPT 信任层，似乎是一个战略性决策，旨在主动解决潜在客户的顾虑。AI，特别是生成式 AI，可能对数据安全和隐私产生重大影响。通过强调 Salesforce 对信任、数据完整性和治理的承诺，贝尼奥夫旨在向客户保证这些方面将得到妥善管理。

对于像 AI 这样的技术要大规模采用，信任和数据安全至关重要。在这些领域的失误可能导致客户信心丧失、监管审查和潜在的法律后果。因此，似乎马克·贝尼奥夫正专注于建立信任这一坚实基础，从而为降低成本和增加收入等其他利益奠定基础。从某种意义上说，这种对信任的关注可以视为一种长期战略，用于可持续的增长和 AI 技术的采用。

展望未来，Salesforce 总裁兼首席工程官 *斯里尼·塔拉普拉贾达* 设想了朝着更自主的使用案例发展，其中 AI 模型可以自动处理事件和修复措施。然而，他也承认了挑战和微调的需求，以及信任和数据完整性的重要性。

以下部分深入探讨了围绕 Salesforce 的复杂动态——这家 CRM 领域的开创者以其强大的产品和创新的解决方案闻名，但也面临着自己的挑战。

# Salesforce 的综合 SWOT 分析

在本节中，我们将进行全面分析，揭示 Salesforce 在市场中的优势、弱点和潜在威胁，同时突显公司在竞争面前的强大韧性。此外，在我们穿行这些变动中，我们也在思考 Salesforce 可能采取的战略方向，塑造出一种独特的即刻行动与长期创新相结合的方案，以确保其持续增长和市场领导地位。

我们开始吧：

+   **优势**：

    +   **强大的品牌认知度**：得益于强大的品牌认知，Salesforce 在 CRM 领域占据主导地位。

    +   **丰富的产品组合**：Salesforce 提供广泛的服务，涵盖销售、营销和客户服务，提升了其吸引寻求集成解决方案的企业的魅力。

    +   **创新且用户友好**：Salesforce 因其创新的功能和用户友好的界面而常被称赞——这些因素显著提升了客户体验。

    +   **强大的生态系统**：Salesforce 的生态系统超越了其产品套件，拥有一个由第三方开发者和服务提供商构成的强大网络，为其平台提供支持。

+   **弱点**：

    +   **定价**：Salesforce 的服务通常比竞争对手更昂贵，这使得它对小型企业或初创公司吸引力较低。2023 年最新的 9%（平均）涨价无疑没有解决这个问题。AI Cloud 刚刚发布，初始年费为 36 万美元。

    +   **复杂性**：虽然 Salesforce 提供了全面的功能套件，但这也可能导致某些用户遇到复杂性和陡峭的学习曲线。

    +   **对第三方应用的依赖**：为了访问某些功能，Salesforce 经常需要第三方集成，这可能会增加成本和技术难度。

+   **竞争者分析**：

    +   **微软**：凭借其 Dynamics 365 套件，微软已经在 CRM 市场中占据了重要地位。与其他微软产品（如 Office 365）的无缝集成，以及其 AI 和机器学习平台日益增长的能力，可能使 Dynamics 365 成为一个强大的竞争者。

    +   **Adobe**：Adobe Experience Cloud 拥有强大的营销、分析和商业功能，可能会对 Salesforce 构成威胁，特别是在营销领域。Adobe 在数字内容和数据管理方面的优势，加上与微软等战略合作伙伴的合作，可能帮助其获得更多的市场份额。

    +   **SAP**：作为全球领先的企业软件供应商之一，SAP 拥有广泛的客户基础，可以销售其 SAP Customer Experience 套件。其在 ERP 方面的优势，也可能帮助其比 Salesforce 更有效地整合 CRM 和 ERP 功能。

    +   **Oracle**：与 SAP 类似，Oracle 在企业软件和数据库解决方案中的长期存在可能帮助它在 CRM 市场中赢得份额，特别是在其现有客户群中。

    +   **HubSpot**：以其营销工具和用户友好的界面而闻名，HubSpot 可能是 **中小型企业**（**SMB**）领域的强劲竞争者。

    +   **新兴玩家**：许多较小且更灵活的公司，如 Pipedrive、Zoho CRM 和 Freshsales，具有在 SMB 市场中占据重要份额的潜力。这些公司可以快速创新并提供具有竞争力的定价。

虽然很难预测谁能够“击败”Salesforce，但每个竞争者都有其优势，这些优势可能帮助它们在 CRM 市场中占据更多份额。这个行业正在快速发展，新技术和不断变化的客户期望在塑造竞争格局中扮演着重要角色。

Salesforce 是一家广泛分析的公司，其许多优势和劣势已经为竞争者和华尔街所熟知。然而，仍有一些方面可能不为人所深刻理解或广泛讨论：

+   **积极因素**：

    +   **生态系统**：Salesforce 围绕其平台创建了一个庞大的生态系统，其中包括**独立软件供应商**（**ISVs**）、**系统集成商**（**SIs**）以及一个庞大的开发者社区。这个充满活力的生态系统创造了一个网络效应，增强了公司在竞争中的地位，而这一点常常被忽视。

    +   **Trailhead 与技能发展**：Salesforce 的 Trailhead 平台是一个免费的在线学习平台，专门教授 Salesforce 相关知识，创造了一个不断增长的潜在 Salesforce 员工和客户池。这确保了平台上有稳定的熟练工作者供应，并有助于其推广——这一资产常被低估。

    +   **慈善云**：慈善云是一个帮助企业管理慈善活动的独特产品，虽然并未引起太多关注，但它为 Salesforce 的综合服务套件增添了价值，并可能为公司开辟新的市场。

+   **负面因素**：

    +   **复杂性**：虽然 Salesforce 广泛的产品系列使其能够满足各种业务需求，但也增加了实施的复杂性，可能使得实施变得具有挑战性。潜在客户往往低估了这一方面，结果可能导致不满。

    +   **定价**：Salesforce 的服务被认为是高质量的，但对于中小型企业来说，价格也相对较高。批评者认为公司在解决这个问题方面做得不够，未能使其产品对小型企业更加可及。

    +   **整合挑战**：虽然 Salesforce 进行了一些重要的收购，但将这些技术和服务整合成一个无缝的产品仍然是一个挑战，有时会导致不连贯的用户体验。

当我们深入研究 Salesforce 时，必须理解这家科技巨头正处于其公司发展历程中的一个关键十字路口。在接下来的部分中，我们将探讨 Salesforce 在应对即时财务需求的同时，如何平衡其长期创新战略。

## Salesforce – 战略拐点

以下是 Salesforce 如何平衡这些取悦激进投资者的即时行动与长期举措，以避免像 IBM 和 Oracle 那样走上财务工程管理股价的道路：

+   **股票回购与提高效率**：Salesforce 实施了 200 亿美元的股票回购计划，并通过裁减 10%的员工来减少开支。这有助于提高短期盈利能力，并可与提升效率的创新（如 AI 自动化）相结合，从而为长期投资和战略举措释放资源。

+   **Salesforce Skunkworks**：建立一个先进的研究部门，专门开发下一代技术，可以确保 Salesforce 保持领先地位，并继续颠覆市场，而不仅仅是维持现有地位。

+   **涨价与 Salesforce 大学**：Salesforce 已将价格提高了 9%，短期内可以承受。然而，为了确保客户持续看到其投资的价值，Salesforce 可以建立一所大学，培养高技能的劳动力，推动持续的创新和客户满意度。

+   **重塑远程工作**：尽管 Salesforce 最近要求员工回到办公室，但同时也可以投资于先进的远程协作工具。这将满足现代职场人士日益多样化的工作方式，提供灵活性与协作的理想结合。

+   **碳负目标**：像实现碳负排放这样的环保目标可以提升 Salesforce 的声誉，吸引环保意识强的客户和投资者，并有效抵消因削减成本措施带来的负面影响。

+   **数字公民倡议**：倡导改善数据隐私、安全性和 AI 伦理问题，可以将 Salesforce 树立为负责任的科技领袖，并可能为其运营创造更有利的监管环境。

+   **扩展 Salesforce 生态系统**：鼓励更多的应用开发者加入生态系统，可能进一步提升 Salesforce 平台的功能性和吸引力，推动长期客户忠诚度和收入增长。

+   **AI 驱动的 CRM 演进**：持续投资于 AI 以提升其 CRM 平台，可以确保 Salesforce 在竞争中保持领先地位，并能在客户眼中证明其高端定价的合理性。

+   **医疗和金融服务解决方案**：专注于为高增长领域提供专业解决方案，可以创造新的收入来源，从而弥补因削减成本措施而失去的收入。

通过将这些立即行动与建议的创新长期战略相结合，Salesforce 可以同时实现短期财务目标和可持续、面向未来的增长。

在接下来的部分中，我们将探讨在动态的期权交易世界中，如何利用 AI 和先进的情感分析工具。借助 Salesforce 的 AI 驱动 CRM 发展，我们将采用**自然语言处理**（**NLP**）技术和机器学习算法，精确地剖析市场情绪。这一严格的情感分析，使用 NLTK 和 TextBlob 等工具，为精准的情感调整跨期交易策略奠定基础，从而为您带来更有效且更有利可图的交易体验。整个过程由 Python 编程语言提供支持，并通过互动式 Power BI 可视化呈现，让您对市场脉搏有无与伦比的洞察。

# 利用 AI 和情感分析 – Salesforce 情感调整期权跨期交易

创建一个结合人工智能驱动的 CRM 演进与情感调整的跨式期权策略的计划，涉及监控关于 Salesforce 人工智能驱动的 CRM 演进的情感，并根据该情感设置期权交易。

情感调整的跨式期权策略涉及购买具有相同到期日但不同行使价的看涨期权和看跌期权，你可以根据情感来调整这些期权。

这是使用 Python 实现该策略的简化步骤概述，假设你已经能够访问期权定价数据和情感分析结果：

1.  如果尚未安装 `pip`，请首先安装它。一旦你设置好了 Python，可以使用 `pip`（Python 包管理器）来安装库。打开命令提示符或终端，输入以下命令：

    ```py
    pip install pandas yfinance matplotlib nltk requests
    ```

    安装完成后，在你的 Python 脚本中导入必要的库：

    ```py
    import pandas as pd
    import yfinance as yf
    import matplotlib.pyplot as plt
    from nltk.sentiment.vader import SentimentIntensityAnalyzer
    import requests
    import datetime as dt
    ```

1.  使用 `yfinance` 库获取 Salesforce 的期权数据。以下是一个示例代码：

    ```py
    # specify the ticker symbol and get the data
    data = yf.Ticker('CRM')
    # Get options expiring on December 15, 2023
    options = data.option_chain('2023-12-15')
    calls = options.calls
    puts = options.puts
    ```

1.  `Marketaux 的网站` 在 [`www.marketaux.com/`](https://www.marketaux.com/) 并点击 **GET FREE API KEY** 注册一个免费的 API 密钥。

    **这是** **API 调用**：

    ```py
    import requests
    def get_marketaux_news():
          url = 'https://marketaux.com/api/v1/news'  # Update this if the endpoint is different
          params = {
                    'apikey': 'your-api-key-here',
                    'ticker': 'CRM'
         }
         response = requests.get(url, params=params)
         return response.json()
    news_data = get_marketaux_news()
    ```

    用你注册时获得的 Marketaux API 密钥替换 `'your-api-key-here'`。现在，你可以调用 `get_marketaux_news()` 来获取 CRM 的金融新闻。

1.  **数据标注**：在这里，我们将使用 MarketAux API 来提取 CRM 的金融新闻。

    要自动标注数据，我们可以使用自然语言处理（NLP）技术。Python 的 NLTK 库，以及其他流行的库如 TextBlob，可以用来确定文本的情感倾向。这是一种简单的情感分析。然而，请注意，这种自动情感分析可能并不总是完美的，并且可能存在一些不准确之处：

    ```py
    from textblob import TextBlob
    def label_sentiment(text):
        analysis = TextBlob(text)
        if analysis.sentiment.polarity > 0:
            return 1
        elif analysis.sentiment.polarity < 0:
            return -1
        else:
            return 0
    # Example usage:
    text = "Salesforce had an amazing quarter with record profits."
    label = label_sentiment(text)
    print(label)  # Outputs: 1
    ```

    在这个脚本中，`label_sentiment` 函数接收一段文本作为输入，使用 `TextBlob` 计算其情感倾向，然后返回一个标签：`1` 代表正面情感，`-1` 代表负面情感，`0` 代表中立情感。

    现在，假设你已经提取了一些关于 Salesforce 的新闻文章。然后，你可以使用 `label_sentiment` 函数自动为每篇文章分配一个情感标签，如下所示：

    ```py
    # Assume `articles` is a list of articles about Salesforce
    for article in articles:
        label = label_sentiment(article)
        print(f"Article: {article[:50]}... Label: {label}")
    ```

    请记住，这种自动情感标注方法非常简单，可能并不完全准确，特别是对于复杂或有细微差别的文本。要实现更复杂的情感分析模型，你可以考虑使用机器学习技术，并在一个预标注的金融情感数据集上训练模型。

    至于自动化过程无法处理的手动数据标注，你可以简单地将这些文本呈现给用户，并请求他们的反馈，如下所示：

    ```py
    for article in articles:
        label = label_sentiment(article)
        if label == 0:  # If the automated process labels the text as neutral
            print(f"Article: {article}")
            user_label = input("Is this article positive (1), negative (-1), or neutral (0)? ")
            # Then store the user's label somewhere for later use
    ```

    这将允许用户为自动化过程标注为中立的文本提供自己的情感标签，从而随着时间的推移进一步提升你的情感分析能力。记住，你需要一种方法将这些用户提供的标签存储在数据库或其他持久化存储系统中，以备将来使用。

1.  `sqlite3` 模块。

    以下是关于如何创建 SQLite 数据库并存储标注好的情感分析数据的逐步指南：

    1.  导入所需的库：

        ```py
        import sqlite3
        from sqlite3 import Error
        ```

    1.  创建到 SQLite 数据库的连接。如果数据库不存在，将会创建一个：

        ```py
        def create_connection():
            conn = None;
            try:
                conn = sqlite3.connect('sentiment_analysis.db') # Creates a SQLite database named 'sentiment_analysis.db'
                print(f'successful connection with sqlite version {sqlite3.version}')
            except Error as e:
                print(f'Error {e} occurred')
            return conn
        conn = create_connection()
        ```

    1.  创建一个表来存储情感分析数据：

        ```py
        def create_table(conn):
            try:
                query = '''
                    CREATE TABLE IF NOT EXISTS sentiment_data (
                        id integer PRIMARY KEY,
                        article text NOT NULL,
                        sentiment integer NOT NULL
                    );
                '''
                conn.execute(query)
                print('Table created successfully')
            except Error as e:
                print(f'Error {e} occurred')
        create_table(conn)
        ```

    1.  将标注好的情感分析数据插入数据库：

        ```py
        def insert_data(conn, data):
            try:
                query = '''
                    INSERT INTO sentiment_data(article, sentiment) VALUES(?,?)
                '''
                conn.execute(query, data)
                conn.commit()
                print('Data inserted successfully')
            except Error as e:
                print(f'Error {e} occurred')
        # Let's assume that the sentiment_data list contains tuples of articles and their respective sentiment
        sentiment_data = [("Salesforce announces record profits", 1), ("Salesforce's latest product failed to impress", -1)]
        for data in sentiment_data:
            insert_data(conn, data)
        ```

    1.  从数据库中获取数据：

        ```py
        def fetch_data(conn):
            try:
                query = 'SELECT * FROM sentiment_data'
                cursor = conn.execute(query)
                rows = cursor.fetchall()
                for row in rows:
                    print(row)
            except Error as e:
                print(f'Error {e} occurred')
        fetch_data(conn)
        ```

    ```py
    conn.close()
    ```

这是存储情感分析数据的一种简单方式。

+   **分析情感**：要对存储在 SQLite 数据库中的数据进行情感分析，可以按照以下子步骤进行操作。

    在这个示例中，我们将从 SQLite 数据库中提取数据，并应用**词袋模型**（**BoW**）方法，结合**词频-逆文档频率**（**TF-IDF**）特征提取，随后使用逻辑回归进行情感分类：

    1.  从 SQLite 数据库中提取数据：

        ```py
        import sqlite3
        import pandas as pd
        def fetch_data():
            conn = sqlite3.connect('sentiment_analysis.db')
            query = 'SELECT * FROM sentiment_data'
            df = pd.read_sql_query(query, conn)
            conn.close()
            return df
        df = fetch_data()
        ```

    1.  将数据划分为训练集和测试集：

        ```py
        from sklearn.model_selection import train_test_split
        X = df['article']
        y = df['sentiment']
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        ```

    1.  使用 TF-IDF 词袋模型进行特征提取：

        ```py
        from sklearn.feature_extraction.text import TfidfVectorizer
        vectorizer = TfidfVectorizer(use_idf=True, max_df=0.95)
        X_train_vectorized = vectorizer.fit_transform(X_train)
        ```

    1.  训练一个逻辑回归模型进行情感分类：

        ```py
        Python
        from sklearn.linear_model import LogisticRegression
        model = LogisticRegression()
        model.fit(X_train_vectorized, y_train)
        ```

    1.  转换测试数据并预测情感：

        ```py
        X_test_vectorized = vectorizer.transform(X_test)
        y_pred = model.predict(X_test_vectorized)
        ```

    1.  评估模型的表现：

        ```py
        from sklearn.metrics import classification_report
        print(classification_report(y_test, y_pred))
        ```

    这段代码将训练一个逻辑回归模型，应用于你的情感标注新闻文章。分类报告将显示模型的表现，包括精准率、召回率和 F1 分数等指标。

    请记住，模型的成功取决于标注数据的质量和数量。此外，文本数据通常需要一些预处理步骤，如转换为小写、去除标点符号以及词形还原或词干提取，以提高模型的效果。你可能需要尝试这些步骤，以获得最佳结果。

    +   使用 `yfinance` 库下载 Salesforce 的期权链数据。以下是如何操作的示例：

    ```py
    import yfinance as yf
    # Define the ticker symbol
    ticker = yf.Ticker('CRM')
    # Get options expirations
    expiry_dates = ticker.options
    # Create empty dataframes to store calls and puts
    calls = pd.DataFrame()
    puts = pd.DataFrame()
    # Loop through all expiry dates and download option chain data
    for expiry in expiry_dates:
        # Check if the expiry is in the desired range (June 30, 2023 – December 15, 2023)
        expiry_date = pd.to_datetime(expiry)
        start_date = pd.to_datetime('2023-06-30')
        end_date = pd.to_datetime('2023-12-15')
        if start_date <= expiry_date <= end_date:
            option_chain = ticker.option_chain(expiry)
            # Add the expiry date to the dataframes
            option_chain.calls['expiry'] = expiry_date
            option_chain.puts['expiry'] = expiry_date
            # Append the data to the main dataframes
            calls = calls.append(option_chain.calls)
            puts = puts.append(option_chain.puts)
    # Reset the index of the dataframes
    calls.reset_index(drop=True, inplace=True)
    puts.reset_index(drop=True, inplace=True)
    print("Calls Data:")
    print(calls.head())
    print("\nPuts Data:")
    print(puts.head())
    ```

    该脚本将创建两个数据框，`calls` 和 `puts`，分别包含 Salesforce 股票在指定时间段内的看涨期权和看跌期权。数据框中的每一行表示一个期权合约，列则表示期权的不同特性，如执行价格（`strike`）、期权价格（`lastPrice`）、隐含波动率（`impliedVolatility`）等。

    最后的示例是一个基础示例，旨在为金融新闻和期权定价提供情感分析。它没有考虑市场隐含波动率和历史波动率等复杂的市场动态，这些因素会显著影响结果。虽然这个示例作为基础，但现实中的场景需要更为深入的分析，以准确描绘市场行为和结果。

    波动率是期权交易中的一个关键指标，用来衡量标的资产价格波动的程度，从而影响期权价格。两种主要的波动率类型，**历史波动率**（**HV**）和**隐含波动率**（**IV**），在期权交易中起着至关重要的作用。较高的波动率通常会导致期权溢价较高，因为不确定性增加，帮助交易者评估期权的相对成本和潜在价格变动，并据此制定策略。

    请记住，脚本运行的时间可能会比较长，这取决于期权的到期日期数量。此外，期权链数据的实际结构和内容可能会根据数据源和市场条件有所不同。请始终检查数据，并根据需要调整脚本。

    +   **根据情绪选择行权价格，并选择看涨和看跌期权的行权价格**：一种简单的方法是先取所有可用期权的均值（平均）行权价格作为起点，然后根据情绪向上或向下调整。如果情绪为正面，选择一个高于均值的看涨行权价格和一个低于均值的看跌行权价格。如果情绪为负面，选择一个低于均值的看涨行权价格和一个高于均值的看跌行权价格：

    ```py
    # Compute mean strike price for calls and puts
    mean_call_strike = calls['strike'].mean()
    mean_put_strike = puts['strike'].mean()
    # Factor to adjust the strike prices. This can be tweaked based on how strongly you want to react to the sentiment
    adjustment_factor = 0.05
    if average_sentiment > 0:
        # Sentiment is positive, lean bullish
        call_strike = mean_call_strike * (1 + adjustment_factor)  # Choose a call strike higher than mean
        put_strike = mean_put_strike * (1 - adjustment_factor)  # Choose a put strike lower than mean
    else:
        # Sentiment is negative, lean bearish
        call_strike = mean_call_strike * (1 - adjustment_factor)  # Choose a call strike lower than mean
        put_strike = mean_put_strike * (1 + adjustment_factor)  # Choose a put strike higher than mean
    # Round the strike prices to the nearest available strike
    call_strike = calls.iloc[(calls['strike']-call_strike).abs().argsort()[:1]]
    put_strike = puts.iloc[(puts['strike']-put_strike).abs().argsort()[:1]]
    print("Chosen Call Strike Price:", call_strike)
    print("Chosen Put Strike Price:", put_strike)
    ```

重要提示

请注意，`adjustment_factor` 在这个示例中是相对任意的。该脚本根据情绪分析将均值行权价格上下调整 5%。此参数可以根据你希望期权策略对情绪分析结果反应的强度进行调整。较高的值会导致更积极的调整，而较低的值则会导致更保守的调整。

`calls` 数据框存储了关于 Salesforce 可用的看涨期权信息。`mean_call_strike` 是通过该数据框的“strike”列计算得出的。然后，基于情绪分析，选择一个高于或低于该均值的看涨行权价格。

`puts` 数据框存储了关于 Salesforce 可用的看跌期权信息。`mean_put_strike` 是通过该数据框的“strike”列计算得出的。然后，基于情绪分析，选择一个高于或低于该均值的看跌行权价格。

最终选择的行权价格（`call_strike` 和 `put_strike`）将被打印出来。

1.  **设置跨式期权交易**：以下是通过选择我们在看涨和看跌数据框中与我们选择的行权价格对应的行来购买期权，并存储该信息的示例：

    ```py
    # Select the option data for the chosen call and put strike prices
    chosen_call_option = calls.loc[calls['strike'] == call_strike]
    chosen_put_option = puts.loc[puts['strike'] == put_strike]
    # Print the details of the options you are "buying"
    print("Buying Call Option")
    print(chosen_call_option)
    print("\nBuying Put Option")
    print(chosen_put_option)
    ```

    在这个示例中，`chosen_call_option` 和 `chosen_put_option` 是包含我们所“购买”的看涨期权和看跌期权信息的数据框。

重要提示

请注意，上述代码仅是购买期权的简单示范；它并不会实际执行交易。在实时交易环境中，你将使用经纪商的 API 来执行这些交易，通常需要提供你的账户信息，并确认你愿意接受与期权交易相关的风险。在尝试交易期权之前，请务必充分理解这些风险。

1.  将 `calls` 和 `puts` 数据框导出为 CSV 文件。你可以在 Python 中使用 `pandas` 的 `to_csv` 函数来做到这一点：

    ```py
    calls.to_csv('calls.csv', index=False)
    puts.to_csv('puts.csv', index=False)
    ```

1.  将 SQLite 数据导出为 CSV：接下来，你需要将存储在 SQLite 数据库中的数据导出为 CSV 文件。以下是你可以在 Python 中实现的方法：

    ```py
    import pandas as pd
    import sqlite3
    # Create a connection to the SQLite database
    con = sqlite3.connect('sentiment_analysis.db')
    # Read the data from the SQLite database into a pandas DataFrame
    df = pd.read_sql_query("SELECT * from sentiment_table", con)
    # Export the DataFrame to a CSV file
    df.to_csv('sentiment.csv', index=False)
    # Don't forget to close the SQLite connection
    con.close()
    ```

1.  将 `sentiment_table` 替换为你在 SQLite 数据库中表的实际名称。

1.  在 Power BI 中导入数据：启动 Power BI 并开始一个新项目。点击`date`，你可以在 Power BI 中设置关系。点击 *x* 轴上的`date` 和 *y* 轴上的`sentiment`。你还可以创建表格或矩阵来展示你的选项数据。通过点击 **Visualizations** 面板中的图标，然后拖拽你想要可视化的字段，可以创建这些内容。

1.  刷新数据：要用新数据更新你的 Power BI 报告，你需要刷新数据。你可以通过点击 **Home** 栏中的 **Refresh** 来手动刷新，或者如果你的数据源是本地或网络路径中的 CSV 文件，你也可以在 **Data source settings** 中设置自动刷新。

重要提示

请注意，如果你拥有 Power BI Pro 或 Premium 版本，你可以使用 Power BI 的 Power Automate 功能，直接连接到各种数据源（如你的 SQLite 数据库），并设置实时刷新。这将避免你将数据导出为 CSV 文件并手动管理刷新。

在接下来的章节中，体验先进的情感分析工具、40 法则应用以及人工智能驱动的技术相结合，使你的 Salesforce 股票交易更加高效。

## 人工智能、40 法则（SaaS 指标）与情感分析 —— 精通 Salesforce 股票交易

在这一部分，我们将利用 **40 法则** 来评估 SaaS 公司中的增长与盈利性之间的权衡，为 Salesforce 的健康状况提供一个有洞察力的快照。进一步地，我们将使用情感分析工具，如 NLTK、TextBlob 和 VaderSentiment，来剖析市场情绪。这种定量的财务分析与定性的情感评估相结合，通过 Python 执行时，能够制定出一个精准的情感调整交易指南，从而提升你的交易决策效果。我们还将通过实践 Python 代码、网页抓取技术，以及诸如 BERT 等高级 NLP 工具的演示，进一步丰富这个指南，帮助你全面理解。准备好沉浸在金融与数据科学交织的世界中吧！

SaaS 公司的 40 法则是投资者用来评估这些公司在增长和盈利能力之间权衡的一个指南。

对于 Salesforce，40 法则的公式如下：SaaS 公司收入的增长率，加上其自由现金流的利润率，应该超过 40%。这一计算帮助通过同时考虑公司的增长和盈利能力，提供公司健康状况的全面快照。

例如，如果 Salesforce 的增长率为 10%，自由现金流利润率为 30%，那么它符合 40 法则。这个法则可以帮助投资者评估一个 SaaS 公司运营的效率和平衡。40 法则结合其他衡量标准，如市场情绪，为投资者提供了一种比较公司表现的方法，帮助判断 Salesforce 股票是否值得买入或卖出。

下面是一个大致的示例，展示如何使用 Python 代码处理 Salesforce 从 2022 年第三季度到 2024 年第一季度的数据。我们将使用 pandas，这是一个强大的 Python 数据处理库：

1.  计算历史信息的 40 法则：

    ```py
    pip install beautifulsoup4 requests
    import pandas as pd
    data = {
        "Quarter": ["Q3 2023", "Q4 2023", "Q1 2024"],
        "Revenue Growth": [0.14, 0.14, 0.11],
        "FCF Margin": [0.014, 0.299, 0.507],
        "Stock Price": [128.27, 167.35, 223.38]
    }
    df = pd.DataFrame(data)
    # Calculate Rule of 40
    df["Rule of 40"] = df["Revenue Growth"] + df["FCF Margin"]
    *Stock prices are the closing price at the end of the following trading days – lowest price in 2022 after Q3 2023 earnings call – 12/16/22, March 1, 2023 and May 31, 2023
    ```

1.  从新闻网站提取关于 Salesforce 的文章和评论，涵盖一个历史时期——使用`BeautifulSoup`选项。

    这是一个示例，展示如何在 Python 中使用`BeautifulSoup`库从一个假设的新闻网站抓取评论：

    ```py
    import requests
    from bs4 import BeautifulSoup
    # URL of the news article
    url = 'https://www.newswebsite.com/salesforce_article'
    # Send a GET request
    response = requests.get(url)
    # Parse the HTML content of the page with BeautifulSoup
    soup = BeautifulSoup(response.content, 'html.parser')
    # Find the comments. The details of how to do this will depend on how the website is structured.
    # Here we're assuming each comment is in a div with the class 'comment'
    comments = soup.find_all('div', class_='comment')
    # Extract the text of each comment
    comment_texts = [comment.get_text() for comment in comments]
    # Now comment_texts is a list of the text of each comment
    ```

    请记住，这是一个简化的示例，实际实现可能会非常复杂，原因在于网页上的 HTML 往往是非结构化的，且杂乱无章。此外，如果你想从多个网站提取信息，复杂度会进一步增加，因为每个网站的结构和类名可能不同。

    要从其他来源（如 Twitter，现在称为 X）收集数据，你可能需要使用 API。Twitter 提供了访问推文和其他数据的 API，但你需要申请访问权限，并遵守其使用政策。

    一旦你收集到这些评论，就可以像前面新闻标题的示例那样分析它们的情感。请注意，由于评论中常常使用非正式语言，它们可能更难分析，因此你可能需要更复杂的 NLP 工具。

    对于更高级的读者，下面是一个复杂的 NLP 工具示例，用于协助进行评论的情感分析。

1.  为 Salesforce 在某个历史时期评估市场情绪——使用`VaderSentiment`选项。

    为了评估市场情绪，我们可以使用 Python 中的 NLP 库，如`VaderSentiment`。这包括从财经新闻和社交媒体帖子中提取文本数据，然后分析这些文本的情感。

    这是一个简化的示范，展示如何使用`VaderSentiment`库从新闻标题中评估情感。

    首先，你需要获取新闻数据。你可以通过多种方式来实现，具体方法取决于新闻的来源。如果你从网站上获取新闻，你可以使用像`BeautifulSoup`这样的网页抓取工具。如果你使用的是提供 API 的服务，你可以通过 API 获取数据。

    假设你有一个包含新闻标题及其日期的列表，存储在名为`news_df`的数据框中。它可能如下所示：

    ```py
    news_data = {
        'Date': ['2022-11-30', '2022-12-01', '2022-12-02', '2023-10-15'],
        'Headline': [
            'Salesforce announces record earnings',
            'Analysts concerned about Salesforce growth',
            'Salesforce acquires new startup, boosting portfolio',
            'Salesforce struggles to meet this quarter earnings expectation',
        ],
    }
    news_df = pd.DataFrame(news_data)
    news_df['Date'] = pd.to_datetime(news_df['Date'])
    ```

    使用`VaderSentiment`库分析每个新闻标题的情感。你可以将这些数据作为新列添加到你的数据框中：

    ```py
    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
    analyzer = SentimentIntensityAnalyzer()
    def get_sentiment(score):
        if score < -0.05:
            return "Negative"
        elif score > 0.05:
            return "Positive"
        else:
            return "Neutral"
    news_df['Sentiment'] = news_df['Headline'].apply(lambda headline: get_sentiment(analyzer.polarity_scores(headline)['compound']))
    sentiment_over_time = news_df.groupby('Date')['Sentiment'].value_counts().unstack().fillna(0)
    ```

    这将为你提供一个新的数据框，名为`sentiment_over_time`，显示每一天的不同情感（积极、消极和中立）的数量。

    请注意，这是一个简化的示例，实际应用中会涉及更复杂的分析。

    若要包含新闻文章和其他数据源中的评论，你可能需要使用网页抓取工具。然而，必须注意，从这些平台抓取评论可能违反它们的服务条款，你应始终确保你的数据收集方法符合所有相关法律和法规。

1.  使用 NLP 评估历史时期的市场情感——Python 中的`transformers`库，它提供了一个简单的接口来使用一系列预训练模型。

    这是一个使用 BERT 进行情感分析的简单示例：

    ```py
    pip install transformers
    from transformers import pipeline
    # Initialize the sentiment analysis pipeline
    nlp = pipeline("sentiment-analysis")
    # Analyze the sentiment of a comment
    comment = "Salesforce had an incredible quarter!"
    result = nlp(comment)[0]
    # Print the result
    print(f"label: {result['label']}, with score: {result['score']}")
    transformers library might not perform well on informal language or slang often found in comments. You might need to fine-tune the model on a dataset of comments to get better results, which is a more involved process.
    ```

1.  通过包括新闻文章中的用户评论来使用 NLP 评估 Salesforce 的市场情感，历史时期——BERT 选项。

    如果你有一个包含情感标签的大型评论数据集，你可以利用这些数据来训练你的 BERT 模型，以更好地理解在特定上下文中的情感。这涉及使用`transformers.Trainer`和`transformers.TrainingArguments`类，这大致如下所示：

    ```py
    from transformers import BertForSequenceClassification, Trainer, TrainingArguments
    # Initialize a model and training arguments
    model = BertForSequenceClassification.from_pretrained("bert-base-uncased")
    training_args = TrainingArguments(
        output_dir='./results',          # output directory
        num_train_epochs=3,              # total number of training epochs
        per_device_train_batch_size=16,  # batch size per device during training
        per_device_eval_batch_size=64,   # batch size for evaluation
        warmup_steps=500,                # number of warmup steps for learning rate scheduler
        weight_decay=0.01,               # strength of weight decay
    )
    # Initialize a trainer with your model and training args
    trainer = Trainer(
        model=model,                         # the instantiated Transformers model to be trained
        args=training_args,                  # training arguments, defined above
        train_dataset=train_dataset,         # training dataset
        eval_dataset=test_dataset            # evaluation dataset
    )
    # Train the model
    trainer.train()
    ```

    在这里，`train_dataset`和`test_dataset`将是包含评论及其关联情感标签的数据集。模型将从`train_dataset`中的标注示例中学习，而`test_dataset`将用于评估其性能。

    像这样的 BERT 模型微调需要大量的计算资源，可能无法在标准的个人计算机上实现。你可能需要使用云计算资源或一台具有强大 GPU 的机器。

1.  使用历史数据回测你的策略。这涉及将你的策略应用于过去的数据，并查看它会如何表现。这可以帮助你完善策略和阈值：

    让我们使用 Salesforce 股票表现的 2023 年第三季度至 2024 年第一季度（财年季度）的数据进行回测，这段时间由于公司经历了很多变化，股价波动较大：

    ```py
    pip install numpy scikit-learn
    import pandas as pd
    import numpy as np
    from sklearn.metrics import confusion_matrix, classification_report
    # Data Gathering
    # Let's assume you have already gathered the financial and sentiment data
    # and loaded them into pandas dataframes: financial_data and sentiment_data
    financial_data = pd.read_csv('financial_data.csv')
    sentiment_data = pd.read_csv('sentiment_data.csv')
    # Convert date columns to datetime
    financial_data['Date'] = pd.to_datetime(financial_data['Date'])
    sentiment_data['Date'] = pd.to_datetime(sentiment_data['Date'])
    # Merge financial and sentiment data on date
    merged_data = pd.merge(financial_data, sentiment_data, on='Date')
    # Sort by date
    merged_data.sort_values('Date', inplace=True)
    # Calculate Rule of 40
    merged_data['Rule_of_40'] = merged_data['Revenue_Growth_Rate'] + merged_data['Cash_Flow_Margin']
    # Analyze Market Sentiment
    # Assume the sentiment analysis resulted in a sentiment score column in sentiment_data
    # We will consider a sentiment score above 0 as positive, and below 0 as negative
    merged_data['Sentiment'] = np.where(merged_data['Sentiment_Score'] > 0, "Positive", "Negative")
    # Define your thresholds
    # Buy if Rule of 40 is above 40 and sentiment is positive
    merged_data['Buy'] = np.where((merged_data['Rule_of_40'] > 40) & (merged_data['Sentiment'] == "Positive"), 1, 0)
    # Sell if Rule of 40 is below 30 and sentiment is negative
    merged_data['Sell'] = np.where((merged_data['Rule_of_40'] < 30) & (merged_data['Sentiment'] == "Negative"), 1, 0)
    # Now that we have signals, let's backtest the strategy
    # We will start with no positions in the stock
    merged_data['Position'] = np.where(merged_data['Buy'] == 1, 1, np.where(merged_data['Sell'] == 1, -1, 0))
    # The position column represents our trading signals
    # A value of 1 means we enter a long position, -1 means we exit our position
    merged_data['Position'] = merged_data['Position'].shift().fillna(0).cumsum()
    # Now we can calculate the strategy returns
    merged_data['Market_Returns'] = merged_data['Close'].pct_change()
    merged_data['Strategy_Returns'] = merged_data['Market_Returns'] * merged_data['Position']
    # And the cumulative strategy returns
    merged_data['Cumulative_Market_Returns'] = (1 + merged_data['Market_Returns']).cumprod() - 1
    merged_data['Cumulative_Strategy_Returns'] = (1 + merged_data['Strategy_Returns']).cumprod() - 1
    # Print the cumulative strategy returns
    print(merged_data['Cumulative_Strategy_Returns'])
    ```

    这个脚本创建了一个简单的回测，当满足买入条件时进入多头仓位，当满足卖出条件时退出仓位。策略的回报通过将市场回报与每个周期的仓位相乘来计算。

    请确保你拥有所有必要的数据和列，并且格式与之前描述的一致。根据实际数据结构，必要时调整数据加载和处理步骤。

    以下是`financial_data.csv`和`sentiment_data.csv`文件的示例，其中包含模拟数据，类似于真实数据。理解如何操作前述 Python 脚本后，请务必用自己的数据替换模拟数据：

    **financial_data.csv**:

    日期, 开盘, 最高, 最低, 收盘, 成交量, 收入增长率, 现金流利润率

    2023-07-01,250,260,245,255,1000000,0.2,0.15

    .**sentiment_data.csv**:

    日期, 情绪分数

    2023-07-01,0.1

    上述两个文件应与 Python 脚本放置在同一目录下。

    请注意，回测有其局限性，结果可能不能反映未来的表现。务必考虑其他因素，如交易成本和市场影响，这些都可能影响实际交易结果。建议在实际交易之前，使用实时市场数据测试交易策略。

1.  实现你的策略。一旦你对策略有信心，就可以开始实时应用它。定期监控 40 规则值和市场情绪，并据此做出买卖决策。

    在我们继续之前，这里有一些需要遵守的重要要求：

    1.  这需要一个数据收集过程，其中包括存储 Salesforce 的季度财务数据，并捕捉关键指标如收入增长率和现金流利润率：

        ```py
        pip install yfinance
        import yfinance as yf
        import pandas as pd
        def calculate_rule_of_40(ticker_symbol):
            ticker = yf.Ticker(ticker_symbol)
            # Get quarterly financial data
            financials_quarterly = ticker.quarterly_financials.transpose()
            # Calculate revenue growth percentage
            financials_quarterly['Revenue Growth'] = financials_quarterly['Total Revenue'].pct_change()
            # Calculate free cash flow margin
            financials_quarterly['Free Cash Flow'] = financials_quarterly['Operating Cash Flow'] - financials_quarterly['Capital Expenditures']
            financials_quarterly['Free Cash Flow Margin'] = financials_quarterly['Free Cash Flow'] / financials_quarterly['Total Revenue']
            # Calculate rule of 40
            financials_quarterly['Rule of 40'] = financials_quarterly['Revenue Growth'] + financials_quarterly['Free Cash Flow Margin']
            return financials_quarterly
        financial_data = calculate_rule_of_40('CRM')
        print(financial_data)
        import requests
        import pandas as pd
        import csv
        # ... rest of the script ...
        # Get the data from the API
        financial_data = get_financial_data("CRM")
        # Calculate Rule of 40
        rule_of_40 = calculate_rule_of_40(financial_data)
        # Store the Rule of 40 in a CSV file
        with open('rule_of_40.csv', 'w', newline='') as file:
            writer = csv.writer(file)
            # Write a header row
            writer.writerow(['Ticker', 'Rule of 40'])
            # Write the Rule of 40
            writer.writerow(["CRM", rule_of_40])
        print(f"Rule of 40 for CRM: {rule_of_40}")
        print("Rule of 40 saved to rule_of_40.csv")
        ```

    这个 Python 脚本提取指定股票代码（在此例中为 Salesforce 的`'CRM'`）的财务数据，并计算季度收入增长、自由现金流、自由现金流利润率以及 40 规则。相关信息存储在名为`rule_of_40.csv`的 CSV 文件中。

    1.  这还需要一个情绪数据的收集过程，基于财务新闻文章和任何额外的数据，如用户评论。此外，所有新闻文章和用户评论必须有`1`（正面）、`-1`（负面）或`0`（中性）的情绪分数：

        ```py
        pip install yfinance
        pip install requests
        pip install bs4
        pip install vaderSentiment
        import requests
        from bs4 import BeautifulSoup
        from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
        def yahoo_finance_news(ticker):
            url = f"https://finance.yahoo.com/quote/{ticker}?p={ticker}&.tsrc=fin-srch"
            r = requests.get(url)
            soup = BeautifulSoup(r.text, 'html.parser')
            news_data = soup.find_all('h3', class_='Mb(5px)')
            return ['https://finance.yahoo.com'+ndata.find('a')['href'] for ndata in news_data]
        def sentiment_score(news_url):
            # Initialize the sentiment analyzer
            analyzer = SentimentIntensityAnalyzer()
            r = requests.get(news_url)
            soup = BeautifulSoup(r.text, 'html.parser')
            paragraphs = soup.find_all('p')
            total_compound = 0
            for para in paragraphs:
                sentiment_dict = analyzer.polarity_scores(para.text)
                total_compound += sentiment_dict['compound']
            avg_compound = total_compound / len(paragraphs)
            # Classify the average compound score into positive, neutral or negative
            if avg_compound >= 0.05:
                return 1
            elif avg_compound <= -0.05:
                return -1
            else:
                return 0
        # Get the news article URLs
        news_urls = yahoo_finance_news('CRM')
        # Calculate sentiment score for each news article
        sentiment_scores = [sentiment_score(news_url) for news_url in news_urls]
        print(sentiment_scores)
        import csv
        # ... rest of the script ...
        # Calculate sentiment score for each news article
        sentiment_scores = [sentiment_score(news_url) for news_url in news_urls]
        # Open a CSV file in write mode ('w')
        with open('sentiment_scores.csv', 'w', newline='') as file:
            writer = csv.writer(file)
            # Write a header row
            writer.writerow(['News URL', 'Sentiment Score'])
            # Write the sentiment scores
            for news_url, sentiment_score in zip(news_urls, sentiment_scores):
                writer.writerow([news_url, sentiment_score])
        print("Sentiment scores saved to sentiment_scores.csv")
        ```

    这个脚本获取与指定股票代码（在此例中为 Salesforce 的`'CRM'`）相关的新闻文章的 URL，抓取每篇新闻文章的文本，并使用`VaderSentiment`分析器计算新闻文章的平均情绪分数。相关信息存储在名为`sentiment_scores.csv`的 CSV 文件中。

    购买和卖出 Salesforce 股票的阈值已预设：当 40 规则计算值超过`40`且情绪分数为正（`1`）时发出买入信号；当 40 规则计算值低于`30`且情绪分数为负（`-1`）时发出卖出信号。

    1.  一旦财务和情绪数据存储在 CSV 文件中，并且买入和卖出阈值已设置，你可以设置一个 Python 脚本，将这些数据导入到 Python 交易脚本中。请记住，如果财务和新闻网站允许，你可以始终考虑使用 API 来获取财务和情绪数据。如果 CSV 文件过大，这是一个不错的选择。以下的 Python 代码示例需要修改，以便使用 API 而不是 CSV 文件，但如果这是你偏好的方法，它是可行的。

    该脚本可以被安排在定期时间间隔运行（如每分钟、每小时或你认为合适的时间间隔）。

    下面是实现交易的 Python 脚本简化版本：

    ```py
    import requests
    import pandas as pd
    import numpy as np
    from datetime import datetime
    from time import sleep
    from your_trading_library import execute_trade
    # Read data from CSV files as CSV file
    financial_data = pd.read_csv('financial_data.csv')
    sentiment_data = pd.read_csv('sentiment_data.csv')
    # Set the frequency at which the script will run (in seconds)
    frequency = 60
    # Set up a pandas DataFrame to store the data
    data = pd.DataFrame()
    while True:
        # Read financial and sentiment data from CSV files
        financial_data = pd.read_csv(financial_data_csv_path)
        sentiment_data = pd.read_csv(sentiment_data_csv_path)
                # Check if the latest data meets the buy or sell conditions
        latest_data = data.iloc[-1]
        if latest_data['Rule_of_40'] > 40 and latest_data['Sentiment'] == "Positive":
            execute_trade('Salesforce', 'buy')
        elif latest_data['Rule_of_40'] < 30 and latest_data['Sentiment'] == "Negative":
            execute_trade('Salesforce', 'sell')
        # Wait until the next run
        sleep(frequency)
    ```

    在这个脚本中，`execute_trade` 是一个假设的交易库中的函数，用来执行交易。将其替换为你正在使用的实际交易库中的相应函数。

    最后，请注意，该脚本将无限期运行，直到你停止它。建议设置适当的错误处理和日志记录机制，以确保脚本在发生错误时不会默默失败。

在下一部分，我们将使用 Power BI 作为数据可视化工具来分析和传达你 Salesforce 40 法则战略的有效性。

## 可视化 Salesforce 战略 – Power BI 与 40 法则相遇

在本部分中，我们将深入探讨如何通过 Power BI 中的引人入胜的可视化，将原始财务数据和情绪评分转化为可操作的洞察。通过这些步骤，我们旨在帮助你将复杂的财务计算转化为简单、易于理解的可视化线索，以指导你的决策过程。

pandas 数据框 `df` 将包含在前面部分中提到的第一步中计算的 40 法则。此外，你还可以将 Salesforce 的历史股价信息纳入 Power BI 可视化。通过同时包含这两组数据，你可以看到一个 Power BI 可视化图表，突出展示 Salesforce 的 40 法则和 Salesforce 股价的时间序列，这可能会提供一些有趣的见解。

在 Power BI 中可视化数据时，按照以下步骤操作：

1.  将数据框保存到 CSV 文件：`df.to_csv('salesforce_data.csv', index=False)`。

1.  在 Power BI Desktop 中，点击**首页** > **获取数据** > **文本/CSV**。

1.  找到并选择 `'salesforce_data.csv'`，然后点击**打开**。

1.  在**导航器**对话框中，选择表格并点击**加载**。

1.  数据加载后，你可以使用`Quarter`到`Stock Price`以及`Rule of 40`到**Values**。根据你的需求调整图表类型和其他格式设置。

在接下来的部分，我们将介绍一个新角色——ActivistGPT，他将扮演一个激进投资者的角色，审视 Salesforce.com 的战略和未来计划。作为一名批判性的观察者，ActivistGPT 深入剖析公司如何应对日益激烈的 CRM 市场竞争，如何利用生成式人工智能和机器学习等新兴技术，以及如何在增长与盈利之间保持微妙的平衡。

# ActivistGPT – 激进投资者角色

本节内容承诺将通过激进投资者的视角对 Salesforce.com 进行深刻且发人深省的审视，提出一系列需要公司和投资者共同关注的问题。

创建一个新的角色，ActivistGPT，作为激进投资者的化身，我们希望了解 Salesforce 的管理团队如何应对当前和未来的挑战，同时推动可持续增长和价值创造。

以下是针对 Salesforce 的激进投资者提问：

1.  公司应对客户关系管理（CRM）市场日益激烈竞争的策略是什么？

1.  Salesforce 如何定位自己以利用新兴技术（如生成式人工智能或机器学习）来提升其产品？

1.  管理层计划如何在增长与盈利之间保持平衡？

1.  公司并购活动背后的策略是什么？他们如何计划整合这些收购并从中获得价值？

1.  公司计划如何应对潜在的风险，例如数据隐私法规和网络安全威胁？

在短期内，股票回购、成本削减以及暂停并购活动等措施确实可能提升财务表现和股价。然而，这些措施必须谨慎实施，以免影响公司长期的增长潜力和运营效率。因此，我建议 Salesforce 专注于提高运营效率，并推动有机增长，同时制定有节制的并购策略，考虑到竞争环境和技术行业的快速变化。

从长远来看，Salesforce 应继续投资于研发、创新和人才招聘，以保持竞争优势并促进可持续增长。同时，它还应考虑制定全面的环境、社会和治理（ESG）战略，以确保长期的价值创造。

如果股票短期内上涨 50%，激进投资者是否卖出或继续持有股票将取决于对公司长期战略和前景的信心。如果股票价格的上涨准确反映了公司的潜力，继续持有股票可能是明智的。然而，如果上涨主要是由于短期因素，可能无法持续，那么出售股票可能是一个可考虑的选择。

ActivistGPT 是一款革命性的 AI 代理，使用 LangChain、GPT-4 和 Streamlit 技术构建。这些技术的强大融合极大地放大了其潜力。LangChain 是一个 OpenAI 项目，提供互联网搜索和数学计算能力，使 ActivistGPT 能够强有力地分析来自各个来源的数据。GPT-4 架构赋予 ActivistGPT 异常强大的语言理解和生成能力，使其能够解读复杂的金融文档并生成深入的建议。Streamlit 是一个开源 Python 库，用于创建互动式网页界面，使 ActivistGPT 提供的复杂分析可以随时随地供任何人使用。这种技术融合使 ActivistGPT 成为一个令人兴奋、开创性的金融和商业转型工具。

## ActivistGPT – LangChain、ChatGPT 和 Streamlit 激进 AI 代理

(*Franck Stephane Ndzomga* 在 2023 年 6 月 19 日和 6 月 21 日的两篇 Medium 文章中提供了不同主题的指导。)

+   **名称**：ActivistGPT（融合了 Elliott Management、Third Point、Starboard Value、Inclusive Capital 和 ValueAct 的特征）。

+   **背景**：ActivistGPT 被设计为汲取以敏锐眼光和创造价值著称的激进投资者的集体智慧。这个角色体现了他们的韧性、战略思维和金融专业知识。

+   **技能**：

    +   擅长识别表现不佳的资产、低效问题以及潜在的增长领域

    +   对金融市场、公司治理和公司财务有深厚的知识

    +   擅长战略思维，能够为复杂问题提出创造性解决方案

    +   擅长解读财务报表并识别趋势或潜在问题领域

    +   能够与利益相关者互动并进行说服，利用影响力推动变革

+   **动机**：ActivistGPT 的终极目标是最大化股东价值。它瞄准像 Salesforce 这样的表现不佳的公司，旨在通过变革提升财务纪律、盈利能力和整体表现。它由纠正低效、浪费开支和管理不善的愿望驱动。

+   **方法**：就像它所模仿的激进投资者一样，ActivistGPT 不怕挑战现状并提出激进的变革。它利用影响力和说服力表达自己的观点，通常采用对抗性但建设性的方式。它理解每个公司都是独一无二的，因此会量身定制其策略。

+   **价值**：ActivistGPT 可以在推动 Salesforce 转型中发挥重要作用。以下是它如何应对特定问题的方案：

    +   **劳动力和支出管理**：ActivistGPT 将首先进行运营效率分析，识别可以在不影响质量或生产力的情况下减少开支的领域。它将建议进行战略性裁员和重组，确保 Salesforce 保留关键人才，同时剔除冗余岗位。

    +   **财务纪律**：ActivistGPT 将提出一项全面的财务管理计划，促进谨慎和高效。它将呼吁详细的预算编制、优先事项排序和所有支出的监控。

    +   **股票回购计划**：为了增加股东价值并利用闲置现金，ActivistGPT 将推动一个 200 亿美元的股票回购计划。

    +   **定价策略**：鉴于 Salesforce 产品的价值，ActivistGPT 建议进行 9%的平均提价，这一提价可以通过改进的服务、产品升级或其他因素来证明其合理性。

    +   **并购重点**：ActivistGPT 建议关闭并购委员会，认为焦点应放在内部增长和整合上，而不是通过收购来扩展。

    +   **领导继任计划**：鉴于 Salesforce 近期领导层的不稳定，ActivistGPT 将敦促董事会制定一份明确且可持续的马克·贝尼奥夫继任计划。

+   **个性**：ActivistGPT 具有果断、战略性和无情的个性。它不怕引起争议，要求各层级的问责。它拥有长远的愿景，并不懈努力实现这一愿景。

请记住，尽管 ActivistGPT 提供战略分析和建议，最终的决策权属于董事会、管理层和股东。建议的策略和方法应根据公司的独特需求、行业动态和长期愿景进行仔细考虑和执行。

### 第一部分 – LangChain、ChatGPT 和 Streamlit – ActivistGPT（为代理创建后端）

本文的目的是引导您了解如何创建一个由 GPT-4 驱动的激进 AI 代理——ActivistGPT，它可以为 Salesforce 提供见解。我们将分享我们构建这个 AI 激进者的步骤，并展示它如何帮助揭示 Salesforce 潜在问题的数据点。

构建一个全面的 AI 激进者，特别是针对特定实体的，需要将 AI 代理与多个数据源集成。这使得能够进行强有力的分析和精准的建议。在这个项目中，我们从我们希望创建的产品开始：ActivistGPT。AI 激进者的角色是什么？他们分析公司数据、财务新闻、利润表、资产负债表和现金流量表。他们还会审查投资者会议，并提出可以改善公司运营和影响的关注领域的建议。

在 ActivistGPT 的初始版本中，我们使用了 LangChain，并赋予代理互联网搜索和数学计算能力。我们简单地提出了这个问题：“分析 Salesforce 并提供关注领域的见解。”

这是 ActivistGPT 的代码。这代表了我的思维过程的简单初始阶段，为最终将成为更复杂工具的结构提供了框架：

```py
from apiKey import apikey
from apiKey import serpapi
import os
from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.llms import OpenAI
os.environ["OPENAI_API_KEY"] = apikey
os.environ["SERPAPI_API_KEY"] = serpapi
llm = OpenAI(temperature=0)
tools = load_tools(["serpapi", "llm-math"], llm=llm)
agent = initialize_agent(tools,
                         llm,
                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
                         verbose=True)
agent.run("Analyze Salesforce and provide insight on areas of concern")
```

为了获得更多的灵活性，我们将使用 OpenAI API 中的最新功能：Functions。然而，首先，我们需要编写代码以获取有关 Salesforce 的最新新闻、财务状况表、收入表和投资倍数。我们将把所有这些内容写入一个文本文件，作为 ActivistGPT 的长期记忆：

```py
import os
import requests
import json
from apiKey import apikey
from apiKey import serpapi
import yfinance as yf
from yahooquery import Ticker
os.environ["OPENAI_API_KEY"] = apikey
os.environ["SERPAPI_API_KEY"] = serpapi
def get_company_news(company_name):
    params = {
        "engine": "google",
        "tbm": "nws",
        "q": company_name,
        "api_key": os.environ["SERPAPI_API_KEY"],
    }
    response = requests.get('https://serpapi.com/search', params=params)
    data = response.json()
    return data.get('news_results')
def write_news_to_file(news, filename):
    with open(filename, 'w') as file:
        for news_item in news:
            if news_item is not None:
                title = news_item.get('title', 'No title')
                link = news_item.get('link', 'No link')
                date = news_item.get('date', 'No date')
                file.write(f"Title: {title}\n")
                file.write(f"Link: {link}\n")
                file.write(f"Date: {date}\n\n")
# ... (rest of the code is similar to the one provided earlier, but targeting Salesforce)
```

我们可以像这样创建 ActivistGPT 的核心功能：

```py
def activist_gpt(request):
    # ... (similar to the previous code, but targeting Salesforce)
    # ...
    return second_response["choices"][0]["message"]["content"]
while True:
    user_question = input("Enter your analysis request:\n\n")
    if user_question == 'exit':
        break
    print(activist_gpt(user_question))
```

当我们询问 ActivistGPT 关于 Salesforce 潜在的关注领域时，结果如下：

```py
Received request: Analyze Salesforce for potential areas of concern?
```

根据提供的数据和最近的新闻，以下是 Salesforce 的一些关注领域：

1.  **高运营费用**：Salesforce 的运营费用增长速度超过了其收入增长速度，这可能会影响长期的盈利能力

1.  **对大单的依赖**：Salesforce 的商业模式在很大程度上依赖于获得大单，这本质上涉及高风险和不可预测性

1.  **产品复杂性**：Salesforce 的产品

需要注意几点：

+   没有 LangChain 项目，这项工作是不可能完成的。LangChain 是 OpenAI 的一个开源项目，旨在使开发者能够构建能够与人类进行对话的 AI 代理。

+   我们使用了 Serpapi，一个付费服务，进行互联网搜索。虽然也可以使用像 Google 的定制搜索 JSON API 这样的免费服务，但我们发现 Serpapi 提供了更强大和一致的结果。然而，请注意，使用 Serpapi 需要付费。

+   我们使用了 Yahoo Finance 的 Python 库`yfinance`和`YahooQuery` Python 库来收集股票数据和财务报表。这些库是免费使用的，但遵守服务条款和使用限制始终是良好的做法。这些服务提供的数据仅供个人使用，未经明确许可，不得用于商业目的。

+   最后，请注意，这只是一个实验性项目。AI 代理的投资建议不可靠也不全面。在做出任何投资决策之前，进行充分的研究或咨询财务顾问是至关重要的。

### 第二部分 – LangChain、ChatGPT 和 Streamlit – ActivistGPT（为 ActivistGPT 代理创建前端）

现在我们可以声明该项目的后端已经开发完成。下一步是设计一个互动式用户界面，使专为 Salesforce 定制的强大 AI 财务分析师 ActivistGPT 能够让每个人都能使用。虽然有多种选择，包括使用 Flask 等 Web 开发框架，但我们决定使用 Streamlit，因为它能更高效地构建我的用户界面。

Streamlit 是一个开源的 Python 库，旨在简化为机器学习和数据科学项目定制的互动 Web 应用程序的创建过程。它简化了数据科学家和工程师开发、部署和共享数据驱动应用程序的流程。

Streamlit 的独特之处在于它允许用户仅通过 Python 构建互动式 Web 应用程序，完全不需要 HTML、CSS 或 JavaScript。这一功能使得数据脚本可以迅速转化为可分发的 Web 应用程序，且都在 Python 生态系统内。Streamlit 兼容多种可视化库，且与许多流行的数据科学库（如 pandas、NumPy、Matplotlib 等）无缝集成。

首要任务是设计 Web 应用程序前端的高层次结构。这一步至关重要，有助于概念化预期的结果。在这项任务中，我们将使用 Excalidraw。我们设想用户输入公司名称后，点击 **分析** 按钮。在点击 **分析** 后，ActivistGPT 将回顾 Salesforce 的表现，绘制股票的走势，并提供是否购买该股票的建议。

以下代码使用 Streamlit 来完成此任务。请注意，这段代码可能未经过优化，欢迎您进一步改进。我们的目标是创建一个功能原型。

这是后端和前端的代码：

```py
def activist_gpt(request):
    print(f"Received request: {request}")
    response = openai.ChatCompletion.create(
        model="gpt-4.0-turbo",
        messages=[{
            "role":
            "user",
            "content":
            f"Given the user request, what is the comapany name and the company stock ticker ?: {request}?"
        }],
        functions=[{
            "name": "get_data",
            "description":
            "Get financial data on a specific company for investment purposes",
            "parameters": {
                "type": "object",
                "properties": {
                    "company_name": {
                        "type":
                        "string",
                        "description":
                        "The name of the company",
                    },
                    "company_ticker": {
                        "type":
                        "string",
                        "description":
                        "the ticker of the stock of the company"
                    },
                    "period": {
                        "type": "string",
                        "description": "The period of analysis"
                    },
                    "filename": {
                        "type": "string",
                        "description": "the filename to store data"
                    }
                },
                "required": ["company_name", "company_ticker"],
            },
        }],
        function_call={"name": "get_data"},
    )
    ... Frontend
# Similarly, in the frontend script, we replace `financial_analyst` with `activist_gpt`.
import streamlit as st
import matplotlib.pyplot as plt
from backend import activist_gpt  # Here, 'backend' should be replaced with the actual name of your backend script
def main():
    st.title("ActivistGPT App")
    company_name = st.text_input("Company name:", "Salesforce")
    analyze_button = st.button("Analyze")
    if analyze_button:
        if company_name:
            st.write("Analyzing... Please wait.")
            investment_thesis, hist = activist_gpt(company_name)
            # Select 'Open' and 'Close' columns from the hist dataframe
            hist_selected = hist[['Open', 'Close']]
            # Create a new figure in matplotlib
            fig, ax = plt.subplots()
            # Plot the selected data
            hist_selected.plot(kind='line', ax=ax)
            # Set the title and labels
            ax.set_title(f"{company_name} Stock Price")
            ax.set_xlabel("Date")
            ax.set_ylabel("Stock Price")
            # Display the plot in Streamlit
            st.pyplot(fig)
            st.write("Investment Thesis / Recommendation:")
            st.markdown(investment_thesis, unsafe_allow_html=True)
        else:
            st.write("Please enter the company name.")
if __name__ == "__main__":
    main()
```

在前端，我们已将文本输入框预填充为 `Salesforce`，以反映 ActivistGPT 的特定用例。然而，您也可以选择留空此字段，允许用户分析任何公司。您还可以进行其他自定义，以便根据您的需求调整应用程序。这就是将 Streamlit 和 OpenAI 一起使用来创建 AI 驱动的 Web 应用程序的强大之处和灵活性。

准备好迎接下一节的激动人心的更新吧。我们将深入探讨 LLM（大语言模型）的世界，揭示一些强大的工具，帮助您提升财务分析和数据可视化的能力。哪个 LLM 最适合您的需求？专有的、开源的，还是专为财务用例设计的财务 LLM？

听说过**LoRa**吗？它是 OpenAI 开发的**低资源适应**技术，旨在使用相对较少的数据高效微调大语言模型。它节省时间、性能出色，并能让你更好地控制模型的输出——特别是在限制潜在滥用方面非常有用。

在训练大语言模型时，有一点是明确的：数据质量通常比数据量更为重要。高质量的数据能提升模型表现，防止过拟合，并提高计算效率。当然，理想的情况是拥有大量高质量数据，但如果必须选择，高质量通常是更安全的选择。

OpenAI 并没有袖手旁观。他们通过推出平台，如 Evals——一个开源基准指数，专门用于评估大语言模型及相关系统，积极参与开源 LLM 的竞争。

# 开源与专有大语言模型

开源和专有大语言模型各自具有独特的优点和局限性。开源大语言模型对所有人开放，能够根据各种需求进行定制。它们广泛应用于各种自然语言处理操作，从文本生成到摘要、翻译和分析。开源大语言模型相较于专有模型的优势包括更高的灵活性、控制力和可负担性，同时也更注重数据隐私和安全性。

另一方面，专有的大语言模型（LLMs）可能具备提升可用性和效率的先进功能，从而增强其商业吸引力。然而，这些模型通常较难理解，并且通常提供的功能范围较窄。

某些特定行业和应用可能因涉及的数据敏感性而限制使用商业大语言模型服务，例如在医疗场景中，由于合规要求，**个人身份信息**（**PII**）不能被暴露。在这种情况下，开源大语言模型通常更受青睐。

一些著名的开源大语言模型（LLMs）包括 OpenAI 的 GPT-3、Google 的 LaMDA 和 PaLM（为 Bard 提供基础）、Hugging Face 的 BLOOM 和 XLM-RoBERTa、Nvidia 的 NeMO、XLNet、Cohere 和 GLM-130B。这些模型因其公共可访问性和定制能力而备受青睐。它们提供多种自然语言处理（NLP）功能，同时确保了更高的灵活性、控制性、成本效益、数据隐私和安全性。

OpenAI 为开源领域做出了贡献，推出了诸如 Point-E、Whisper、Jukebox 和 CLIP 等模型。此外，OpenAI 还开发了一个软件框架——Evals，帮助用户衡量 AI 模型的表现。

然而，使用开源模型确实引发了隐私问题，尤其是在处理机密数据时。模型训练过程中数据泄露的风险是一个重大问题，这可能导致模型输出中私密信息的无意泄露。目前正在采取措施以减轻这些风险，并制定未来模型的应对策略。

然而，随着开源解决方案的出现，已经有能够确保数据隐私的 AI 模型部署方法。例如，BlindAI 是一个开源平台，在保证数据保密的同时，促进了 AI 模型查询和部署，这得益于硬件强制执行的可信执行环境。

总之，尽管关于使用开源模型存在隐私问题，但已经有积极的努力在解决这些问题，开发出能够确保数据隐私的解决方案。

## 专有模型

专有模型是由私营组织开发的，其源代码、模型参数和其他细节通常是保密的：

+   `OpenAI 的 GPT-4`，`Google 的 LaMDA 和 PaLM LLM`，`Nvidia 的 NeMO LLM`，以及 Cohere 的 Command LLM。

+   **金融大型语言模型（LLMs）**：

    +   BloombergGPT 是由 Bloomberg 开发的，基于 50 亿个参数，但目前仅对 Bloomberg 订阅用户开放（在本文撰写时没有 API 或聊天界面可用）。

    +   摩根大通正在开发一款类似 ChatGPT 的软件服务，名为 IndexGPT，用于为客户选择投资。根据商标申请，IndexGPT 将利用“*基于人工智能的云计算软件*”来“*分析和选择量身定制的证券，以满足客户需求*”。摩根大通是首家旨在将类似 GPT 的产品直接提供给客户的金融机构。

请参见*OpenAI 如何应对开源模型竞争？*部分的表格，了解专有 LLMs 和金融 LLMs 在速度、定价、延迟、透明度、灵活性、安全性和数据治理方面的表现。

**应用场景**：专有模型对于需要可靠且高性能 AI 系统的企业有很大好处，并且这些企业愿意为此付费。它们在需要严格控制用户体验和防止滥用的情况下也非常有用。

## 开源模型

开源模型是指其架构、参数和训练数据（或至少其中一部分）是公开的 AI 模型。用于开发这些模型的源代码通常也是免费提供的。

例如，斯坦福大学的 Alpaca、Hugging Face 的 BLOOM、Cerebras 的 Cerebras-GPT、Databricks 的 Dolly、Meta 的 LLaMA，以及 Im-sys 的 Vicuna-13B。

请参见*OpenAI 如何应对开源模型竞争？*部分的表格，了解开源 LLMs 在速度、定价、延迟、透明度、灵活性、安全性和数据治理方面的表现。

让我们来看一些应用场景。开源模型在学术研究中非常有用，特别是在关注理解模型运作机制的场合。它们对于初创公司和需要灵活定制模型以满足特定需求的公司也非常有用，尤其是在没有足够资金购买专有模型的情况下。

## 开源模型与专有模型的未来

至于开源模型和专有模型之间是否会有明显的胜者，每种模型类型都有其优势和应用场景。

开源模型可能在需要快速创新、透明性和定制化的领域中占据领先地位。它们非常适合促进一个广泛、多样的研究社区，并推动 AI 技术的前沿发展。另一方面，专有模型可以提供更多的控制和强大的支持，使其在需要可靠性和控制的商业应用中具有吸引力。

在不久的将来（6 到 12 个月内），我们可能会看到开源模型在性能和能力方面缩小与专有模型的差距。这一趋势可能会受到重要专有模型或其版本被开源、泄露或逆向工程的推动。

然而，专有模型在某些商业应用中仍然可能占据优势，尤其是在需要强大支持、控制用户体验以及防止滥用的情况下。从长远来看，随着政策变化、技术突破以及 AI 行业商业模式的发展，市场格局可能会发生变化。

## 金融应用场景（投资、交易和金融分析）的最佳模型选择

选择适用于金融分析、交易和投资的语言模型，取决于你的具体需求，例如你处理的金融数据类型、所需的准确度以及你拥有的资源。让我们讨论几种选择：

1.  **专有模型如 GPT-4**：作为 OpenAI 开发的最先进的语言模型，GPT-4 可以生成高质量、类人的文本。它可以在金融文本上进行训练，用于分析趋势、生成报告、预测市场动向等。然而，使用 GPT-4 可能需要大量计算资源，通常你需要通过 OpenAI 的 API 来访问它，而这可能伴随有使用限制和费用。

1.  **开源模型如 Vicuna**：如果你拥有调整和维护 AI 模型的专业知识和资源，像 Vicuna 这样的开源模型可能是一个不错的选择。这些模型可以自由使用和修改，你可以在自己特定的金融数据集上进行训练。然而，这些模型可能在开箱即用时，性能不如像 GPT-4 这样的专有模型。

1.  **专门的金融 LLM 如 BloombergGPT**：这些模型是专门为金融行业设计的，这可能是一个重要的优势。它们可能已经在相关的金融数据上进行过训练，并优化了诸如预测股价、分析公司业绩、生成财务报告等任务。然而，这些模型通常是专有的，使用起来可能会非常昂贵。你也无法像使用开源模型一样灵活地修改它们。就 BloombergGPT 而言，截至本文写作时，没有可用的 API 或聊天界面。

一般来说，答案不会是“万能”的。最适合你的模型将取决于你的具体需求和约束。例如，如果你有大量数据并且需要高度准确的预测，专业的金融大型语言模型（LLM）可能值得花费。而如果你需要分析某种特定类型的金融数据，而现有模型对此覆盖不足，那么通过在你自己的数据上训练开源模型可能会获得最佳结果。

同样值得注意的是，AI 模型应该仅作为你财务分析工具箱中的一个工具。金融市场受到各种因素的影响，即使是最先进的 AI 模型也无法以 100% 的准确度预测它们。始终用人工分析和判断来补充 AI 预测。

## Power BI 叙述生成最佳模型——数据可视化

在从数据可视化中生成叙述的背景下（这一领域称为 **自然语言生成** 或 **NLG**），这些模型可以提供显著的帮助。例如，让我们看看一些选项：

1.  **专有模型如 GPT-4**：如果你想基于 Power BI 仪表盘生成复杂的叙述或解释，或有特定的高级语言生成需求，像 GPT-4 这样的模型可能会有所帮助。你将数据洞察传递给模型，然后它会生成类似人类的叙述。

1.  **开源模型如 Vicuna**：如果你需要更多控制生成过程，或者想要在特定数据集或语言风格上对模型进行微调，开源模型可能是一个更好的选择。

1.  **专门的金融 LLM 如 BloombergGPT**：如果你的 Power BI 仪表盘专注于金融数据，并且你需要针对金融语言和概念量身定制的叙述，专门的金融 LLM 可能会具有优势。

请记住，将此类模型与 Power BI 集成可能需要定制开发工作，因为直接的现成支持可能并不存在。模型的选择将取决于你的具体使用案例、你想要生成的叙述的复杂性以及你的资源。

## 训练大型语言模型时的其他主要因素

**LoRa** 是由 OpenAI 开发的用于微调大型语言模型（LLMs）的小数据量技术。它基于提示工程的概念，不需要大量数据来进行微调，而是通过与特定提示相关的额外参数来优化模型的预测。

这就是它强大的原因：

1.  **效率**：正如其名称所示，LoRa 特别设计用于处理较小的数据集。它节省了大量的时间和计算资源，因为你不需要向模型输入大量数据就能获得理想的结果。

1.  **性能**：与完整模型微调相比，LoRa 展现了可比的，甚至在数据稀缺时有时更好的性能。

1.  **保障**：由于它基于提示调优的理念，你可以对模型输出保持更多的控制，这在你希望限制模型潜在滥用或意外后果时尤其有用。

使用 LoRa 对开源模型进行微调可能比使用专有模型更便宜、更快速：

1.  **成本**：开源模型不需要支付许可费用，而专有模型通常需要。因此，使用和微调开源模型的总体成本可能更低。

1.  **灵活性**：开源模型可以更适应各种任务，因为你可以根据需求调整其架构和训练过程。

1.  **社区支持**：开源模型通常伴随有庞大且活跃的社区，可以提供支持并解决常见问题，并且这些社区通常会共同致力于改进和扩展。

## 数据质量与数据规模

是的，在训练大型语言模型（LLMs）时，数据的质量往往比数量更为重要。原因如下：

1.  **模型性能**：优质数据可以显著提高模型的性能。即使数据集较小，只要数据相关、精心策划且无错误，模型也能做出更准确的预测。相反，若数据集庞大，但包含大量无关或错误的数据，则可能导致模型做出错误的预测。

1.  **过拟合**：在大量低质量数据上训练模型可能导致过拟合，这意味着模型可能在训练数据上表现良好，但在新的、未见过的数据上表现不佳。这是因为模型学习到了数据中的噪声，而不是潜在的模式。

1.  **计算效率**：训练 LLMs 计算开销大且耗时。使用较小的高质量数据集可以减少训练时间和计算资源，从而提高效率。

然而，同样重要的是要记住，“质量”和“数量”并不一定是对立的因素。在理想情况下，你会希望拥有大量的高质量数据。但如果必须在更多低质量数据和更少高质量数据之间做选择，后者通常是更安全的选择。

此外，像数据增强这样的技术——通过现有数据集人工创建新数据——可以帮助你在不牺牲质量的情况下平衡这两者。这些技术能够增加数据量，同时确保其质量，从而使模型的学习更加稳健。

最后，请记住，尽管高质量的数据至关重要，模型的有效性还取决于其他因素，如模型的架构、所用的学习算法、模型参数的调优以及可用的计算资源。

## OpenAI 如何应对开源模型的竞争？

OpenAI 已经将多个开源 LLM 贡献给了公共领域。例如，他们推出了一个名为 Evals 的平台，这是一个开源基准指数，理想用于评估 LLM 及相关系统。此外，他们还发布了其先进的文本嵌入模型和最新版本的 GPT-3.5 模型。

让我们来看看专有、开源和专门的金融 LLM 的概述：

| **类别** | **专有模型** | **开源模型** | **专门的金融 LLMs** |
| --- | --- | --- | --- |
| 部署速度 | 即开即用的部署方式可以更快上线 | 自托管设置可能需要额外的时间和专业知识 | 更具小众性，因此可能需要额外的时间和专业知识，类似于开源模型的设置 |
| 定价模型 | 主要基于使用量定价；微调可能会产生额外费用 | 模型免费分发，但微调可能需要资源 | 可能基于使用量定价，并且针对专门功能可能产生额外费用 |
| 延迟 | 可能响应较慢；可能影响实时使用场景 | 根据使用场景，模型可以更加轻量，从而响应更快 | 性能可能有所不同。一些模型在特定金融任务中可能响应更快，但对于一般任务可能较慢 |
| 透明度和灵活性 | 代码可见性通常有限 | 提供最大程度的代码透明性和适应性 | 代码可见性和适应性可能因提供者而异 |
| 安全性和数据治理 | 通常提供增强的安全性和治理功能，但数据处理和治理可能不明确 | 虽然通常缺乏内建的安全性和治理功能，但可以集成到公司现有的安全框架中，并通过本地数据安全地进行微调 | 安全性和数据治理功能可能内建，但数据处理的细节可能未完全披露 |

# 总结

*第五章*带领我们进入了一个引人入胜的旅程，通过市场情感的视角讲述了 Salesforce 的复兴故事。我们亲身体验了这家科技巨头如何在艰难的低谷期中找到重生的力量和方向，主要得益于战略干预和行业定义性的向 AI 的转型。

我们探讨了情感分析与 40 法则的强大结合，探索了它们在现代投资策略中的应用。我们了解到一种基于这两个原则的 AI 驱动期权交易策略，为投资决策提供了全新且创新的视角。

通过一步步的指导，我们见证了使用 LangChain、ChatGPT 和 Streamlit 创建一位激进投资 AI 代理的过程。这次对 AI 工具的深入探索为投资激进主义提供了新颖的视角，展示了技术如何引领重大变革。

最后，我们踏上了一段评估之旅，深入了解了大语言模型（LLM）的世界，对比了专有、开源和专业选项。我们揭示了适用于不同使用场景的理想 LLM 选择，尤其是与金融和投资相关的场景。

总体来说，本章融合了 Salesforce 历程中的宝贵历史教训、深刻的交易策略，并对人工智能驱动的投资未来进行了展望。我们希望这些见解能够为你的投资与技术之旅提供有价值的知识。

*第六章*，*SVB 的倒塌与伦理 AI：智能 AI 监管*，展示了技术，尤其是自然语言处理（NLP）和人工智能，如何彻底改变我们对沟通的理解与分析，特别是在金融和社交媒体的世界中。

这段启发性的旅程将从自然语言处理（NLP）的全面概述开始——这是一种人工智能技术，使计算机能够理解、分析甚至模拟人类语言和情感。我们将深入探讨 NLP 在重新塑造社交媒体格局方面的关键作用，它创造了实时监控公众情绪并预测重大社会经济现象（如银行倒闭）的潜力。

了解公众情绪及其变化不再是一个谜团，这要归功于人工智能和社交媒体。本章将深入探讨这些变化，特别是与金融机构相关的变化，如何成为即将到来的危机的预兆。我们将揭示无论你是经验丰富的金融专业人士，还是个人投资者，都可以如何利用这一力量，在银行倒闭发生之前发现潜在的风险。
