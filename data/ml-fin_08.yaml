- en: Chapter 8. Privacy, Debugging, and Launching Your Products
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 隐私、调试与产品发布
- en: Over the course of the last seven chapters we've developed a large toolbox of
    machine learning algorithms that we could use for machine learning problems in finance.
    To help round-off this toolbox, we're now going to look at what you can do if
    your algorithms don't work.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的七章中，我们已经开发了一整套可以用于金融领域的机器学习算法工具箱。为了完善这个工具箱，我们现在将讨论当你的算法无法正常工作时，你该怎么办。
- en: 'Machine learning models fail in the worst way: silently. In traditional software,
    a mistake usually leads to the program crashing, and while they''re annoying for
    the user, they are helpful for the programmer. At least it''s clear that the code
    failed, and often the developer will find an accompanying crash report that describes
    what went wrong. Yet as you go beyond this book and start developing your own
    models, you''ll sometimes encounter machine learning code crashes too, which,
    for example, could be caused if the data that you fed into the algorithm had the
    wrong format or shape.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型最糟糕的失败方式是：无声无息。在传统软件中，错误通常会导致程序崩溃，虽然对用户来说这些错误很烦人，但对程序员来说却是有帮助的。至少可以明确知道代码失败了，开发者通常还能找到一份错误报告，说明问题出在哪里。然而，当你走出本书，开始开发自己的模型时，你有时也会遇到机器学习代码崩溃的情况，例如，如果你输入算法的数据格式或形状不正确，就可能发生崩溃。
- en: These issues can usually be debugged by carefully tracking which shape the data
    had at what point. More often, however, models that fail just output poor predictions.
    They'll give no signal that they have failed, to the point that you might not
    even be aware that they've even failed at all, but at other times, the model might
    not train well, it won't converge, or it won't achieve a low loss rate.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题通常可以通过仔细追踪数据在各个阶段的形状来调试。然而，更常见的是，失败的模型只是输出差的预测。它们不会发出任何失败的信号，以至于你甚至可能没有意识到它们已经失败，但有时模型可能训练得不好，无法收敛，或者无法达到较低的损失率。
- en: 'In this chapter, we''ll be focusing on how you debug these silent failures
    so that they don''t impact the machine learning algorithms that you''ve created.
    This will include looking at the following subject areas:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论如何调试这些无声的失败，以免它们影响你所创建的机器学习算法。这将包括以下主题：
- en: Finding flaws in your data that lead to flaws in your learned model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现数据中的缺陷，这些缺陷导致你训练出的模型出现问题
- en: Using creative tricks to make your model learn more from less data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用创意技巧让你的模型从更少的数据中学到更多
- en: Unit testing data in production or training to ensure standards are met
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对生产或训练中的数据进行单元测试，以确保符合标准
- en: Being mindful of privacy and regulation, such as GDPR
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 留意隐私和法规，例如 GDPR
- en: Preparing data for training and avoiding common pitfalls
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备训练数据并避免常见的陷阱
- en: Inspecting the model and peering into the "black box"
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查模型并深入了解“黑箱”
- en: Finding optimal hyperparameters
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找最佳的超参数
- en: Scheduling learning rates in order to reduce overfitting
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整学习率以减少过拟合
- en: Monitoring training progress with TensorBoard
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 监控训练进度
- en: Deploying machine learning products and iterating on them
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署机器学习产品并对其进行迭代
- en: Speeding up training and inference
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速训练和推理
- en: The first step you must take, before even attempting to debug your program,
    is to acknowledge that even good machine learning engineers fail frequently. There
    are many reasons why machine learning projects fail, and most have nothing to
    do with the skills of the engineers, so don't think that just because it's not
    working, you're at fault.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须采取的第一步，在尝试调试程序之前，是要承认即使是优秀的机器学习工程师也经常会失败。机器学习项目失败的原因有很多，大多数与工程师的技能无关，所以不要因为它没有按预期工作就认为是你出错了。
- en: If these bugs are spotted early enough, then both time and money can be saved.
    Furthermore, in high-stakes environments, including finance-based situations,
    such as trading, engineers that are aware can pull the plug when they notice their
    model is failing. This should not be seen as a failure, but as a success to avoid
    problems.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些错误能够尽早发现，那么既可以节省时间，又能节省金钱。此外，在高风险环境中，包括以金融为基础的情境，如交易，当工程师意识到模型失败时，可以及时停止。这个过程不应该被视为失败，而应视为避免问题的成功。
- en: Debugging data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试数据
- en: You'll remember that back in the first chapter of this book, we discussed how
    machine learning models are a function of their training data, meaning that, for
    example, bad data will lead to bad models, or as we put it, garbage in, garbage
    out. If your project is failing, your data is the most likely culprit. Therefore,
    in this chapter we will start by looking at the data first, before moving on to
    look at the other possible issues that might cause our model to crash.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得在本书的第一章中，我们讨论了机器学习模型是其训练数据的函数，这意味着，例如，糟糕的数据会导致糟糕的模型，或者用我们的话来说，垃圾进，垃圾出。如果你的项目失败了，数据很可能是罪魁祸首。因此，在本章中，我们将首先从数据开始，之后再看可能导致模型崩溃的其他问题。
- en: However, even if you have a working model, the real-world data coming in might
    not be up to the task. In this section, we will learn how to find out whether
    you have good data, what to do if you have not been given enough data, and how
    to test your data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使你有一个有效的模型，现实世界中的数据也可能无法满足任务要求。在本节中，我们将学习如何判断你是否拥有良好的数据，如何应对数据不足的情况，以及如何测试你的数据。
- en: How to find out whether your data is up to the task
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何判断你的数据是否足以完成任务
- en: 'There are two aspects to consider when wanting to know whether your data is
    up to the task of training a good model:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在判断你的数据是否足以训练一个良好模型时，有两个方面需要考虑：
- en: Does the data predict what you want it to predict?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据能预测你希望它预测的内容吗？
- en: Do you have enough data?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你有足够的数据吗？
- en: To find out whether your model does contain predicting information, also called
    a signal, you could ask yourself the question, could a human make a prediction
    given this data? It's important for your AI to be given data that can be comprehended
    by humans, because after all, the only reason we know intelligence is possible
    is because we observe it in humans. Humans are good at understanding written text,
    but if a human cannot understand a text, then the chances are that your model
    won't make much sense of it either.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要判断你的模型是否包含预测信息，也就是信号，你可以问自己这个问题：给定这些数据，人类能做出预测吗？重要的是，AI需要提供人类可以理解的数据，毕竟，我们之所以知道智能是可能的，正是因为我们在观察人类的智能。人类擅长理解书面文本，但如果一个人类无法理解一段文本，那么你的模型很可能也无法理解它。
- en: A common pitfall to this test is that humans have context that your model does
    not have. A human trader does not only consume financial data, but they might
    have also experienced the product of a company or seen the CEO on TV. This external
    context flows into the trader's decision but is often forgotten when a model is
    built. Likewise, humans are also good at focusing on important data. A human trader
    will not consume all of the financial data out there because most of it is irrelevant.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个测试的常见陷阱是，人类拥有模型没有的背景信息。一个人类交易员不仅会使用金融数据，还可能曾经使用过某个公司的产品，或者在电视上看到过该公司的 CEO。这些外部背景信息会影响交易员的决策，但在构建模型时往往会被忽视。同样，人类也擅长关注重要数据。人类交易员不会使用所有的金融数据，因为大部分数据是无关的。
- en: Adding more inputs to your model won't make it better; on the contrary, it often
    makes it worse, as the model overfits and gets distracted by all the noise. On
    the other hand, humans are irrational; they follow peer pressure and have a hard
    time making decisions in abstract and unfamiliar environments. Humans would struggle
    to find an optimal traffic light policy, for instance, because the data that traffic
    lights operate on is not intuitive to us.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 向模型添加更多输入并不会让它变得更好；相反，它通常会让模型变得更差，因为模型会过度拟合并被噪声干扰。另一方面，人类是非理性的；他们会受同龄人压力的影响，并且在抽象和陌生的环境中难以做出决策。例如，人类在寻找最优的交通信号灯策略时会感到困难，因为交通信号灯的操作数据对我们来说并不直观。
- en: 'This brings us to the second sanity check: a human might not be able to make
    predictions, but there might be a causal (economic) rationale. There is a causal
    link between a company''s profits and its share price, the traffic on a road and
    traffic jams, customer complaints and customers leaving your company, and so on.
    While humans might not have an intuitive grasp of these links, we can discover
    them through reasoning.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了第二个合理性检查：人类可能无法做出预测，但可能存在一种因果（经济）推理。公司的利润与股价、道路上的车流与交通堵塞、客户投诉与客户离开公司之间存在因果关系，等等。尽管人类可能无法直观地理解这些关系，我们可以通过推理发现它们。
- en: There are some tasks for which a causal link is required. For instance, for
    a long time, many quantitative trading firms insisted on their data having a causal
    link to the predicted outcomes of models. Yet nowadays, the industry seems to
    have slightly moved away from that idea as it gets more confident in testing its
    algorithms. If humans cannot make a prediction and there is no causal rationale
    for why your data is predictive, you might want to reconsider whether your project
    is feasible.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些任务要求数据之间有因果关系。例如，长期以来，许多量化交易公司坚持认为它们的数据必须与模型预测的结果之间存在因果关系。然而，如今，随着行业在测试其算法方面越来越自信，似乎这种观点略有改变。如果人类无法做出预测，并且没有因果理由说明你的数据具有预测性，那么你可能需要重新考虑你的项目是否可行。
- en: 'Once you have determined that your data contains enough signal, you need to
    ask yourself whether you have enough data to train a model to extract the signal.
    There is no clear answer to the question of how much is enough, but roughly speaking,
    the amount needed depends on the complexity of the model you hope to create. There
    are a couple of rules of thumb to follow, however:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定数据中包含足够的信号，你需要问自己是否有足够的数据来训练一个模型提取这些信号。对于“足够”这个问题并没有明确的答案，但大致而言，所需的量取决于你希望创建的模型的复杂性。不过，仍然有一些经验法则可以遵循：
- en: For classification, you should have around 30 independent samples per class.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于分类任务，每个类别应该大约有30个独立样本。
- en: You should have 10 times as many samples as there are features, especially for
    structured data problems.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别是对于结构化数据问题，你的样本数应该是特征数的10倍。
- en: Your dataset should get bigger as the number of parameters in your model gets
    bigger.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着模型中参数数量的增多，你的数据集也应该变得更大。
- en: Keep in mind these rules are only rules of thumb and might be very different
    for your specific application. If you can make use of transfer learning, then
    you can drastically reduce the number of samples you need. This is why most computer
    vision applications use transfer learning.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这些规则只是经验法则，可能与您的具体应用大不相同。如果你能够利用迁移学习，那么你可以大幅减少所需的样本数。这也是为什么大多数计算机视觉应用都使用迁移学习的原因。
- en: If you have any reasonable amount of data, say, a few hundred samples, then
    you can start building your model. In this case, a sensible suggestion would be
    to start with a simple model that you can deploy while you collect more data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一定数量的数据，比如几百个样本，那么你可以开始构建你的模型。在这种情况下，一个合理的建议是从一个简单的模型入手，并在收集更多数据的同时开始部署它。
- en: What to do if you don't have enough data
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如果你没有足够的数据该怎么办
- en: Sometimes, you find yourself in a situation where despite starting your project,
    you simply do not have enough data. For example, the legal team might have changed
    its mind and decided that you cannot use the data, for instance due to GDPR, even
    though they greenlit it earlier. In this case, you have multiple options.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能会发现自己处于一种情况，尽管已经开始了项目，但你根本没有足够的数据。例如，法律团队可能改变了主意，决定由于GDPR的原因，你不能使用数据，尽管他们之前已经批准了。在这种情况下，你有多个选择。
- en: Most of the time, one of the best options would be to "augment your data." We've already
    seen some data augmentation in [Chapter 3,](ch03.xhtml "Chapter 3. Utilizing Computer
    Vision") *Utilizing Computer Vision*. Of course, you can augment all kinds of data
    in various ways, including slightly changing some database entries. Taking augmentation
    a step further, you might be able to *generate your data*, for example, in a simulation.
    This is effectively how most reinforcement learning researchers gather data, but
    this can also work in other cases.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，最佳的选择之一是“增强你的数据”。我们已经在[第3章](ch03.xhtml "第3章：利用计算机视觉") *利用计算机视觉*中看到了一些数据增强。当然，你可以以各种方式增强各种数据，包括稍微修改一些数据库条目。更进一步的增强，你甚至可以*生成数据*，例如，在仿真中生成数据。这实际上是大多数强化学习研究人员收集数据的方式，但在其他情况下也可以适用。
- en: The data we used for fraud detection back in [Chapter 2](ch02.xhtml "Chapter 2. Applying
    Machine Learning to Structured Data"), *Applying Machine Learning to Structured
    Data* was obtained from simulation. The simulation requires you to be able to
    write down the rules of your environment within a program. Powerful learning algorithms
    tend to figure out these often over-simplistic rules, so they might not generalize
    to the real world as well. Yet, simulated data can be a powerful addition to real
    data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第2章](ch02.xhtml "第2章：将机器学习应用于结构化数据")中用于欺诈检测的数据，*将机器学习应用于结构化数据*，是通过模拟获得的。该模拟要求你能够在程序中写出环境的规则。强大的学习算法往往能够弄懂这些过于简单的规则，因此它们可能无法很好地泛化到真实世界中。然而，模拟数据仍然可以成为现实数据的有力补充。
- en: Likewise, you can often *find external data*. Just because you haven't tracked
    a certain data point, it does not mean that nobody else has. There is an astonishing
    amount of data available on the internet. Even if the data was not originally
    collected for your purpose, you might be able to retool data by either relabeling
    it or by using it for **transfer learning**. You might be able to train a model
    on a large dataset for a different task and then use that model as a basis for
    your task. Equally, you can find a model that someone else has trained for a different
    task and repurpose it for your task.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你通常可以*找到外部数据*。仅仅因为你没有跟踪某个数据点，并不意味着其他人没有。互联网上有惊人的数据量可供使用。即使这些数据最初并非为你的目的而收集，你也许可以通过重新标记数据或使用**迁移学习**来重新利用这些数据。你或许可以在一个大数据集上训练一个模型，用于不同的任务，然后将该模型作为你任务的基础。同样，你也可以找到别人为其他任务训练的模型，并将其重新用于你的任务。
- en: Finally, you might be able to create a **simple model**, which does not capture
    the relationship in the data completely but is enough to ship a product. Random
    forests and other tree-based methods often require much less data than neural
    networks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能能够创建一个**简单的模型**，它虽然不能完全捕捉数据中的关系，但足以用于发布产品。随机森林和其他基于树的方法通常比神经网络需要的数据量要少得多。
- en: It's important to remember that for data, quality trumps quantity in the majority
    of cases. Getting a small, high-quality dataset in and training a weak model is
    often your best shot to find problems with data early. You can always scale up
    data collection later. A mistake many practitioners make is that they spend huge
    amounts of time and money on getting a big dataset, only to find that they have
    the wrong kind of data for their project.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，对于数据来说，在大多数情况下，质量胜过数量。获取一个小而高质量的数据集并训练一个简单的模型，通常是及早发现数据问题的最佳方法。你可以在后续再扩大数据收集的规模。许多从业人员犯的一个错误是，花费大量时间和金钱去获取一个庞大的数据集，结果发现这些数据并不适合他们的项目。
- en: Unit testing data
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据单元测试
- en: If you build a model, you're making assumptions about your data. For example,
    you assume that the data you feed into your time series model is actually a time
    series with dates that follow each other in order. You need to test your data
    to make sure that this assumption is true. This is something that is especially
    true with live data that you receive once your model is already in production.
    Bad data might lead to poor model performance, which can be dangerous, especially
    in a high-stakes environment.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你构建了一个模型，那你就是在对你的数据做出假设。例如，你假设输入到时间序列模型中的数据确实是一个按顺序排列的时间序列数据。你需要测试数据，以确保这一假设成立。这对于那些已经投入生产的实时数据尤为重要。错误的数据可能导致模型性能不佳，这在高风险环境中可能是非常危险的。
- en: Additionally, you need to test whether your data is clean from things such as
    personal information. As we'll see in the following section on privacy, personal
    information is a liability that you want to get rid of, unless you have good reasons
    and consent from the user to use it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你需要测试你的数据是否存在个人信息等问题。正如我们在接下来的隐私部分中所看到的，个人信息是一种负担，你需要去除它，除非你有充分的理由并且获得了用户的同意才能使用它。
- en: 'Since monitoring data quality is important when trading based on many data
    sources, Two Sigma Investments LP, a New York City-based international hedge fund,
    has created an open source library for data monitoring. It is called *marbles*,
    and you can read more about it here: [https://github.com/twosigma/marbles](https://github.com/twosigma/marbles).
    marbles builds on Python''s `unittest` library.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在基于多个数据源进行交易时，监控数据质量非常重要，位于纽约市的国际对冲基金 Two Sigma Investments LP 创建了一个用于数据监控的开源库。它叫做
    *marbles*，你可以在这里了解更多：[https://github.com/twosigma/marbles](https://github.com/twosigma/marbles)。marbles
    基于 Python 的 `unittest` 库。
- en: 'You can install it with the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令安装它：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can find a Kaggle kernel demonstrating marbles here: [https://www.kaggle.com/jannesklaas/marbles-test](https://www.kaggle.com/jannesklaas/marbles-test).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：你可以在这里找到一个展示 marbles 的 Kaggle 内核：[https://www.kaggle.com/jannesklaas/marbles-test](https://www.kaggle.com/jannesklaas/marbles-test)。'
- en: The following code sample shows a simple marbles unit test. Imagine you are
    gathering data about the unemployment rate in Ireland. For your models to work,
    you need to ensure that you actually get the data for consecutive months, and
    don't count one month twice, for instance.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例展示了一个简单的 marbles 单元测试。假设你正在收集关于爱尔兰失业率的数据。为了确保模型的有效性，你需要确保获取到的是连续几个月的数据，并且避免重复计算某个月的数据。
- en: 'We can ensure this happens by running the following code:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过运行以下代码来确保这一点：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Don''t worry if you don''t fully understand the code. We''re now going to go
    through each stage of the code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有完全理解代码，也不用担心。接下来我们将逐步解析代码的每个阶段：
- en: Marbles features two main components. The `core` module does the actual testing,
    while the `mixins` module provides a number of useful tests for different types
    of data. This simplifies your test writing and gives you more readable and semantically
    interpretable tests.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Marbles 有两个主要组成部分。`core` 模块执行实际的测试，而 `mixins` 模块则为不同类型的数据提供了许多有用的测试。这简化了你的测试编写，并使得测试更加易读且具有语义可解释性。
- en: You can use all the libraries, like pandas, that you would usually use to handle
    and process data for testing.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用所有平时用来处理和测试数据的库，例如 pandas。
- en: Now it is time to define our test class. A new test class must inherit marbles'
    `TestCase` class. This way, our test class is automatically set up to run as a
    marbles test. If you want to use a mixin, you also need to inherit the corresponding
    mixin class.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是定义测试类的时候了。一个新的测试类必须继承 marbles 的 `TestCase` 类。通过这种方式，我们的测试类会自动被设置为 marbles
    测试。如果你想使用 mixin，你还需要继承相应的 mixin 类。
- en: In this example, we are working with a series of dates that should be increasing
    monotonically. The `MonotonicMixins` class provides a range of tools that allow
    you to test for a monotonically increasing series automatically.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个例子中，我们处理的是一个应当单调递增的日期序列。`MonotonicMixins` 类提供了一系列工具，可以帮助你自动测试一个单调递增的序列。
- en: If you are coming from Java programming, the concept of multiple inheritances
    might strike you as weird, but in Python, classes can easily inherit multiple
    other classes. This is useful if you want your class to inherit two different
    capabilities, such as running a test and testing time-related concepts.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你来自 Java 编程语言，多个继承的概念可能会让你觉得很奇怪，但在 Python 中，类可以轻松地继承多个其他类。这在你希望你的类继承两个不同的功能时非常有用，比如执行一个测试和测试与时间相关的概念。
- en: The `setUp` function is a standard test function in which we can load the data
    and prepare for the test. In this case, we just need to define a pandas DataFrame
    by hand. Alternatively, you could also load a CSV file, load a web resource, or
    pursue any other way in order to get your data.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`setUp` 函数是一个标准的测试函数，在其中我们可以加载数据并为测试做准备。在这个例子中，我们只需要手动定义一个 pandas DataFrame。你也可以选择加载
    CSV 文件、加载网络资源，或者采用任何其他方式来获取数据。'
- en: In our DataFrame, we have the Irish unemployment rate for two months. As you
    can see, the last month has been counted twice. As this should not happen, it
    will cause an error.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的 DataFrame 中，我们有两个月的爱尔兰失业率数据。正如你所看到的，最后一个月的数据被重复计算了两次。由于这种情况不应该发生，它会导致错误。
- en: The `tearDown` method is a standard test method that allows us to cleanup after
    our test is done. In this case, we just free RAM, but you can also choose to delete
    files or databases that were just created for testing.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tearDown` 方法是一个标准的测试方法，用于在测试完成后进行清理。在这个例子中，我们只是释放内存，但你也可以选择删除刚为测试创建的文件或数据库。'
- en: Methods describing actual tests should start with `test_`. marbles will automatically
    run all of the test methods after setting up.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述实际测试的方法应以 `test_` 开头。marbles 会在设置完毕后自动运行所有测试方法。
- en: We assert that the time indicator of our data strictly increases. If our assertion
    had required intermediate variables, such as a maximum value, marbles will display
    it in the error report. To make our error more readable, we can attach a handy
    note.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们断言数据的时间指示符严格递增。如果我们的断言需要中间变量，比如最大值，marbles 会在错误报告中显示出来。为了让错误信息更易读，我们可以附加一个便捷的说明。
- en: 'To run a unit test in a Jupyter Notebook, we need to tell marbles to ignore
    the first argument; we achieve this by running the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Jupyter Notebook 中运行单元测试，我们需要告诉 marbles 忽略第一个参数；我们可以通过运行以下命令来实现：
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It''s more common to run unit tests directly from the command line. So, if
    you saved the preceding code in the command line, you could run it with this command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 更常见的是直接从命令行运行单元测试。因此，如果你将前面的代码保存到命令行中，你可以使用以下命令来运行它：
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Of course, there are problems with our data. Luckily for us, our test ensures
    that this error does not get passed on to our model, where it would cause a silent
    failure in the form of a bad prediction. Instead, the test will fail with the
    following error output:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们的数据存在一些问题。幸运的是，我们的测试确保了这个错误不会传递到我们的模型中，否则它会导致一种静默失败，以错误的预测形式出现。相反，测试会以以下错误输出失败：
- en: Note
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: This code will not run and will fail.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：这段代码无法运行，会导致失败。'
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'So, what exactly caused the data to fail? Let''s have a look:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，究竟是什么导致了数据失败呢？我们来看看：
- en: 'The top line shows the status of the entire test. In this case, there was only
    one test method, and it failed. Your test might have multiple different test methods,
    and marbles would display the progress by showing how tests fail or pass.     The next couple of lines describe the failed test method. This line describes
    that the `test_date_order` method of the `TimeSeriesTestCase` class failed.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顶部一行显示了整个测试的状态。在这个例子中，只有一个测试方法，并且它失败了。你的测试可能有多个不同的测试方法，marbles 会通过显示测试是失败还是通过来展示进度。接下来的几行描述了失败的测试方法。这一行描述了
    `TimeSeriesTestCase` 类中的 `test_date_order` 方法失败的情况。
- en: marbles shows precisely how the test failed. The values of the dates tested
    are shown, together with the cause for failure.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: marbles 精确地显示了测试失败的原因。测试的日期值被显示出来，并且给出了失败的原因。
- en: In addition to the actual failure, marbles will display a traceback showing
    the actual code where our test failed.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了实际的失败之外，marbles 还会显示一个回溯信息，指明我们测试失败的实际代码位置。
- en: A special feature of marbles is the ability to display local variables. This
    way, we can ensure that there was no problem with the setup of the test. It also
    helps us in getting the context as to how exactly the test failed.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: marbles 的一个特别功能是能够显示局部变量。这样，我们可以确保测试的设置没有问题。它还帮助我们了解测试失败的上下文。
- en: Finally, marbles will display our note, which helps the test consumer understand
    what went wrong.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，marbles 会显示我们的说明，帮助测试使用者理解出了什么问题。
- en: As a summary, marbles displays that the test failed with one failure. Sometimes,
    you may be able to accept data even though it failed some tests, but more often
    than not you'll want to dig in and see what is going on.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结来说，marbles 显示测试失败，并且有一个失败的测试。有时，即使数据失败了一些测试，你也许可以接受这些数据，但更常见的是你会想要深入分析，看看到底发生了什么。
- en: The point of unit testing data is to make the failures loud in order to prevent
    data issues from giving you bad predictions. A failure with an error message is
    much better than a failure without one. Often, the failure is caused by your data
    vendor, and by testing all of the data that you got from all of the vendors, it
    will allow you to be aware when a vendor makes a mistake.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试数据的目的在于让失败显而易见，以防数据问题导致错误预测。带有错误信息的失败比没有错误信息的失败要好得多。通常，失败是由于数据供应商的原因，通过测试所有来自不同供应商的数据，你可以在供应商犯错时及时发现问题。
- en: Unit testing data also helps you to ensure you have no data that you shouldn't
    have, such as personal data. Vendors need to clean datasets of all personally
    identifying information, such as social security numbers, but of course, they
    sometimes forget. Complying with ever stricter data privacy regulation is a big
    concern for many financial institutions engaging in machine learning.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 单元测试数据还有助于确保你没有不应有的数据，比如个人数据。供应商需要清理数据集中的所有个人身份信息，例如社会保障号码，但他们有时会忽视这一点。遵守日益严格的数据隐私法规是许多从事机器学习的金融机构的重大关切。
- en: The next section will therefore discuss how to preserve privacy and comply with
    regulations while still gaining benefits from machine learning.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，下一部分将讨论如何在保护隐私和遵守法规的同时，仍能从机器学习中获得收益。
- en: Keeping data private and complying with regulations
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保持数据私密并遵守法规
- en: In recent years, consumers have woken up to the fact that their data is being
    harvested and analyzed in ways that they cannot control, and that is sometimes
    against their own interest. Naturally, they are not happy about it and regulators
    have to come up with some new data regulations.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，消费者意识到他们的数据被以他们无法控制的方式收集和分析，并且有时这些做法会损害他们的利益。自然，他们对此并不满意，监管机构必须提出一些新的数据法规。
- en: At the time of writing, the European Union has introduced the **General Data
    Protection Regulation** (**GDPR**), but it's likely that other jurisdictions will
    develop stricter privacy protections, too.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，欧盟已推出**通用数据保护条例**（**GDPR**），但其他地区也很可能会制定更严格的隐私保护措施。
- en: 'This text will not go into depth on how to comply with this law specifically.
    However, if you wish to expand your understanding of the topic, then the UK government''s
    guide to GDPR is a good starting place to learn more about the specifics of the
    regulation and how to comply with it: [https://www.gov.uk/government/publications/guide-to-the-general-data-protection-regulation](https://www.gov.uk/government/publications/guide-to-the-general-data-protection-regulation).'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 本文不会深入探讨如何具体遵守这项法律。然而，如果您希望进一步了解此话题，英国政府关于GDPR的指南是一个很好的起点，可以帮助您了解法规的具体内容及如何遵守：[https://www.gov.uk/government/publications/guide-to-the-general-data-protection-regulation](https://www.gov.uk/government/publications/guide-to-the-general-data-protection-regulation)。
- en: This section will outline both the key principles of the recent privacy legislation
    and some technological solutions that you can utilize in order to comply with
    these principles.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将概述最近隐私立法的关键原则以及一些技术解决方案，您可以利用这些方案来遵守这些原则。
- en: 'The overarching rule here is to, "delete what you don''t need." For a long
    time, a large percentage of companies have just stored all of the data that they
    could get their hands on, but this is a bad idea. Storing personal data is a liability
    for your business. It''s owned by someone else, and you are on the hook for taking
    care of it. The next time you hear a statement such as, "We have 500,000 records
    in our database," think of it more along the lines of, "We have 500,000 liabilities
    on our books." It can be a good idea to take on liabilities, but only if there
    is an economic value that justifies these liabilities. What happens astonishingly
    often though is that you might collect personal data by accident. Say you are
    tracking device usage, but accidentally include the customer ID in your records.
    You need practices in place that monitor and prevent such accidents, here are
    four of the key ones:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的总体规则是：“删除不需要的东西。”长期以来，很多公司只是存储所有能够收集到的数据，但这是一个不好的主意。存储个人数据对您的业务来说是一种负担。它是别人拥有的，而您则有责任照看它。下次当您听到诸如“我们的数据库中有50万个记录”时，不妨把它理解为“我们的账本上有50万项负债”。承担负债有时是一个好主意，但只有在这些负债有经济价值的情况下才值得这样做。令人惊讶的是，您可能会不小心收集到个人数据。例如，您在追踪设备使用情况时，可能不小心将客户ID包括在记录中。您需要实施一些预防和监控此类意外的做法，以下是四个关键措施：
- en: '**Be transparent and obtain consent**: Customers want good products, and they
    understand how their data can make your product better for them. Rather than pursuing
    an adversarial approach in which you wrap all your practices in a very long agreement
    and then make users agree to it, it is usually more sensible to clearly tell users
    what you are doing, how their data is used, and how that improves the product.
    If you need personal data, you need consent. Being transparent will help you down
    the line as users will trust you more and this can then be used to improve your
    product through customer feedback.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保持透明并获得同意**：顾客希望获得优质的产品，他们理解自己的数据如何能使您的产品更好地服务于他们。与其采用对立的方式，在其中将所有实践封装在一份很长的协议中，然后要求用户同意，不如明白地告诉用户您在做什么、他们的数据如何被使用以及这如何改善产品。如果您需要个人数据，您需要获得同意。保持透明将帮助您在以后赢得更多用户信任，进而通过客户反馈改进您的产品。'
- en: '**Remember that breaches happen to the best**: No matter how good your security
    is, there is a chance that you''ll get hacked. So, you should design your personal
    data storage under the assumption that the entire database might be dumped on
    the internet one day. This assumption will help you to create stronger privacy
    and help you to avoid disaster once you actually get hacked.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记住，漏洞发生在最优秀的人身上**：无论你的安全措施多么完善，总有被黑客攻击的可能。所以，你应该假设整个数据库有一天可能会被泄露到互联网，并在此基础上设计个人数据存储。这个假设将帮助你创建更强的隐私保护，并帮助你在真正被黑客攻击时避免灾难。'
- en: '**Be mindful about what can be inferred from data**: You might not be tracking
    personally identifying information in your database, but when combined with another
    database, your customers can still be individually identified.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**留意数据能推断出的信息**：你可能在数据库中没有跟踪个人身份信息，但当这些数据与另一个数据库结合时，你的客户仍然可以被单独识别。'
- en: Say you went for coffee with a friend, paid by credit card, and posted a picture
    of the coffee on Instagram. The bank might collect anonymous credit card records,
    but if someone went to crosscheck the credit card records against the Instagram
    pictures, there would only be one customer who bought a coffee and posted a picture
    of coffee at the same time in the same area. This way, all your credit card transactions
    are no longer anonymous. Consumers expect companies to be mindful of these effects.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 假设你和朋友去喝咖啡，用信用卡付款，并且在Instagram上发布了咖啡的照片。银行可能会收集匿名的信用卡记录，但如果有人去交叉检查信用卡记录和Instagram上的照片，就会发现只有一个顾客在同一地点、同一时间购买了咖啡并发布了咖啡的照片。这样，你的所有信用卡交易就不再是匿名的。消费者期望公司能注意到这些影响。
- en: '**Encrypt and Obfuscate data**: Apple, for instance, collects phone data but
    adds random noise to the collected data. The noise renders each individual record
    incorrect, but in aggregate the records still give a picture of user behavior.
    There are a few caveats to this approach; for example, you can only collect so
    many data points from a user before the noise cancels out, and the individual
    behavior is revealed.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密和模糊化数据**：例如，Apple收集电话数据，但会向收集到的数据添加随机噪声。这些噪声使得每一条单独的记录都不准确，但总体而言，这些记录仍然能够呈现出用户行为的全貌。这个方法有一些注意事项；例如，你只能从一个用户那里收集一定数量的数据点，否则噪声会抵消，最终揭示个体行为。'
- en: 'Noise, as introduced by obfuscation, is random. When averaged over a large
    sample of data about a single user, the mean of the noise will be zero as it does
    not present a pattern by itself. The true profile of the user will be revealed.
    Similarly, recent research has shown that deep learning models can learn on homomorphically
    encrypted data. Homomorphic encryption is a method of encryption that preserves the
    underlying algebraic properties of the data. Mathematically, this can be expressed as
    follows:'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 噪声是通过模糊化引入的，它是随机的。当对单个用户的大量数据进行平均时，噪声的均值将为零，因为它本身没有呈现出任何模式。用户的真实画像将会被揭示出来。类似的，最近的研究表明，深度学习模型可以在同态加密的数据上进行训练。同态加密是一种加密方法，它保持数据的基本代数属性。从数学上讲，这可以表达为以下形式：
- en: '![Keeping data private and complying with regulations](img/B10354_08_001.jpg)![Keeping
    data private and complying with regulations](img/B10354_08_002.jpg)'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![保持数据私密并遵守法规](img/B10354_08_001.jpg)![保持数据私密并遵守法规](img/B10354_08_002.jpg)'
- en: Here *E* is an encryption function, *m* is some plain text data, and *D* is
    a decryption function. As you can see, adding the encrypted data is the same as
    first adding the data and then encrypting it. Adding the data, encrypting it,
    and then decrypting it is the same as just adding the data.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，*E*是加密函数，*m*是某些明文数据，*D*是解密函数。正如你所看到的，添加加密后的数据与先添加数据然后加密是相同的。添加数据、加密然后解密与直接添加数据是一样的。
- en: This means you can encrypt the data and still train a model on it. Homomorphic
    encryption is still in its infancy, but through approaches like this, you can
    ensure that in the case of a data breach, no sensitive individual information
    is leaked.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着你可以加密数据，并仍然在其上训练模型。同态加密仍处于起步阶段，但通过这种方法，你可以确保在发生数据泄露时，没有敏感的个人信息被泄露。
- en: '**Train locally, and upload only a few gradients**: One way to avoid uploading
    user data is to train your model on the user''s device. The user accumulates data
    on the device. You can then download your model on to the device and perform a
    single forward and backward pass on the device.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在本地训练，只上传少量梯度**：避免上传用户数据的一种方法是将模型训练在用户设备上。用户在设备上积累数据。然后，你可以将模型下载到设备上，并在设备上执行一次前向和反向传播。'
- en: To avoid the possibility of inference of user data from the gradients, you only
    upload a few gradients at random. You can then apply the gradients to your master
    model.
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了避免从梯度中推断出用户数据的可能性，你只上传少量随机的梯度。然后，你可以将这些梯度应用到你的主模型中。
- en: To further increase the overall privacy of the system, you do not need to download
    all the newly update weights from the master model to the user's device, but only
    a few. This way, you train your model asynchronously without ever accessing any
    data. If your database gets breached, no user data is lost. However, we need to
    note that this only works if you have a large enough user base.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了进一步增强系统的整体隐私性，你不需要将所有更新后的权重从主模型下载到用户设备，而只需要下载一小部分。通过这种方式，你可以异步训练模型，而无需访问任何数据。如果你的数据库遭到泄露，用户数据不会丢失。然而，我们需要注意的是，只有在用户基数足够大的情况下，这种方法才有效。
- en: Preparing the data for training
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备训练数据
- en: 'In earlier chapters, we have seen the benefits of normalizing and scaling features,
    we also discussed how you should scale all numerical features. There are four
    ways of feature scaling; these include s*tandardization, Min-Max, mean normalization,*
    and *unit length scaling*. In this section we''ll break down each one:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们已经看到了标准化和缩放特征的好处，并讨论了如何缩放所有数值特征。特征缩放有四种方式；它们包括**标准化、Min-Max、均值归一化**和**单位长度缩放**。在本节中，我们将逐一解析每种方式：
- en: '**Standardization** ensures that all of the data has a mean of zero and a standard
    deviation of one. It is computed by subtracting the mean and dividing by the standard
    deviation of the data:![Preparing the data for training](img/B10354_08_003.jpg)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化**确保所有数据的均值为零，标准差为一。它是通过减去均值并除以数据的标准差来计算的：![准备训练数据](img/B10354_08_003.jpg)'
- en: This is probably the most common way of scaling features. It's especially useful
    if you suspect that your data contains outliers as it is quite robust. On the
    flip side, standardization does not ensure that your features are between zero
    and one, which is the range in which neural networks learn best.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可能是最常见的特征缩放方式。如果你怀疑数据中包含异常值，这种方法尤其有用，因为它对异常值比较稳健。另一方面，标准化不能保证你的特征值在零到一之间，而神经网络通常在这个范围内表现最好。
- en: '**Min-Max** rescaling does exactly that. It scales all data between zero and
    one by first subtracting the minimum value and then dividing by the range of values.
    We can see this expressed in the formula below:![Preparing the data for training](img/B10354_08_004.jpg)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Min-Max**缩放正是做到了这一点。它首先减去最小值，然后除以值的范围，将所有数据缩放到零和一之间。我们可以通过下面的公式看到这一点：![准备训练数据](img/B10354_08_004.jpg)'
- en: If you know for sure that your data contains no outliers, which is the case
    in images, for instance, Min-Max scaling will give you a nice scaling of values
    between zero and one.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你确信数据中没有异常值，例如在图像处理中，Min-Max缩放将把数据的值很好地缩放到零和一之间。
- en: Similar to Min-Max, **mean normalization** ensures your data has values between
    minus one and one with a mean of zero. This is done by subtracting the mean and
    then dividing by the range of data, which is expressed in the following formula:![Preparing
    the data for training](img/B10354_08_005.jpg)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于Min-Max，**均值归一化**确保你的数据值在-1和1之间，且均值为零。这是通过减去均值并除以数据的范围来完成的，公式如下所示：![准备训练数据](img/B10354_08_005.jpg)
- en: Mean normalization is done less frequently but, depending on your application,
    might be a good approach.
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 均值归一化使用得较少，但根据你的应用场景，这可能是一个不错的方法。
- en: For some applications, it is better to not scale individual features, but instead
    vectors of features. In this case, you would apply **unit length scaling** by
    dividing each element in the vector by the total length of the vector, as we can
    see below:![Preparing the data for training](img/B10354_08_006.jpg)
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于某些应用，最好不要对单独的特征进行缩放，而是对特征向量进行缩放。在这种情况下，你可以通过将向量中的每个元素除以向量的总长度来应用**单位长度缩放**，如下所示：![准备训练数据](img/B10354_08_006.jpg)
- en: The length of the vector usually means the L2 norm of the vector ![Preparing
    the data for training](img/B10354_08_007.jpg), that is, the square root of the
    sum of squares. For some applications, the vector length means the L1 norm of
    the vector, ![Preparing the data for training](img/B10354_08_008.jpg), which is
    the sum of vector elements.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 向量的长度通常意味着向量的 L2 范数 ![Preparing the data for training](img/B10354_08_007.jpg)，即平方和的平方根。对于某些应用，向量的长度意味着
    L1 范数 ![Preparing the data for training](img/B10354_08_008.jpg)，即向量元素的和。
- en: However you scale, it is important to only measure the scaling factors, mean,
    and standard deviation on the test set. These factors include only a select amount
    of the information about the data. If you measure them over your entire dataset,
    then the algorithm might perform better on the test set than it will in production,
    due to this information advantage.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您如何缩放，都很重要的一点是仅在测试集上衡量缩放因子、均值和标准差。这些因素只包含关于数据的一部分信息。如果您在整个数据集上衡量它们，那么由于信息优势，算法可能在测试集上的表现会比在生产环境中的表现要好。
- en: Equally importantly, you should check that your production code has proper feature
    scaling as well. Over time, you should recalculate your feature distribution and
    adjust your scaling.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是，您应该检查您的生产代码是否具有正确的特征缩放。随着时间的推移，您应该重新计算特征分布并调整缩放。
- en: Understanding which inputs led to which predictions
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解哪些输入导致了哪些预测
- en: Why did your model make the prediction it made? For complex models, this question
    is pretty hard to answer. A global explanation for a very complex model might
    in itself be very complex. The **Local Interpretable Model-Agnostic Explanations**
    (**LIME**) is, a popular algorithm for model explanation that focuses on local
    explanations. Rather than trying to answer; "How does this model make predictions?"
    LIME tries to answer; "Why did the model make *this* prediction on *this* data?"
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么您的模型做出了那个预测？对于复杂的模型来说，这个问题很难回答。对于一个非常复杂的模型，全球解释本身可能就非常复杂。**局部可解释模型无关解释**（**LIME**）是一个受欢迎的模型解释算法，专注于局部解释。LIME
    不是试图回答：“这个模型是如何做出预测的？”而是试图回答：“为什么模型在*这*个数据上做出了*这个*预测？”
- en: Note
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: The authors of LIME, Ribeiro, Singh, and Guestrin, curated a great
    GitHub repository around their algorithm with many explanations and tutorials,
    which you can find here: [https://github.com/marcotcr/lime](https://github.com/marcotcr/lime).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：LIME 的作者 Ribeiro、Singh 和 Guestrin 针对他们的算法整理了一个很棒的 GitHub 仓库，里面有许多解释和教程，您可以在这里找到：[https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)。'
- en: 'On Kaggle kernels, LIME is installed by default. However, you can install LIME
    locally with the following command:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kaggle Kernels 上，LIME 默认已安装。不过，您也可以通过以下命令在本地安装 LIME：
- en: '[PRE6]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The LIME algorithm works with any classifier, which is why it is model agnostic.
    To make an explanation, LIME cuts up the data into several sections, such as areas
    of an image or utterances in a text. It then creates a new dataset by removing
    some of these features. It runs this new dataset through the black box classifier
    and obtains the classifiers predicted probabilities for different classes. LIME
    then encodes the data as vectors describing what features were present. Finally,
    it trains a linear model to predict the outcomes of the black box model with different
    features removed. As linear models are easy to interpret, LIME will use the linear
    model to determine the most important features.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: LIME 算法适用于任何分类器，这也是它与模型无关的原因。为了进行解释，LIME 会将数据划分为多个部分，例如图像的区域或文本中的语句。然后，它通过删除一些特征来创建一个新的数据集。它将这个新数据集通过黑盒分类器，并获得分类器对不同类别的预测概率。接着，LIME
    将数据编码为向量，描述哪些特征是存在的。最后，它训练一个线性模型，通过去除不同的特征来预测黑盒模型的结果。由于线性模型容易解释，LIME 将使用线性模型来确定最重要的特征。
- en: 'Let''s say that you are using a text classifier, such as TF-IDF, to classify
    emails such as those in the 20 newsgroup dataset. To get explanations from this
    classifier, you would use the following snippet:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您正在使用文本分类器，例如 TF-IDF，来分类像 20 个新闻组数据集中的电子邮件。要从这个分类器获得解释，您可以使用以下代码片段：
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, let''s understand what''s going on in that code snippet:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们理解一下该代码片段中的内容：
- en: The LIME package has several classes for different types of data.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LIME 包含多个类，用于处理不同类型的数据。
- en: To create a new blank explainer, we need to pass the names of classes of our classifier.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建一个新的空白解释器，我们需要传入分类器的类名。
- en: We'll provide one text example for which we want an explanation.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将提供一个文本示例，您希望为其提供解释。
- en: We provide the prediction function of our classifier. We need to provide a function
    that provides probabilities. For Keras, this is just `model.predict`;for scikit
    models, we need to use the `predict_proba` method.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们提供了分类器的预测函数。我们需要提供一个返回概率的函数。对于Keras，这个函数就是`model.predict`；对于scikit模型，我们需要使用`predict_proba`方法。
- en: LIME shows the maximum number of features. We want to show only the importance
    of the six most important features in this case.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LIME展示了最大数量的特征。在这种情况下，我们只想展示最重要的六个特征的重要性。
- en: 'Finally, we can render a visualization of our prediction, which looks like
    this:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以呈现我们预测结果的可视化，效果如下：
- en: '![Understanding which inputs led to which predictions](img/B10354_08_01.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![理解哪些输入导致了哪些预测](img/B10354_08_01.jpg)'
- en: LIME text output
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: LIME文本输出
- en: The explanation shows the classes with different features that the text gets
    classified as most often. It shows the words that most contribute to the classification
    in the two most frequent classes. Under that, you can see the words that contributed
    to the classification highlighted in the text.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 解释展示了文本最常被分类为的不同特征的类别。它显示了对分类贡献最大的词语，以及在两个最常见类别中的分类贡献。下方，你可以看到在文本中被突出显示的贡献于分类的词语。
- en: As you can see, our model picked up on parts of the email address of the sender
    as distinguishing features, as well as the name of the university, "Rice." It
    sees "Caused" to be a strong indicator that the text is about atheism. Combined,
    these are all things we want to know when debugging datasets.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们的模型捕捉到了发件人电子邮件地址的一部分作为区分特征，以及大学名称“Rice”。它还认为“Caused”是文本与无神论相关的强烈指示。将这些因素结合起来，这些都是我们在调试数据集时想要了解的内容。
- en: LIME does not perfectly solve the problem of explaining models. It struggles
    if the interaction of multiple features leads to a certain outcome for instance.
    However, it does well enough to be a useful data debugging tool. Often, models
    pick up on things they should not be picking up on. To debug a dataset, we need
    to remove all these "give-away" features that statistical models like to overfit
    to.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: LIME并不能完美解决解释模型的问题。例如，当多个特征的交互作用导致某个特定结果时，它可能会遇到困难。然而，它足够好，能够成为一个有用的数据调试工具。通常，模型会捕捉到一些它们不应该捕捉的特征。为了调试数据集，我们需要去除所有这些统计模型容易过拟合的“提示”特征。
- en: Looking back at this section, you've now seen a wide range of tools that you
    can use to debug your dataset. Yet, even with a perfect dataset, there can be
    issues when it comes to training. The next section is about how to debug your
    model.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾本节内容，你现在已经看到了可以用来调试数据集的一系列工具。然而，即使数据集完美无缺，训练时仍然可能遇到问题。下一节将介绍如何调试你的模型。
- en: Debugging your model
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试你的模型
- en: Complex deep learning models are prone to error. With millions of parameters,
    there are a number things that can go wrong. Luckily, the field has developed
    a number of useful tools to improve model performance. In this section, we will
    introduce the most useful tools that you can use to debug and improve your model.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的深度学习模型容易出错。由于有数百万个参数，可能会出现很多问题。幸运的是，随着这个领域的发展，已经有了许多有用的工具来提升模型性能。在本节中，我们将介绍一些你可以用来调试和改进模型的最有用工具。
- en: Hyperparameter search with Hyperas
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Hyperas进行超参数搜索
- en: Manually tuning the hyperparameters of a neural network can be a tedious task.
    Despite you possibly having some intuition about what works and what does not,
    there are no hard rules to apply when it comes to tuning hyperparameters. This
    is why practitioners with lots of computing power on hand use automatic hyperparameter
    search. After all, hyperparameters form a search space just like the model's parameters
    do. The difference is that we cannot apply backpropagation to them and cannot
    take derivatives of them. We can still apply all non-gradient based optimization
    algorithms to them.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 手动调节神经网络的超参数可能是一个繁琐的任务。尽管你可能对哪些有效、哪些无效有一定的直觉，但在调节超参数时并没有硬性规则。因此，许多拥有强大计算能力的从业者采用自动超参数搜索。毕竟，超参数构成了一个搜索空间，就像模型的参数一样。不同之处在于，我们无法对它们应用反向传播，也无法对其求导。但我们仍然可以对它们应用所有非梯度优化算法。
- en: There are a number of different hyperparameter optimization tools, but we will
    look at Hyperas because of its ease of use. Hyperas is a wrapper for `hyperopt`,
    a popular optimization library made for working with Keras.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的超参数优化工具，但我们将重点介绍Hyperas，因为它易于使用。Hyperas是`hyperopt`的一个封装，`hyperopt`是一个流行的优化库，专为与Keras配合使用而设计。
- en: Note
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can find Hyperas on GitHub: [https://github.com/maxpumperla/hyperas](https://github.com/maxpumperla/hyperas).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：你可以在 GitHub 上找到 Hyperas：[https://github.com/maxpumperla/hyperas](https://github.com/maxpumperla/hyperas)。'
- en: 'We can install Hyperas with `pip`:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `pip` 安装 Hyperas：
- en: '[PRE8]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Depending on your setup, you might need to make a few adjustments to the installation.
    If this is the case, then the Hyperas GitHub page, link above, offers more information.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的环境设置，你可能需要对安装过程做一些调整。如果是这种情况，前面提到的 Hyperas GitHub 页面提供了更多信息。
- en: Hyperas offers two optimization methods, **Random Search** and **Tree of Parzen
    Estimators**. Within a range of parameters that we think are reasonable, the random
    search will sample randomly and train a model with random hyperparameters. It will
    then pick the best-performing model as the solution.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Hyperas 提供了两种优化方法：**随机搜索** 和 **Parzen 估计树**。在我们认为合理的超参数范围内，随机搜索会随机抽样并用随机超参数训练一个模型。然后它会选择性能最好的模型作为最终解。
- en: '**Random search** is simple and robust, and it can be scaled easily. It basically
    makes no assumption about the hyperparameters, their relation, and the loss surface.
    On the flip side, it is relatively slow.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机搜索** 简单且稳健，并且可以轻松扩展。它基本上不对超参数、它们之间的关系和损失面做出任何假设。另一方面，它相对较慢。'
- en: The **Tree of Parzen** (**TPE**) algorithm models the relation *P(x|y),* where
    *x* represents the hyperparameters and *y* the associated performance. This is
    the exact opposite modeling of Gaussian processes, which model *P(y|x)* and are
    popular with many researchers.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**Parzen 估计树**（**TPE**）算法建模了 *P(x|y)* 的关系，其中 *x* 代表超参数，*y* 代表相关的性能。这与高斯过程的建模方式正好相反，高斯过程建模的是
    *P(y|x)*，并且广受许多研究人员的青睐。'
- en: 'Empirically, it turns out that TPE performs better. For the precise details, see
    the 2011 paper, *Algorithms for Hyper-Parameter Optimization*, available at: [https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization)
    -- that was authored by James S. Bergstra and others. TPE is faster than random
    search but can get stuck in local minima and struggles with some difficult loss
    surfaces. As a rule of thumb, it makes sense to start with TPE, and if TPE struggles,
    move to random search.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 实践证明，TPE 的表现更好。有关详细信息，请参见 2011 年的论文《*超参数优化算法*》，可在以下链接查阅：[https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization)
    —— 该论文由 James S. Bergstra 等人撰写。TPE 比随机搜索更快，但可能会陷入局部最小值，并且在某些困难的损失面上表现不佳。根据经验，通常建议从
    TPE 开始，如果 TPE 遇到困难，再切换到随机搜索。
- en: Note
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: The code for this example can be found at: [https://www.kaggle.com/jannesklaas/Hyperas](https://www.kaggle.com/jannesklaas/Hyperas).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：本示例的代码可以在以下链接找到：[https://www.kaggle.com/jannesklaas/Hyperas](https://www.kaggle.com/jannesklaas/Hyperas)。'
- en: 'The following example will show you how to use Hyperas and Hyperopt for an
    MNIST dataset classifier:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例将展示如何使用 Hyperas 和 Hyperopt 来构建一个 MNIST 数据集分类器：
- en: '[PRE9]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'While the code was short, let''s explain what it all means:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然代码很简短，但我们还是来解释一下它的含义：
- en: As Hyperas is built on Hyperopt, we need to import some pieces directly from
    `hyperopt`. The `Trials` class runs the actual trials, `STATUS_OK` helps communicate
    that a test went well, and `tpe` is an implementation of the TPE algorithm.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于 Hyperas 构建于 Hyperopt 之上，我们需要直接从 `hyperopt` 导入一些组件。`Trials` 类执行实际的实验，`STATUS_OK`
    帮助表示测试顺利，`tpe` 是 TPE 算法的实现。
- en: Hyperas provides a number of handy functions that make working with Hyperopt
    easier. The `optim` function finds optimal hyperparameters and can be used just
    like Keras' `fit` function. `choice` and `uniform` can be used to choose between
    discrete and continuous hyperparameters respectively.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hyperas 提供了一些方便的函数，使得与 Hyperopt 一起工作更加容易。`optim` 函数找到最佳的超参数，可以像 Keras 的 `fit`
    函数一样使用。`choice` 和 `uniform` 分别可以用于选择离散和连续的超参数。
- en: 'To build on the previous ideas that we''ve explored, let''s now add the following,
    which we will explain in more detail once the code has been written:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在我们之前探索的基础上进行扩展，接下来我们将添加以下内容，代码编写完后我们将详细解释：
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s take a moment to look at the code we''ve just produced:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间看看我们刚刚编写的代码：
- en: Hyperas expects a function that loads the data; we cannot just pass on a dataset
    from memory.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hyperas 期望一个加载数据的函数；我们不能直接传递一个内存中的数据集。
- en: To scale the search, Hyperas creates a new runtime in which it does model creation
    and evaluation. This also means imports that we did in a notebook do not always
    transfer into the runtime. To be sure that all modules are available, we need
    to do all imports in the `data` function. This is also true for modules that will
    only be used for the model.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了扩展搜索，Hyperas创建了一个新的运行时，在其中进行模型创建和评估。这也意味着我们在笔记本中做的导入并不总是会传递到运行时中。为了确保所有模块都可用，我们需要在`data`函数中进行所有导入。这对于只在模型中使用的模块也同样适用。
- en: 'We now load the data. Since Kaggle kernels do not have access to the internet,
    we need to load the MNIST data from disk. If you have internet, but no local version
    of the files, you can get the data using following code:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在加载数据。由于Kaggle内核无法访问互联网，我们需要从磁盘加载MNIST数据。如果你有互联网，但没有本地版本的文件，你可以使用以下代码获取数据：
- en: '[PRE11]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: I would still keep the no internet version around because it is the default
    setting.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我仍然会保留没有互联网版本，因为它是默认设置。
- en: The `data` function also needs to preprocess the data. We do the standard reshaping
    and scaling that we did when we worked with MNIST earlier.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`data`函数还需要对数据进行预处理。我们做了与之前处理MNIST时相同的标准重塑和缩放。'
- en: 'Finally, we return the data. This data will be passed into the function that
    builds and evaluates the model:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们返回数据。这些数据将传递给构建和评估模型的函数：
- en: '[PRE12]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'As you can see, the preceding snippet of code is made up of eight defining
    pieces. Let''s now explore them so that we''re able to fully understand the code
    we''ve just produced:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，前面的代码片段由八个定义性部分组成。接下来我们将探索这些部分，以便能够完全理解我们刚刚写出的代码：
- en: The `model` function both defines the model and evaluates it. Given a training
    dataset from the `data` function, it returns a set of quality metrics.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`model`函数既定义了模型，也对其进行了评估。给定来自`data`函数的训练数据集，它会返回一组质量指标。'
- en: When fine-tuning with Hyperas, we can define a Keras model just as we usually
    would. Here, we only have to replace the hyperparameters we want to tune with
    Hyperas functions.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用Hyperas进行微调时，我们可以像通常一样定义一个Keras模型。在这里，我们只需用Hyperas函数替换我们希望调整的超参数。
- en: To tune dropout, for instance, we replace the `Dropout` hyperparameter with
    `{{uniform(0, 0.5)}}`. Hyperas will automatically sample and evaluate dropout
    rates between `0` and `0.5`, sampled from a uniform distribution.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 例如，为了调整dropout，我们将`Dropout`超参数替换为`{{uniform(0, 0.5)}}`。Hyperas将自动从`0`到`0.5`之间的均匀分布中采样并评估dropout率。
- en: To sample from discrete distributions, for instance, the size of a hidden layer,
    we replace the hyperparameter with `{{choice([256, 512, 1024])}}`. Hyperas will
    choose from a hidden layer size of 256, 512, and 1,024 now.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从离散分布中采样，例如隐藏层的大小，我们用`{{choice([256, 512, 1024])}}`替换超参数。Hyperas现在将从256、512和1024三个隐藏层大小中进行选择。
- en: We can do the same to choose activation functions.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们也可以做同样的事情来选择激活函数。
- en: To evaluate the model, we need to compile and fit it. In this process, we can
    also choose between different batch sizes. In this case, we only train for one
    epoch, to keep the time needed for this example short. You could also run a whole
    training process with Hyperas.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要评估模型，我们需要编译并拟合它。在此过程中，我们还可以选择不同的批次大小。在这种情况下，我们只训练一个epoch，以保持本示例所需的时间较短。你也可以使用Hyperas运行整个训练过程。
- en: To gain insight into how well the model is doing, we evaluate it on test data.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了了解模型的表现如何，我们在测试数据上对其进行评估。
- en: Finally, we return the model's score, the model itself, and an indicator that
    everything went okay. Hyperas tries to minimize a loss function. To maximize accuracy,
    we set the loss to be the negative accuracy. You could also pass the model loss
    here, depending on what the best optimization method is for your problem.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们返回模型的得分、模型本身以及一个指示一切正常的标志。Hyperas尝试最小化损失函数。为了最大化准确性，我们将损失设置为负准确性。你也可以根据你的问题传递模型损失，这取决于最佳的优化方法是什么。
- en: 'Finally, we run the optimization:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们运行优化：
- en: '[PRE13]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We pass the `model` method and the `data` method, and we specify how many trials
    we want to run and which class should govern the trials. Hyperopt also offers
    a distributed trials class in which workers communicate via MongoDB.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递`model`方法和`data`方法，并指定要运行多少次试验，以及哪个类应负责管理这些试验。Hyperopt还提供了一个分布式试验类，工作节点通过MongoDB进行通信。
- en: When working in a Jupyter Notebook, we need to provide the name of the notebook
    we are working in. Kaggle Notebooks all have the filename `__notebook_source__`,
    regardless of the name you gave them.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Jupyter Notebook时，我们需要提供我们正在使用的笔记本名称。Kaggle Notebooks的文件名都是`__notebook_source__`，无论你给它们取了什么名字。
- en: 'After it''s run, Hyperas returns the best-performing model as well as the hyperparameters
    of the best model. If you print out `best_run`, you should see output similar
    to this:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 运行后，Hyperas会返回表现最佳的模型以及最佳模型的超参数。如果你打印出`best_run`，你应该会看到类似这样的输出：
- en: '[PRE14]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For `choice` selections, Hyperas shows the index. In this case, the activation
    function `tanh` was chosen.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`choice`选择，Hyperas显示的是索引。在这个例子中，选择了激活函数`tanh`。
- en: In this case we ran the hyperparameter search only for a few trials. Usually,
    you would run a few hundred or thousand trials. To do this we would use automated
    hyperparameter search, which can be a great tool to improve model performance
    if you have enough compute power available.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们只进行了几次超参数搜索。通常情况下，你会运行几百次或几千次实验。为了做到这一点，我们可以使用自动化超参数搜索，这是提升模型性能的一个很好的工具，前提是你有足够的计算能力。
- en: However, it won't get a model that does not work at all to work. When choosing
    this approach, you need to be sure to have a somewhat-working approach first before
    investing in hyperparameter search.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它并不能使一个完全不起作用的模型开始工作。选择这种方法时，你需要确保在投资超参数搜索之前，首先有一个“勉强可用”的方法。
- en: Efficient learning rate search
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有效的学习率搜索
- en: One of the most important hyperparameters is the learning rate. Finding a good
    learning rate is hard. Too small and your model might train so slowly that you
    believe it is not training at all, but if it's too large it will overshoot and
    not reduce the loss as well.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最重要的超参数是学习率。找到一个合适的学习率非常困难。学习率太小，模型可能训练得太慢，以至于你认为它根本没有训练，但如果学习率过大，模型会超调，无法有效地减少损失。
- en: When it comes to finding a learning rate, standard hyperparameter search techniques
    are not the best choice. For the learning rate, it is better to perform a line
    search and visualize the loss for different learning rates, as this will give
    you an understanding of how the loss function behaves.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到寻找学习率时，标准的超参数搜索技术并不是最好的选择。对于学习率，更好的方法是进行线性搜索，并可视化不同学习率下的损失情况，因为这将帮助你理解损失函数的行为。
- en: When doing a line search, it is better to increase the learning rate exponentially.
    You are more likely to care about the region of smaller learning rates than about
    very large learning rates.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行线性搜索时，最好是指数方式增加学习率。你可能更关心较小学习率的区域，而不是非常大的学习率。
- en: 'In our example below, we perform 20 evaluations and double the learning rate
    in every evaluation. We can run this by executing the following code:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们进行20次评估，并在每次评估中将学习率加倍。我们可以通过执行以下代码来运行此过程：
- en: '[PRE15]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s now take a more detailed look at the preceding featured code:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更详细地看看前面的特色代码：
- en: We specify a low, but still reasonable, initial learning rate from which we
    start our search.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们指定一个较低但仍然合理的初始学习率，从这个学习率开始我们的搜索。
- en: We then perform training 20 times with different learning rates. We need to set
    up the model from scratch each time.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用不同的学习率进行20次训练。每次都需要从头开始设置模型。
- en: We calculate our new learning rate. In our case, we double the learning rate
    in each evaluation step. You could also use a smaller increase if you want a more
    fine-grained picture.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算出新的学习率。在我们的例子中，我们在每次评估步骤中将学习率加倍。如果你希望得到更细粒度的结果，也可以使用较小的增量。
- en: We then fit the model with our new learning rate.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们用新的学习率来拟合模型。
- en: Finally, we keep track of the loss.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们跟踪损失。
- en: 'If your dataset is very large, you can perform this learning rate search on
    a subset of the data. The interesting part comes from the visualization of learning
    rates:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据集非常大，你可以在数据的一个子集上执行此学习率搜索。这里的有趣部分来自于对学习率的可视化：
- en: '[PRE16]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When you run this code, it will then output the following chart:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行这段代码时，它将输出以下图表：
- en: '![Efficient learning rate search](img/B10354_08_02.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![有效的学习率搜索](img/B10354_08_02.jpg)'
- en: Learning rate finder
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率查找器
- en: As you can see, the loss is optimal between 1e-3 and 1e-2\. We can also see
    that the loss surface is relatively flat in this area. This gives us insight that
    we should use a learning rate around 1e-3\. To avoid overshooting, we select a
    learning rate somewhat lower than the optimum found by line search.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，损失在 1e-3 和 1e-2 之间是最优的。我们还可以看到，在这一区域内，损失曲面相对平坦。这给了我们一个提示，应该使用接近 1e-3 的学习率。为了避免超调，我们选择一个略低于通过线搜索找到的最优学习率。
- en: Learning rate scheduling
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习率调度
- en: 'Why stop at using one learning rate? In the beginning, your model might be
    far away from the optimal solution, and so because of that you want to move as
    fast as possible. As you approach the minimum loss, however, you want to move
    slower to avoid overshooting. A popular method is to anneal the learning rate
    so that it represents a cosine function. To this end, we need to the find a learning
    rate scheduling function, that given a time step, *t*, in epochs returns a learning
    rate. The learning rate becomes a function of *t*:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么只使用一个学习率呢？一开始，您的模型可能离最优解很远，因此您希望尽可能快速地移动。然而，随着损失接近最小值，您希望移动得更慢，以避免超调。一种流行的方法是退火学习率，使其表现为余弦函数。为此，我们需要找到一个学习率调度函数，该函数在给定时间步
    *t* 的情况下，返回一个学习率。学习率成为 *t* 的函数：
- en: '![Learning rate scheduling](img/B10354_08_009.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![学习率调度](img/B10354_08_009.jpg)'
- en: 'Here *l* is the cycle length and ![Learning rate scheduling](img/B10354_08_010.jpg)
    is the initial learning rate. We modify this function to ensure that *t* does
    not become larger than the cycle length:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 *l* 是周期长度，![学习率调度](img/B10354_08_010.jpg) 是初始学习率。我们修改此函数以确保 *t* 不会超过周期长度：
- en: '[PRE17]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding code features three key features:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码包含了三个关键特点：
- en: In our function, we need to set up a starting point from which we anneal. This
    can be a relatively large learning rate. We also need to specify how many epochs
    we want to anneal.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的函数中，我们需要设置一个起始点，从这个点开始退火。这可以是一个相对较大的学习率。我们还需要指定退火的 epoch 数。
- en: A cosine function does not monotonically decrease; it goes back up after a cycle.
    We will use this property later; for now, we will just make sure that the learning
    rate does not go back up.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 余弦函数并不是单调递减的；它在一个周期后会回升。我们稍后会利用这个特性；现在，我们只需要确保学习率不会回升。
- en: Finally we calculate the new learning rate using the preceding formula. This is the
    new learning rate.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用前面的公式计算新的学习率。这就是新的学习率。
- en: 'To get a better understanding of what the learning rate scheduling function
    does, we can plot the learning rate it would set over 10 epochs:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解学习率调度函数的作用，我们可以绘制它在 10 个 epoch 中设定的学习率：
- en: '[PRE18]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'With the output of the code being shown in the following graph:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的输出将在下图中显示：
- en: '![Learning rate scheduling](img/B10354_08_03.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![学习率调度](img/B10354_08_03.jpg)'
- en: Cosine anneal
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦退火
- en: 'We can use this function to schedule learning rates with Keras'' `LearningRateScheduler`
    callback:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这个函数通过 Keras 的 `LearningRateScheduler` 回调来调度学习率：
- en: '[PRE19]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We now have a callback that Keras will call at the end of each epoch in order
    to get a new learning rate. We pass this callback to the `fit` method and voilà,
    our model trains with a decreasing learning rate:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个回调，Keras 会在每个 epoch 结束时调用它以获取新的学习率。我们将此回调传递给 `fit` 方法，瞧，我们的模型开始以递减的学习率进行训练：
- en: '[PRE20]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'A version of the learning rate annealing is to add restarts. At the end of
    an annealing cycle, we move the learning rate back up. This is a method used to
    avoid overfitting. With a small learning rate, our model might find a very narrow
    minimum. If the data we want to use our model on is slightly different from the
    training data, then the loss surface might change a bit, and our model could be
    out of the narrow minimum for this new loss surface. If we set the learning rate
    back up, our model will get out of narrow minima. Broad minima, however, are stable
    enough for the model to stay in them:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 一种学习率退火的版本是加入重启。在每个退火周期结束时，我们将学习率重新提高。这是一种用于避免过拟合的方法。使用较小的学习率时，模型可能会找到一个非常狭窄的最小值。如果我们想要在稍微不同的测试数据上使用模型，那么损失曲面可能会发生一些变化，模型可能会偏离这个狭窄的最小值。如果我们将学习率重新提高，模型将摆脱狭窄的最小值。然而，广阔的最小值足够稳定，模型可以停留在这些地方：
- en: '![Learning rate scheduling](img/B10354_08_04.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![学习率调度](img/B10354_08_04.jpg)'
- en: Shallow broad minima
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 浅的广阔最小值
- en: 'As the cosine function goes back up by itself, we only have to remove the line
    to stop it from doing so:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 由于余弦函数本身会向上回升，我们只需要移除这条线，防止它回升：
- en: '[PRE21]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The new learning rate schedule now looks like this:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 新的学习率调度现在看起来像这样：
- en: '![Learning rate scheduling](img/B10354_08_05.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![学习率调度](img/B10354_08_05.jpg)'
- en: Learning rate restarts
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率重启
- en: Monitoring training with TensorBoard
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 监控训练过程
- en: An important part of debugging a model is knowing when things go wrong before
    you have invested significant amounts of time training the model. TensorBoard
    is a TensorFlow extension that allows you to easily monitor your model in a browser.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 调试模型时，一个重要的部分就是在没有投入大量训练时间之前，知道何时出现问题。TensorBoard 是一个 TensorFlow 扩展，可以让你轻松地在浏览器中监控模型。
- en: To provide an interface from which you can watch your model's progress, TensorBoard
    also offers some options useful for debugging. For example, you can observe the
    distributions of the model's weights and gradients during training.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供一个可以观看模型进展的界面，TensorBoard 还提供了一些调试时非常有用的选项。例如，你可以观察训练过程中模型权重和梯度的分布。
- en: Note
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: TensorBoard does not run on Kaggle. To try out TensorBoard, install
    Keras and TensorFlow on your own machine.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：TensorBoard 不支持在 Kaggle 上运行。如果想尝试 TensorBoard，请在你的电脑上安装 Keras 和 TensorFlow。'
- en: 'To use TensorBoard with Keras, we set up a new callback. TensorBoard has many
    options, so let''s walk through them step by step:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Keras 中使用 TensorBoard，我们需要设置一个新的回调函数。TensorBoard 有很多选项，让我们一步步了解它们：
- en: '[PRE22]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'There are five key pieces of the preceding code that we need to take into consideration:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要考虑前面代码中的五个关键部分：
- en: First, we need to specify where Keras should save the data that TensorBoard
    later visualizes. Generally, it is a good idea to save all logs of your different
    runs in one `logs` folder and give every run its own subfolder, such as `test2`
    in this case. This way, you can easily compare different runs within TensorBoard
    but also keep different runs separate.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要指定 Keras 应该将数据保存到哪里，TensorBoard 会在后续可视化这些数据。通常情况下，最好将不同运行的所有日志保存在一个 `logs`
    文件夹中，并为每次运行创建一个子文件夹，比如这里的 `test2`。这样，你可以轻松地在 TensorBoard 中比较不同的运行结果，同时保持各个运行结果的独立性。
- en: By default, TensorBoard would just show you the loss and accuracy of your model.
    In this case, we are interested in histograms showing weights and distributions.
    We save the data for the histograms every epoch.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，TensorBoard 只会显示模型的损失和准确度。在这种情况下，我们关心的是显示权重和分布的直方图。我们会在每个周期保存直方图的数据。
- en: To generate data, TensorBoard runs batches through the model. We need to specify
    a batch size for this process.
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了生成数据，TensorBoard 会将批次通过模型运行。我们需要为此过程指定一个批次大小。
- en: We need to tell TensorBoard what to save. TensorBoard can visualize the model's
    computational graph, its gradients, and images showing weights. The more we save
    however, the slower the training.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要告诉 TensorBoard 要保存什么内容。TensorBoard 可以可视化模型的计算图、梯度以及显示权重的图像。然而，我们保存的内容越多，训练速度就会越慢。
- en: TensorBoard can also visualize trained embeddings nicely. Our model does not
    have embeddings, so we are not interested in saving them.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorBoard 还可以很好地可视化训练好的嵌入层。我们的模型没有嵌入层，所以我们不需要保存它们。
- en: 'Once we have the callback set up, we can pass it to the training process. We
    will train the MNIST model once again. We multiply the inputs by 255, making training much
    harder. To achieve all of this we need to run the following code:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦回调函数设置完成，我们可以将其传递给训练过程。我们将再次训练 MNIST 模型。我们将输入数据乘以 255，这使得训练变得更加困难。为了实现这一点，我们需要运行以下代码：
- en: '[PRE23]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To start TensorBoard, open your console and type in the following:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动 TensorBoard，请打开终端并输入以下命令：
- en: '[PRE24]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Here `full_path_to_your_logs` is the path you saved your logs in, for example,
    `logs` in our case. TensorBoard runs on port `6006` by default, so in your browser,
    go to `http://localhost:6006` to see TensorBoard.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 `full_path_to_your_logs` 是你保存日志的路径，例如，在我们的案例中是 `logs`。TensorBoard 默认在 `6006`
    端口运行，因此你可以在浏览器中访问 `http://localhost:6006` 来查看 TensorBoard。
- en: 'Once the page has loaded, navigate to the **HISTOGRAMS** section; this section
    should look something like this:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 页面加载完成后，导航到 **HISTOGRAMS** 部分；该部分应该类似于下面这样：
- en: '![Monitoring training with TensorBoard](img/B10354_08_06.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![使用 TensorBoard 监控训练过程](img/B10354_08_06.jpg)'
- en: TensorBoard histograms
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 直方图
- en: You can see the distribution of gradients and weights in the first layer. As
    you can see, the gradients are uniformly distributed and extremely close to zero.
    The weights hardly change at all over the different epochs. We are dealing with
    a **vanishing gradient problem**; we will cover this problem in depth later.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以查看第一层的梯度和权重分布。如你所见，梯度均匀分布，并且非常接近零。权重在不同周期之间几乎没有变化。我们正在处理**梯度消失问题**；我们将在后续详细讨论这个问题。
- en: Armed with the real-time insight that this problem is happening, we can react
    faster. If you really want to dig into your model, TensorBoard also offers a visual
    debugger. In this debugger, you can step through the execution of your TensorFlow
    model and examine every single value inside it. This is especially useful if you
    are working on complex models, such as generative adversarial networks, and are
    trying to understand why something complex goes wrong.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实时了解问题的发生，我们可以更快地做出反应。如果你真的想深入了解你的模型，TensorBoard 还提供了一个可视化调试器。在这个调试器中，你可以逐步执行你的
    TensorFlow 模型，并检查其中的每一个值。如果你正在处理复杂的模型，比如生成对抗网络，并试图理解为何某些复杂情况出现问题，这个功能尤为有用。
- en: Note
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: The TensorFlow debugger does not work well with models trained in
    Jupyter Notebooks. Save your model training code to a Python `.py` script and
    run that script.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：TensorFlow 调试器在 Jupyter Notebooks 中训练的模型上表现不佳。请将你的模型训练代码保存为 Python `.py`
    脚本并运行该脚本。'
- en: 'To use the TensorFlow debugger, you have to set your model''s runtime to a
    special debugger runtime. In specifying the debugger runtime, you also need to
    specify which port you want the debugger to run, in this case, port `2018`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 TensorFlow 调试器，你必须将模型的运行时设置为特殊的调试器运行时。在指定调试器运行时时，你还需要指定调试器运行的端口，在本例中为端口`2018`：
- en: '[PRE25]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Once Keras begins to work with the debugger runtime, you can debug your model.
    For the debugger to work, you need to name your Keras model to `model`. However,
    you do not need to train the model with a TensorBoard callback.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Keras 开始与调试器运行时协同工作，你就可以调试你的模型。为了使调试器正常工作，你需要将 Keras 模型命名为 `model`。不过，你不需要通过
    TensorBoard 回调来训练该模型。
- en: 'Now, start TensorBoard and activate the debugger by specifying the debugger
    port as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，启动 TensorBoard 并通过指定调试器端口来激活调试器，如下所示：
- en: '[PRE26]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now you can open TensorBoard as usual in your browser on port `6006`. TensorBoard
    now has a new section called **DEBUGGER**:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以像往常一样在浏览器中打开 TensorBoard，端口号为`6006`。TensorBoard 现在新增了一个名为**DEBUGGER**的部分：
- en: '![Monitoring training with TensorBoard](img/B10354_08_07.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![使用 TensorBoard 监控训练](img/B10354_08_07.jpg)'
- en: TensorBoard debugger
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard 调试器
- en: By clicking **STEP**, you execute the next step in the training process. With
    **CONTINUE…,** you can train your model for one or more epochs. By navigating
    the tree on the left side, you can view the components of your model. You can
    visualize individual elements of your model, to see how different actions affect
    them. Using the debugger effectively requires a bit of practice, but if you are
    working with complex models, it is a great tool.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**STEP**，你将执行训练过程中的下一步。使用**CONTINUE…**，你可以训练模型一个或多个周期。通过在左侧导航树中浏览，你可以查看模型的各个组件。你可以可视化模型的单个元素，以观察不同操作如何影响它们。有效使用调试器需要一些练习，但如果你正在处理复杂的模型，它是一个很好的工具。
- en: Exploding and vanishing gradients
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度爆炸和梯度消失
- en: The vanishing gradient problem describes the issue that sometimes gradients
    in a deep neural network become very small and as a result, training occurs very
    slowly. Exploding gradients are the opposite problem; they are gradients that
    become so large that the network does not converge.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度消失问题描述了在深度神经网络中，梯度有时会变得非常小，导致训练速度非常慢。梯度爆炸是相反的问题；它们是变得极大，以至于网络无法收敛的梯度。
- en: Of the two, the vanishing gradient problem is the more persistent issue. Vanishing
    gradients are caused by the fact that in deep networks, gradients of earlier layers
    depend on gradients of layers closer to the output. If the output gradients are
    small, then the gradients behind them are even smaller. Thus, the deeper the network,
    the more issues that occur with regard to vanishing gradients.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两者中，梯度消失问题是更为持久的问题。梯度消失是由于在深层网络中，早期层的梯度依赖于更靠近输出层的梯度。如果输出梯度很小，那么后续梯度就会更小。因此，网络越深，梯度消失问题就越严重。
- en: 'The key causes of small gradients include sigmoid and `tanh` activation functions.
    If you look at the following sigmoid function, you''ll see that it is very flat
    toward large values:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 小梯度的主要原因包括sigmoid和`tanh`激活函数。如果你观察以下sigmoid函数，你会发现它在较大值时非常平坦：
- en: '![Exploding and vanishing gradients](img/B10354_08_08.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![梯度爆炸与梯度消失](img/B10354_08_08.jpg)'
- en: Sigmoid vanishing
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid梯度消失
- en: The small gradients of the sigmoid function are the reason why the ReLU activation
    function has become popular for training deep neural networks. Its gradient is
    equal to one for all positive input values. However, it is zero for all negative
    input values.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid函数的小梯度是ReLU激活函数在训练深度神经网络时变得流行的原因。对于所有正输入值，ReLU的梯度为1。然而，对于所有负输入值，它的梯度为0。
- en: Another cause of vanishing gradients is saddle points in the loss function.
    Although no minimum was reached, the loss function is very flat in some areas,
    producing small gradients.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度消失的另一个原因是损失函数中的鞍点。虽然没有达到最小值，但损失函数在某些区域非常平坦，导致梯度非常小。
- en: To combat the vanishing gradient problem, you should use ReLU activation. If you
    see that your model is training slowly, consider increasing the learning rate
    to move out of a saddle point faster. Finally, you might just want to let the
    model train longer if it suffers from small gradients.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对抗梯度消失问题，你应该使用ReLU激活函数。如果你发现模型训练得很慢，可以考虑提高学习率，以便更快地脱离鞍点。最后，如果模型遭遇小梯度问题，你也可以让它训练得更长时间。
- en: 'The exploding gradient problem is usually caused by large absolute weight values.
    As backpropagation multiplies the later layers'' gradients with the layers'' weights,
    large weights amplify gradients. To counteract the exploding gradient problem,
    you can use weight regularization, which incentivizes smaller weights. Using a method
    called **gradient clipping**, you can ensure that gradients do not become larger
    than a certain value. In Keras, you can clip both the norm and the absolute value
    of gradients:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度爆炸问题通常由较大的权重值引起。当反向传播将后续层的梯度与该层的权重相乘时，较大的权重会放大梯度。为了应对梯度爆炸问题，你可以使用权重正则化来鼓励较小的权重。通过使用一种叫做**梯度裁剪**的方法，你可以确保梯度不会变得大于某个特定的值。在Keras中，你可以裁剪梯度的范数和绝对值：
- en: '[PRE27]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Convolutional layers and **long short-term memory (LSTM) networks** are less
    susceptible to both vanishing and exploding gradients. ReLU and batch normalization
    generally stabilize the network. Both of these problems might be caused by non-regularized
    inputs, so you should check your data too. Batch normalization also counteracts
    exploding gradients.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层和**长短期记忆（LSTM）网络**对梯度消失和梯度爆炸的敏感度较低。ReLU和批量归一化通常能够稳定网络。这两个问题可能由未正则化的输入引起，所以你也应该检查你的数据。批量归一化也能抵消梯度爆炸。
- en: 'If exploding gradients are a problem, you can add a batch normalization layer
    to your model as follows:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 如果梯度爆炸是个问题，你可以通过添加批量归一化层到模型中来解决，方法如下：
- en: '[PRE28]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Batch normalization also reduces the risk of vanishing gradients and has enabled
    the construction of much deeper networks recently.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化还减少了梯度消失的风险，并且最近使得构建更深层的网络成为可能。
- en: You have now seen a wide range of tools that can be used to debug your models.
    As a final step, we are going to learn some methods to run models in production
    and speed up the machine learning process.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经了解了多种可以用来调试模型的工具。作为最后一步，我们将学习一些在生产环境中运行模型并加速机器学习过程的方法。
- en: Deployment
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Deployment into production is often seen as separate from the creation of models.
    At many companies, data scientists create models in isolated development environments
    on training, validation, and testing data that was collected to create models.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型部署到生产环境通常被视为与模型创建分开的一步。在许多公司中，数据科学家在孤立的开发环境中创建模型，使用的是收集来的训练、验证和测试数据。
- en: Once the model performs well on the test set, it then gets passed on to deployment
    engineers, who know little about how and why the model works the way it does.
    This is a mistake. After all, you are developing models to use them, not for the
    fun of developing them.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型在测试集上表现良好，它就会交给部署工程师，而这些工程师对模型是如何以及为何按这种方式工作的知之甚少。这是一个错误。毕竟，你开发模型是为了使用它们，而不是为了开发它们本身的乐趣。
- en: Models tend to perform worse over time for several reasons. The world changes,
    so the data you trained on might no longer represent the real world. Your model
    might rely on the outputs of some other systems that are subject to change. There
    might be unintended side effects and weaknesses of your model that only show with
    extended usage. Your model might influence the world that it tries to model. **Model
    decay** describes how models have a lifespan after which performance deteriorates.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 模型随着时间的推移往往表现得越来越差，原因有很多。世界在变化，因此你训练时使用的数据可能不再代表现实世界。你的模型可能依赖于其他系统的输出，而这些系统本身也可能发生变化。可能会出现一些意想不到的副作用和模型的弱点，只有在长期使用时才能显现出来。你的模型可能会影响它试图模拟的世界。**模型衰退**描述了模型在经历一段生命周期后，性能会逐渐下降的现象。
- en: Data scientists should have the full life cycle of their models in mind. They
    need to be aware of how their model works in production in the long run.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家应该全盘考虑他们模型的生命周期。他们需要了解模型在生产环境中长期运行的表现。
- en: In fact, the production environment is the perfect environment to optimize your
    model. Your datasets are only an approximation for the real world. Live data gives
    a much fresher and more accurate view of the world. By using online learning or
    active learning methods, you can drastically reduce the need for training data.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，生产环境是优化模型的理想场所。你的数据集仅仅是现实世界的近似。实时数据提供了一个更新且更准确的世界视图。通过使用在线学习或主动学习方法，你可以大幅减少对训练数据的依赖。
- en: This section describes some best practices for getting your models to work in
    the real world. The exact method of serving your model can vary depending on your
    application. See the upcoming section *Performance Tips* for more details on choosing
    a deployment method.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了一些最佳实践，帮助你将模型应用到实际环境中。具体的模型服务方式可能会根据应用场景有所不同。有关选择部署方法的更多细节，请参见接下来的*性能提示*部分。
- en: Launching fast
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速上线
- en: The process of developing models depends on real-world data as well as an insight
    into how the performance of the model influences business outcomes. The earlier
    you can gather data and observe how model behavior influences outcomes, the better.
    Do not hesitate to launch your product with a simple heuristic.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 开发模型的过程依赖于真实世界的数据以及对模型性能如何影响业务结果的洞察。你越早收集数据并观察模型行为如何影响结果，就越好。不要犹豫，尽早使用简单的启发式方法发布产品。
- en: Take the case of fraud detection, for instance. Not only do you need to gather
    transaction data together with information about occurring frauds, you also want
    to know how quick fraudsters are at finding ways around your detection methods.
    You want to know how customers whose transactions have been falsely flagged as
    fraud react. All of this information influences your model design and your model
    evaluation metrics. If you can come up with a simple heuristic, deploy the heuristic
    and then work on the machine learning approach.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 以欺诈检测为例。你不仅需要收集交易数据以及发生欺诈的信息，还需要了解欺诈者绕过你检测方法的速度有多快。你还想知道那些被错误标记为欺诈的客户会做出什么反应。所有这些信息都会影响你的模型设计和模型评估指标。如果你能提出一个简单的启发式方法，先部署这个启发式方法，再着手处理机器学习模型，那会是一个不错的选择。
- en: When developing a machine learning model, try simple models first. A surprising
    number of tasks can be modeled with simple, linear models. Not only do you obtain
    results faster, but you can also quickly identify the features that your model
    is likely to overfit to. Debugging your dataset before working on a complex model
    can save you many headaches.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发机器学习模型时，先尝试简单的模型。令人惊讶的是，许多任务都可以用简单的线性模型来建模。这样不仅能更快地获得结果，还能迅速识别出你的模型可能会过拟合的特征。在处理复杂模型之前先调试你的数据集，可以避免很多麻烦。
- en: A second advantage of getting a simple approach out of the door quickly is that
    you can prepare your infrastructure. Your infrastructure team is likely made up
    of different people from the modeling team. If the infrastructure team does not
    have to wait for the modeling team but can start optimizing the infrastructure
    immediately, then you gain a time advantage.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 快速推出简单方法的另一个优势是，你可以提前准备好基础设施。你的基础设施团队很可能由不同于建模团队的人组成。如果基础设施团队不需要等建模团队，而是能立即开始优化基础设施，那么你就能获得时间上的优势。
- en: Understanding and monitoring metrics
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解和监控指标
- en: To ensure that optimizing metrics such as the mean squared error or cross-entropy
    loss actually lead to a better outcome, you need to be mindful of how your model
    metrics relate to higher order metrics, which you can see visualized in the following
    diagram. Imagine you have some consumer-facing app in which you recommend different
    investment products to retail investors.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保优化指标（如均方误差或交叉熵损失）确实能带来更好的结果，你需要注意你的模型指标与更高阶指标之间的关系，这一点可以通过下图可视化。假设你有一个面向消费者的应用，在该应用中，你向零售投资者推荐不同的投资产品。
- en: '![Understanding and monitoring metrics](img/B10354_08_09.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![理解和监控指标](img/B10354_08_09.jpg)'
- en: Higher order effects
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 更高阶效果
- en: You might predict whether the user is interested in a given product, measured
    by the user reading the product description. However, the metric you want to optimize
    in your application is not your model accuracy, but the click-through rate of
    users going to the description screen. On a higher order, your business is not
    designed to maximize the click-through rate, but revenue. If your users only click
    on low-revenue products, your click-through rate does not help you.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会预测用户是否对某个产品感兴趣，这可以通过用户阅读产品描述来衡量。然而，在你的应用中，你要优化的指标不是模型的准确性，而是用户进入描述页面的点击率。在更高的层面上，你的业务并不是为了最大化点击率，而是为了最大化收入。如果用户只点击低收入的产品，那么你的点击率并不能为你带来帮助。
- en: Finally, your business' revenue might be optimized to the detriment of society.
    In this case, regulators will step in. Higher order effects are influenced by
    your model. The higher the order of the effect, the harder it is to attribute
    to a single model. Higher order effects have large impacts, so effectively, higher
    order effects serve as meta-metrics to lower-order effects. To judge how well
    your application is doing, you align its metrics, for example, click-through rates,
    with the metrics relevant for the higher order effect, for example, revenue. Equally,
    your model metrics need to be aligned with your application metrics.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你的业务收入可能会在牺牲社会福祉的情况下得到优化。在这种情况下，监管机构会介入。更高阶的效果会受到模型的影响。效果的阶数越高，越难归因于单一模型。更高阶的效果有较大影响，因此，从本质上讲，更高阶的效果充当了低阶效果的元指标。为了评估你的应用表现如何，你需要将其指标（例如点击率）与更高阶效果相关的指标（例如收入）对齐。同样，你的模型指标也需要与应用指标对齐。
- en: This alignment is often an emergent feature. Product managers eager to maximize
    their own metrics pick the model that maximizes their metrics, regardless of what
    metrics the modelers were optimizing. Product managers that bring home a lot of
    revenue get promoted. Businesses that are good for society receive subsidies and
    favorable policy. By making the alignment explicit, you can design a better monitoring
    process. For instance, if you have two models, you can A/B test them to see which
    one improves the application metrics.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对齐通常是一个自发的特性。产品经理为了最大化自己的指标，会选择最大化其指标的模型，而不管模型优化的是什么指标。那些带来大量收入的产品经理会得到晋升。而那些对社会有益的企业则会获得补贴和有利政策。通过使这种对齐明确化，你可以设计出更好的监控过程。例如，如果你有两个模型，可以通过A/B测试来查看哪个模型能够提升应用指标。
- en: Often, you will find that to align with a higher order metric, you'll need to
    combine several metrics, such as accuracy and speed of predictions. In this case,
    you should craft a formula that combines the metrics into one single number. A
    single number will allow you to doubtlessly choose between two models and help
    your engineers to create better models.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会发现，为了与更高阶指标对齐，你需要结合多个指标，比如预测的准确性和速度。在这种情况下，你应当设计一个公式，将这些指标合并成一个单一的数值。单一数值可以让你毫不犹豫地选择两个模型之间的优劣，并帮助你的工程师打造更好的模型。
- en: For instance, you could set a maximum latency of 200 milliseconds and your metric
    would be, "Accuracy if latency is below 200 milliseconds, otherwise zero." If
    you do not wish to set one maximum latency value, you could choose, "Accuracy
    divided by latency in milliseconds." The exact design of this formula depends
    on your application. As you observe how your model influences its higher order
    metric, you can adapt your model metric. The metric should be simple and easy
    to quantify.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，你可以设置最大延迟为200毫秒，指标就是“当延迟小于200毫秒时的准确率，否则为零。”如果你不想设定一个最大延迟值，你可以选择“准确率除以延迟毫秒数。”这个公式的具体设计取决于你的应用。当你观察到模型如何影响其更高阶指标时，你可以调整你的模型指标。这个指标应当简洁且易于量化。
- en: Next, to regularly test your model's impact on higher order metrics, you should regularly
    test your models own metrics, such as accuracy. To this end, you need a constant
    stream of ground truth labels together with your data. In some cases, such as
    detecting fraud, ground truth data is easily collected, although it might come
    in with some latency. In this case, customers might need a few weeks to find out
    they have been overcharged.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了定期测试模型对高阶指标的影响，你应该定期测试模型自身的指标，比如准确率。为此，你需要不断地获取与数据一起的真实标签。在某些情况下，比如欺诈检测，真实数据比较容易收集，尽管可能会有些延迟。在这种情况下，客户可能需要几周才能发现自己被多收费。
- en: In other cases, you might not have ground truth labels. Often, you can hand-label
    data for which you have no ground truth labels coming in. Through good UI design,
    the process of checking model predictions can be fast. Testers only have to decide
    whether your model's prediction was correct or not, something they can do through
    button presses in a web or mobile app. If you have a good review system in place,
    data scientists who work on the model should regularly check the model's outputs.
    This way, patterns in failures (our model does poorly on dark images) can be detected
    quickly, and the model can be improved.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，你可能没有真实标签。通常，你可以为没有真实标签的数据进行手动标注。通过良好的用户界面设计，检查模型预测的过程可以非常迅速。测试者只需要决定模型的预测是否正确，这可以通过网页或移动应用中的按钮操作来完成。如果你有一个良好的审查系统，参与模型开发的数据科学家应该定期检查模型的输出。这样，失败模式（比如模型在暗图像上表现不佳）就能迅速被发现，进而改进模型。
- en: Understanding where your data comes from
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解你的数据来源
- en: More often than not, your data gets collected by some other system that you
    as the model developer have no control over. Your data might be collected by a
    data vendor or by a different department in your firm. It might even be collected
    for different purposes than your model. The collectors of the data might not even
    know you are using the data for your model.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 更多时候，你的数据是由其他系统收集的，而你作为模型开发者对此并没有控制权。你的数据可能是由数据供应商收集的，或者由公司内的其他部门收集的，甚至可能是为了与模型无关的目的而收集的。数据的收集者可能甚至不知道你正在使用这些数据来构建模型。
- en: If, say, the collection method of the data changes, the distribution of your
    data might change too. This could break your model. Equally, the real world might
    just change, and with it the data distribution. To avoid changes in the data breaking
    your model, you first need to be aware of what data you are using and assign an
    owner to each feature. The job of the feature owner is to investigate where the
    data is coming from and alert the team if changes in the data are coming. The
    feature owner should also write down the assumptions underlying the data. In the
    best case, you test these assumptions for all new data streaming in. If the data
    does not pass the tests, investigate and eventually modify your model.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，如果数据的收集方式发生变化，你的数据分布可能也会随之变化。这可能会破坏你的模型。同样，现实世界的变化也会导致数据分布发生变化。为了避免数据的变化破坏你的模型，你首先需要了解你正在使用的数据，并为每个特征指定负责人。特征负责人的工作是调查数据的来源，并在数据发生变化时通知团队。特征负责人还应记录数据背后的假设。在最佳情况下，你应该对所有新流入的数据进行假设测试。如果数据未通过测试，就要调查并最终修改模型。
- en: Equally, your model outputs might get used as inputs of other models. Help consumers
    of your data reach you by clearly identifying yourself as the owner of the model.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你的模型输出可能会被用作其他模型的输入。通过清楚地标明自己是模型的所有者，帮助数据的使用者联系到你。
- en: Alert users of your model of changes to your model. Before deploying a model,
    compare the new model's predictions to the old model's predictions. Treat models
    as software and try to identify "breaking changes," that would significantly alter
    your model's behavior. Often, you might not know who is accessing your model's
    predictions. Try to avoid this by clear communication and setting access controls
    if necessary.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署模型之前，提醒用户注意模型的变化。将新模型的预测与旧模型的预测进行比较。将模型视为软件，尝试识别那些会显著改变模型行为的“破坏性变化”。通常，你可能不知道是谁在访问模型的预测结果。尽量通过明确的沟通和必要时设置访问控制来避免这种情况。
- en: Just as software has dependencies, libraries that need to be installed for the software
    to work, machine learning models have data dependencies. Data dependencies are
    not as well understood as software dependencies. By investigating your model's
    dependencies, you can reduce the risk of your model breaking when data changes.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 就像软件有依赖关系一样，机器学习模型也有数据依赖关系，这些依赖关系是模型能够正常工作的前提。数据依赖关系不像软件依赖关系那样被充分理解。通过研究模型的依赖关系，可以减少数据发生变化时模型崩溃的风险。
- en: Performance tips
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能优化建议
- en: In many financial applications, speed is of the essence. Machine learning, especially
    deep learning, has a reputation for being slow. However, recently, there have
    been many advances in hardware and software that enable faster machine learning
    applications.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多金融应用中，速度至关重要。机器学习，特别是深度学习，常常被认为是比较慢的。然而，最近在硬件和软件方面有许多进展，使得机器学习应用能够更快。
- en: Using the right hardware for your problem
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正确的硬件来解决问题
- en: A lot of progress in deep learning has been driven by the use of **graphics
    processing units** (**GPUs**). GPUs enable highly parallel computing at the expense
    of operating frequency. Recently, multiple manufacturers have started working
    on specialized deep learning hardware. Most of the time, GPUs are a good choice
    for deep learning models or other parallelizable algorithms such as XGboost gradient-boosted
    trees. However, not all applications benefit equally.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的许多进展得益于**图形处理单元**（**GPU**）的使用。GPU能够以牺牲操作频率为代价进行高度并行计算。最近，多个制造商开始研发专用的深度学习硬件。大多数情况下，GPU是深度学习模型或其他可以并行化的算法（如XGboost梯度提升树）的良好选择。然而，并不是所有应用都能同样受益。
- en: In **natural language processing (NLP)**, for instance, batch sizes often need
    to be small, so the parallelization of operations does not work as well since
    not that many samples are processed at the same time. Additionally, some words
    appear much more often than others, giving large benefits to caching frequent
    words. Thus, many NLP tasks run faster on CPUs than GPUs. If you can work with
    large batches, however, a GPU or even specialized hardware is preferable.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在**自然语言处理（NLP）**中，例如，批次大小通常需要较小，因此并行化操作的效果不如预期，因为一次处理的样本数量不多。此外，某些词语出现的频率远高于其他词语，这使得缓存频繁出现的词语大大提升了效率。因此，许多NLP任务在CPU上运行得比GPU更快。然而，如果你能够处理大批量数据，那么GPU甚至是专用硬件更为理想。
- en: Making use of distributed training with TF estimators
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用TF估算器进行分布式训练
- en: Keras is not only a standalone library that can use TensorFlow, but it is also
    an integrated part of TensorFlow. TensorFlow features multiple high-level APIs
    that can be used to create and train models.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Keras不仅是一个可以使用TensorFlow的独立库，还是TensorFlow的集成部分。TensorFlow具有多个高级API，可以用于创建和训练模型。
- en: From version 1.8 onward, the estimator API's features distribute training on
    multiple machines, while the Keras API does not feature them yet. Estimators also
    have a number of other speed-up tricks, so they are usually faster than Keras
    models.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 从1.8版本开始，估算器API的功能可以在多台机器上分配训练，而Keras API尚未支持这些功能。估算器还具有其他一些加速技巧，因此通常比Keras模型更快。
- en: Note
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find information on how to set up your cluster for distributed TensorFlow
    here: [https://www.tensorflow.org/deploy/distributed](https://www.tensorflow.org/deploy/distributed).'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到如何为分布式TensorFlow设置集群的信息：[https://www.tensorflow.org/deploy/distributed](https://www.tensorflow.org/deploy/distributed)。
- en: 'By changing the `import` statements, you can easily use Keras as part of TensorFlow
    and don''t have to change your main code:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 通过更改`import`语句，你可以轻松地将Keras作为TensorFlow的一部分使用，而无需更改主要代码：
- en: '[PRE29]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In this section, we will create a model to learn the MNIST problem before training
    it using the estimator API. First, we load and prepare the dataset as usual. For
    more efficient dataset loading, see the next section:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个模型来解决MNIST问题，并使用估算器API进行训练。首先，我们像往常一样加载并准备数据集。有关更高效的数据集加载，请参见下一节：
- en: '[PRE30]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can create a Keras model as usual:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像往常一样创建Keras模型：
- en: '[PRE31]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The TensorFlow version of Keras offers a one-line conversion to a TF estimator:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow版的Keras提供了一行代码将其转换为TF估算器：
- en: '[PRE32]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'To set up training, we need to know the name assigned to the model input. We can
    quickly check this with the following code:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置训练，我们需要知道分配给模型输入的名称。我们可以使用以下代码快速检查这一点：
- en: '[PRE33]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Estimators get trained with an input function. The input function allows us
    to specify a whole pipeline, which will be executed efficiently. In this case,
    we only want an input function that yields our training set:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 估计器是通过输入函数进行训练的。输入函数允许我们指定一个完整的管道，这个管道会高效执行。在这种情况下，我们只需要一个生成训练集的输入函数：
- en: '[PRE34]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Finally, we train the estimator on the input. And that is it; you can now utilize
    distributed TensorFlow with estimators:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在输入数据上训练估计器。就是这样；你现在可以利用分布式 TensorFlow 与估计器：
- en: '[PRE35]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Using optimized layers such as CuDNNLSTM
  id: totrans-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用优化的层，如 CuDNNLSTM
- en: You will often find that someone created a special layer optimized to perform
    certain tasks on certain hardware. Keras' `CuDNNLSTM` layer, for example, only
    runs on GPUs supporting CUDA, a programming language specifically for GPUs.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常会发现有人创建了一个特殊的层，优化了在特定硬件上执行某些任务。例如，Keras 的 `CuDNNLSTM` 层仅在支持 CUDA 的 GPU 上运行，CUDA
    是一种专为 GPU 设计的编程语言。
- en: When you lock in your model to specialized hardware, you can often make significant
    gains in your performance. If you have the resources, it might even make sense
    to write your own specialized layer in CUDA. If you want to change hardware later, you
    can usually export weights and import them to a different layer.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将模型固定到专用硬件上时，你通常可以显著提升性能。如果你有资源，甚至可以考虑用 CUDA 编写自己的专用层。如果以后需要更换硬件，通常可以导出权重并将其导入到不同的层中。
- en: Optimizing your pipeline
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化你的管道
- en: 'With the right hardware and optimized software in place, your model often ceases
    to be the bottleneck. You should check your GPU utilization by entering the following
    command in your Terminal:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在有了正确的硬件和优化的软件的情况下，你的模型通常不再是瓶颈。你应该通过在终端中输入以下命令来检查 GPU 的使用情况：
- en: '[PRE36]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If your GPU utilization is not at around 80% to 100%, you can gain significantly
    by optimizing your pipeline. There are several steps you can take to optimize
    your pipeline:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的 GPU 使用率没有达到大约 80% 到 100%，通过优化管道，你可以获得显著的性能提升。你可以采取以下几步来优化你的管道：
- en: '**Create a pipeline running parallel to the model**: Otherwise, your GPU will
    be idle while the data is loading. Keras does this by default. If you have a generator
    and want to have a larger queue of data to be held ready for preprocessing, change
    the `max_queue_size` parameter of the `fit_generator` method. If you set the `workers`
    argument of the `fit_generator` method to zero, the generator will run on the
    main thread, which slows things down.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建一个与模型并行运行的管道**：否则，在数据加载时，GPU 将处于空闲状态。Keras 默认会这样做。如果你有一个生成器并希望有一个更大的数据队列以便准备好进行预处理，可以更改
    `fit_generator` 方法的 `max_queue_size` 参数。如果你将 `fit_generator` 方法的 `workers` 参数设置为零，生成器将在主线程上运行，这会使得速度变慢。'
- en: '**Preprocess data in parallel**: Even if you have a generator working independently
    of the model training, it might not keep up with the model. So, it is better to
    run multiple generators in parallel. In Keras, you can do this by setting `use_multiprocessing`
    to `true` and setting the number of workers to anything larger than one, preferably
    to the number of CPUs available. Let''s look at an example:'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并行预处理数据**：即使你有一个独立于模型训练工作的生成器，它可能也无法跟上模型的速度。因此，最好同时运行多个生成器。在 Keras 中，你可以通过将
    `use_multiprocessing` 设置为 `true` 并将 `workers` 的数量设置为大于 1 的值，最好是可用 CPU 的数量。我们来看一个示例：'
- en: '[PRE37]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You need to make sure your generator is thread safe. You can make any generator
    thread safe with the following code snippet:'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你需要确保你的生成器是线程安全的。你可以使用以下代码片段使任何生成器变得线程安全：
- en: '[PRE38]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s look at the three key components of the preceding code:'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们来看一下前面代码中的三个关键组件：
- en: The `thread_safe_iter` class makes any iterator thread safe by locking threads
    when the iterator has to produce the next yield.
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`thread_safe_iter` 类通过在迭代器必须生成下一个值时锁定线程，使得任何迭代器都变得线程安全。'
- en: When `next()` is called on the iterator, the iterators thread is locked. Locking
    means that no other function, say, another variable, can access variables from
    the thread while it is locked. Once the thread is locked, it yields the next element.
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当在迭代器上调用 `next()` 时，迭代器的线程会被锁定。锁定意味着在线程被锁定期间，其他函数（比如另一个变量）无法访问线程中的变量。一旦线程被锁定，它会生成下一个元素。
- en: '`thread_safe_generator` is a Python decorator that turns any iterator it decorates
    into a thread-safe iterator. It takes the function, passes it to the thread-safe
    iterator, and then returns the thread-safe version of the function.'
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`thread_safe_generator` 是一个 Python 装饰器，它将任何它装饰的迭代器变成线程安全的迭代器。它接收函数，将其传递给线程安全的迭代器，然后返回线程安全版本的函数。'
- en: You can also use the `tf.data` API together with an estimator, which does most
    of the work for you.
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以将 `tf.data` API 与估算器结合使用，这会为你完成大部分工作。
- en: '**Combine files into large files**: Reading a file takes time. If you have
    to read thousands of small files, this can significantly slow you down. TensorFlow
    offers its own data format called TFRecord. You can also just fuse an entire batch
    into a single NumPy array and save that array instead of every example.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将文件合并为大文件**：读取文件需要时间。如果你需要读取成千上万的小文件，这可能会显著拖慢速度。TensorFlow 提供了自己的数据格式——TFRecord。你也可以将整个批次合并成一个
    NumPy 数组，并保存该数组，而不是每个示例。'
- en: '**Train with the** `tf.data.Dataset` **API**: If you are using the TensorFlow
    version of Keras, you can use the `Dataset` API, which optimizes data loading
    and processing for you. The `Dataset` API is the recommended way to load data
    into TensorFlow. It offers a wide range of ways to load data, for instance, from
    a CSV file with `tf.data.TextLineDataset`, or from TFRecord files with `tf.data.TFRecordDataset`.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用** `tf.data.Dataset` **API 进行训练**：如果你使用的是 TensorFlow 版本的 Keras，你可以使用 `Dataset`
    API，它为你优化了数据加载和处理。`Dataset` API 是将数据加载到 TensorFlow 中的推荐方式。它提供了多种数据加载方法，例如，使用 `tf.data.TextLineDataset`
    从 CSV 文件加载数据，或使用 `tf.data.TFRecordDataset` 从 TFRecord 文件加载数据。'
- en: Note
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: For a more comprehensive guide to the `Dat` `aset` API, see [https://www.tensorflow.org/get_started/datasets_quickstart](https://www.tensorflow.org/get_started/datasets_quickstart).'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**注意**：有关 `Dataset` API 的更全面指南，请参见 [https://www.tensorflow.org/get_started/datasets_quickstart](https://www.tensorflow.org/get_started/datasets_quickstart)。'
- en: In this example, we will use the dataset API with NumPy arrays that we have
    already loaded into RAM, such as the MNIST database.
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用数据集 API 与已经加载到 RAM 中的 NumPy 数组，比如 MNIST 数据库。
- en: 'First, we create two plain datasets for data and targets:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们创建两个普通的数据集，分别用于数据和目标：
- en: '[PRE39]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `map` function allows us to perform operations on data before passing it
    to the model. In this case, we apply one-hot encoding to our targets. However,
    this could be any function. By setting the `num_parallel_calls` argument, we can
    specify how many processes we want to run in parallel:'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`map` 函数允许我们在将数据传递给模型之前对数据执行操作。在此案例中，我们对目标进行独热编码。然而，这可以是任何函数。通过设置 `num_parallel_calls`
    参数，我们可以指定希望并行运行的进程数量：'
- en: '[PRE40]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We zip the data and targets into one dataset. We instruct TensorFlow to shuffle
    the data when loading, keeping 200 instances in memory from which to draw samples.
    Finally, we make the dataset yield batches of batch size `32`:'
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将数据和目标合并成一个数据集。我们指示 TensorFlow 在加载数据时进行洗牌，保持 200 个实例在内存中供采样使用。最后，我们让数据集生成批次，批次大小为
    `32`：
- en: '[PRE41]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can now fit a Keras model on this dataset just as we would fit it to a generator:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们可以像将 Keras 模型拟合到生成器一样，将模型拟合到这个数据集上：
- en: '[PRE42]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: If you have truly large datasets, the more you can parallelize, the better.
    Parallelization does come with overhead costs, however, and not every problem
    actually features huge datasets. In these cases, refrain from trying to do too
    much in parallel and focus on slimming down your network, using CPUs and keeping
    all your data in RAM if possible.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有非常大的数据集，越多的并行化越好。然而，并行化会带来额外的开销，并不是每个问题都涉及到庞大的数据集。在这种情况下，避免过度并行化，集中精力精简网络，使用
    CPU，并尽可能将所有数据保留在 RAM 中。
- en: Speeding up your code with Cython
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Cython 加速你的代码
- en: Python is a popular language because developing code in Python is easy and fast.
    However, Python can be slow, which is why many production applications are written
    in either C or C++. Cython is Python with C data types, which significantly speeds
    up execution. Using this language, you can write pretty much normal Python code,
    and Cython converts it to fast-running C code.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种流行的语言，因为用 Python 开发代码既简单又快速。然而，Python 可能会较慢，这也是为什么许多生产应用程序使用 C 或 C++
    编写的原因。Cython 是带有 C 数据类型的 Python，它显著加速了执行。使用这种语言，你可以编写几乎正常的 Python 代码，Cython 会将其转换为快速运行的
    C 代码。
- en: Note
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Note**: You can read the full Cython documentation here: [http://cython.readthedocs.io](http://cython.readthedocs.io).
    This section is a short introduction to Cython. If performance is important to
    your application, you should consider diving deeper.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：你可以在这里阅读完整的 Cython 文档：[http://cython.readthedocs.io](http://cython.readthedocs.io)。本节是
    Cython 的简短介绍。如果性能对你的应用至关重要，你应该考虑深入研究。'
- en: 'Say you have a Python function that prints out the Fibonacci series up to a
    specified point. This code snippet is taken straight from the Python documentation:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个 Python 函数，它会打印出到指定点的 Fibonacci 数列。这个代码片段直接来自 Python 文档：
- en: '[PRE43]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note that we have to import the `print_function` to make sure that `print()`
    works in the Python 3 style. To use this snippet with Cython, save it as `cython_fib_8_7.pyx`.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们必须导入 `print_function` 以确保 `print()` 能以 Python 3 风格工作。要在 Cython 中使用此代码片段，请将其保存为
    `cython_fib_8_7.pyx`。
- en: 'Now create a new file called `8_7_cython_setup.py`:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 现在创建一个名为 `8_7_cython_setup.py` 的新文件：
- en: '[PRE44]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The three main features of the code are these:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的三个主要特征如下：
- en: The `setup` function is a Python function to create modules, such as the ones
    you install with `pip`.
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`setup` 函数是一个 Python 函数，用于创建模块，类似于你通过 `pip` 安装的模块。'
- en: '`cythonize` is a function to turn a `pyx` Python file into Cython C code.'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`cythonize` 是一个将 `pyx` Python 文件转化为 Cython C 代码的函数。'
- en: We create a new model by calling `setup` and passing on our Cythonized code.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过调用 `setup` 并传递我们的 Cython 化代码来创建一个新模型。
- en: 'To run this, we now run the following command in a Terminal:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行这个，我们现在在终端中运行以下命令：
- en: '[PRE45]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This will create a C file, a build file, and a compiled module. We can import
    this module now by running:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个 C 文件、一个构建文件和一个编译后的模块。现在我们可以通过运行以下命令导入这个模块：
- en: '[PRE46]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This will print out the Fibonacci numbers up to 1,000\. Cython also comes with
    a handy debugger that shows where Cython has to fall back onto Python code, which
    will slow things down. Type the following command into your Terminal:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出 Fibonacci 数列直到 1,000。Cython 还自带一个方便的调试器，显示 Cython 需要回退到 Python 代码的位置，这会导致速度变慢。请在终端中输入以下命令：
- en: '[PRE47]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This will create an HTML file that looks similar to this when opened in a browser:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个 HTML 文件，打开时在浏览器中看起来类似于此：
- en: '![Speeding up your code with Cython](img/B10354_08_10.jpg)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Cython 加速代码](img/B10354_08_10.jpg)'
- en: Cython profile
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: Cython 性能分析
- en: 'As you can see, Cython has to fall back on Python all the time in our script
    because we did not specify the types of variables. By letting Cython know what
    data type a variable has, we can speed up the code significantly. To define a
    variable with a type, we use `cdef`:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，因为我们没有指定变量的类型，Cython 在我们的脚本中总是需要回退到 Python。通过告诉 Cython 变量的类型，我们可以显著加速代码。要定义一个具有类型的变量，我们使用
    `cdef`：
- en: '[PRE48]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This snippet is already better. Further optimization is certainly possible,
    by first calculating the numbers before printing them, we can reduce the reliance
    on Python `print` statements. Overall, Cython is a great way to keep the development
    speed and ease of Python and gain execution speed.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码片段已经更好了。进一步优化当然是可能的，通过在打印之前先计算这些数字，我们可以减少对 Python `print` 语句的依赖。总体来说，Cython
    是一个保持 Python 开发速度和易用性，同时提高执行速度的绝佳方式。
- en: Caching frequent requests
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缓存频繁请求
- en: An under-appreciated way to make models run faster is to cache frequent requests
    in a database. You can go so far as to cache millions of predictions in a database
    and then look them up. This has the advantage that you can make your model as
    large as you like and expend a lot of computing power to make predictions.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 一种被低估的加速模型运行的方法是将频繁的请求缓存到数据库中。你可以将数百万个预测缓存到数据库中，然后查找它们。这样做的好处是，你可以将模型做得足够大，并投入大量计算资源进行预测。
- en: By using a MapReduce database, looking up requests in a very large pool of possible
    requests and predictions is entirely possible. Of course, this requires requests
    to be somewhat discrete. If you have continuous features, you can round them if
    precision is not as important.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 MapReduce 数据库，在一个非常大的请求和预测池中查找请求是完全可能的。当然，这要求请求必须是某种离散的。如果你有连续的特征，如果精度不重要，可以将其四舍五入。
- en: Exercises
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Now that we're at the end of this chapter, it's time to put what we've learned
    into use. Using the knowledge that you've gained in this chapter, why not try
    the following exercises?
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经到了本章的结尾，现在是时候将我们学到的内容付诸实践了。运用你在本章中获得的知识，为什么不尝试以下练习呢？
- en: Try to build any model that features exploding gradients in training. Hint: Do
    not normalize inputs and play with the initialization of layers.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试构建任何在训练中会出现梯度爆炸的模型。提示：不要对输入进行标准化，并尝试调整层的初始化方式。
- en: Go to any example in this book and try to optimize performance by improving
    the data pipeline.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去书中的任何例子，尝试通过改善数据管道来优化性能。
- en: Summary
  id: totrans-396
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you have learned a number of practical tips for debugging
    and improving your model. Let''s recap all of the things that we have looked at:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学到了许多调试和改进模型的实用技巧。让我们回顾一下我们所学到的所有内容：
- en: Finding flaws in your data that lead to flaws in your learned model
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 找出数据中的缺陷，导致你的学习模型出现缺陷
- en: Using creative tricks to make your model learn more from less data
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用创造性技巧让你的模型从更少的数据中学到更多
- en: Unit testing data in production or training to make sure standards are met
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产环境或训练中进行单元测试，以确保满足标准
- en: Being mindful of privacy
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意隐私问题
- en: Preparing data for training and avoiding common pitfalls
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备训练数据并避免常见陷阱
- en: Inspecting the model and peering into the "black box"
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查模型并窥探“黑箱”
- en: Finding optimal hyperparameters
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找最佳超参数
- en: Scheduling learning rates in order to reduce overfitting
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整学习率，以减少过拟合
- en: Monitoring training progress with TensorBoard
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 监控训练进度
- en: Deploying machine learning products and iterating on them
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署机器学习产品并对其进行迭代
- en: Speeding up training and inference
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速训练和推理
- en: You now have a substantial number of tools in your toolbox that will help you
    run actual, practical machine learning projects and deploy them in real-life (for
    example, trading) applications.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经拥有了一些重要的工具，可以帮助你运行实际的、具有实际应用的机器学习项目，并将它们部署到现实生活中的应用中（例如，交易）。
- en: Making sure your model works before deploying it is crucial and failure to properly
    scrutinize your model can cost you, your employer, or your clients millions of
    dollars. For these reasons, some firms are reluctant to deploy machine learning
    models into trading at all. They fear that they will never understand the models
    and thus won't be able to manage them in a production environment. Hopefully,
    this chapter alleviates that fear by showcasing some practical tools that can
    make models understandable, generalizable, and safe to deploy.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署模型之前，确保你的模型正常工作至关重要，如果没有仔细审查模型，可能会导致你、你的雇主或客户损失数百万美元。出于这些原因，一些公司对将机器学习模型部署到交易中持谨慎态度。他们担心自己永远无法理解这些模型，因此无法在生产环境中管理它们。希望本章通过展示一些实用工具，能够消除这种恐惧，使模型变得可理解、可泛化，并且能够安全部署。
- en: 'In the next chapter, we will look at a special, persistent, and dangerous problem
    associated with machine learning models: bias. Statistical models tend to fit
    to and amplify human biases. Financial institutions have to follow strict regulations
    to prevent them from being racially or gender biased. Our focus will be to see
    how we can detect and remove biases from our models in order to make them both
    fair and compliant.'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论与机器学习模型相关的一个特殊、持续且危险的问题：偏差。统计模型往往会适应并放大人类的偏见。金融机构必须遵守严格的规定，以防止种族或性别偏见。我们的重点是探讨如何检测并消除模型中的偏见，使其既公平又合规。
