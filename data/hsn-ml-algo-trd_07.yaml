- en: Linear Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性模型
- en: The family of linear models represents one of the most useful hypothesis classes.
    Many learning algorithms that are widely applied in algorithmic trading rely on
    linear predictors because they can be efficiently trained in many cases, they
    are relatively robust to noisy financial data, and they have strong links to the
    theory of finance. Linear predictors are also intuitive, easy to interpret, and
    often fit the data reasonably well or at least provide a good baseline.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型家族代表了最有用的假设类之一。许多在算法交易中广泛应用的学习算法依赖于线性预测器，因为它们在许多情况下可以被有效地训练，在金融数据嘈杂的情况下相对稳健，并且与金融理论有着密切的联系。线性预测器也直观易懂，易于解释，并且通常能够很好地拟合数据，或者至少提供一个良好的基线。
- en: 'Linear regression has been known for over 200 years when Legendre and Gauss
    applied it to astronomy and began to analyze its statistical properties. Numerous
    extensions have since adapted the linear regression model and the baseline **ordinary
    least squares** (**OLS**) method to learn its parameters:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归已经有 200 多年的历史了，当勒让德和高斯将其应用于天文学并开始分析其统计性质时。此后，许多扩展都改编了线性回归模型和基线**普通最小二乘法**（**OLS**）方法来学习其参数：
- en: '**Generalized linear models** (**GLM**) expand the scope of applications by
    allowing for response variables that imply an error distribution other than the
    normal distribution. GLM include the probit or logistic models for **categorical
    response variables** that appear in classification problems.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义线性模型**（**GLM**）通过允许响应变量表示除正态分布之外的误差分布来扩展应用范围。GLM 包括用于分类问题中的**分类响应变量**的
    probit 或 logistic 模型。'
- en: More **robust estimation methods** enable statistical inference where the data
    violates baseline assumptions due to, for example, correlation over time or across
    observations. This is often the case with panel data that contains repeated observations
    on the same units such as historical returns on a universe of assets.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多**稳健估计方法**使得在数据违反基线假设的情况下进行统计推断成为可能，例如，随时间或跨观测存在相关性。这在包含对相同单位的重复观测的面板数据中经常发生，例如，对一组资产的历史回报。
- en: '**Shrinkage methods** aim to improve the predictive performance of linear models.
    They use a complexity penalty that biases the coefficients learned by the model
    with the goal of reducing the model''s variance and improving out-of-sample predictive
    performance.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收缩方法**旨在改善线性模型的预测性能。它们使用一个复杂度惩罚，偏向于通过减少模型的方差并提高样本外预测性能来改善模型学习的系数。'
- en: In practice, linear models are applied to regression and classification problems
    with the goals of inference and prediction. Numerous asset pricing models that
    have been developed by academic and industry researchers leverage linear regression.
    Applications include the identification of significant factors that drive asset
    returns, for example, as a basis for risk management, as well as the prediction
    of returns over various time horizons. Classification problems, on the other hand,
    include directional price forecasts.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，线性模型被应用于推断和预测的回归和分类问题。学术界和工业界研究人员开发的众多资产定价模型利用了线性回归。应用包括识别驱动资产回报的重要因素，例如，作为风险管理的基础，以及对各种时间范围内的回报进行预测。另一方面，分类问题包括方向性价格预测。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: How linear regression works and which assumptions it makes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归的工作原理及其假设条件
- en: How to train and diagnose linear regression models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何训练和诊断线性回归模型
- en: How to use linear regression to predict future returns
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用线性回归预测未来收益
- en: How use regularization to improve the predictive performance
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用正则化来提高预测性能
- en: How logistic regression works
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: logistic 回归的工作原理
- en: How to convert a regression into a classification problem
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将回归转换为分类问题
- en: For code examples, additional resources, and references, see the directory for
    this chapter in the online GitHub repository.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 对于代码示例、额外资源和参考资料，请参阅在线 GitHub 仓库中本章的目录。
- en: Linear regression for inference and prediction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于推断和预测的线性回归
- en: As the name suggests, linear regression models assume that the output is the
    result of a linear combination of the inputs. The model also assumes a random
    error that allows for each observation to deviate from the expected linear relationship.
    The reasons that the model does not perfectly describe the relationship between
    inputs and output in a deterministic way include, for example, missing variables,
    measurement, or data collection issues.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，线性回归模型假设输出是输入的线性组合的结果。该模型还假设存在随机误差，允许每个观察值偏离预期的线性关系。模型不能完美描述输入和输出之间关系的原因包括，例如，缺少变量，测量或数据收集问题。
- en: If we want to draw statistical conclusions about the true (but not observed)
    linear relationship in the population based on the regression parameters estimated
    from the sample, we need to add assumptions about the statistical nature of these
    errors. The baseline regression model makes the strong assumption that the distribution
    of the errors is identical across errors and that errors are independent of each
    other, that is, knowing one error does not help to forecast the next error. The
    assumption of **independent and identically distributed** (**iid**) errors implies
    that their covariance matrix is the identity matrix multiplied by a constant representing
    the error variance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想根据从样本估计的回归参数来对人口中的真实（但未观察到的）线性关系进行统计推断，我们需要对这些误差的统计性质添加假设。基线回归模型做出了这样一个强假设，即错误的分布在错误之间是相同的，并且错误是彼此独立的，也就是说，知道一个错误不会有助于预测下一个错误。**独立同分布**（**iid**）错误的假设意味着它们的协方差矩阵是由一个代表错误方差的常数与单位矩阵相乘得到的。
- en: These assumptions guarantee that the OLS method delivers estimates that are
    not only unbiased but also efficient, that is, they have the lowest sampling error
    learning algorithms. However, these assumptions are rarely met in practice. In
    finance, we often encounter panel data with repeated observations on a given cross-section.
    The attempt to estimate the systematic exposure of a universe of assets to a set
    of risk factors over time typically surfaces correlation in the time or cross-sectional
    dimension, or both. Hence, alternative learning algorithms have emerged that assume
    more error covariance matrices that differ from multiples of the identity matrix.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设保证了OLS方法提供的估计值不仅是无偏的，而且是有效的，即它们具有最低的抽样误差学习算法。然而，在实践中很少满足这些假设。在金融领域，我们经常遇到具有给定截面上重复观察的面板数据。试图估计一组资产对一组风险因素的系统性暴露随时间变化的努力通常会导致时间维度或截面维度中的相关性，或者两者兼有。因此，出现了更多假设与单位矩阵的多个倍数不同的错误协方差矩阵的替代学习算法。
- en: On the other hand, methods that learn biased parameters for a linear model may
    yield estimates with a lower variance and, hence, improve the predictive performance.
    **Shrinkage methods** reduce the model complexity by applying regularization that
    adds a penalty term to the linear objective function. The penalty is positively
    related to the absolute size of the coefficients so that these are shrunk relative
    to the baseline case. Larger coefficients imply a more complex model that reacts
    more strongly to variations in the inputs. Properly calibrated, the penalty can
    limit the growth of the model's coefficients beyond what an optimal bias-variance
    trade-off would suggest.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，学习为线性模型学习有偏参数的方法可能会产生方差较低的估计值，从而提高预测性能。**收缩方法**通过在线性目标函数中添加惩罚项来降低模型复杂性。惩罚与系数的绝对值大小正相关，因此相对于基线情况，这些系数被收缩。更大的系数意味着更复杂的模型，对输入的变化反应更强烈。正确校准的惩罚可以限制模型系数的增长，超出了最佳偏差-方差权衡建议的范围。
- en: We will introduce the baseline cross-section and panel techniques for linear
    models and important enhancements that produce accurate estimates when key assumptions
    are violated. We will then illustrate these methods by estimating factor models
    that are ubiquitous in the development of algorithmic trading strategies. Lastly,
    we will focus on regularization methods.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍线性模型的基线截面和面板技术以及在关键假设被违反时产生准确估计的重要增强技术。然后，我们将通过估计在算法交易策略开发中无处不在的因子模型来说明这些方法。最后，我们将重点介绍正则化方法。
- en: The multiple linear regression model
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元线性回归模型
- en: We will introduce the model's specification and objective function, methods
    to learn its parameters, statistical assumptions that allow for inference and
    diagnostics of these assumptions, as well as extensions to adapt the model to
    situations where these assumptions fail.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍模型的规范和目标函数、学习其参数的方法、允许推断和诊断这些假设的统计假设，以及扩展以适应这些假设失败情况的模型。
- en: How to formulate the model
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建模型
- en: The multiple regression model defines a linear functional relationship between
    one continuous outcome variable and *p* input variables that can be of any type
    but may require preprocessing. Multivariate regression, in contrast, refers to
    the regression of multiple outputs on multiple input variables.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 多元回归模型定义了一个连续的结果变量与*p*个输入变量之间的线性函数关系，这些输入变量可以是任何类型，但可能需要预处理。相比之下，多元回归是指多个输出在多个输入变量上的回归。
- en: 'In the population, the linear regression model has the following form for a
    single instance of the output *y*, an input vector ![](img/ca17efd5-4e85-4e63-a2b2-59e7e7afc866.png), and
    the error *ε*:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在总体中，线性回归模型对于输出*y*的单个实例、输入向量 ![](img/ca17efd5-4e85-4e63-a2b2-59e7e7afc866.png)和误差*ε*具有以下形式：
- en: '![](img/c3c0ce60-a6be-4b9d-96c4-e0f29963c384.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3c0ce60-a6be-4b9d-96c4-e0f29963c384.png)'
- en: 'The interpretation of the coefficients is straightforward: the value of a coefficient ![](img/f2a0ef61-33a5-44a1-9f1a-fb132389afa3.png) is the
    partial, average effect of the variable *x[i ]*on the output, holding all other
    variables constant.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的解释很简单：系数 ![](img/f2a0ef61-33a5-44a1-9f1a-fb132389afa3.png) 的值是变量*x[i]*对输出的部分平均影响，在所有其他变量保持不变的情况下。
- en: 'The model can also be written more compactly in matrix form. In this case,
    *y* is a vector of *N* output observations, *X*is the design matrix with *N* rows
    of observations on the *p* variables plus a column of 1s for the intercept, and ![](img/681890d8-fe44-4a8b-8bc4-33b2159a51c5.png) is
    the vector containing the *P = p+1* coefficients ![](img/96e3b5c2-497d-449d-9c8e-bf3c4a038d2a.png):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也可以更简洁地以矩阵形式书写。在这种情况下，*y*是*N*个输出观测值的向量，*X*是设计矩阵，其中有*N*行观测值和*p*个变量，另外还有一列1作为截距，而 ![](img/681890d8-fe44-4a8b-8bc4-33b2159a51c5.png) 是包含*p+1*个系数的向量 ![](img/96e3b5c2-497d-449d-9c8e-bf3c4a038d2a.png)：
- en: '![](img/18eef579-bc58-4079-a75f-b75ccb553879.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18eef579-bc58-4079-a75f-b75ccb553879.png)'
- en: The model is linear in its *p +1* parameters but can model non-linear relationships
    by choosing or transforming variables accordingly, for example by including a
    polynomial basis expansion or logarithmic terms. It can also use categorical variables
    with dummy encoding, and interactions between variables by creating new inputs
    of the form *x[i] . x[j]*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在其*p+1*个参数中是线性的，但可以通过相应地选择或转换变量来建模非线性关系，例如通过包含多项式基扩展或对数项。它还可以使用具有虚拟编码的分类变量，并通过创建形如*x[i]
    . x[j]*的新输入来对变量之间的交互进行建模。
- en: To complete the formulation of the model from a statistical point of view so
    that we can test a hypothesis about the parameters, we need to make specific assumptions
    about the error term. We'll do this after first introducing the alternative methods
    to learn the parameters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 从统计学角度完善模型的构建，以便我们可以测试关于参数的假设，我们需要对误差项进行具体的假设。我们将在首先介绍学习参数的替代方法之后做这个。
- en: How to train the model
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何训练模型
- en: 'There are several methods to learn the model parameters ![](img/cabc1f80-1d1b-4793-8a1f-80370fd84fea.png) from
    the data: **ordinary least squares** (**OLS**), **maximum likelihood estimation**
    (**MLE**), and **stochastic gradient descent** (**SGD**).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以从数据中学习模型参数 ![](img/cabc1f80-1d1b-4793-8a1f-80370fd84fea.png) ：**普通最小二乘法**（**OLS**）、**最大似然估计**（**MLE**）和**随机梯度下降**（**SGD**）。
- en: Least squares
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小二乘法
- en: The least squares method is the original method to learn the parameters of the
    hyperplane that best approximates the output from the input data. As the name
    suggests, the best approximation minimizes the sum of the squared distances between
    the output value and the hyperplane represented by the model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法是学习最能够近似输入数据输出的超平面参数的原始方法。顾名思义，最佳近似将最小化输出值与模型表示的超平面之间的平方距离之和。
- en: 'The difference between the model''s prediction and the actual outcome for a
    given data point is the residual (whereas the deviation of the true model from
    the true output in the population is called **error**). Hence, in formal terms,
    the least squares estimation method chooses the coefficient vector ![](img/b3139f6c-4371-4a74-9335-bbe76eeeba46.png) to
    minimize the **residual** **sum of squares** (**RSS**):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 给定数据点的模型预测与实际结果之间的差异是残差（而真实模型与真实输出在总体中的偏差被称为**误差**）。因此，在正式术语中，最小二乘估计方法选择系数向量 ![](img/b3139f6c-4371-4a74-9335-bbe76eeeba46.png) 以最小化**残差平方和**（**RSS**）：
- en: '![](img/8123f8ed-b798-41e9-be38-a8c004d4d0ef.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8123f8ed-b798-41e9-be38-a8c004d4d0ef.png)'
- en: 'Hence, the least-squares coefficients ![](img/087b73ba-7e6b-4d5b-b7c6-fd90f2cf6d8d.png) are
    computed as:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最小二乘系数 ![](img/087b73ba-7e6b-4d5b-b7c6-fd90f2cf6d8d.png) 计算如下：
- en: '![](img/8480afe1-ae4b-4e12-91db-e20143a84b40.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8480afe1-ae4b-4e12-91db-e20143a84b40.png)'
- en: 'The optimal parameter vector that minimizes RSS results from setting the derivatives
    of the preceding expression with respect to ![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) to zero.
    This produces a unique solution, assuming X has full column rank, that is, the
    input variables are not linearly dependent, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化 RSS 的最优参数向量是通过将前述表达式对 ![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) 的导数置零而得到的。这产生了一个唯一的解，假设
    X 具有完整的列秩，即输入变量不是线性相关的，如下所示：
- en: '![](img/53ae7775-f160-40be-b1ec-4a80c1fba44e.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53ae7775-f160-40be-b1ec-4a80c1fba44e.png)'
- en: 'When *y* and *X* have been de-meaned by subtracting their respective means, ![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) represents
    the ratio of the covariance between the inputs and the outputs ![](img/af4e8def-395c-49b0-a82e-25b2593dd732.png) and the
    output variance ![](img/181b1459-5eef-4d5b-b978-c00e00be4c71.png). There is also
    a geometric interpretation: the coefficients that minimize RSS ensure that the
    vector of residuals ![](img/7ff3850e-4378-4c76-b59a-72eb4c5aa04d.png) is orthogonal
    to the subspace of ![](img/540ecc41-c8d6-462b-8676-971ecc683b25.png)spanned by
    the columns of *X*, and the estimates ![](img/80dcda91-dc61-4571-8345-9f646a4e9b5a.png) are orthogonal
    projections into that subspace.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当 *y* 和 *X* 通过减去它们各自的均值而被去均值时，![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) 表示输入和输出 ![](img/af4e8def-395c-49b0-a82e-25b2593dd732.png) 之间协方差的比率和输出方差 ![](img/181b1459-5eef-4d5b-b978-c00e00be4c71.png)。还有一种几何解释：最小化
    RSS 的系数确保 ![](img/7ff3850e-4378-4c76-b59a-72eb4c5aa04d.png) 的向量与由 *X* 的列张成的子空间 ![](img/540ecc41-c8d6-462b-8676-971ecc683b25.png) 是正交的，并且 ![](img/80dcda91-dc61-4571-8345-9f646a4e9b5a.png) 是该子空间的正交投影。
- en: Maximum likelihood estimation
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: MLE is an important general method to estimate the parameters of a statistical
    model. It relies on the likelihood function that computes how likely it is to
    observe the sample of output values for a given set of both input data as a function
    of the model parameters. The likelihood differs from probabilities in that it
    is not normalized to range from 0 to 1.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MLE 是估计统计模型参数的重要一般方法。它依赖于似然函数，该函数计算观察到的输出值样本在给定一组输入数据的情况下作为模型参数的函数的可能性。似然性与概率的不同之处在于它不被标准化为从
    0 到 1 的范围。
- en: 'We can set up the likelihood function for the linear regression example by
    assuming a distribution for the error term, such as the standard normal distribution:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过假设误差项的分布（如标准正态分布）为线性回归示例设置似然函数：
- en: '![](img/60eff427-da2c-43a5-8d3e-7f13c71a89a9.png).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/60eff427-da2c-43a5-8d3e-7f13c71a89a9.png).'
- en: 'This allows us to compute the conditional probability of observing a given
    output ![](img/ca374814-159c-47ee-beda-967393c46f27.png) given the corresponding
    input vector *x[i]* and the parameters, ![](img/3fb23a9c-71d9-4391-9ace-33350e36821b.png):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够计算给定输出 ![](img/ca374814-159c-47ee-beda-967393c46f27.png) 在相应输入向量 *x[i]* 和参数 ![](img/3fb23a9c-71d9-4391-9ace-33350e36821b.png) 的条件概率：
- en: '![](img/219455c0-b5e2-43a9-9310-4472d95f6164.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/219455c0-b5e2-43a9-9310-4472d95f6164.png)'
- en: 'Assuming the output values are conditionally independent given the inputs,
    the likelihood of the sample is proportional to the product of the conditional
    probabilities of the individual output data points. Since it is easier to work
    with sums than with products, we apply the logarithm to obtain the log-likelihood
    function:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输出值在给定输入条件下是独立的，样本的似然性与单个输出数据点的条件概率的乘积成比例。由于使用和比使用乘积更容易，我们应用对数来获得对数似然函数：
- en: '![](img/197fca5b-2456-41f0-a988-fc5b646fa4a2.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/197fca5b-2456-41f0-a988-fc5b646fa4a2.png)'
- en: 'The goal of MLE is to maximize the probability of the output sample that has
    in fact been observed by choosing model parameters, taking the observed inputs
    as given. Hence, the MLE parameter estimate results from maximizing the (log)
    likelihood function:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: MLE的目标是通过选择模型参数最大化实际观察到的输出样本的概率，将观察到的输入视为给定。因此，MLE参数估计结果来自于最大化（对数）似然函数：
- en: '![](img/c2814000-7a34-48a2-b790-2dd022c3944d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2814000-7a34-48a2-b790-2dd022c3944d.png)'
- en: Due to the assumption of normal distribution, maximizing the log-likelihood
    function produces the same parameter solution as least squares because the only
    expression that depends on the parameters is squared residual in the exponent.
    For other distributional assumptions and models, MLE will produce different results,
    and in many cases, least squares is not applicable, as we will see later for logistic
    regression.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于正态分布的假设，最大化对数似然函数产生与最小二乘相同的参数解，因为仅有一个表达式与参数有关，即指数中的平方残差。对于其他分布假设和模型，MLE将产生不同的结果，在许多情况下，最小二乘不适用，我们稍后将在逻辑回归中看到。
- en: Gradient descent
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降（Gradient descent）
- en: Gradient descent is a general-purpose optimization algorithm that will find
    stationary points of smooth functions. The solution will be a global optimum if
    the objective function is convex. Variations of gradient descent are widely used
    in the training of complex neural networks, but also to compute solutions for
    MLE problems.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种通用的优化算法，将找到平滑函数的稳定点。如果目标函数是凸的，则解将是全局最优解。梯度下降的变体被广泛用于训练复杂的神经网络，也用于计算MLE问题的解决方案。
- en: The algorithm uses the gradient of the objective function that contains its
    partial derivatives with respect to the parameters. These derivatives indicate
    how much the objective changes for infinitesimal steps in the direction of the
    corresponding parameters. It turns out that the maximal change of the function
    value results from a step in the direction of the gradient itself.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 算法使用目标函数的梯度，其中包含相对于参数的偏导数。这些导数指示了在相应参数方向上的微小步长中目标变化的程度。结果表明，函数值的最大变化来自于梯度方向的步长。
- en: Hence, when minimizing a function that describes, for example, the cost of a
    prediction error, the algorithm computes the gradient for the current parameter
    values using the training data and modifies each parameter according to the negative
    value of its corresponding gradient component. As a result, the objective function
    will assume a lower value and move the parameters move closer to the solution. The
    optimization stops when the gradient becomes small, and the parameter values change
    very little.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当最小化描述例如预测误差成本的函数时，该算法使用训练数据为当前参数值计算梯度，并根据对应梯度分量的负值修改每个参数。结果，目标函数将取得较低的值，并使参数更接近解。当梯度变得很小时，参数值几乎不再变化时，优化停止。
- en: The size of these steps is the learning rate, which is a critical parameter
    that may require tuning; many implementations include the option for this learning
    rate to increase with the number of iterations gradually. Depending on the size
    of the data, the algorithm may iterate many times over the entire dataset. Each
    such iteration is called an **epoch.** The number of epochs and the tolerance
    used to stop further iterations are hyperparameters you can tune.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步长的大小是学习率，这是一个可能需要调整的关键参数；许多实现包括逐渐增加学习率的选项，随着迭代次数的增加。根据数据的大小，算法可能会多次迭代整个数据集。每次迭代称为一个**周期（epoch）**。您可以调整的超参数包括周期数和用于停止进一步迭代的容差。
- en: Stochastic gradient descent randomly selects a data point and computes the gradient
    for this data point as opposed to an average over a larger sample to achieve a
    speedup. There are also batch versions that use a certain number of data points
    for each step.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降（Stochastic gradient descent）随机选择一个数据点，并针对该数据点计算梯度，而不是对更大样本的平均值，以实现加速。还有批量版本，每个步骤使用一定数量的数据点。
- en: The Gauss—Markov theorem
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高斯-马尔科夫定理
- en: To assess the statistical of the model and conduct inference, we need to make
    assumptions about the residuals, that is, the properties of the unexplained part
    of the input. The **Gauss—Markov theorem** (**GMT**) defines the assumptions required
    for OLS to produce unbiased estimates of the model parameters ![](img/33eb8f33-f98e-4c29-82c8-76db82a7b46a.png), and
    when these estimates have the lowest standard error among all linear models for
    cross-sectional data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估模型的统计特性并进行推断，我们需要对残差（即输入未解释部分的属性）做出假设。**高斯-马尔科夫定理**（**GMT**）定义了OLS需要的假设，以产生模型参数的无偏估计！[](img/33eb8f33-f98e-4c29-82c8-76db82a7b46a.png)，并且当这些估计在横截面数据的所有线性模型中具有最低标准误差时。
- en: 'The baseline multiple regression model makes the following GMT assumptions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 基线多元回归模型做出以下GMT假设：
- en: In the population, **linearity** holds, ![](img/8feae49c-7c0f-492c-8581-fa3fb1b0d30a.png) where ![](img/ebb48f07-023f-4a4f-b46d-a0cf606d8ceb.png) are
    unknown but constant and ![](img/c6cfab11-33d7-4c05-81c8-fded5bb113da.png) is
    a random error
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在总体中，**线性**成立，![](img/8feae49c-7c0f-492c-8581-fa3fb1b0d30a.png)，其中![](img/ebb48f07-023f-4a4f-b46d-a0cf606d8ceb.png)是未知但恒定的，而![](img/c6cfab11-33d7-4c05-81c8-fded5bb113da.png)是一个随机误差
- en: The data for the input variables ![](img/ac422091-f903-413e-ab66-b8f884a4b0d8.png) are
    a **random sample** from the population
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入变量的数据![](img/ac422091-f903-413e-ab66-b8f884a4b0d8.png)是来自总体的**随机样本**
- en: No perfect **collinearity**—there are no exact linear relationships among the
    input variables
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有完美的**共线性** - 输入变量之间不存在确切的线性关系
- en: The **error has a conditional mean of zero** given any of the inputs: ![](img/fc56cd9c-b8ea-483b-b6c6-b6a01481a1df.png)
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误在给定任何输入时的条件均值为零：![](img/fc56cd9c-b8ea-483b-b6c6-b6a01481a1df.png)
- en: '**Homoskedasticity**, the error term ![](img/f0ded6ea-538b-40a8-9d3a-cb9f5483e17d.png) has
    constant variance given the inputs: ![](img/e5f9d3b1-a11c-4072-9cd9-d443cc1ce234.png)'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同方差性**，误差项![](img/f0ded6ea-538b-40a8-9d3a-cb9f5483e17d.png)在给定输入时具有恒定方差：![](img/e5f9d3b1-a11c-4072-9cd9-d443cc1ce234.png)'
- en: 'The fourth assumption implies that no missing variable exists that is correlated
    with any of the input variables. Under the first four assumptions, the OLS method
    delivers **unbiased** estimates: including an irrelevant variable does not bias
    the intercept and slope estimates, but omitting a relevant variable will bias
    the OLS estimates. OLS is then also **consistent**: as the sample size increases,
    the estimates converge to the true value as the standard errors become arbitrary.
    The converse is unfortunately also true: if the conditional expectation of the
    error is not zero because the model misses a relevant variable or the functional
    form is wrong (that is, quadratic or log terms are missing), then all parameter
    estimates are biased. If the error is correlated with any of the input variables
    then OLS is also not consistent, that is, adding more data will not remove the
    bias.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个假设意味着不存在与任何输入变量相关的缺失变量。在前四个假设下，OLS方法提供**无偏估计**：包括一个无关变量不会使截距和斜率估计产生偏差，但忽略一个相关变量会使OLS估计产生偏差。然后OLS也是**一致的**：随着样本量的增加，估计值收敛到真实值，标准误差变得任意。不幸的是，反之亦然：如果误差的条件期望不为零，因为模型遗漏了一个相关变量或者功能形式错误（即，缺少二次项或对数项），那么所有参数估计都是有偏的。如果误差与任何输入变量相关，则OLS也不一致，即添加更多数据不会消除偏差。
- en: If we add the fifth assumptions, then OLS also produces the best linear, unbiased
    estimates (BLUE), where best means that the estimates have the lowest standard
    error among all linear estimators. Hence, if the five assumptions hold and statistical inference
    is the goal, then the OLS estimates is the way to go. If the goal, however, is
    to predict, then we will see that other estimators exist that trade off some bias
    for a lower variance to achieve superior predictive performance in many settings.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果添加了第五个假设，则OLS也会产生最佳线性无偏估计（BLUE），其中最佳意味着估计在所有线性估计器中具有最低标准误差。因此，如果五个假设成立，并且统计推断是目标，那么OLS估计是正确的选择。然而，如果目标是预测，那么我们将看到在许多情况下存在其他估计器，它们在一定的偏差情况下换取更低的方差以实现更好的预测性能。
- en: Now that we have introduced the basic OLS assumptions, we can take a look at
    inference in small and large samples.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了基本的OLS假设，我们可以看看小样本和大样本推断。
- en: How to conduct statistical inference
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何进行统计推断
- en: Inference in the linear regression context aims to draw conclusions about the
    true relationship in the population from the sample data. This includes tests
    of hypothesis about the significance of the overall relationship or the values
    of particular coefficients, as well as estimates of confidence intervals.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归背景下的推断旨在从样本数据中得出关于总体真实关系的结论。这包括关于总体关系的显著性或特定系数值的假设检验，以及置信区间的估计。
- en: The key ingredient for statistical inference is a test statistic with a known
    distribution. We can use it to assume that the null hypothesis is true and compute
    the probability of observing the value for this statistic in the sample, familiar
    as the p-value. If the p-value drops below a significance threshold (typically
    five percent) then we reject the hypothesis because it makes the actual sample
    value very unlikely. At the same time, we accept that the p-value reflects the
    probability that we are wrong in rejecting what is, in fact, a correct hypothesis.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 统计推断的关键要素是一个具有已知分布的检验统计量。我们可以假设零假设成立，并计算在样本中观察到该统计量值的概率，这个概率被称为 p 值。如果 p 值低于显著性阈值（通常为五百分之一），那么我们拒绝该假设，因为它使得实际样本值非常不可能。同时，我们接受
    p 值反映了我们在拒绝实际上是正确的假设时错误的概率。
- en: In addition to the five GMT assumptions, the classical linear model assumes **normality**—the population
    error is normally distributed and independent of the input variables. This assumption
    implies that the output variable is normally distributed, conditional on the input
    variables. This strong assumption permits the derivation of the exact distribution
    of the coefficients, which in turn implies exact distributions of the test statistics
    required for similarly exact hypotheses tests in small samples. This assumption
    often fails—asset returns, for instance, are not normally distributed—but, fortunately,
    the methods used under normality are also approximately valid.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了五个 GMT 假设之外，经典线性模型还假设**正态性**—总体误差服从正态分布且与输入变量独立。这一假设意味着在输入变量条件下，输出变量服从正态分布。这个强假设允许导出系数的精确分布，进而意味着在小样本中需要的测试统计的精确分布。这一假设通常会失败—例如，资产回报不服从正态分布—但是，幸运的是，正态性下使用的方法也是近似有效的。
- en: 'We have the following distributional characteristics and test statistics, approximately
    under GMT assumptions 1–5, and exactly when normality holds:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拥有以下分布特征和测试统计量，近似地满足 GMT 假设 1–5，当正态性成立时则完全满足：
- en: The parameter estimates follow a multivariate normal distribution: ![](img/41d4d2b8-7cf6-4a50-aa7a-b9ada8e5b6eb.png) .
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数估计服从多元正态分布： ![](img/41d4d2b8-7cf6-4a50-aa7a-b9ada8e5b6eb.png) 。
- en: Under GMT 1–5, the parameter estimates are already unbiased and we can get an unbiased
    estimate of ![](img/c255ed13-6923-4756-ba34-fc71c5b92cb3.png), the constant error
    variance, using ![](img/b5d5614e-5b53-416d-83d9-d168b96e8207.png).
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 GMT 1–5 下，参数估计已经是无偏的，我们可以使用 ![](img/b5d5614e-5b53-416d-83d9-d168b96e8207.png) 对 ![](img/c255ed13-6923-4756-ba34-fc71c5b92cb3.png) 进行无偏估计，即常数误差方差。
- en: The t statistic for a hypothesis tests about an individual coefficient ![](img/fbfdf074-0b0d-4404-9e4b-80a87114d05a.png)is ![](img/60566dde-3959-4693-a060-9cac717f012b.png) and
    follows a t distribution with *N-p-1* degrees of freedom where ![](img/3bda39a2-09ae-4e22-9920-c0dfe0fa9414.png) is
    the j's element of the diagonal of ![](img/7a6b5101-d2be-4553-b96f-43949ce9508b.png).
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于关于个别系数的假设检验，*t* 统计量为 ![](img/fbfdf074-0b0d-4404-9e4b-80a87114d05a.png)，并且服从于自由度为
    *N-p-1* 的 *t* 分布，其中 ![](img/3bda39a2-09ae-4e22-9920-c0dfe0fa9414.png) 是 ![](img/7a6b5101-d2be-4553-b96f-43949ce9508b.png) 对角线的第
    j 个元素。
- en: The *t* distribution converges to the normal distribution and since the 97.5
    quantile of the normal distribution is 1.96, a useful rule of thumb for a 95%
    confidence interval around a parameter estimate is ![](img/bb155050-7a1f-40b1-b171-eb5ca79d1622.png).
    An interval that includes zero implies that we can't reject the null hypothesis
    that the true parameter is zero and, hence, irrelevant for the model.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t* 分布收敛于正态分布，而正态分布的 97.5 分位数为 1.96，因此，围绕参数估计的 95% 置信区间的一个有用的经验法则是 ![](img/bb155050-7a1f-40b1-b171-eb5ca79d1622.png)。包含零的区间意味着我们无法拒绝真实参数为零的零假设，因此对模型无关。'
- en: The *F* statistic allows for tests of restrictions on several parameters, including
    whether the entire regression is significant. It measures the change (reduction)
    in the RSS that results from additional variables.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*F*统计量允许对多个参数的限制进行检验，包括整个回归是否显著。它测量了RSS的变化（减少），这是由于添加额外变量而导致的。'
- en: Finally, the **Lagrange Multiplier** (**LM**) test is an alternative to the
    *F* test to restrict multiple restrictions.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，**拉格朗日乘数（LM）**测试是对*F*测试的替代，以限制多个限制。
- en: How to diagnose and remedy problems
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何诊断和解决问题
- en: Diagnostics validate the model assumptions and prevent wrong conclusions when
    interpreting the result and conducting statistical inference. They include measures
    of goodness of fit and various tests of the assumptions about the error term,
    including how closely the residuals match a normal distribution. Furthermore,
    diagnostics test whether the residual variance is indeed constant or exhibits
    heteroskedasticity, and if the errors are conditionally uncorrelated or exhibit
    serial correlation, that is, if knowing one error helps to predict consecutive
    errors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断验证模型假设，并在解释结果和进行统计推断时防止错误的结论。它们包括拟合优度的测量和关于误差项假设的各种测试，包括残差与正态分布的吻合程度。此外，诊断测试残差方差是否确实恒定，或者是否存在异方差，并且错误是否有条件地不相关或者存在串联相关性，即，知道一个错误是否有助于预测连续的错误。
- en: In addition to the tests outlined as follows, it is always important to visually
    inspect the residuals to detect whether there are systematic patterns because
    these indicate that the model is missing one or more factors that drive the outcome.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 除了以下概述的测试之外，始终重要的是可视化检查残差，以检测是否存在系统模式，因为这些指示模型缺少一个或多个驱动结果的因素。
- en: Goodness of fit
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合优度
- en: Goodness-of-fit measures assess how well a model explains the variation in the
    outcome. They help to assess the quality of model specification, for instance,
    to select among different model designs. They differ in how they evaluate the
    fit. The measures discussed here provide in-sample information; we will use out-of-sample
    testing and cross-validation when we focus on predictive models in the next section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合优度测量评估模型对结果变异的解释程度。它们有助于评估模型规范的质量，例如，在不同的模型设计之间进行选择。它们在评估拟合度时有所不同。在这里讨论的测量提供样本内信息；当我们在下一节专注于预测模型时，我们将使用样本外测试和交叉验证。
- en: 'Prominent goodness-of-fit measures include the (adjusted) R² that should be
    maximized and is based on the least-squares estimate:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 突出的拟合优度测量包括（调整后的）**R²**，应该最大化，基于最小二乘估计：
- en: R² measures the share of the variation in the outcome data explained by the
    model and is computed as ![](img/6a2363f4-83b4-42ce-85f0-3103f56a7a5a.png), where
    TSS is the sum of squared deviations of the outcome from its mean. It also corresponds
    to the squared correlation coefficient between the actual outcome values and those
    estimated (fitted) by the model. The goals is to maximize R² but it never decreases
    as the model adds more variables and, hence, encourages overfitting.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**R²**度量了模型解释结果数据变异的份额，并计算为![](img/6a2363f4-83b4-42ce-85f0-3103f56a7a5a.png)，其中TSS是结果与其均值的平方偏差之和。它还对应于实际结果值与模型估计（拟合）值之间的平方相关系数。目标是最大化**R²**，但随着模型增加更多变量，它永远不会减少，因此会鼓励过度拟合。'
- en: The adjusted R² penalizes R² for adding more variables; each additional variable
    needs to reduce RSS significantly to produce better goodness of fit.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整后的**R²**对于增加更多变量对**R²**进行惩罚；每个额外变量都需要显著减少RSS，以产生更好的拟合优度。
- en: 'Alternatively, the Akaike (AIC) and the **Bayesian Information Criterion**
    (**BIC**) are to be minimized and are based on the maximum-likelihood estimate:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，需要最小化的是**Akaike（AIC）**和**贝叶斯信息准则（BIC）**，它们基于最大似然估计：
- en: '![](img/58a56311-c140-4adf-bcd0-adb48108167a.png), where ![](img/030f5c24-ec0a-47c9-9a82-265617c34044.png) is
    the value of the maximized likelihood function, k is the number of parameters'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/58a56311-c140-4adf-bcd0-adb48108167a.png)，其中![](img/030f5c24-ec0a-47c9-9a82-265617c34044.png)是最大化似然函数的值，k是参数个数'
- en: '![](img/232898ca-2946-4ac5-8d69-1b9f4e32bfdb.png) where *N* is the sample size'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/232898ca-2946-4ac5-8d69-1b9f4e32bfdb.png)，其中*N*是样本量'
- en: Both metrics penalize for complexity, with BIC imposing a higher penalty so
    that it might underfit whereas AIC might overfit in relative terms. Conceptually, AIC
    aims at finding the model that best describes an unknown data-generating process,
    whereas BIC tries to find the best model among the set of candidates. In practice,
    both criteria can be used jointly to guide model selection when the goal is in-sample
    fit; otherwise, cross-validation and selection based on estimates of generalization
    error are preferable.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个指标都对复杂性进行了惩罚，BIC施加了更高的惩罚，因此可能会欠拟合，而AIC可能会过拟合相对于BIC而言。从概念上讲，AIC旨在找到最佳描述未知数据生成过程的模型，而BIC试图在候选模型集中找到最佳模型。在实践中，当目标是样本内拟合时，可以联合使用这两个标准来引导模型选择；否则，基于交叉验证和泛化误差估计的选择更可取。
- en: Heteroskedasticity
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异方差性
- en: GMT assumption 5 requires the residual covariance to take the shape ![](img/881489a2-b2d6-4688-a184-051c15fca6b3.png),
    that is, a diagonal matrix with entries equal to the constant variance of the
    error term. Heteroskedasticity occurs when the residual variance is not constant
    but differs across observations. If the residual variance is positively correlated
    with an input variable, that is, when errors are larger for input values that
    are far from their mean, then OLS standard error estimates will be too low, and,
    consequently, the t-statistic will be inflated leading to false discoveries of
    relationships where none actually exist.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: GMT假设5要求残差协方差采用形状 ![](img/881489a2-b2d6-4688-a184-051c15fca6b3.png)，即，一个对角矩阵，其条目等于误差项的恒定方差。异方差性发生在残差方差不恒定但在观察之间不同的情况下。如果残差方差与输入变量呈正相关，即，当误差较大时，与其平均值相差较远的输入值，则OLS标准误差估计将过低，因此t统计量将被夸大，导致在实际上不存在关系的情况下发现虚假关系。
- en: Diagnostics starts with a visual inspection of the residuals. Systematic patterns
    in the (supposedly random) residuals suggest statistical tests of the null hypothesis
    that errors are homoscedastic against various alternatives. These tests include
    the Breusch—Pagan and White tests.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断从对残差进行视觉检查开始。残差中的系统模式表明了针对误差同方差性的零假设进行统计检验的多种替代方案。这些测试包括 Breusch—Pagan 和 White
    测试。
- en: 'There are several ways to correct OLS estimates for heteroskedasticity:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以校正OLS估计的异方差性：
- en: Robust standard errors (sometimes called white standard errors) take heteroskedasticity
    into account when computing the error variance using a so-called **sandwich**
    **estimator**.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鲁棒标准误差（有时称为白色标准误差）在计算误差方差时考虑了异方差性，使用所谓的**三明治**估计器。
- en: Clustered standard errors assume that there are distinct groups in your data
    that are homoskedastic but the error variance differs between groups. These groups
    could be different asset classes or equities from different industries.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类标准误差假设您的数据中存在不同的组，这些组在同方差但错误方差在组之间不同。这些组可以是不同的资产类别或来自不同行业的股票。
- en: 'Several alternatives to OLS estimate the error covariance matrix using different
    assumptions when ![](img/1fa8ab87-92ba-4bad-b08f-75d550e4d599.png). The following
    are available in `statsmodels`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种替代方法可使用不同的假设来估计误差协方差矩阵，当![](img/1fa8ab87-92ba-4bad-b08f-75d550e4d599.png)时。以下是`statsmodels`中提供的选项：
- en: '**Weighted least squares** (**WLS**): For heteroskedastic errors where the
    covariance matrix has only diagonal entries as for OLS, but now the entries are
    allowed to vary'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加权最小二乘法** (**WLS**)：适用于异方差误差，其中协方差矩阵仅具有对角元素，如OLS，但现在允许元素变化。'
- en: Feasible **generalized least squares** (**GLSAR**), for autocorrelated errors
    that follow an autoregressive AR (p) process (see the chapter on linear time series
    models)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可行**广义最小二乘法** (**GLSAR**)，用于遵循自回归AR（p）过程的自相关误差（请参阅线性时间序列模型章节）
- en: '**Generalized least squares** (**GLS**) for arbitrary covariance matrix structure;
    yields efficient and unbiased estimates in the presence of heteroskedasticity
    or serial correlation'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义最小二乘法** (**GLS**) 适用于任意协方差矩阵结构；在存在异方差性或序列相关性时产生高效且无偏的估计。'
- en: Serial correlation
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列相关性
- en: Serial correlation means that consecutive residuals produced by linear regression
    are correlated, which violates the fourth GMT assumption. Positive serial correlation
    implies that the standard errors are underestimated and the t-statistics will
    be inflated, leading to false discoveries if ignored. However, there are procedures
    to correct for serial correlation when calculating standard errors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 串行相关意味着线性回归产生的连续残差是相关的，这违反了第四个 GMT 假设。正串行相关意味着标准误差被低估，t-统计量将被夸大，如果忽略这一点，可能导致错误的发现。然而，在计算标准误差时，有纠正串行相关的程序。
- en: The Durbin—Watson statistic diagnoses serial correlation. It tests the hypothesis
    that the OLS residuals are not autocorrelated against the alternative that they
    follow an autoregressive process (that we will explore in the next chapter). The
    test statistic ranges from 0 to 4, and values near 2 indicate non-autocorrelation,
    lower values suggest positive, and higher values indicate negative autocorrelation.
    The exact threshold values depend on the number of parameters and observations
    and need to be looked up in tables.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Durbin-Watson 统计量诊断串行相关。它检验OLS残差不自相关的假设，而不是按照自回归过程（我们将在下一章中探讨）的替代。测试统计量的范围从0到4，接近2的值表明非自相关，较低的值表示正，较高的值表示负的自相关。确切的阈值值取决于参数和观测值的数量，需要在表中查找。
- en: Multicollinearity
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多重共线性
- en: 'Multicollinearity occurs when two or more independent variables are highly
    correlated. This poses several challenges:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个或更多自变量高度相关时，就会出现多重共线性。这带来了几个挑战：
- en: It is difficult to determine which factors influence the dependent variable
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难确定哪些因素影响因变量。
- en: The individual p values can be misleading—a p-value can be high even if the
    variable is important
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个 p 值可能会误导——即使变量很重要，p 值可能也很高。
- en: The confidence intervals for the regression coefficients will be excessive,
    possibly even including zero, making it impossible to determine the effect of
    an independent variable on the outcome
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归系数的置信区间可能过大，甚至可能包括零，这使得无法确定自变量对结果的影响。
- en: There is no formal or theory-based solution that corrects for multicollinearity.
    Instead, try to remove one or more of the correlated input variables, or increase
    the sample size.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正式的或基于理论的解决方案来纠正多重共线性。而是尝试删除一个或多个相关的输入变量，或增加样本量。
- en: How to run linear regression in practice
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实践运行线性回归
- en: 'The accompanying notebook `linear_regression_intro.ipynb` illustrates a simple
    and then a multiple linear regression, the latter using both OLS and gradient
    descent. For the multiple regression, we generate two random input variables *x[1 ]*and
    *x[2]* that range from -50 to +50, and an outcome variable calculated as a linear
    combination of the inputs plus random Gaussian noise to meet the normality assumption
    GMT 6:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 附带的笔记本 `linear_regression_intro.ipynb` 展示了简单线性回归和多重线性回归，后者使用OLS和梯度下降两种方法。对于多元回归，我们生成两个随机输入变量
    *x[1]* 和 *x[2]*，范围从-50到+50，并计算结果变量作为输入的线性组合加上随机高斯噪声以满足正态性假设 GMT 6：
- en: '![](img/e51fe442-ed74-43fd-82fe-bc610bc10f8e.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e51fe442-ed74-43fd-82fe-bc610bc10f8e.png)'
- en: OLS with statsmodels
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 statsmodels 进行 OLS
- en: 'We use `statsmodels` to estimate a multiple regression model that accurately
    reflects the data generating process as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `statsmodels` 来估计准确反映数据生成过程的多元回归模型，如下所示：
- en: '[PRE0]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This yields the following **OLS Regression Results** summary:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是**OLS 回归结果**的摘要：
- en: '![](img/bb6ff5b6-0bd0-4778-9951-91d5cc77e648.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb6ff5b6-0bd0-4778-9951-91d5cc77e648.png)'
- en: Summary ofOLS Regression Results
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: OLS 回归结果摘要
- en: 'The upper part of the summary displays the dataset characteristics, namely
    the estimation method, the number of observations and parameters, and indicates
    that standard error estimates do not account for heteroskedasticity. The middle
    panel shows the coefficient values that closely reflect the artificial data generating
    process. We can confirm that the estimates displayed in the middle of the summary
    result can be obtained using the OLS formula derived previously:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要的上半部分显示了数据集的特征，即估计方法、观测值和参数的数量，并指出标准误差估计不考虑异方差性。中间面板显示了与人工数据生成过程密切相关的系数值。我们可以确认，摘要结果中间显示的估计值可以使用先前推导的
    OLS 公式获得：
- en: '[PRE1]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following diagram illustrates the hyperplane fitted by the model to the
    randomly generated data points:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示了模型对随机生成的数据点拟合的超平面：
- en: '![](img/e3ec55b4-5d60-473b-ae25-2d5a9be6af8d.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3ec55b4-5d60-473b-ae25-2d5a9be6af8d.png)'
- en: Hyperplane
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 超平面
- en: The upper right part of the panel displays the goodness-of-fit measures just
    discussed, alongside the F-test that rejects the hypothesis that all coefficients
    are zero and irrelevant. Similarly, the t-statistics indicate that intercept and
    both slope coefficients are, unsurprisingly, highly significant.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 面板的右上部显示了刚讨论过的拟合优度指标，以及拒绝所有系数为零且不相关的假设的F检验。同样，t统计量表明截距和斜率系数都是非常显著的，这并不令人意外。
- en: The bottom part of the summary contains the residual diagnostics. The left panel
    displays skew and kurtosis that are used to test the normality hypothesis. Both
    the Omnibus and the Jarque—Bera test fails to reject the null hypothesis that
    the residuals are normally distributed. The Durbin—Watson statistic tests for
    serial correlation in the residuals and has a value near 2 which, given 2 parameters
    and 625 observations, fails to reject the hypothesis of no serial correlation.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要底部包含了残差诊断。左侧面板显示了用于检验正态性假设的偏度和峰度。Omnibus和Jarque—Bera测试都未能拒绝残差正态分布的零假设。Durbin—Watson统计量检验残差的序列相关性，并且在值接近2的情况下，考虑到2个参数和625个观测值，未能拒绝无序列相关性的假设。
- en: 'Lastly, the condition number provides evidence about multicollinearity: it is
    the ratio of the square roots of the largest and the smallest eigenvalue of the design
    matrix that contains the input data. A value above 30 suggests that the regression
    may have significant multicollinearity.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，条件数提供了关于多重共线性的证据：它是包含输入数据的设计矩阵的最大和最小特征值的平方根的比值。值超过30表明回归可能存在显著的多重共线性。
- en: '`statsmodels` includes additional diagnostic tests that are linked in the notebook.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels`包含了与笔记本中链接的其他诊断测试。'
- en: Stochastic gradient descent with sklearn
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn的随机梯度下降
- en: 'The `sklearn` library includes an `SGDRegressor` model in its `linear_models`
    module. To learn the parameters for the same model using this method, we need
    to first standardize the data because the gradient is sensitive to the scale.
    We use `StandardScaler()` for this purpose that computes the mean and the standard
    deviation for each input variable during the fit step, and then subtracts the
    mean and divides by the standard deviation during the transform step that we can
    conveniently conduct in a single `fit_transform()` command:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn`库在其`linear_models`模块中包含了一个`SGDRegressor`模型。要使用该方法学习相同模型的参数，我们需要首先标准化数据，因为梯度对尺度敏感。我们使用`StandardScaler()`来计算每个输入变量的平均值和标准差，并在拟合步骤中减去平均值并除以标准差，在转换步骤中进行方便的单个`fit_transform()`命令：'
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then we instantiate the `SGDRegressor` using the default values except for
    a `random_state` setting to facilitate replication:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用默认值实例化`SGDRegressor`，除了设置`random_state`以便复制：
- en: '[PRE3]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can fit the `sgd` model, create the in-sample predictions for both the
    OLS and the `sgd` models, and compute the root mean squared error for each:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以拟合`sgd`模型，为OLS模型和`sgd`模型创建样本内预测，并计算每个模型的均方根误差：
- en: '[PRE4]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, both models yield the same result. We will now take on a more ambitious
    project using linear regression to estimate a multi-factor asset pricing model.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，两个模型产生相同的结果。我们现在将承担一个更雄心勃勃的项目，使用线性回归来估计多因子资产定价模型。
- en: How to build a linear factor model
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建线性因子模型
- en: Algorithmic trading strategies use **linear factor models** to quantify the
    relationship between the return of an asset and the sources of risk that represent
    the main drivers of these returns. Each factor risk carries a premium, and the
    total asset return can be expected to correspond to a weighted average of these
    risk premia.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 算法交易策略使用**线性因子模型**来量化资产收益与代表这些收益主要驱动因素的风险来源之间的关系。每个因子风险都带有一个风险溢价，总资产收益可以预期对应于这些风险溢价的加权平均。
- en: 'There are several practical applications of factor models across the portfolio
    management process from construction and asset selection to risk management and
    performance evaluation. The importance of factor models continues to grow as common
    risk factors are now tradeable:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因子模型在投资组合管理过程中有多个实际应用，从构建和资产选择到风险管理和绩效评估。随着常见风险因素现在可以交易，因子模型的重要性不断增长：
- en: A summary of the returns of many assets by a much smaller number of factors
    reduces the amount of data required to estimate the covariance matrix when optimizing
    a portfolio
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多资产的回报摘要通过少量因子来减少在优化投资组合时估算协方差矩阵所需的数据量
- en: An estimate of the exposure of an asset or a portfolio to these factors allows
    for the management of the resultant risk, for instance by entering suitable hedges
    when risk factors are themselves traded
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对资产或投资组合对这些因子的敞口的估计允许管理由此产生的风险，例如当风险因子本身被交易时，可以通过输入适当的对冲来管理风险
- en: A factor model also permits the assessment of the incremental signal content
    of new alpha factors
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因子模型还允许评估新α因子的增量信号内容。
- en: A factor model can also help assess whether a manager's performance relative
    to a benchmark is indeed due to skill in selecting assets and timing the market,
    or if instead, the performance can be explained by portfolio tilts towards known
    return drivers that can today be replicated as low-cost, passively managed funds
    without incurring active management fees
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因子模型还可以帮助评估经理相对于基准的业绩是否确实是由于选择资产和市场时机的技能，或者是否业绩可以解释为投资组合倾向于已知回报驱动因素，这些因素今天可以以低成本、被动管理的基金形式复制，而无需支付主动管理费用。
- en: The following examples apply to equities, but risk factors have been identified
    for all asset classes (see references in the GitHub repository).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于股票，但已为所有资产类别确定了风险因子（请参阅GitHub存储库中的参考资料）。
- en: From the CAPM to the Fama—French five-factor model
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从资本资产定价模型到法玛-法国五因子模型
- en: 'Risk factors have been a key ingredient to quantitative models since the **Capital
    Asset Pricing Model **(**CAPM**) explained the expected returns of all *N* assets ![](img/31afacbc-b4b4-4f0f-97ac-fff357bc652a.png)
    using their respective exposure ![](img/a332fea0-7be6-4858-a873-73742a227f66.png)
    to a single factor, the expected excess return of the overall market over the
    risk-free rate ![](img/4f4b2d16-602f-4672-941b-3be7cc28d1a4.png). The model takes
    the following linear form:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 自从资本资产定价模型（**CAPM**）解释了所有*N*资产的预期回报，即使用它们对单一因子的各自暴露！[](img/a332fea0-7be6-4858-a873-73742a227f66.png)到整体市场相对于无风险利率的预期超额回报！[](img/4f4b2d16-602f-4672-941b-3be7cc28d1a4.png)以来，风险因子一直是定量模型的关键因素。该模型采用以下线性形式：
- en: '![](img/3a6152b2-582b-4452-a8d2-c70388fd9827.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a6152b2-582b-4452-a8d2-c70388fd9827.png)'
- en: This differs from classic fundamental analysis a la Dodd and Graham where returns
    depend on firm characteristics. The rationale is that, in the aggregate, investors
    cannot eliminate this so-called systematic risk through diversification. Hence, in
    equilibrium, they require compensation for holding an asset commensurate with
    its systematic risk. The model implies that, given efficient markets where prices
    immediately reflect all public information, there should be no superior risk-adjusted
    returns, that is, the value of ![](img/f9d4110b-3746-4824-9340-1ec387bb81f6.png)
    should be zero.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这与道德和格雷厄姆经典的基本分析有所不同，后者依赖于公司特征来确定回报。理由是，在总体上，投资者无法通过分散化消除这种所谓的系统风险。因此，在均衡状态下，他们要求持有资产的补偿与其系统风险相称。该模型暗示，在市场有效的情况下，价格立即反映所有公开信息，就不应该有优越的风险调整回报，也就是说，![](img/f9d4110b-3746-4824-9340-1ec387bb81f6.png)的价值应该为零。
- en: 'Empirical tests of the model use linear regression and have consistently failed,
    prompting a debate whether the efficient markets or the single factor aspect of
    the joint hypothesis is to blame. It turns out that both premises are probably
    wrong:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的实证测试使用线性回归，并一直失败，促使人们争论是市场有效还是联合假设的单一因子方面有问题。事实证明，这两个前提都可能是错误的：
- en: 'Joseph Stiglitz earned the 2001 Nobel Prize in economics in part for showing
    that markets are generally not perfectly efficient: if markets are efficient,
    there is no value in collecting data because this information is already reflected
    in prices. However, if there is no incentive to gather information, it is hard
    to see how it should be already reflected in prices.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约瑟夫·斯蒂格利茨在部分地获得了2001年诺贝尔经济学奖，因为他表明市场通常并非完全有效：如果市场有效，那么收集数据就没有价值，因为这些信息已经反映在价格中。但是，如果没有收集信息的动机，很难看到它如何已经反映在价格中。
- en: On the other hand, theoretical and empirical improvements on the CAPM suggest
    that additional factors help explain some of the anomalies that consisted in superior
    risk-adjusted returns that do not depend on overall market exposure, such as higher
    returns for smaller firms.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，对CAPM的理论和实证改进表明，额外因素有助于解释一些不依赖于整体市场敞口的超常风险调整回报的异常，例如较小公司的较高回报。
- en: Stephen Ross proposed the **Arbitrage Pricing Theory** (**APT**) in 1976 as
    an alternative that allows for several risk factors while eschewing market efficiency.
    In contrast to the CAPM, it assumes that opportunities for superior returns due
    to mispricing may exist but will quickly be arbitraged away. The theory does not
    specify the factors, but research by the author suggests that the most important
    are changes in inflation and industrial production, as well as changes in risk
    premia or the term structure of interest rates.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 斯蒂芬·罗斯于1976年提出了**套利定价理论**（**APT**），作为一种允许多种风险因素存在的替代方案，同时避免了市场效率。与CAPM相比，它假设由于定价错误而产生的超常回报机会可能存在，但会迅速被套利消除。该理论并未明确规定这些因素，但作者的研究表明，最重要的因素是通货膨胀和工业生产的变化，以及风险溢价或利率期限结构的变化。
- en: Kenneth French and Eugene Fama (who won the 2013 Nobel Prize) identified additional
    risk factors that depend on firm characteristics and are widely used today. In
    1993, the Fama—French three-factor model added the relative size and value of
    firms to the single CAPM source of risk. In 2015, the five-factor model further
    expanded the set to include firm profitability and level of investment that had
    been shown to be significant in the intervening years. In addition, many factor
    models include a price momentum factor.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 肯尼斯·弗伦奇和尤金·法玛（获得2013年诺贝尔奖）确定了取决于公司特征的额外风险因素，并且今天被广泛使用。1993年，法玛—弗伦奇三因子模型在单一CAPM风险的基础上增加了公司的相对规模和价值。2015年，五因子模型进一步扩展了该集合，包括在介入年份已被证明显著的公司盈利能力和投资水平。此外，许多因子模型包括价格动量因子。
- en: 'The Fama—French risk factors are computed as the return difference on diversified
    portfolios with high or low values according to metrics that reflect a given risk
    factor. These returns are obtained by sorting stocks according to these metrics
    and then going long stocks above a certain percentile while shorting stocks below
    a certain percentile. The metrics associated with the risk factors are defined
    as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛—弗伦奇风险因素的计算是指根据反映给定风险因素的度量标准对多样化投资组合的回报差异。通过根据这些度量标准对股票进行排序，然后对超过某一百分位数的股票做多头，对低于某一百分位数的股票做空头，获得这些回报。与风险因素相关的度量标准定义如下：
- en: '**Size**: **Market Equity** (**ME**)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大小**: **市场权益**（**ME**）'
- en: '**Value**: **Book Value of Equity** (**BE**) divided by ME'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值**: **股权账面价值**（**BE**）除以ME'
- en: '**Operating Profitability (OP)**: Revenue minus cost of goods sold/assets'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运营盈利能力（OP）**：收入减去销售成本/资产'
- en: '**Investment**: Investment/assets'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资**: 投资/资产'
- en: There are also unsupervised learning techniques for a data-driven discovery
    of risk factors using factors and principal component analysis that we will explore
    in [Chapter 12](c187906e-9fde-4f85-b709-df88dd0f7e88.xhtml), *Unsupervised Learning.*
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 还有无监督学习技术用于基于数据的风险因素的发现，包括基于因子和主成分分析的方法，我们将在[第12章](c187906e-9fde-4f85-b709-df88dd0f7e88.xhtml)，*无监督学习*中进行探讨。
- en: Obtaining the risk factors
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取风险因素
- en: Fama and French make updated risk factor and research portfolio data available
    through their website, and you can use the `pandas_datareader` library to obtain
    the data. For this application, refer to the `fama_macbeth.ipynb` notebook for
    additional detail.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和弗伦奇通过他们的网站提供了更新的风险因素和研究投资组合数据，您可以使用`pandas_datareader`库获取这些数据。对于此应用，请参考`fama_macbeth.ipynb`笔记本以获取更多详细信息。
- en: 'In particular, we will be using the five Fama—French factors that result from
    sorting stocks first into three size groups and then into two for each of the
    remaining three firm-specific factors. Hence, the factors involve three sets of
    value-weighted portfolios formed as 3 x 2 sorts on size and book-to-market, size
    and operating profitability, and size and investment. The risk factor values computed
    as the average returns of the **portfolios** (**PF**) as outlined in the following
    table:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们将使用从首先将股票分成三个规模组，然后对剩余三个公司特定因素中的每个进行两次排序的五个法玛—弗伦奇因子。因此，这些因素涉及根据大小和账面市值、大小和经营盈利能力以及大小和投资进行的3
    x 2排序形成的三组加权价值组合。风险因素值计算为如下表所述的**投资组合**（**PF**）的平均回报：
- en: '| **Concept** | **Label** | **Name** | **Risk factor calculation** |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| **概念** | **标签** | **名称** | **风险因子计算** |'
- en: '| Size | SMB | Small minus big | Nine small stock PF minus nine large stock
    PF |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 规模 | SMB | 小减大 | 九个小型股票PF减去九个大型股票PF |'
- en: '| Value | HML | High minus low |  Two value PF minus two growth (with low BE/ME
    value) PF |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 值 | HML | 高减低 | 两个价值PF减去两个增长PF（具有低BE/ME值）|'
- en: '| Profitability | RMW | Robust minus weak | Two robust OP PF minus two weak
    OP PF |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 盈利能力 | RMW | 强大减弱 | 两个强劲OP PF减去两个弱OP PF |'
- en: '| Investment | CMA | Conservative minus aggressive | Two conservative investment
    portfolios minus two aggressive investment portfolios |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 投资 | CMA | 保守减激进 | 两个保守投资组合减去两个激进投资组合 |'
- en: '| Market | Rm-Rf | Excess return on the market | Value-weight return of all
    firms incorporated in and listed on  major US exchanges with good data minus the
    one-month Treasury bill rate |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 市场 | Rm-Rf | 市场的超额回报 | 所有在主要美国交易所上市和上市的公司的价值加权回报，具有良好数据减去一个月期国库券利率 |'
- en: 'We will use returns at a monthly frequency that we obtain for the period 2010
    – 2017 as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用从2010年至2017年期间获得的月频率的回报如下：
- en: '[PRE5]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Fama and French also make available numerous portfolios that we can illustrate
    the estimation of the factor exposures, as well as the value of the risk premia
    available in the market for a given time period. We will use a panel of the 17
    industry portfolios at a monthly frequency. We will subtract the risk-free rate
    from the returns because the factor model works with excess returns:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Fama和French还提供了许多我们可以用来说明因子暴露估计的投资组合，以及市场上某个特定时间段可用的风险溢价的价值。我们将使用一个包含17个行业投资组合的面板，并以月频率进行计算。我们将从回报中减去无风险利率，因为因子模型使用超额回报：
- en: '[PRE6]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We will now build a linear factor model based on this panel data using a method
    that addresses the failure of some basic linear regression assumptions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将基于这些面板数据构建一个线性因子模型，使用一种解决一些基本线性回归假设失败的方法。
- en: Fama—Macbeth regression
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fama—Macbeth回归
- en: Given data on risk factors and portfolio returns, it is useful to estimate the
    portfolio's exposure, that is, how much the risk factors drive portfolio returns,
    as well as how much the exposure to a given factor is worth, that is, the what
    market's risk factor premium is. The risk premium then permits to estimate the
    return for any portfolio provided the factor exposure is known or can be assumed.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于风险因子和投资组合回报的数据，估计投资组合的暴露是有用的，即风险因子驱动投资组合回报的程度，以及给定因子的暴露值的价值，即市场的风险因子溢价是多少。然后，风险溢价可以估算任何投资组合的回报，前提是已知或可以假定因子暴露。
- en: More formally, we will have *i=1, ..., N* asset or portfolio returns over *t=1,
    ..., T* periods and each asset's excess period return will be denoted ![](img/65e5c37d-8bfd-47b8-85a9-07e538fd00f8.png). The
    goals is to test whether the *j=1, ..., M* factors ![](img/ca9ceac1-0c7c-4833-b6d1-dd15cb47660d.png)explain
    the excess returns and the risk premium associated with each factor. In our case,
    we have *N=17* portfolios and *M=5* factors, each with =96 periods of data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，我们将对*t=1, ..., T*期间的*i=1, ..., N*资产或投资组合的回报进行测试，每个资产的超额期间回报将被表示为![](img/65e5c37d-8bfd-47b8-85a9-07e538fd00f8.png)。目标是测试*j=1,
    ..., M*因子是否解释了超额回报以及与每个因子相关的风险溢价。在我们的案例中，我们有*N=17*个投资组合和*M=5*个因子，每个因子都有96个数据周期。
- en: Factor models are estimated for many stocks in a given period. Inference problems
    will likely arise in such cross-sectional regressions because the fundamental
    assumptions of classical linear regression may not hold. Potential violations
    include measurement errors, covariation of residuals due to heteroskedasticity
    and serial correlation, and multicollinearity.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 因子模型是针对给定期间内许多股票进行估计的。在这种横截面回归中可能会出现推断问题，因为经典线性回归的基本假设可能不成立。潜在的违规行为包括测量误差，由异方差和串行相关引起的残差协方差，以及多重共线性。
- en: 'To address the inference problem caused by the correlation of the residuals,
    Fama and MacBeth proposed a two-step methodology for a cross-sectional regression
    of returns on factors. The two-stage Fama—Macbeth regression is designed to estimate
    the premium rewarded for the exposure to a particular risk factor by the market. The
    two stages consist of:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决残差相关引起的推断问题，Fama和MacBeth提出了一种两步法的方法，用于对因子上的横截面回归。两阶段的Fama—Macbeth回归旨在估计市场对特定风险因子暴露所奖励的溢价。两个阶段包括：
- en: '**First stage**: *N* time-series regression, one for each asset or portfolio,
    of its excess returns on the factors to estimate the factor loadings. In matrix
    form, for each asset:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一阶段**：*N*时间序列回归，对于每个资产或投资组合，它的超额收益对因子进行回归，以估计因子载荷。以矩阵形式，对于每个资产：'
- en: '![](img/e187e1c1-3c7a-4dc4-a691-0e80d387a11b.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e187e1c1-3c7a-4dc4-a691-0e80d387a11b.png)'
- en: '**Second stage**: T cross-sectional regression, one for each time period, to
    estimate the risk premium. In matrix form, we obtain a vector ![](img/8a5b412f-8c0f-40f0-97d5-d3f50789362e.png) of
    risk premia for each period:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二阶段**：T个横截面回归，每个时间段一个，以估计风险溢价。以矩阵形式，我们获得每个时间段的风险溢价向量![](img/8a5b412f-8c0f-40f0-97d5-d3f50789362e.png)：'
- en: '![](img/ebf5ed03-1aaf-4cef-85aa-33cc4fb12ad1.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebf5ed03-1aaf-4cef-85aa-33cc4fb12ad1.png)'
- en: Now we can compute the factor risk premia as the time average and get t-statistic
    to assess their individual significance, using the assumption that the risk premia
    estimates are independent over time:![](img/105fc0bb-9211-48d6-b2cb-c1ff1081bbf3.png).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将因子风险溢价计算为时间平均值，并使用假设风险溢价估计在时间上独立来获取t统计量，评估它们的个体显著性：![](img/105fc0bb-9211-48d6-b2cb-c1ff1081bbf3.png)。
- en: If we had a very large and representative data sample on traded risk factors
    we could use the sample mean as a risk premium estimate. However, we typically
    do not have a sufficiently long history to and the margin of error around the
    sample mean could be quite large. The Fama—Macbeth methodology leverages the covariance
    of the factors with other assets to determine the factor premia. The second moment
    of asset returns is easier to estimate than the first moment, and obtaining more
    granular data improves estimation considerably, which is not true of mean estimation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们拥有一个非常大且具代表性的交易风险因子数据样本，我们可以将样本均值用作风险溢价估计。然而，我们通常没有足够长的历史记录，而且样本均值周围的误差范围可能相当大。法马—麦克贝斯方法利用因子与其他资产的协方差来确定因子溢价。资产收益的二阶矩比第一阶矩更容易估计，并且获得更细粒度的数据会显着改善估计，这在均值估计中并不成立。
- en: 'We can implement the first stage to obtain the 17 factor loading estimates
    as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以实现第一阶段，以获取17个因子载荷估计，如下所示：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For the second stage, we run 96 regressions of the period returns for the cross
    section of portfolios on the factor loadings:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二阶段，我们对横截面投资组合的期间收益进行96次回归，以估计因子载荷：
- en: '[PRE8]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we compute the average for the 96 periods to obtain our factor risk
    premium estimates:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算96个周期的平均值，以获取我们的因子风险溢价估计值：
- en: '[PRE9]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `linear_models` library extends `statsmodels` with various models for panel
    data and also implements the two-stage Fama—MacBeth procedure:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`linear_models`库通过各种面板数据模型扩展了`statsmodels`，并且还实现了两阶段法马—麦克贝斯程序：'
- en: '[PRE10]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This provides us with the same result:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了相同的结果：
- en: '![](img/74d5d23a-9727-43c3-b1a1-3cb8ece117dd.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/74d5d23a-9727-43c3-b1a1-3cb8ece117dd.png)'
- en: LinearFactorModel Estimation Summary
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 线性因子模型估计摘要
- en: The accompanying notebook illustrates the use of categorical variables by using
    industry dummies when estimating risk premia for a larger panel of individual
    stocks.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 随附的笔记本通过在估计较大的个别股票风险溢价时使用行业虚拟变量来说明了分类变量的使用。
- en: 'Shrinkage methods: regularization for linear regression'
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缩小方法：线性回归的正则化
- en: The least squares methods to train a linear regression model will produce the
    best, linear, and unbiased coefficient estimates when the Gauss—Markov assumptions
    are met. Variations like GLS fare similarly well even when OLS assumptions about
    the error covariance matrix are violated. However, there are estimators that produce
    biased coefficients to reduce the variance to achieve a lower generalization error
    overall.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当高斯—马尔可夫假设得到满足时，最小二乘法用于训练线性回归模型将会产生最佳、线性和无偏的系数估计。即使OLS关于误差协方差矩阵的假设被违反，类似GLS的变种也会表现得相当好。然而，有一些估计器会产生偏斜的系数，以减少方差以达到更低的总体泛化误差。
- en: When a linear regression model contains many correlated variables, their coefficients
    will be poorly determined because the effect of a large positive coefficient on
    the RSS can be canceled by a similarly large negative coefficient on a correlated
    variable. Hence, the model will have a tendency for high variance due to this
    wiggle room of the coefficients that increases the risk that the model overfits
    to the sample.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 当线性回归模型包含许多相关变量时，它们的系数将被较差地确定，因为大正系数对RSS的影响可能会被相关变量上的同样大的负系数抵消。因此，由于系数的这种摆动空间，模型将具有高方差的倾向，增加模型过度拟合样本的风险。
- en: How to hedge against overfitting
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何对抗过度拟合
- en: One popular technique to control overfitting is that of **regularization**,
    which involves the addition of a penalty term to the error function to discourage
    the coefficients from reaching large values. In other words, size constraints
    on the coefficients can alleviate the resultant potentially negative impact on
    out-of-sample predictions. We will encounter regularization methods for all models
    since overfitting is such a pervasive problem.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 控制过拟合的一种流行技术是**正则化**，它涉及将惩罚项添加到误差函数中，以阻止系数达到较大的值。换句话说，对系数的大小施加约束可以缓解结果对样本外预测的潜在负面影响。由于过拟合是如此普遍的问题，我们将在所有模型中遇到正则化方法。
- en: 'In this section, we will introduce shrinkage methods that address two motivations
    to improve on the approaches to linear models discussed so far:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍缩小方法，以解决改进迄今为止讨论的线性模型方法的两个动机：
- en: '**Prediction accuracy**: The low bias but high variance of least squares estimates
    suggests that the generalization error could be reduced by shrinking or setting
    some coefficients to zero, thereby trading off a slightly higher bias for a reduction
    in the variance of the model.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测准确性**：最小二乘估计的低偏差但高方差表明，通过收缩或将某些系数设置为零，可以减少泛化误差，从而在略微增加偏差的同时减少模型的方差。'
- en: '**Interpretation**: A large number of predictors may complicate the interpretation
    or communication of the big picture of the results. It may be preferable to sacrifice
    some detail to limit the model to a smaller subset of parameters with the strongest
    effects.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释性**：大量的预测变量可能会使结果的解释或传达变得复杂化。牺牲一些细节以限制模型只包括具有最强效果的参数子集可能更可取。'
- en: 'Shrinkage models restrict the regression coefficients by imposing a penalty
    on their size. These models achieve this goal by adding a term to the objective function
    so that the coefficients of a shrinkage model minimize the RSS plus a penalty
    that is positively related to the (absolute) size of the coefficients. The added
    penalty turns finding the linear regression coefficients into a constrained minimization
    problem that, in general, takes the following Lagrangian form:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型通过对其大小施加惩罚来限制回归系数。这些模型通过向目标函数添加一个项来实现此目标，使得收缩模型的系数最小化 RSS 加上一个与系数（绝对值）大小正相关的惩罚项。添加的惩罚将线性回归系数的查找转变为一个约束最小化问题，通常采用以下拉格朗日形式：
- en: '![](img/2dd72b9d-c072-47ce-834f-356b6c948b14.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2dd72b9d-c072-47ce-834f-356b6c948b14.png)'
- en: The regularization parameter λ determines the size of the penalty effect, that
    is, the strength of the regularization. As soon as λ is positive, the coefficients
    will differ from the unconstrained least squared parameters, which implies a biased
    estimate. The hyperparameter λ should be adaptively chosen using cross-validation
    to minimize an estimate of expected prediction error.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化参数 λ 决定了惩罚效果的大小，即正则化的强度。一旦 λ 为正，系数将与无约束的最小二乘参数不同，这意味着一个有偏的估计。超参数 λ 应该通过交叉验证来自适应地选择，以最小化预测误差的估计。
- en: Shrinkage models differ by how they calculate the penalty, that is, the functional
    form of S. The most common versions are the ridge regression that uses the sum
    of the squared coefficients, whereas the lasso model bases the penalty on the
    sum of the absolute values of the coefficients.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型的区别在于它们如何计算惩罚，即 S 的函数形式。最常见的版本是岭回归，它使用了系数平方的和，而套索模型则基于系数绝对值的和来设置惩罚。
- en: How ridge regression works
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 岭回归的工作原理
- en: 'The ridge regression shrinks the regression coefficients by adding a penalty
    to the objective function that equals the sum of the squared coefficients, which
    in turn corresponds to the L² norm of the coefficient vector:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归通过将惩罚添加到目标函数中来缩小回归系数，该惩罚等于系数的平方和，进而对应于系数向量的 L² 范数：
- en: '![](img/119120f8-5beb-4dd6-9aaf-d613fb2edb63.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/119120f8-5beb-4dd6-9aaf-d613fb2edb63.png)'
- en: 'Hence, the ridge coefficients are defined as:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，岭回归系数定义如下：
- en: '![](img/b2783010-31ca-4a32-8997-dd5c559c40e6.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2783010-31ca-4a32-8997-dd5c559c40e6.png)'
- en: The intercept ![](img/71cf85ed-96c5-49f5-b91d-07099b5ed007.png) has been excluded
    from the penalty to make the procedure independent of the origin chosen for the
    output variable—otherwise, adding a constant to all output values would change
    all slope parameters as opposed to a parallel shift.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 截距![](img/71cf85ed-96c5-49f5-b91d-07099b5ed007.png)已从惩罚中排除，以使程序独立于为输出变量选择的原点——否则，将常数添加到所有输出值将改变所有斜率参数而不是平行移位。
- en: 'It is important to standardize the inputs by subtracting from each input the
    corresponding mean and dividing the result by the input''s standard deviation because
    the ridge solution is sensitive to the scale of the inputs. There is also a closed
    solution for the ridge estimator that resembles the OLS case:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是通过从每个输入中减去相应的均值并将结果除以输入的标准差来标准化输入，因为岭解对输入的尺度敏感。岭估计器也有一个类似OLS情况的闭式解：
- en: '![](img/4d2c6a4a-0e95-4314-932e-9cdec5694253.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d2c6a4a-0e95-4314-932e-9cdec5694253.png)'
- en: The solution adds the scaled identity matrix λ*I* to *X^TX* before inversion,
    which guarantees that the problem is non-singular, even if *X^T**X* does not have full
    rank. This was one of the motivations for using this estimator when it was originally
    introduced.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在求逆之前，解决方案将缩放后的单位矩阵λ*I*添加到*X^TX*中，这保证了问题是非奇异的，即使*X^T**X*没有满秩。这是最初引入该估计量时的动机之一。
- en: 'The ridge penalty results in proportional shrinkage of all parameters. In the
    case of **orthonormal inputs**, the ridge estimates are just a scaled version
    of the least squares estimates, that is:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚导致所有参数的成比例收缩。在**正交输入**的情况下，岭估计只是最小二乘估计的缩放版本，即：
- en: '![](img/bba72082-ca29-4704-a72d-d811aa84a7c2.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bba72082-ca29-4704-a72d-d811aa84a7c2.png)'
- en: Using the **singular value decomposition** (**SVD**) of the input matrix *X*,
    we can gain insight into how the shrinkage affects inputs in the more common case
    where they are not orthonormal. The SVD of a centered matrix represents the principal
    components of a matrix (refer to [Chapter 11](2fbfa6b5-87f3-49c3-b13a-5ead63471370.xhtml),
    *Gradient Boosting Machines*, on unsupervised learning) that capture uncorrelated
    directions in the column space of the data in descending order of variance.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 使用输入矩阵*X*的**奇异值分解**（**SVD**），我们可以深入了解在更常见的情况下，收缩如何影响非正交输入。中心矩阵的SVD表示矩阵的主成分（参见[第11章](2fbfa6b5-87f3-49c3-b13a-5ead63471370.xhtml)，*梯度提升机*，有关无监督学习的内容），按方差降序捕获数据的列空间中的不相关方向。
- en: Ridge regression shrinks coefficients on input variables that are associated
    with directions in the data that have less variance more than input variables
    that correlate with directions that exhibit more variance. Hence, the implicit
    assumption of ridge regression is that the directions in the data that vary the
    most will be most influential or most reliable when predicting the output.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归会收缩与数据中方差较小的方向相关联的输入变量的系数，而不是收缩与展现更多方差的方向相关联的输入变量的系数。因此，岭回归的隐含假设是，在数据中变化最大的方向在预测输出时最有影响力或最可靠。
- en: How lasso regression works
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套索回归的工作原理
- en: 'The lasso, known as basis pursuit in signal processing, also shrinks the coefficients
    by adding a penalty to the sum of squares of the residuals, but the lasso penalty
    has a slightly different effect. The lasso penalty is the sum of the absolute
    values of the coefficient vector, which corresponds to its L¹ norm. Hence, the
    lasso estimate is defined by:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 套索，在信号处理中称为基 Pursuit，通过向残差的平方和添加惩罚来缩小系数，但套索惩罚具有稍微不同的效果。套索惩罚是系数向量的绝对值的总和，对应于其L¹范数。因此，套索估计由以下方式定义：
- en: '![](img/c05889b1-7c7b-415e-b0eb-280833978de1.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c05889b1-7c7b-415e-b0eb-280833978de1.png)'
- en: Similarly to ridge regression, the inputs need to be standardized. The lasso
    penalty makes the solution nonlinear, and there is no closed-form expression for
    the coefficients as in ridge regression. Instead, the lasso solution is a quadratic
    programming problem and there are available efficient algorithms that compute
    the entire path of coefficients that result for different values of λ with the
    same computational cost as for ridge regression.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 与岭回归类似，输入需要被标准化。套索惩罚使解决方案非线性，并且与岭回归不同，系数没有闭式表达式。相反，套索解是一个二次规划问题，有可用的高效算法可以计算出对于不同λ值产生的系数整个路径，其计算成本与岭回归相同。
- en: The lasso penalty had the effect ofgradually reducing some coefficients to zero
    as the regularization increases. For this reason, the lasso can be used for the
    continuous selection of a subset of features.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Lasso 惩罚的效果是随着正则化的增加逐渐将一些系数减少到零。因此，Lasso 可用于连续选择一组特征。
- en: How to use linear regression to predict returns
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用线性回归预测回报
- en: The notebook `linear_regression.ipynb` contains examples for the prediction
    of stock prices using OLS with `statsmodels` and `sklearn`, as well as ridge and
    lasso models. It is designed to run as a notebook on the Quantopian research platform
    and relies on the `factor_library` introduced in [Chapter 4](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml), *Alpha
    Factors Research*.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本 `linear_regression.ipynb` 包含使用 `statsmodels` 和 `sklearn` 进行 OLS 的股价预测的示例，以及岭回归和
    Lasso 模型。它旨在在 Quantopian 研究平台上作为笔记本运行，并依赖于 [第四章](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml)
    中介绍的 `factor_library`，*Alpha Factors Research*。
- en: Prepare the data
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: We need to select a universe of equities and a time horizon, build and transform
    alpha factors that we will use as features, calculate forward returns that we
    aim to predict, and potentially clean our data.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择一组股票和一个时间范围，构建和转换我们将用作特征的 alpha 因子，计算我们希望预测的前瞻回报，并可能清理我们的数据。
- en: Universe creation and time horizon
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 宇宙创建和时间范围
- en: 'We will use equity data for the years 2014 and 2015 from a custom `Q100US`
    universe that uses built-in filters, factors, and classifiers to select the 100
    stocks with the highest average dollar volume of the last 200 trading days filtered
    by additional default criteria (see Quantopian docs linked on GitHub for detail).
    The universe dynamically updates based on the filter criteria so that, while there
    are 100 stocks at any given point, there may be more than 100 distinct equities
    in the sample:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 2014 年和 2015 年的股票数据，来自使用内置过滤器、因子和分类器选择最后 200 个交易日的平均美元成交量最高的 100 支股票的自定义
    `Q100US` 宇宙，根据额外的默认标准进行筛选（请参阅 GitHub 上链接的 Quantopian 文档以获取详细信息）。该宇宙会根据筛选标准动态更新，因此，在任何给定点上可能有
    100 支股票，但样本中可能有超过 100 个不同的股票：
- en: '[PRE11]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Target return computation
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标回报计算
- en: 'We will test predictions for various `lookahead` periods to identify the best
    holding periods that generate the best predictability, measured by the information
    coefficient. More specifically, we compute returns for 1, 5, 10, and 20 days using
    the built-in `Returns` function, resulting in over 50,000 observations for the
    universe of 100 stocks over two years (that include approximately 252 trading
    days each):'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测试不同 `lookahead` 期间的预测，以确定产生最佳可预测性的最佳持有期，该期间由信息系数衡量。更具体地说，我们使用内置的 `Returns`
    函数计算 1、5、10 和 20 天的收益，结果是在两年内（每年大约有 252 个交易日）对 100 支股票的宇宙产生超过 50,000 个观察值：
- en: '[PRE12]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Alpha factor selection and transformation
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alpha 因子选择和转换
- en: We will use over 50 features that cover a broad range of factors based on market,
    fundamental, and alternative data. The notebook also includes custom transformations
    to convert fundamental data that is typically available in quarterly reporting
    frequency to rolling annual totals or averages to avoid excessive season fluctuations.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用超过 50 个涵盖市场、基本和替代数据的各种因素的特征。笔记本还包括自定义转换，将通常以季度报告频率提供的基本数据转换为滚动年度总额或平均值，以避免过度季节波动。
- en: 'Once the factors have been computed through the various pipelines outlined
    in [Chapter 4](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml), *Alpha Factors Research*,
    we combine them using `pd.concat()`, assign index names, and create a categorical
    variable that identifies the asset for each data point:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过 [第四章](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml) 中概述的各种流水线计算出因子，*Alpha
    因子研究*，我们使用 `pd.concat()` 将它们组合起来，分配索引名称，并创建一个用于识别每个数据点的资产的分类变量：
- en: '[PRE13]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Data cleaning – missing data
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清洗 - 缺失数据
- en: 'In a next step, we remove rows and columns that lack more than 20 percent of
    the observations, resulting in a loss of six percent of the observations and three
    columns:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们删除缺少超过 20% 观察值的行和列，导致损失 6% 的观察值和 3 列：
- en: '[PRE14]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'At this point, we have 51 features and the categorical identifier of the stock:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们有 51 个特征和股票的分类标识符：
- en: '[PRE15]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Data exploration
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据探索
- en: For linear regression models, it is important to explore the correlation among
    the features to identify multicollinearity issues, and to check the correlation
    between the features and the target. The notebook contains a seaborn clustermap
    that shows the hierarchical structure of the feature correlation matrix. It identifies
    a small number of highly correlated clusters.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归模型，重要的是探索特征之间的相关性，以识别多重共线性问题，并检查特征与目标之间的相关性。笔记本包含一个seaborn clustermap，显示特征相关矩阵的层次结构。它识别出少量高度相关的集群。
- en: Dummy encoding of categorical variables
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对分类变量进行虚拟编码
- en: 'We need to convert the categorical `stock` variable into a numeric format so
    that the linear regression can process it. For this purpose, we use dummy encoding
    that creates individual columns for each category level and flags the presence
    of this level in the original categorical column with an entry of `1`, and `0`
    otherwise. The pandas function `get_dummies()` automates dummy encoding. It detects
    and properly converts columns of type objects as illustrated next. If you need
    dummy variables for columns containing integers, for instance, you can identify
    them using the keyword `columns`:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将分类变量`stock`转换为数字格式，以便线性回归可以处理它。为此，我们使用创建每个类别级别的单独列并使用`1`标记此级别在原始分类列中存在，否则标记为`0`的虚拟编码。
    pandas函数`get_dummies()`自动执行虚拟编码。它检测并正确转换类型为对象的列，如下所示。如果您需要对包含整数的列获取虚拟变量，例如，您可以使用`columns`关键字标识它们：
- en: '[PRE16]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When converting all categories to dummy variables and estimating the model
    with an intercept (as you typically would), you inadvertently create multicollinearity:
    the matrix now contains redundant information and no longer has full rank, that
    is, becomes singular. It is simple to avoid this by removing one of the new indicator
    columns. The coefficient on the missing category level will now be captured by
    the intercept (which is always `1` when every other category dummy is `0`). Use
    the `drop_first` keyword to correct the dummy variables accordingly:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 当将所有类别转换为虚拟变量并估计模型时，使用截距（通常情况下）会无意中创建多重共线性：矩阵现在包含冗余信息，不再具有完整的秩，即，变得奇异。通过删除新指标列中的一个来简单避免这种情况。缺失类别级别上的系数现在将由截距（当其他每个类别虚拟为`0`时始终为`1`）捕获。使用`drop_first`关键字相应地更正虚拟变量：
- en: '[PRE17]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Applied to our combined features and returns, we obtain 181 columns because
    there are more than 100 stocks as the universe definition automatically updates
    the stock selection:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于我们的综合特征和回报，我们获得了181列，因为有超过100只股票作为宇宙定义，它会自动更新股票选择：
- en: '[PRE18]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Creating forward returns
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建前瞻回报
- en: 'The goal is to predict returns over a given holding period. Hence, we need
    to align the features with return values with the corresponding return data point
    1, 5, 10, or 20 days into the future for each equity. We achieve this by combining
    the pandas `.groupby()` method with the `.shift()` method as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是预测给定持有期内的回报。因此，我们需要将特征与回报值与相应的未来1、5、10或20天的回报数据点对齐，对于每个股票。我们通过将pandas的`.groupby()`方法与`.shift()`方法结合使用来实现这一点：
- en: '[PRE19]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: There are now different numbers of observations for each return series as the
    forward shift has created missing values at the tail end for each equity.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在每个回报系列的观察次数不同，因为前向移位在每个股票的尾部创建了缺失值。
- en: Linear OLS regression using statsmodels
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用statsmodels进行线性OLS回归
- en: 'We can estimate a linear regression model using OLS with `statsmodels` as demonstrated
    previously. We select a forward return, for example for a 10-day holding period,
    remove outliers below the 2.5% and above the 97.5% percentiles, and fit the model
    accordingly:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像之前演示的那样使用`statsmodels`估计线性回归模型的OLS。我们选择一个前瞻回报，例如一个10天的持有期，删除低于2.5%和高于97.5%百分位数的异常值，然后相应地拟合模型：
- en: '[PRE20]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Diagnostic statistics
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 诊断统计
- en: The summary is available in the notebook to save some space due to the large
    number of variables. The diagnostic statistics show that, given the high p-value
    on the Jarque—Bera statistic, the hypothesis that the residuals are normally distributed
    cannot be rejected.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要可在笔记本中保存一些空间，因为变量数量很多。诊断统计显示，鉴于Jarque—Bera统计量的高p值，不能拒绝残差服从正态分布的假设。
- en: However, the Durbin—Watson statistic is low at 1.5 so we can reject the null
    hypothesis of no autocorrelation comfortably at the 5% level. Hence, the standard
    errors are likely positively correlated. If our goal were to understand which
    factors are significantly associated with forward returns, we would need to rerun
    the regression using robust standard errors (a parameter in `statsmodels .fit()`
    method), or use a different method altogether such as a panel model that allows
    for more complex error covariance.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，杜宾-沃森统计量为1.5，因此我们可以在5%的水平上舒适地拒绝无自相关的零假设。因此，标准误差可能呈正相关。如果我们的目标是了解哪些因素与前向收益显著相关，我们需要使用稳健标准误差重新运行回归（在`statsmodels
    .fit()`方法中的一个参数），或者完全使用不同的方法，如允许更复杂误差协方差的面板模型。
- en: Linear OLS regression using sklearn
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn进行线性OLS回归
- en: Since sklearn is tailored towards prediction, we will evaluate the linear regression
    model based on its predictive performance using cross-validation.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 由于sklearn专门用于预测，我们将根据其预测性能使用交叉验证评估线性回归模型。
- en: Custom time series cross-validation
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义时间序列交叉验证
- en: Our data consists of grouped time series data that requires a custom cross-validation
    function to provide the train and test indices that ensure that the test data
    immediately follows the training data for each equity and we do not inadvertently
    create a look-ahead bias or leakage.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据包括分组的时间序列数据，需要一个自定义的交叉验证函数来提供训练和测试索引，以确保测试数据立即跟随每个股票的训练数据，我们不会无意中产生前瞻性偏差或泄漏。
- en: 'We can achieve this using the following function that returns a `generator` yielding
    pairs of train and test dates. The set of train dates that ensure a minimum length
    of the training periods. The number of pairs depends on the parameter `nfolds`. The
    distinct test periods do not overlap and are located at the end of the period
    available in the data. After a test period is used, it becomes part of the training
    data that grow in size accordingly:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下函数实现这一点，该函数返回一个`generator`，产生训练和测试日期的对。确保训练期的最小长度的训练日期集。对数`nfolds`取决于参数。不同的测试期不重叠，位于数据中可用的周期末。在使用测试期后，它将成为相应增长长度的训练数据的一部分：
- en: '[PRE21]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Select features and target
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择特征和目标
- en: 'We need to select the appropriate return series (we will again use a 10-day
    holding period) and remove outliers. We will also convert returns to log returns
    as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择适当的回报系列（我们将再次使用10天的持有期），并去除异常值。我们还将将回报转换为对数回报，如下所示：
- en: '[PRE22]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Cross-validating the model
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对模型进行交叉验证
- en: 'We will use 250 folds to generally predict about 2 days of forward returns
    following the historical training data that will gradually increase in length.
    Each iteration obtains the appropriate training and test dates from our custom
    cross-validation function, selects the corresponding features and targets, and
    then trains and predicts accordingly. We capture the root mean squared error as
    well as the Spearman rank correlation between actual and predicted values:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用250个折叠来通常预测历史训练数据后大约2天的前向收益。每次迭代从我们的自定义交叉验证函数中获得适当的训练和测试日期，选择相应的特征和目标，然后进行训练和预测。我们捕获根均方误差以及实际值和预测值之间的Spearman等级相关性：
- en: '[PRE23]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Test results – information coefficient and RMSE
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试结果-信息系数和RMSE
- en: 'We have captured the test predictions from the 250 folds and can compute both
    the overall and a 21-day rolling average:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从250个折叠中捕获了测试预测，并可以计算整体和21天滚动平均值：
- en: '[PRE24]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We obtain the following chart that highlights the negative correlation of IC
    and RMSE and their respective values:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下图表，突显了IC和RMSE的负相关及其各自的值：
- en: '![](img/f2f699e8-ecac-49db-b305-7af3946654b3.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2f699e8-ecac-49db-b305-7af3946654b3.png)'
- en: Chart highlighting the negative correlation of IC and RMSE
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 突显IC和RMSE的负相关的图表
- en: 'For the entire period, we see that the Information Coefficient measured by
    the rank correlation of actual and predicted returns is weakly positive and statistically
    significant:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 对于整个时期，我们看到信息系数通过实际值和预测值的等级相关性来测量，呈弱正相关且具有统计学显著性：
- en: '![](img/33da13e6-51b6-4893-a3da-9a25c2f4dee5.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33da13e6-51b6-4893-a3da-9a25c2f4dee5.png)'
- en: Ridge regression using sklearn
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn进行岭回归
- en: For the ridge regression, we need to tune the regularization parameter with
    the keyword `alpha` that corresponds to the λ we used previously. We will try
    21 values from 10^(-5) to 10⁵ in logarithmic steps.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于岭回归，我们需要使用关键字`alpha`来调整正则化参数，该参数对应于我们之前使用的λ。 我们将尝试从10^(-5)到10⁵的21个值以对数步长进行尝试。
- en: The scale sensitivity of the ridge penalty requires us to standardize the inputs
    using the `StandardScaler`. Note that we always learn the mean and the standard
    deviation from the training set using the `.fit_transform()` method and then apply
    these learned parameters to the test set using the `.transform()` method.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚的尺度敏感性要求我们使用`StandardScaler`对输入进行标准化。 请注意，我们始终从训练集中学习均值和标准差，然后使用`.fit_transform()`方法将这些学习参数应用于测试集，然后使用`.transform()`方法。
- en: Tuning the regularization parameters using cross-validation
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用交叉验证调整正则化参数
- en: 'We then proceed to cross-validate the hyperparameter values again using `250`
    folds as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们继续使用`250`个折叠交叉验证超参数值：
- en: '[PRE25]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Cross-validation results and ridge coefficient paths
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证结果和岭回归系数路径
- en: 'We can now plot the information coefficient obtained for each hyperparameter
    value and also visualize how the coefficient values evolve as the regularization
    increases. The results show that we get the highest IC value for a value of λ=10\.
    For this level of regularization, the right-hand panel reveals that the coefficients
    have been already significantly shrunk compared to the (almost) unconstrained
    model with *λ=10^(-5)*:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以绘制每个超参数值获得的信息系数，并可视化随着正则化增加而系数值如何变化。 结果显示，我们在λ=10\时获得了最高的IC值。 对于这个正则化水平，右侧面板显示，与（几乎）不受约束的模型相比，系数已经显着收缩，λ=10^(-5)：
- en: '![](img/83c16cfe-0936-4705-a073-fa1849cd7d82.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83c16cfe-0936-4705-a073-fa1849cd7d82.png)'
- en: Cross-validation results and ridge coefficient paths
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证结果和岭回归系数路径
- en: Top 10 coefficients
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前10个系数
- en: 'The standardization of the coefficients allows us to draw conclusions about
    their relative importance by comparing their absolute magnitude. The 10 most relevant
    coefficients are:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的标准化允许我们通过比较它们的绝对值来得出关于它们相对重要性的结论。 最相关的10个系数是：
- en: '![](img/36b556ea-a0b2-46e1-b01a-ac2185ac20df.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36b556ea-a0b2-46e1-b01a-ac2185ac20df.png)'
- en: Top 10 coefficients
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 前10个系数
- en: Lasso regression using sklearn
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn的套索回归
- en: 'The lasso implementation looks very similar to the ridge model we just ran.
    The main difference is that lasso needs to arrive at a solution using iterative
    coordinate descent whereas ridge can rely on a closed-form solution:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 套索实现看起来与我们刚刚运行的岭回归模型非常相似。 主要区别在于，套索需要使用迭代坐标下降来找到解决方案，而岭回归可以依赖于闭合形式的解决方案：
- en: '[PRE26]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Cross-validated information coefficient and Lasso Path
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证信息系数和套索路径
- en: 'As before, we can plot the average information coefficient for all test sets
    used during cross-validation. We see again that regularization improves the IC
    over the unconstrained model, delivering the best out-of-sample result at a level
    of *λ=10^(-5)*. The optimal regularization value is quite different from ridge
    regression because the penalty consists of the sum of the absolute, not the squared
    values of the relatively small coefficient values. We can also see that for this
    regularization level, the coefficients have been similarly shrunk, as in the ridge
    regression case:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前一样，我们可以绘制在交叉验证期间使用的所有测试集的平均信息系数。 我们再次看到，正则化可以提高IC超出不受约束模型，以λ=10^(-5)为水平获得最佳的样本外结果。
    最优的正则化值与岭回归不同，因为惩罚是相对较小的系数值的绝对值之和，而不是平方值。 我们还可以看到，对于这个正则化水平，系数已经类似地收缩，就像岭回归案例中一样：
- en: '![](img/013530cc-20f7-463a-ac1d-354825bd10e3.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/013530cc-20f7-463a-ac1d-354825bd10e3.png)'
- en: Cross-validated information coefficient and Lasso Path
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证信息系数和套索路径
- en: In sum, ridge and lasso will produce similar results. Ridge often computes faster,
    but lasso also yields continuous features subset selection by gradually reducing
    coefficients to zero, hence eliminating features.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，岭回归和套索将产生类似的结果。 岭回归通常计算速度更快，但套索也通过逐渐将系数减小到零来产生连续的特征子集选择，从而消除了特征。
- en: Linear classification
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性分类
- en: The linear regression model discussed so far assumes a quantitative response
    variable. In this section, we will focus on approaches to modeling qualitative
    output variables for inference and prediction, a process that is known as **classification**
    and that occurs even more frequently than regression in practice.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的线性回归模型假设定量响应变量。 在本节中，我们将重点讨论对推断和预测建模定性输出变量的方法，这个过程被称为**分类**，在实践中甚至比回归更频繁地发生。
- en: Predicting a qualitative response for a data point is called **classifying**
    that observation because it involves assigning the observation to a category,
    or class. In practice, classification methods often predict probabilities for
    each of the categories of a qualitative variable and then use this probability
    to decide on the proper classification.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 针对数据点预测定性响应被称为**分类**该观察，因为它涉及将观察分配到一个类别或类别。 在实践中，分类方法通常为定性变量的每个类别预测概率，然后使用此概率来决定适当的分类。
- en: We could approach the classification problem ignoring the fact that the output
    variable assumes discrete values, and apply the linear regression model to try
    to predict a categorical output using multiple input variables. However, it is
    easy to construct examples where this method performs very poorly. Furthermore,
    it doesn't make intuitive sense for the model to produce values larger than 1
    or smaller than 0 when we know that *y ∈ [0, 1]*.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以忽略输出变量取离散值的事实，并应用线性回归模型尝试使用多个输入变量来预测分类输出。然而，很容易构造出这种方法表现非常糟糕的例子。 此外，当我们知道*y
    ∈ [0, 1]*时，模型产生大于1或小于0的值并不直观。
- en: There are many different classification techniques, or classifiers, that are
    available to predict a qualitative response. In this section, we will introduce
    the widely used logistic regression which is closely related to linear regression. We
    will address more complex methods in the following chapters, on generalized additive
    models that include decision trees and random forests, as well as gradient boosting
    machines and neural networks.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的分类技术或分类器可用于预测定性响应。 在本节中，我们将介绍广泛使用的逻辑回归，它与线性回归密切相关。 在接下来的章节中，我们将介绍更复杂的方法，包括决策树和随机森林的广义可加模型，以及梯度提升机和神经网络。
- en: The logistic regression model
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归模型
- en: The logistic regression model arises from the desire to model the probabilities
    of the output classes given a function that is linear in *x*, just like the linear
    regression model, while at the same time ensuring that they sum to one and remain
    in the [0, 1] as we would expect from probabilities.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型源于希望对输出类别的概率建模，给定一个在*x*中线性的函数，就像线性回归模型一样，同时确保它们总和为一，并保持在[0, 1]，正如我们从概率期望的那样。
- en: In this section, we introduce the objective and functional form of the logistic
    regression model and describe the training method. We then illustrate how to use
    logistic regression for statistical inference with macro data using statsmodels,
    and how to predict price movements using the regularized logistic regression implemented
    by sklearn.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍逻辑回归模型的目标和函数形式，并描述培训方法。 然后，我们说明如何使用statsmodels对宏观数据进行统计推断，并使用sklearn实现的正则化逻辑回归来预测价格走势。
- en: Objective function
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标函数
- en: 'For illustration, we''ll use the output variable y that takes on the value
    1 if a stock return is positive over a given time horizon d, and 0 otherwise:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将使用输出变量y，如果在给定时间跨度d内股票收益为正，则取值为1，否则为0：
- en: '![](img/959b63ca-ea20-4c97-bc7c-154d2341e74a.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](img/959b63ca-ea20-4c97-bc7c-154d2341e74a.png)'
- en: 'We could easily extend y to three categories, where 0 and 2 reflect negative
    and positive price moves beyond a certain threshold, and 1 otherwise. Rather than
    modeling the output variable *y*, however, logistic regression models the probability
    that y belongs to either of the categories given a vector of alpha factors or
    features ![](img/90185215-12e0-4ea9-9ab1-2b277832e26c.png). In other words, the logistic
    regression models the probability that the stock price goes up, conditional on
    the values of the variables included in the model:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地将y扩展到三个类别，其中0和2反映超过某个阈值的负面和正面价格变动，否则为1。 然而，与其对*y*建模，逻辑回归模型对*y*属于给定一向量α因子或特征![](img/90185215-12e0-4ea9-9ab1-2b277832e26c.png)的类别的概率进行建模。
    换句话说，逻辑回归模型了解包含在模型中的变量值时，股票价格上涨的概率：
- en: '![](img/767f64a0-9327-4123-8a14-68b4aa0fab23.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/767f64a0-9327-4123-8a14-68b4aa0fab23.png)'
- en: The logistic function
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: 'To prevent the model from producing values outside the [0, 1] interval, we
    must model *p(x)* using a function that only gives outputs between 0 and 1 over
    the entire domain of *x*. The logistic function meets this requirement and always
    produces an S-shaped curve (see notebook examples), and so, regardless of the
    value of X, we will obtain a sensible prediction:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止模型生成超出 [0, 1] 区间的值，我们必须使用一个只在整个 *x* 的定义域上产生 0 和 1 之间输出的函数来对 *p(x)* 建模。逻辑函数满足这一要求，并且始终产生一个
    S 形曲线（见笔记本示例），因此，无论 X 的值如何，我们都将得到一个合理的预测：
- en: '![](img/5ca89660-1107-4c0a-a57d-adae0541bcee.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ca89660-1107-4c0a-a57d-adae0541bcee.png)'
- en: 'Here, the vector *x* includes a 1 for the intercept captured by the first component
    of ![](img/5218aa4d-ecfa-4abb-970a-67b11c0c557a.png), ![](img/565b1832-0731-474d-8eb8-9ad248442204.png).
    We can transform this expression to isolate the part that looks like a linear
    regression to arrive at:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，向量 *x* 包括一个由 ![](img/5218aa4d-ecfa-4abb-970a-67b11c0c557a.png) 第一个分量捕获的截距，![](img/565b1832-0731-474d-8eb8-9ad248442204.png)。我们可以转换此表达式以隔离类似线性回归的部分，得到：
- en: '![](img/30e97c9b-97c4-44a5-a528-d1e54384d4bc.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![](img/30e97c9b-97c4-44a5-a528-d1e54384d4bc.png)'
- en: The quantity *p(x)/[1−p(x)]* is called the **odds**, an alternative way to express
    probabilities that may be familiar from gambling, and can take on any value odds
    between 0 and ∞, where low values also imply low probabilities and high values
    imply high probabilities.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 量 *p(x)/[1−p(x)]* 称为 **几率**，是表达概率的另一种方式，可能与赌博中熟悉的方式相似，可以取 0 到 ∞ 之间的任意值，其中较低的值也意味着较低的概率，而较高的值意味着较高的概率。
- en: The logit is also called log-odds (since it is the logarithm of the odds). Hence,
    the logistic regression represents a logit that is linear in *x* and looks a lot
    like the preceding linear regression.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 对数几率也称为对数几率（因为它是几率的对数）。因此，逻辑回归表示的对数线性回归 *x* 看起来与前述的线性回归非常相似。
- en: Maximum likelihood estimation
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: 'The coefficient vector ![](img/67a36c05-1101-4552-92e7-a069bab53116.png) must
    be estimated using the available training data. Although we could use (non-linear)
    least squares to fit the logistic regression model, the more general method of
    maximum likelihood is preferred, since it has better statistical properties. As
    we have just discussed, the basic intuition behind using maximum likelihood to
    fit a logistic regression model is to seek estimates for ![](img/67a36c05-1101-4552-92e7-a069bab53116.png)
    such that the predicted probability ![](img/86fcfb37-c25d-4cbd-b39d-a72674162df0.png)
    corresponds as closely as possible to the actual outcome. In other words, we try
    to find ![](img/6754827d-5689-4136-b222-c162c910b0c7.png) such that these estimates
    yield a number close to 1 for all cases where the stock price went up, and a number
    close to 0 otherwise. More formally, we are seeking to maximize the likelihood
    function:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 系数向量 ![](img/67a36c05-1101-4552-92e7-a069bab53116.png) 必须使用可用的训练数据进行估计。虽然我们可以使用（非线性）最小二乘法来拟合
    logistic 回归模型，但更一般的最大似然方法更受欢迎，因为它具有更好的统计特性。正如我们刚刚讨论的，使用最大似然拟合 logistic 回归模型的基本直觉是寻找估计值
    ![](img/67a36c05-1101-4552-92e7-a069bab53116.png)，使得预测的概率 ![](img/86fcfb37-c25d-4cbd-b39d-a72674162df0.png)
    尽可能接近实际结果。换句话说，我们试图找到 ![](img/6754827d-5689-4136-b222-c162c910b0c7.png) 这样这些估计值在股价上涨的所有情况下都接近
    1，否则接近 0 的情况。更正式地说，我们正在寻求最大化似然函数：
- en: '![](img/9ee6262d-4015-4968-a752-11c1a87ef6ba.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ee6262d-4015-4968-a752-11c1a87ef6ba.png)'
- en: 'It is easier to work with sums than with products, so let''s take logs on both
    sides to get the log-likelihood function and the corresponding definition of the
    logistic regression coefficients:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 使用总和比乘积更容易，因此让我们两边都取对数，得到对数似然函数和 logistic 回归系数的相应定义：
- en: '![](img/598f2e46-7876-403f-a502-2f045e6161e1.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![](img/598f2e46-7876-403f-a502-2f045e6161e1.png)'
- en: Maximizing this equation by setting the derivatives of ![](img/a4a91a01-a2c2-47a4-8ed3-a2ba2408d686.png) with
    respect to ![](img/67a36c05-1101-4552-92e7-a069bab53116.png) to zero yields p+1
    so-called score equations that are nonlinear in the parameters that can be solved
    using iterative numerical methods for the concave log-likelihood function.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将 ![](img/a4a91a01-a2c2-47a4-8ed3-a2ba2408d686.png) 对 ![](img/67a36c05-1101-4552-92e7-a069bab53116.png) 的导数设为零来通过最大化此方程获得
    p+1 个所谓的得分方程，在参数中是非线性的，可以使用迭代数值方法来解决凹的对数似然函数。
- en: How to conduct inference with statsmodels
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用 statsmodels 进行推理
- en: We will illustrate how to use logistic regression with `statsmodels` based on
    a simple built-in dataset containing quarterly US macro data from 1959 – 2009
    (see the notebook `logistic_regression_macro_data.ipynb` for detail).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何使用 `statsmodels` 进行逻辑回归，基于一个包含从 1959 年至 2009 年的季度美国宏观数据的简单内置数据集（详见笔记本
    `logistic_regression_macro_data.ipynb`）。
- en: 'The variables and their transformations are listed in the following table:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 变量及其转换列于以下表格中：
- en: '| **Variable** | **Description** | **Transformation** |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| **变量** | **描述** | **转换** |'
- en: '| `realgdp` | Real gross domestic product | Annual Growth Rate |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| `realgdp` | 实际国内生产总值 | 年增长率 |'
- en: '| `realcons` | Real personal consumption expenditures | Annual Growth Rate
    |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| `realcons` | 实际个人消费支出 | 年增长率 |'
- en: '| `realinv` | Real gross private domestic investment | Annual Growth Rate |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| `realinv` | 实际私人国内投资总额 | 年增长率 |'
- en: '| `realgovt` | Real federal expenditures and gross investment | Annual Growth
    Rate |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| `realgovt` | 实际联邦支出和总投资 | 年增长率 |'
- en: '| `realdpi` | Real private disposable income | Annual Growth Rate |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| `realdpi` | 实际私人可支配收入 | 年增长率 |'
- en: '| `m1` | M1 nominal money stock | Annual Growth Rate |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| `m1` | M1 名义货币存量 | 年增长率 |'
- en: '| `tbilrate` | Monthly 3 treasury bill rate | Level |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| `tbilrate` | 月度 3 个国库券利率 | 水平 |'
- en: '| `unemp` | Seasonally adjusted unemployment rate (%) | Level |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| `unemp` | 季节性调整后的失业率（%） | 水平 |'
- en: '| `infl` | Inflation rate | Level |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| `infl` | 通货膨胀率 | 水平 |'
- en: '| `realint` | Real interest rate | Level |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| `realint` | 实际利率 | 水平 |'
- en: To obtain a binary target variable, we compute the 20-quarter rolling average
    of the annual growth rate of quarterly real GDP. We then assign 1 if current growth
    exceeds the moving average and 0 otherwise. Finally, we shift the indicator variables
    to align next quarter's outcome with the current quarter.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到一个二元目标变量，我们计算季度实际 GDP 年增长率的 20 季度滚动平均值。然后，如果当前增长超过移动平均值，则分配 1，否则分配 0。最后，我们将指标变量移位，以使下一季度的结果与当前季度对齐。
- en: 'We use an intercept and convert the quarter values to dummy variables and train
    the logistic regression model as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个截距，并将季度值转换为虚拟变量，并按以下方式训练逻辑回归模型：
- en: '[PRE27]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This produces the following summary for our model with 198 observations and
    13 variables, including intercept:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了我们的模型摘要，其中包含截距的 198 个观测值和 13 个变量：
- en: '![](img/d8e2376b-b48e-4f53-8694-0f337f29b986.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8e2376b-b48e-4f53-8694-0f337f29b986.png)'
- en: Logit Regression results
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归结果
- en: The summary indicates that the model has been trained using maximum likelihood
    and provides the maximized value of the log-likelihood function at -67.9.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要显示，该模型已使用最大似然进行训练，并在 -67.9 处提供了对数似然函数的最大化值。
- en: The LL-Null value of -136.42 is the result of the maximized log-likelihood function
    when only an intercept is included. It forms the basis for the pseudo-R² statisticand
    the Log-**Likelihood Ratio** (**LLR**) test.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: LL-Null 值为 -136.42 是只包括截距时对数似然函数的最大化结果。它形成了伪 R² 统计量和 Log-**似然比**（**LLR**）测试的基础。
- en: 'The pseudo-R^(2 )statistic is a substitute for the familiar R² available under
    least squares. It is computed based on the ratio of the maximized log-likelihood
    function for the null model m[0] and the full model m[1] as follows:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 伪 R^(2 ) 统计量是最小二乘法下可用的熟悉 R² 的替代品。它是基于空模型 m[0] 和完整模型 m[1] 的最大化对数似然函数的比率计算的，如下所示：
- en: '![](img/58c66c64-3260-4ce4-83a2-6ed4ec540c23.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58c66c64-3260-4ce4-83a2-6ed4ec540c23.png)'
- en: The values vary from 0 (when the model does not improve the likelihood) to 1
    where the model fits perfectly and the log-likelihood is maximized at 0\. Consequently,
    higher values indicate a better fit.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 值从 0 变化（当模型不改善似然时）到 1（模型完美拟合时）且对数似然在 0 处最大化。因此，较高的值表明拟合效果更好。
- en: 'The LLR test generally compares a more restricted model and is computed as:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: LLR 测试通常比较一个更受限制的模型，并计算如下：
- en: '![](img/0849e323-b0ee-4890-9cdd-9d93940804de.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0849e323-b0ee-4890-9cdd-9d93940804de.png)'
- en: The null hypothesis is that the restricted model performs better but the low
    p-value suggests that we can reject this hypothesis and prefer the full model
    over the null model. This is similar to the F-test for linear regression (where
    we can also use the LLR test when we estimate the model using MLE).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 原假设是受限制模型的性能更好，但低的 p 值表明我们可以拒绝这一假设，并更喜欢完整模型而不是空模型。这类似于线性回归的 F 检验（当我们使用 MLE 估计模型时，也可以使用
    LLR 测试）。
- en: 'The z-statistic plays the same role as the t-statistic in the linear regression
    output and is equally computed as the ratio of the coefficient estimate and its
    standard error. The p-values also indicate the probability of observing the test
    statistic assuming the null hypothesis *H[0] : β = 0* that the population coefficient
    is zero. We can reject this hypothesis for the `intercept`, `realcons`, `realinv`,
    `realgovt`, `realdpi`, and `unemp`.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: Z统计量在线性回归输出中起着与t统计量相同的作用，并且与系数估计和其标准误差的比率一样计算。p值还指示了在假设 H[0]：β = 0（总体系数为零）的情况下观察到测试统计量的概率。我们可以拒绝这个假设，对于`截距`、`realcons`、`realinv`、`realgovt`、`realdpi`和`unemp`。
- en: How to use logistic regression for prediction
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用逻辑回归进行预测
- en: The lasso L[1] penalty and the ridge L[2] penalty can both be used with logistic
    regression. They have the same shrinkage effect as we have just discussed, and
    the lasso can again be used for variable selection with any linear regression
    model.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 套索 L[1] 惩罚和岭 L[2] 惩罚都可以与逻辑回归一起使用。它们具有我们刚刚讨论的相同收缩效应，而套索可以再次用于任何线性回归模型的变量选择。
- en: Just as with linear regression, it is important to standardize the input variables
    as the regularized models are scale sensitive. The regularization hyperparameter
    also requires tuning using cross-validation as in the linear regression case.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归一样，对输入变量进行标准化非常重要，因为正则化模型对比例敏感。正则化超参数还需要使用交叉验证进行调整，就像线性回归的情况一样。
- en: How to predict price movements using sklearn
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用sklearn预测价格变动
- en: 'We continue the price prediction example but now we binarize the outcome variable
    so that it takes on the value 1 whenever the 10-day return is positive and 0 otherwise;
    see the notebook `logistic_regression.ipynb` in the sub directory `stock_price_prediction`:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续价格预测示例，但现在我们将结果变量二值化，以便在 10 天回报为正时取值为 1，否则为 0；请参阅子目录 `stock_price_prediction`
    中的笔记本 `logistic_regression.ipynb`：
- en: '[PRE28]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'With this new categorical outcome variable, we can now train a logistic regression
    using the default L[2] regularization. For logistic regression, the regularization
    is formulated inversely to linear regression: higher values for λ imply less regularization
    and vice versa. We evaluate 11 parameter values using cross validation as follows:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个新的分类结果变量，我们现在可以使用默认的L[2]正则化训练逻辑回归。对于逻辑回归，正则化与线性回归相反：λ的值越高，正则化越少，反之亦然。我们使用交叉验证评估11个参数值如下：
- en: '[PRE29]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We then use the `roc_auc_score` discussed in the previous chapter to compare
    the predictive accuracy across the various regularization parameters:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用前一章讨论的 `roc_auc_score` 来比较各种正则化参数的预测准确度：
- en: '[PRE30]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can again plot the AUC result for the range of hyperparameter values alongside
    the coefficient path that shows the improvements in predictive accuracy as the
    coefficients are a bit shrunk at the optimal regularization value 10²:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次绘制AUC结果，以显示超参数值范围以及系数路径，该路径显示系数在最佳正则化值 10² 处略微收缩时预测精度的提高：
- en: '![](img/e2e88587-b9b2-4e2d-a204-712534c693d7.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2e88587-b9b2-4e2d-a204-712534c693d7.png)'
- en: AUC and Logistic Ridge path
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: AUC和Logistic Ridge路径
- en: Summary
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we introduced the first machine learning models using the important
    baseline case of linear models for regression and classification. We explored
    the formulation of the objective functions for both tasks, learned about various
    training methods, and learned how to use the model for both inference and prediction.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了使用线性模型进行回归和分类的重要基线案例的第一个机器学习模型。我们探讨了两个任务的目标函数的制定，学习了各种训练方法，并学习了如何将模型用于推理和预测。
- en: We applied these new machine learning techniques to estimate linear factor models
    that are very useful to manage risks, assess new alpha factors, and attribute
    performance. We also applied linear regression and classification to accomplish
    the first predictive task of predicting stock returns in absolute and directional
    terms.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些新的机器学习技术应用于估计线性因子模型，这些模型对于管理风险、评估新的阿尔法因子和归因绩效非常有用。我们还应用线性回归和分类来完成第一个预测任务，即在绝对和方向性方面预测股票收益。
- en: In the next chapter, we will look at the important topic of linear time series
    models that are designed to capture serial correlation patterns in the univariate
    and multivariate case. We will also learn about new trading strategies as we explore
    pairs trading based on the concept of cointegration that captures dynamic correlation
    among two stock price series.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论重要的线性时间序列模型主题，这些模型旨在捕捉单变量和多变量情况下的串行相关模式。我们还将学习关于新的交易策略，因为我们将探讨基于协整概念的配对交易，该概念捕捉了两个股价序列之间的动态相关性。
