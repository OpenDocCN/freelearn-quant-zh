- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Credit Risk Analytics
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信用风险分析
- en: Problems such as credit scoring, fraud detection, churn prediction, credit limit
    definition, and financial behavior forecasting (among others) are constant challenges
    for banks and financial institutions, which permanently research for more accurate
    results and ways to decrease business-related risk when providing services. Most
    of these problems can be tackled by using machine learning to classify users who
    are likely to, for example, not pay their bills on time or commit fraud. In this
    chapter, the quantum machine learning side of these scenarios will be explored,
    using a permanent benchmark with classical counterparts for most of the cases.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 信用评分、欺诈检测、客户流失预测、信用额度定义和金融行为预测（等）是银行和金融机构面临的持续挑战，这些机构不断研究如何提供更准确的结果以及降低与业务相关的风险。在提供服务时，大部分这些问题可以通过使用机器学习来解决，例如对可能不会按时支付账单或可能实施欺诈的用户进行分类。在本章中，将探讨这些场景中的量子机器学习方面，针对大多数案例使用与经典算法的恒定基准进行比较。
- en: In the current economic situation, where the stability of the markets is unpredictable
    and the way people work is always changing (thanks to the rise of the “gig economy”),
    it is harder to increase a credit product portfolio and cover a larger number
    of customer cohorts without increasing the risk for businesses. Exploring QML
    and ML methods side by side could leverage the current decision-making architectures
    of different banks, neobanks, fintechs, and other financial institutions that
    consider in their structures the possibility of lending money to companies or
    individuals.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的经济形势下，市场稳定性不可预测，人们的工作方式也在不断变化（得益于“零工经济”的崛起），因此在不增加企业风险的情况下，很难扩大信用产品组合并覆盖更多客户群体。并行探索QML和ML方法可以提升不同银行、新银行、金融科技公司及其他金融机构现有的决策架构，这些机构在结构中考虑了向公司或个人提供贷款的可能性。
- en: As we mentioned previously, the ML alternative is very well suited for cases
    where we have evidence (data) but cannot fully grasp the underlying model or logic
    manually. One of the most well-known machine learning techniques to address these
    kinds of projects relates to supervised learning. Credit scoring systems are a
    common part of decision-making methods that are executed in finance. They use
    boosted decision trees (LGBM and XGBoost), random forests, support vector machines,
    clustering methods, and some regression models to get results that can be used
    to make decisions and automate scoring procedures. Similarly, QML algorithms can
    be tested and compared under the same scenario and eventually provide a business
    advantage. Typical classification algorithms in the quantum spectrum are **Quantum
    Neural Networks** (**QNNs**), **Quantum Support Vector Classifiers** (**QSVCs**),
    and **Variational Quantum Classifiers** (**VQCs**). The code and rationale expressed
    in this chapter can help data science departments or any machine learning-related
    professionals in the finance sector who are usually trying to improve their models,
    finding ways to determine the right approach to extract more benefit from the
    available computational power.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，机器学习作为一种替代方案非常适用于我们拥有证据（数据）但无法手动完全掌握潜在模型或逻辑的情况。解决这类项目的最著名机器学习技术之一与监督学习相关。信用评分系统是金融决策方法中常见的一部分。它们使用提升决策树（LGBM和XGBoost）、随机森林、支持向量机、聚类方法和一些回归模型来得出可用于做出决策和自动评分的结果。同样，QML算法也可以在相同的场景下进行测试和比较，最终提供业务优势。量子领域中的典型分类算法包括**量子神经网络**（**QNNs**）、**量子支持向量分类器**（**QSVCs**）和**变分量子分类器**（**VQCs**）。本章中表达的代码和理论可以帮助数据科学部门或金融领域的机器学习相关专业人员，帮助他们通常试图改进模型，寻找确定正确方法以从现有计算能力中提取更多利益的途径。
- en: In this chapter, we will compare machine learning and quantum machine learning
    algorithms using classical data represented in synthetic datasets, which are statistical
    replicas of real companies or data points. The aim is to assess their credit scores
    based on financial behavior. Additionally, we will analyze the characteristics
    of the dataset and examine the implications of using synthetic data. Finally,
    we will delve into model evaluation techniques.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用合成数据集（这些数据集是实际公司或数据点的统计复制品）表示的经典数据，比较机器学习和量子机器学习算法。目标是根据金融行为评估其信用评分。此外，我们还将分析数据集的特征，并探讨使用合成数据的影响。最后，我们将深入探讨模型评估技术。
- en: 'This chapter has the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要内容包括以下几个主题：
- en: The relevance of credit risk analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用风险分析的相关性
- en: Data exploration and preparation to execute both ML and QML models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行机器学习和量子机器学习模型的数据探索和准备
- en: The implementation of classical and quantum machine learning algorithms
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典与量子机器学习算法的实现
- en: Quantum Support Vector Machines
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量子支持向量机
- en: The relevance of credit risk analysis
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信用风险分析的相关性
- en: With the objective of providing a broader context and understanding of the relevance
    of addressing classification problems in the finance sector, for this part of
    the book, it is important to define some core concepts, even from a high-level
    perspective. The term “credit risk” in the context of this chapter is the chance
    that a lender will lose money if a borrower doesn’t pay back a loan by a certain
    date. As the credit card business has grown quickly, as illustrated in *Figure
    6**.1*, and the financial players have grown over the years, the challenge of
    expanding the scope of targeted people requires more sophisticated underwriting
    systems. This puts a big portion of financial institutions at risk if the means
    to assess this risk are not accurate enough.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供更广泛的背景并理解解决金融领域分类问题的相关性，本书的这一部分需要定义一些核心概念，尽管从高层次的角度来看也很重要。在本章的背景下，“信用风险”一词是指如果借款人在某个日期之前未能偿还贷款，贷方可能会损失资金的风险。随着信用卡业务的迅速增长，如*图
    6**.1*所示，以及金融参与者多年来的扩展，扩大目标人群的范围的挑战需要更为复杂的承销系统。如果评估这些风险的手段不够准确，那么这将使大量金融机构面临风险。
- en: Given the situation previously described, it is often necessary to look at the
    credit risk of customers who have little or no credit history to expand the current
    client segments and find profitability in unexplored markets. Another challenge
    for credit decisioning systems is that most historical datasets related to credit
    card or loan clients are imbalanced because, usually, the portion of customers
    that do not pay on time is small compared with the whole sample. However, this
    could change, depending on the country and the way the target’s social and economic
    structure is set up by the financial institution. Therefore, doing a sensible
    data analysis before starting any project of predictive nature will become critical,
    as it will have a direct impact on the business revenue. Identifying unbalanced,
    biased, or incomplete information is a fundamental part of any data-driven project
    that you might endeavor (no matter whether it’s classical or quantum related).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于前述情况，通常需要关注那些信用历史较少或没有信用记录的客户的信用风险，以扩大现有的客户群体并在尚未开发的市场中找到盈利机会。信用决策系统的另一个挑战是，大多数与信用卡或贷款客户相关的历史数据集存在不平衡问题，因为通常情况下，按时未付款的客户比例相较于整体样本来说较小。然而，这一情况可能会发生变化，取决于所在国家及金融机构如何设置目标社会和经济结构。因此，在开始任何预测性质的项目之前进行合理的数据分析至关重要，因为这将直接影响到业务收入。识别不平衡、偏差或不完整的信息是任何数据驱动项目中的基础部分，无论它是经典的还是与量子相关的。
- en: Most of the machine learning systems on the market have been tested widely,
    and it is well known that, in some cases, they can accurately estimate the number
    of people who could default on their loans or credit card payments. Since the
    early 2000s, the field of machine learning has undergone tremendous growth, and
    the models for credit scoring strategies are now in a better position to help
    large and small banks by doing in-depth credit checks on their customers and prospects,
    mainly using technology to improve their decisioning structures so that assumed
    risk is within the acceptable limits, which may differ depending on the type of
    institution you belong to (see *Figure 6**.1* and [https://wolfstreet.com/2019/05/22/subprime-profit-machine-hiccups-credit-card-charge-offs-rise-in-the-banking-system/](https://wolfstreet.com/2019/05/22/subprime-profit-machine-hiccups-credit-card-charge-offs-rise-in-the-banking-system/)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 市面上大多数机器学习系统都经过了广泛的测试，并且众所周知，在某些情况下，它们可以准确估算可能违约的借款人或信用卡支付者的数量。自2000年代初以来，机器学习领域经历了巨大的发展，现在用于信用评分策略的模型能够更好地帮助大中型银行，通过深入的客户和潜在客户信用检查，主要是利用技术来优化决策结构，从而确保假设的风险在可接受的范围内，这个范围可能会根据所属机构的类型而有所不同（见*图
    6**.1*和[https://wolfstreet.com/2019/05/22/subprime-profit-machine-hiccups-credit-card-charge-offs-rise-in-the-banking-system/](https://wolfstreet.com/2019/05/22/subprime-profit-machine-hiccups-credit-card-charge-offs-rise-in-the-banking-system/)）。
- en: '![Figure 6.1 – The yearly risk of new players trying to expand their portfolio](img/B19146_06_001.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.1 – 新玩家尝试扩大其投资组合的年度风险](img/B19146_06_001.jpg)'
- en: Figure 6.1 – The yearly risk of new players trying to expand their portfolio
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – 新玩家尝试扩大其投资组合的年度风险
- en: Data science and analytics departments in private corporations try to find more
    accurate and efficient ways to measure credit risk (Crouhy, et al., 2000; Crook,
    et al., 2007). Currently, a significant number of financial institutions are investigating
    quantum machine learning methods that can help them make better decisions and
    customize products for a large number of people. Banks such as CaixaBank (Spain),
    Itaú Unibanco (Brazil), alt.bank (Brazil), and Rauva (Portugal) specifically look
    for the benefit of **QML** methods for classification challenges related to risk
    or customer retention (also called *customer churn* in the industry literature)
    using hybrid quantum-classical algorithms. Also, banks such as BBVA (Spain), Crédit
    Agricole (France), Citi (United States), Barclays (United Kingdom), JP Morgan
    (United States), Royal Bank of Canada (Canada), Wells Fargo (United States), and
    HSBC (United Kingdom) look into and use different strategies for this new technology.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 私营企业中的数据科学与分析部门正在寻找更准确、高效的方式来衡量信用风险（Crouhy 等，2000；Crook 等，2007）。目前，许多金融机构正在研究量子机器学习方法，帮助它们做出更好的决策并为大量客户定制产品。像西班牙的
    CaixaBank、巴西的 Itaú Unibanco、巴西的 alt.bank 和葡萄牙的 Rauva 等银行，专门寻找 **QML** 方法在风险或客户保持（行业文献中也称为
    *客户流失*）相关的分类挑战中的优势，使用混合量子经典算法。此外，西班牙的 BBVA、法国的 Crédit Agricole、美国的 Citi、英国的 Barclays、美国的
    JP Morgan、加拿大的 Royal Bank of Canada、美国的 Wells Fargo 和英国的 HSBC 等银行，也在研究并使用这项新技术的不同策略。
- en: Data exploration and preparation to execute both ML and QML models
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行机器学习（ML）和量子机器学习（QML）模型的数据探索与准备
- en: As mentioned before, in this chapter, we will walk you through the implementation
    of hybrid quantum-classical algorithms and how they behave in a real-world scenario
    in finance, but before you start playing with them in a professional setup, you
    should think – or at least review – some the following concepts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在本章中，我们将引导您实现混合量子经典算法，并展示它们在金融实际场景中的表现，但在您开始在专业环境中使用它们之前，您应该思考——或者至少回顾——以下一些概念。
- en: '**Data enrichment** refers to the process of enriching or supplementing an
    existing dataset with extra information. Data enrichment in the context of credit
    scoring systems is the use of additional data sources to supplement extra variables
    and features that could come from a credit bureau or a non-traditional source
    (e.g., mobile data mining) in order to increase the accuracy of credit risk assessments.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据丰富化**是指通过额外的信息来充实或补充现有的数据集。在信用评分系统的背景下，数据丰富化是利用额外的数据源来补充可能来自信用机构或非传统来源（例如，移动数据挖掘）的附加变量和特征，以提高信用风险评估的准确性。'
- en: By incorporating additional data sources like public records (digital footprints),
    social media behavior, financial history, open finance, and other alternative
    data sources, data enrichment can help bridge the gaps in information for a thorough
    analysis of customers. For instance, a lender might utilize a third-party service
    to verify a borrower’s job, income, and assets by obtaining data from financial
    institutions, tax authorities, and credit card institutions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入如公共记录（数字足迹）、社交媒体行为、财务历史、开放金融及其他替代数据源，数据丰富化可以帮助弥合信息空白，从而对客户进行全面分析。例如，贷款机构可能会利用第三方服务，通过获取金融机构、税务机关和信用卡机构的数据来验证借款人的工作、收入和资产。
- en: Creditors can make more informed choices regarding creditworthiness and lower
    the risk of default or delinquency by incorporating new data from credit bureau
    reports. Moreover, data enrichment may assist lenders in identifying new client
    categories and creating more customized solutions based on borrower profiles.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过引入来自信用报告机构的新数据，债权人可以在评估信用worthiness时做出更加明智的选择，从而降低违约或拖欠的风险。此外，数据丰富化可以帮助贷款机构识别新的客户类别，并根据借款人资料定制更个性化的解决方案。
- en: 'To summarize, the typical data sources of a credit scoring system can be aggregated
    into three main groups:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，信用评分系统的典型数据源可以归纳为三大类：
- en: '**Internal data**: Most financial institutions will provide credit to current
    customers that use checking or current accounts. Analyzing this behavior should
    be the base for any further decision.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部数据**：大多数金融机构会向当前使用支票账户或活期账户的客户提供信用。分析这种行为应作为进一步决策的基础。'
- en: '**Financial behavior data**: Retrieve all the financial data required to assess
    the financial behavior of an organization or individual, considering their payment
    history, risk scores, current debts, demographics, and current financial products
    in use.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金融行为数据**：获取所有评估组织或个人金融行为所需的财务数据，考虑其支付历史、风险评分、当前债务、人口统计信息以及当前使用的金融产品。'
- en: '**Out-of-the-box data**: This includes data that comes from different sources
    compared with the sources of traditional bureaus (for example, Equifax). It is
    well known that some financial institutions use psychological factors, smartphone
    metadata, and users’ digital footprints to add a significant number of variables
    and features in decisioning models.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开箱即用的数据**：这包括来自不同来源的数据，而不是传统信用局（例如，Equifax）的来源。众所周知，一些金融机构使用心理因素、智能手机元数据和用户的数字足迹，在决策模型中加入大量的变量和特征。'
- en: Features analysis
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征分析
- en: Feature analysis is the process of determining the most influential factors
    or features on the performance of a machine learning model. In the context of
    credit scoring systems, feature analysis is the process of discovering the most
    predictive characteristics that can be utilized to make correct credit decisions
    and discriminate correctly between potential good or bad payers.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 特征分析是确定影响机器学习模型表现的最重要因素或特征的过程。在信用评分系统的背景下，特征分析是发现最具预测性的特征的过程，这些特征可以用来做出正确的信用决策，并正确区分潜在的良好或不良付款人。
- en: Credit scoring models that employ machine learning often incorporate a number
    of characteristics or descriptive variables, including payment history, credit
    usage, credit tenure, and types of credit used. Nevertheless, not all of these
    characteristics may be equally significant in predicting credit risk, and some
    characteristics may have a greater influence than others.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 采用机器学习的信用评分模型通常会融入多种特征或描述性变量，包括支付历史、信用使用、信用年限和使用的信用类型。然而，并非所有这些特征在预测信用风险时的影响力都是相同的，有些特征可能比其他特征具有更大的影响。
- en: Feature analysis aids in identifying the most influential variables that impact
    credit risk and prioritizing them in a model. Several approaches, including correlation
    analysis, decision trees, and gradient boosting algorithms, can be used to determine
    the characteristics that have the highest predictive potential.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 特征分析有助于识别影响信用风险的最重要变量，并在模型中对它们进行优先排序。可以使用多种方法，包括相关性分析、决策树和梯度提升算法，来确定具有最高预测潜力的特征。
- en: By concentrating on the most essential variables, machine learning models for
    credit scoring can increase precision and lower the chance of default or delinquency.
    Feature analysis can also assist lenders in establishing more tailored risk management
    strategies by enhancing their understanding of the determinants of credit risk.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过集中关注最重要的变量，信用评分的机器学习模型可以提高精度，并降低违约或拖欠的风险。特征分析还可以帮助贷方通过增强对信用风险决定因素的理解，制定更量身定制的风险管理策略。
- en: It is essential to remember that feature analysis techniques are an ongoing
    process, and the most relevant factors may change as economic conditions, customer
    behavior, and other variables alter. Thus, machine learning models for credit
    scoring must be continually updated and adjusted to account for the ever-changing
    nature of credit risk.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 需要记住的是，特征分析技术是一个持续的过程，最相关的因素可能会随着经济条件、客户行为和其他变量的变化而变化。因此，信用评分的机器学习模型必须不断更新和调整，以应对信用风险不断变化的本质。
- en: 'The most well-known strategies and methods applied to execute the feature analysis
    are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 执行特征分析时，最著名的策略和方法如下：
- en: '**Feature selection**: This is a non-trivial process that can have a tremendous
    impact on the final results, depending on the case. There is a myth about machine
    learning projects that more data and variables are always good, which is true,
    but not all of the information will be useful for the ML model. In some scenarios,
    it is actually better to reduce those features to allow a better prediction (Ji
    et al.). To execute these processes, there are a few techniques that consider
    the use of genetic algorithms, or simply analyze the importance, correlation,
    and variance of the features to decide which ones add more value to the predictive
    process. Typically, this stage is included in the data science procedure called
    **Exploratory Data Analysis** (**EDA**), which involves the investigation of datasets
    to extract the best data from them as input for subsequent operations.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择**：这是一个非平凡的过程，视具体情况而定，可能对最终结果产生巨大影响。关于机器学习项目有一个误区，即更多的数据和变量总是好的，这固然是对的，但并非所有信息都对机器学习模型有用。在某些情况下，减少特征反而能实现更好的预测（Ji
    等人）。执行这些过程时，有一些技术考虑使用遗传算法，或者简单地分析特征的重要性、相关性和方差，以决定哪些特征对预测过程更有价值。通常，这一阶段包含在数据科学过程中，称为**探索性数据分析**（**EDA**），它涉及调查数据集，从中提取最佳数据作为后续操作的输入。'
- en: '**Feature engineering**: Once the data and the features are available, the
    original variables might not be enough to develop good results under your specific
    target or key demographics. If so, you may be required to build new features that
    can come as a result of a calculation from the original variables (e.g., if we
    have the customer’s transactions, additional features can be generated that consider
    the average value of the transactions and the same with the median, maximum amount,
    and minimum amount). These new columns inn the datasets can have a high impact
    on the machine learning model’s **Key Performance** **Indicators** (**KPIs**)
    later on.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：一旦数据和特征可用，原始变量可能不足以在特定目标或关键人口统计下取得良好的结果。如果是这样，你可能需要构建新的特征，这些特征可以通过对原始变量的计算得到（例如，如果我们有客户的交易数据，可以生成额外的特征，考虑交易的平均值，以及中位数、最大金额和最小金额）。这些新列可能对机器学习模型的**关键绩效指标**（**KPIs**）产生重大影响。'
- en: Data preprocessing
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: The process of modifying and preparing data for use in machine learning models
    is known as data preprocessing. In the context of credit scoring systems, data
    preparation entails cleaning, converting, and preparing credit data so that it
    may be efficiently utilized to train machine learning models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 修改和准备数据以供机器学习模型使用的过程称为数据预处理。在信用评分系统中，数据准备包括清理、转换和准备信用数据，以便可以高效地用于训练机器学习模型。
- en: Credit data can sometimes be incomplete and disorganized, with missing numbers,
    inconsistent formats, and other difficulties that might hinder the effectiveness
    of machine learning models. Techniques for data preparation can assist in addressing
    these challenges and preparing data for modeling.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 信用数据有时可能不完整且杂乱无章，缺失数字、格式不一致以及其他可能阻碍机器学习模型有效性的困难。数据准备技术可以帮助解决这些问题，并为建模做好数据准备。
- en: 'By utilizing data pre-treatment approaches, machine learning models for credit
    scoring can be trained more efficiently and yield more accurate results. Here
    are two of the most relevant approaches:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用数据预处理方法，信用评分的机器学习模型可以更高效地训练，并产生更准确的结果。以下是两种最相关的方法：
- en: '**Oversampling**: It is common that financial datasets are imbalanced with
    regard to the target variable that a model is predicting. Having distributions
    of 95% non-defaulters and 5% defaulters could represent a significant difficulty
    for ML architectures. There are different techniques to mitigate this problem
    that will allow you to increase one of the classes or simply provide more statistical
    copies of your initial dataset. A typical strategy is to use the **Synthetic Minority
    Oversampling Technique** (**SMOTE**) or synthetic oversampling in general, with
    the application of several sub-strategies. By using these kinds of techniques,
    a financial dataset can be balanced to represent an equal portion of good and
    bad payers; therefore, the ML training process can be impacted positively in terms
    of the data points and patterns to be analyzed.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**过采样**：金融数据集通常存在目标变量不平衡的情况，模型预测的目标变量在不同类别间的分布可能严重偏差。例如，95%的非违约者和5%的违约者可能会给机器学习架构带来很大的困难。为了缓解这一问题，有不同的技术可以增加其中一个类别的样本，或是提供更多原始数据集的统计副本。一种典型的策略是使用**合成少数类过采样技术**（**SMOTE**）或一般的合成过采样，并应用若干子策略。通过使用这些技术，可以平衡金融数据集，代表良好和不良支付者的相等比例，因此，机器学习训练过程中的数据点和模式分析将受到积极影响。'
- en: '**Encoding**: Usually, data comes in different forms and data types. To be
    able to process them within an ML or QML algorithm, we need to ensure that all
    features are numerical, and frequently, a portion of the variables are originally
    categorical. To be able to continue the process, there are a few methods to encode
    categorical data as numerical data, such as one-hot encoding, label encoding,
    binary encoding, and feature hashing. Moreover, QML models pose the challenge
    of translating classical data samples into quantum states, which is a whole field
    by itself. We will explore some common embedding and feature maps within the regime
    of the techniques we will explore, but keep in mind that many different techniques
    exist on how encoding can be tackled, from basic feature mapping to **Quantum
    Generative Adversarial Networks** (**qGANs**), such as embeddings, as we saw in
    [*Chapter 4*](B19146_04.xhtml#_idTextAnchor079) with the stock price distribution
    case.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**编码**：通常，数据有不同的形式和数据类型。为了能够在机器学习（ML）或量子机器学习（QML）算法中处理这些数据，我们需要确保所有特征都是数值型的，而其中一部分变量通常是分类变量。为了继续处理，我们有几种方法可以将分类数据编码为数值数据，例如独热编码、标签编码、二进制编码和特征哈希。此外，QML模型面临的挑战是将经典数据样本转化为量子态，这本身就是一个完整的研究领域。在我们即将探索的技术领域中，我们将探讨一些常见的嵌入和特征映射，但请记住，关于如何解决编码问题，存在许多不同的技术，从基本的特征映射到**量子生成对抗网络**（**qGANs**），例如在[*第4章*](B19146_04.xhtml#_idTextAnchor079)中我们看到的股票价格分布案例中的嵌入技术。'
- en: In the upcoming subsections, as mentioned earlier, the primary focus will be
    on model implementations, and it should be assumed that the dataset has been prepared
    in accordance with all the previous concepts.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子章节中，如前所述，主要的重点将放在模型的实现上，并应假设数据集已经根据所有前述概念进行准备。
- en: Real business data
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 真实商业数据
- en: One of the barriers in QML, when applied to industry cases, is the lack of open
    source examples that use representative data to recreate a true business scenario.
    Most of the tutorials and open code repositories use demo datasets to show the
    architecture of the models, usually with interesting results that are difficult
    to replicate later. In the case of the exercise in this chapter, we will use a
    synthetic copy of real small and medium businesses’ financial behavior so that
    the results and the data treatment can truly mimic an authentic bank or fintech
    scenario at the time, classifying customers by their financial risk.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在量子机器学习（QML）应用于行业案例时，面临的一个障碍是缺乏使用代表性数据的开源示例，无法重现真实的商业场景。大多数教程和开源代码库使用演示数据集来展示模型架构，通常得到的有趣结果很难重复。在本章的练习中，我们将使用真实中小型企业财务行为的合成副本，以便结果和数据处理能够真实地模拟一个银行或金融科技场景，按客户的财务风险进行分类。
- en: Synthetic data
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成数据
- en: Synthetic data is meant to revolutionize artificial intelligence, according
    to experts such as Gartner ([https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai](https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai)).
    Trained on real-world data samples, data generators are able to create samples
    of realistic synthetic data points that are statistical replicas of the original
    ones. The model first discovers the patterns, correlations, and statistical characteristics
    of the sample data so that it can then fake samples similar to those. It is basically
    the same technology behind all the buzz there has been around deepfake technology
    but, in this case, used for corporate tabular data. One of the benefits of using
    synthetic data is the ability to curate the original dataset fixing bias, data
    sample balance, and missing data, as the generator is able to overcome these issues
    by learning the relationship between the features, composing a realistic data
    sample (Figueira et al.). It is particularly relevant when customer data is involved
    in the process, as this can pose privacy-related issues that may be a burden to
    an already complex analytic project. Luckily for us, given that synthetic data
    refers to no specific individual, if properly synthesized, it would be free of
    any regulatory restriction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 根据像Gartner这样的专家的说法，合成数据旨在彻底改变人工智能（[https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai](https://www.gartner.com/en/newsroom/press-releases/2022-06-22-is-synthetic-data-the-future-of-ai)）。经过现实世界数据样本训练的数据生成器能够创建与原始数据点在统计学上相似的合成数据点样本。模型首先发现样本数据的模式、关联和统计特性，然后它可以生成与这些样本相似的虚假样本。它基本上是与深度伪造技术背后使用的技术相同，只不过在这里用于企业的表格数据。使用合成数据的一个好处是能够通过修复偏差、数据样本平衡和缺失数据来优化原始数据集，因为生成器能够通过学习特征之间的关系来克服这些问题，从而生成一个现实的数据样本（Figueira
    等人）。当客户数据涉及到过程中时，这一点尤为重要，因为这可能会带来隐私相关的问题，给已经复杂的分析项目增添负担。幸运的是，考虑到合成数据不指向特定个体，如果正确合成，它将不受任何监管限制。
- en: Synthetic data looks and has the same meaning as the actual data sample used
    to train the algorithm. Since the synthetic dataset includes the same insights
    and correlations as the original, it is a great stand-in for the original. Taking
    this into account, the extracted information can be used safely as training data
    to build machine learning models and test data, such as when testing a credit
    scoring or fraud detection system (Assefa et al.).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据看起来与用于训练算法的实际数据样本相同，并且具有相同的意义。由于合成数据集包含与原始数据相同的洞察和关联，它是原始数据的一个很好的替代品。考虑到这一点，提取的信息可以安全地用作训练数据，以构建机器学习模型和测试数据，例如在测试信用评分或欺诈检测系统时（Assefa
    等人）。
- en: 'The main benefits of this method for generating new data are as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法生成新数据的主要好处如下：
- en: It avoids **General Data Protection Regulation** (**GDPR**) and other legal
    constraints when data is shared between institutions or is simply used to train
    ML models under different environments, without the risk of PII data leakage.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它避免了**通用数据保护条例**（**GDPR**）和其他法律约束，当数据在机构之间共享或仅用于在不同环境下训练机器学习模型时，不会出现个人身份信息（PII）泄露的风险。
- en: It detects more efficiently outliers in cases such as fraud. Fraudulent actions
    are a small fraction of the total activities tracked by a bank. Due to the data
    size, it is difficult for a machine learning model to learn from this sort of
    dataset in order to identify new instances of fraud, and inaccurate findings may
    be a consequence. Undersampling and oversampling are two methods to deal with
    imbalanced datasets. Undersampling is the process of deleting (in this example)
    non-fraud observations to get a balanced dataset. In contrast, oversampling generates
    fresh examples of fraudulent behavior that mimic genuine fraud. The ML model may
    then be trained on the balanced dataset to provide more precise outcomes. In order
    to get a balanced dataset, synthetic data creation methods might be employed to
    generate fictitious cases of fraud.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它能够更高效地检测异常值，例如欺诈行为。欺诈行为是银行所追踪的所有活动中的一小部分。由于数据量庞大，机器学习模型很难从这类数据集中学习，以识别新的欺诈实例，可能会导致不准确的发现。欠采样和过采样是处理不平衡数据集的两种方法。欠采样是指删除（在本例中）非欺诈性观察数据，以获得平衡的数据集。相反，过采样通过生成新的欺诈行为示例来模拟真实的欺诈行为。然后，机器学习模型可以在平衡的数据集上进行训练，从而提供更精确的结果。为了获得平衡的数据集，可以采用合成数据生成方法来生成虚构的欺诈案件。
- en: It improves existing machine learning models, since most of the algorithms related
    to supervised learning and deep learning are usually data-hungry. Even if a financial
    institution has sufficient data to train an ML model, data quantity has a significant
    impact on the accuracy of ML models. Synthetic data can be used to expand the
    size of a dataset dramatically.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它改善了现有的机器学习模型，因为与监督学习和深度学习相关的大多数算法通常对数据量有较高的需求。即使金融机构拥有足够的数据来训练机器学习模型，数据量对模型准确度有着显著影响。合成数据可以极大地扩展数据集的规模。
- en: Case study
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究。
- en: 'The exercise that will be applied in this chapter is built on synthetic public
    data from **small and medium businesses** (**SMBs**) that has been released on
    the Kaggle data science platform by the company NayaOne ([https://www.kaggle.com/datasets/nayaone/sme-uk-businesses-financial-statistics](https://www.kaggle.com/datasets/nayaone/sme-uk-businesses-financial-statistics)).
    The dataframe’s structure is composed of 10 distinct CSV files, each of which
    contains information about a different aspect of a firm, as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将应用的练习基于来自**中小型企业**（**SMBs**）的合成公共数据，这些数据由公司NayaOne在Kaggle数据科学平台上发布（[https://www.kaggle.com/datasets/nayaone/sme-uk-businesses-financial-statistics](https://www.kaggle.com/datasets/nayaone/sme-uk-businesses-financial-statistics)）。数据框架的结构由10个不同的CSV文件组成，每个文件包含关于公司不同方面的信息，具体如下：
- en: 'Account Receivable: Entails the money owed by clients for billed goods or services'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应收账款：指客户为已开票商品或服务所欠的款项。
- en: 'Businesses: A list of companies and their details'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 企业：公司及其详细信息的列表。
- en: 'COVID: The financial data of firms during pandemic waves'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COVID：公司在疫情波动期间的财务数据。
- en: 'Credit Account History: Refers to the history of a credit account'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用账户历史：指信用账户的历史记录。
- en: 'Credit Card History: Entails a record of the business’s credit card activity
    and associated debt'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡历史：包含公司信用卡活动及相关债务的记录。
- en: 'Credit Rating: A quantitative evaluation of a borrower’s creditworthiness in
    general or relative to a financial obligation'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用评级：对借款人总体或相对于财务义务的信用状况的定量评估。
- en: 'Director: An individual from the United Kingdom who holds a director role in
    the businesses presented in the dataset'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 董事：来自英国的个人，在数据集中的企业中担任董事职务。
- en: 'Factoring: Data related to the process when a firm sells its accounts receivable
    to a third party at a discount in a factoring transaction, which is a kind of
    debtor financing'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保理：与公司将其应收账款以折扣价出售给第三方的过程相关的数据，这是一种债务融资方式。
- en: 'Loan: Details on paid and outstanding loans taken out by an organization'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贷款：公司已偿还和未偿还贷款的详细信息。
- en: 'When all the CSV files are put together, they give a total of 269 variables.
    The target variable that determines whether a company is a “good” or “bad” payer
    is based on how the company actually behaved when it had debts, classifying them
    into four distinct groups, namely the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有CSV文件合并时，它们总共有269个变量。决定公司是否为“良好”或“不良”付款人的目标变量是基于公司在拥有债务时的实际行为，将它们划分为四个不同的类别，具体如下：
- en: '**A potential defaulter in terms of loans**: In the context of loans, a debt
    is considered overdue if there was at least one delay in the payment of the loan
    installments'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在违约者（贷款方面）**：在贷款的语境中，如果贷款分期付款中至少有一次延迟支付，则债务被视为逾期。'
- en: '**A potential defaulter in terms of credit cards**: A credit card account is
    deemed overdue if there was at least one payment delay'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在违约者（信用卡方面）**：如果信用卡账户中至少有一次支付延迟，则该账户被视为逾期。'
- en: '**A defaulter**: The corporation is deemed to have defaulted on the loan when
    the loan status variable is recorded as “default”'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**违约者**：当贷款状态变量记录为“违约”时，公司被视为已违约。'
- en: '**Late payers**: A delinquent mark was assigned to all firms with more than
    four late payments in the previous five years'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**拖欠付款者**：对于过去五年内有超过四次逾期付款的公司，分配了拖欠标记。'
- en: All these previous rules defined good behavior in SMBs for 71.46% of the cases
    and bad behavior for the remaining 29.54%. Of course, as is customary, all the
    variables used to calculate the target class variables were dismissed from the
    dataset to avoid highly correlated features.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些先前的规则在71.46%的案例中定义了中小型企业的良好行为，在其余29.54%的案例中定义了不良行为。当然，按照惯例，所有用于计算目标类变量的变量都已从数据集中删除，以避免高度相关的特征。
- en: Provider of the data
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据提供者。
- en: NayaOne is a disruptive start-up from the UK that was founded in 2019\. Its
    revolutionary goal is to provide a single point of access to hundreds or even
    thousands of synthetic data points, enabling machine learning models for the finance
    industry to be built without having to wait months for the proprietary data to
    be ready. Using NayaOne’s platform, every insurtech, fintech, or bank can prototype
    ML models or architectures in weeks rather than months or years.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: NayaOne 是一家来自英国的颠覆性初创公司，成立于2019年。其革命性的目标是提供一个单一的访问点，获取数百甚至数千个合成数据点，使得金融行业的机器学习模型能够在不必等待数月才能获得专有数据的情况下构建。通过使用NayaOne的平台，每个保险科技、金融科技或银行都可以在几周内而不是几个月或几年内原型化机器学习模型或架构。
- en: On top of the benefits of faster prototyping to match an ideal time to market,
    the cost of experimentation can be reduced by at least 80%.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 除了能够更快原型化并匹配理想的市场时间外，实验成本至少能减少80%。
- en: Features
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征
- en: 'The areas of the features used for the model are the following, based on an
    EDA and feature selection analysis:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 用于模型的特征领域如下，基于EDA（探索性数据分析）和特征选择分析：
- en: '`primary_sector`'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`primary_sector`'
- en: '`factoring_provider`'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`factoring_provider`'
- en: '`revenue`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`revenue`'
- en: '`cant_invoices`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cant_invoices`'
- en: '`payment_index`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`payment_index`'
- en: '`new_recruitments`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`new_recruitments`'
- en: Finally, 164 features were chosen as being very important to train the model
    after all the techniques were applied.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，经过所有技术应用后，选择了164个特征作为训练模型时非常重要的特征。
- en: Implementation of classical and quantum machine learning algorithms for a credit
    scoring scenario
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在信用评分场景中实现经典与量子机器学习算法
- en: Applying machine learning and quantum machine learning for credit scoring challenges
    requires the development of a prediction model that can properly determine an
    individual’s or company’s creditworthiness. Typically, this procedure, as shown
    in the steps described previously, includes data collection, data enrichment,
    data preparation, feature engineering, feature selection, model selection, model
    training, model evaluation, and subsequently, deployment. In this section, we
    will cover most of the previous concepts and procedures, assuming that the data
    is already encoded to numerical variables and the feature has been selected.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器学习和量子机器学习应用于信用评分挑战需要开发一个预测模型，该模型能够正确判断个人或公司是否具备信用。通常，这个过程如前述步骤所示，包含数据收集、数据丰富、数据准备、特征工程、特征选择、模型选择、模型训练、模型评估，以及随后的部署。在本节中，我们将覆盖大部分之前的概念和步骤，假设数据已经被编码为数值变量，且特征已被选择。
- en: Data preparation
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据准备
- en: First, the data needs to be loaded. This data will come in one of the more well-known
    formats in the industry, which is CSV. The information that will load into the
    notebook, as previously detailed, is in a classical format, so we can handle the
    first steps of our architecture with pandas and scikit-learn without issues.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，需要加载数据。这些数据将以行业内较为知名的格式之一——CSV格式出现。正如前面详细说明的那样，加载到笔记本中的信息是经典格式，因此我们可以使用pandas和scikit-learn来处理我们架构的第一步，而不会遇到问题。
- en: 'Step one of the preprocessing is loading the CSV, defining the *X* and *y*
    values of the experiment, and later, splitting the train and test sets:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理的第一步是加载CSV，定义实验的 *X* 和 *y* 值，随后再拆分训练集和测试集：
- en: '[PRE0]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'At the moment, to load your data, it’s important to split the dataset into
    two groups – the dataset that will be used to train a model and the dataset that
    will be used to evaluate the model fitness. By having a dataset that has never
    been used to train a model, we aim to set realistic measures for when our models
    will face real incoming data coming when operating in the real world. This dataset
    already contains identifiers to split those two sets from the merged CSV file:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，为了加载数据，重要的是将数据集拆分为两组——一组用于训练模型，另一组用于评估模型的拟合度。通过使用从未用于训练模型的数据集，我们旨在设定切实的衡量标准，以便当我们的模型在真实世界中运行时能够应对真实数据的到来。这个数据集已经包含了从合并的CSV文件中拆分这两组的标识符：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After this, it is simple to split those two sets into feature and target attributes.
    Columns not containing relevant information or that could fake our ability to
    predict over a further test set, given that the label information is encoded,
    need to be removed from the attributes that our model will be able to retrieve
    in reality:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之后，将这两个集合拆分为特征和目标属性就变得简单了。需要移除那些不包含相关信息或者可能会在进一步的测试集上虚假预测我们模型能力的列，因为标签信息已经被编码，这些列就不再是我们模型在实际中能够获取的属性：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It’s important to always review the distribution of the target variable because
    if it is highly imbalanced, it could drive the model towards a simplified decision
    that all samples must be treated like the majority of them. In such cases, other
    oversampling techniques may be necessary to increase the performance of the model
    and balance it with the different sample groups within the dataset. In the example
    shown here, the dataset is balanced enough (70–30 between our two main classes
    of individuals) in preparation for the next sections, those related to the model’s
    architecture:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 始终检查目标变量的分布非常重要，因为如果目标变量高度不平衡，可能会导致模型走向一个简化的决策，即所有样本都被视为大多数样本的类别。在这种情况下，可能需要其他过采样技术来提高模型性能，并使其与数据集中的不同样本组之间保持平衡。在此处展示的示例中，数据集已经足够平衡（我们的两个主要类别之间为
    70-30），以便为接下来的部分做准备，这些部分与模型的架构相关：
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Preprocessing
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预处理
- en: The preprocessing stage is one of the most important steps in any machine learning
    project and model’s architecture. In hybrid quantum-classical algorithms, the
    input also needs to be transformed from classical features to quantum states,
    which are usually called quantum encodings or quantum embeddings. During this
    section, these ideas will be explained in detail, but first, we will focus on
    the classical preprocessing methods that will be extended during the quantum coding
    part.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理阶段是任何机器学习项目和模型架构中最重要的步骤之一。在混合量子-经典算法中，输入也需要从经典特征转变为量子状态，通常称为量子编码或量子嵌入。在本节中，这些概念将被详细解释，但首先我们将重点介绍将在量子编码部分扩展的经典预处理方法。
- en: After the train and test datasets have been obtained, the preprocessing step,
    especially the dimensionality reduction, will take place. As previously mentioned,
    not all attributes hold the same amount of information, and it is crucial to concentrate
    the majority of it to avoid burdening the model with unnecessary work in determining
    the relevance of features. Tree-based models, for example, do take into consideration
    the information gain each attribute provides (Tangirala 2020), and neural networks,
    for example, will render into zero value weights to those attributes that do not
    contribute to improving the decision. However, certain techniques, such as the
    ones we will explore, lack this capacity, and it is important we make a realistic
    exercise, easing the work required by the subsequent model training steps.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得训练和测试数据集后，预处理步骤，特别是降维，将会进行。如前所述，并非所有属性都具有相同的信息量，因此集中大部分信息至关重要，以避免在模型中增加不必要的负担，特别是在确定特征的相关性时。例如，基于树的模型会考虑每个属性所提供的信息增益（Tangirala
    2020），而神经网络则会将那些不有助于改善决策的属性权重变为零。然而，某些技术，如我们将要探讨的那些技术，缺乏这种能力，因此我们需要进行合理的处理，减轻后续模型训练步骤的工作量。
- en: There are a few techniques that can be used in this regard, and in the context
    of QML, they diminish the number of variables to be encoded into quantum devices,
    with fewer qubits to run classification tasks. Recall that this is relevant also
    because of the capacity of some quantum devices, which range from 10 or 100 qubits,
    while datasets can expand to thousands of features for each data point.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面可以使用一些技术，在量子机器学习（QML）的背景下，它们减少了需要编码到量子设备中的变量数量，从而减少了运行分类任务所需的量子比特。请记住，这一点也很重要，因为一些量子设备的能力有限，通常只有
    10 或 100 个量子比特，而数据集可能包含每个数据点成千上万个特征。
- en: 'The two most utilized techniques are as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的两种技术如下：
- en: '**Principal component analysis (PCA) (Bro & Smilde 2014)**: By analyzing the
    covariance matrix and expressing it in terms of linear combinations between various
    features, thereby generating orthogonal axes or principal components, PCA provides
    an ordering where the bottom principal components can be removed, as they encode
    a minimal amount of information. With this technique, the number of components
    or features that we want to extract from the process is a parameter that we can
    define, with the only constraint being that the features should not surpass the
    original number of variables.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析 (PCA) (Bro & Smilde 2014)**：通过分析协方差矩阵并将其表示为不同特征之间的线性组合，从而生成正交轴或主成分，PCA
    提供了一种排序方式，其中底部的主成分可以被去除，因为它们编码的信息量最小。通过这种技术，我们可以定义一个参数来提取所需的成分或特征，唯一的限制是特征数量不能超过原始变量的数量。'
- en: '**Linear discriminant analysis (LDA) (Izenman 2013)**: LDA is a supervised
    algorithm that reduces the feature space by considering class labels. LDA focuses
    on target separability and tries to define the characteristics that better map
    this separable space. If LDA is used, there is a limitation on the number of features
    that could come from the reduction, since LDA can only provide N − 1, where N
    is the number of classes available.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性判别分析（LDA）(Izenman 2013)**：LDA是一种监督算法，通过考虑类别标签来减少特征空间。LDA聚焦于目标可分性，尝试定义更好地映射该可分空间的特征。如果使用LDA，则特征数的减少有一个限制，因为LDA最多只能提供N
    − 1，其中N是可用的类别数。'
- en: The diagram in *Figure 6**.2* highlights the main difference between the two
    techniques. In this case, LDA will be used because it has a proven record of surpassing
    PCA, with a reduced number of qubits and a binary classification (Mancilla and
    Pere 2022). The main constraint is that, previously, the database would have been
    split with the objective to extract more than one component per set and to have
    at least two components for the 2-qubit approach that followed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.2* 中的示意图突出了两种技术之间的主要区别。在这种情况下，将使用LDA，因为它有着超越PCA的证明记录，并且使用较少的量子比特和二分类（Mancilla
    和 Pere 2022）。主要的限制是，之前，数据库已经被划分，目的是从每个集合中提取多个组件，并且至少为接下来的2量子比特方法提供两个组件。'
- en: '![Figure 6.2 – A comparison between PCA and LDA](img/B19146_06_002.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – PCA与LDA的比较](img/B19146_06_002.jpg)'
- en: Figure 6.2 – A comparison between PCA and LDA
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – PCA与LDA的比较
- en: 'Image source: [https://sebastianraschka.com/Articles/2014_python_lda.html](https://sebastianraschka.com/Articles/2014_python_lda.html)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[https://sebastianraschka.com/Articles/2014_python_lda.html](https://sebastianraschka.com/Articles/2014_python_lda.html)
- en: 'For the sake of simplicity, `X_train` and `X_test` will be split in half, allocating
    50% of the features to the `features_a` set and the rest to `features_b`. Since
    we have 167 features, 83 will be allocated in one half and 84 in the other. It
    is highly recommended that this process is replaced by clusters, variable types
    groups, data sources, or a correlation definition:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，`X_train` 和 `X_test` 将被平分，50%的特征分配给`features_a`集合，其余分配给`features_b`。由于我们有167个特征，83个特征将分配到一半，84个特征分配到另一半。强烈建议用聚类、变量类型分组、数据源或相关性定义来替代此过程：
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Another factor that is common is scale disparity. It is important that we make
    our models agnostic to scale and able to focus on the information encoded into
    our features. It is also convenient when dealing with neural networks, as normalization
    always helps with their convergence.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的因素是尺度差异。重要的是，我们的模型应该对尺度保持无关，并能够专注于我们特征中编码的信息。在处理神经网络时，这一点尤其重要，因为归一化总是有助于它们的收敛。
- en: 'In this case, we will replicate the information in different dataframes, adjusted
    to the target techniques we will use in the following sections:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将把信息复制到不同的数据框中，并调整为我们将在接下来的部分中使用的目标技术：
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It is important to highlight that this transformation should only affect the
    scale of the data, as their distribution and the relationship between different
    attributes associated with each sample of our dataset should remain intact. It
    mostly affects the way in which each algorithm is trained and tries to make this
    task easier by scaling the information (Singh and Singh 2020).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 需要强调的是，这一转换应该仅影响数据的尺度，因为它们的分布以及与数据集每个样本相关的不同属性之间的关系应保持不变。它主要影响每个算法的训练方式，试图通过缩放信息来简化这一任务（Singh
    和 Singh 2020）。
- en: Quantum Support Vector Machines
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 量子支持向量机
- en: The **Support Vector Classifier** (**SVC**) and **Quantum Support Vector Classifier**
    (**QSVC**) are the first models that will be used to look at our synthetic dataset,
    and we will see how a quantum algorithm versus a classical algorithm can work
    to find potential defaulters. One of the most widely used techniques is known
    as **Support Vector Machines** (**SVM**) (*Hearst et al., 1998*), which make use
    of hyperplanes in order to find separable spaces within our data regime. These
    hyperplanes are responsible for separating our N-dimensional information into
    different spaces, trying to maximize the margin between samples from the regions
    split by the hyperplane itself. By softening this margin constraint and allowing
    some samples to be misclassified, we allow the model to generalize from the dataset
    itself. This softened version is what we will call an SVC.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**支持向量分类器**（**SVC**）和**量子支持向量分类器**（**QSVC**）是我们将用于分析合成数据集的第一个模型，我们将看到量子算法与经典算法如何协作，以识别潜在的违约客户。最常用的技术之一被称为**支持向量机**（**SVM**）（*Hearst
    等, 1998*），它利用超平面来找到我们数据范围内的可分空间。这些超平面负责将我们的N维信息划分到不同的空间中，力求最大化超平面本身划分区域之间的样本间隔。通过放宽这一间隔约束并允许某些样本被错误分类，我们使得模型能够从数据集本身进行泛化。这个放宽版本就是我们所称的
    SVC。'
- en: 'Thanks to the abstraction level that Python libraries such as scikit-learn
    provide, its usage is as simple as calling a fit function to pass the dataset
    and target data:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了像 scikit-learn 这样的 Python 库提供的抽象级别，其使用就像调用一个拟合函数来传递数据集和目标数据一样简单：
- en: '[PRE6]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As previously mentioned, it is important to pay attention to relevant metrics
    that will help us better understand the actual fitness of the model besides that
    single metric:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，除了关注单一指标之外，还需要注意相关的度量标准，以帮助我们更好地理解模型的实际适应度：
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This is when the relevance of unbalanced datasets shows its ugly face, as we
    can see that our accuracy is mostly driven by our ability to detect non-defaulting
    customers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，数据集不平衡性的问题便显现出来，我们可以看到模型的准确度主要取决于我们识别非违约客户的能力。
- en: Given the nature of SVMs and their requirement to handle space separability,
    one of the initial proposals in the realm of QML essentially leverages the inherent
    high-dimensional encoding offered by quantum states. **Quantum Support Vector
    Machines** (**QSVMs**) (Rebentrost et al. 214) encode classical data into quantum
    states so that after a measurement is obtained, encoded samples show better separability
    – in this case, performed by classical means.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于支持向量机（SVM）的性质及其对空间可分性的要求，量子机器学习领域最初的一个提案本质上利用了量子态所提供的固有高维编码。**量子支持向量机**（**QSVMs**）（Rebentrost
    等，214）将经典数据编码到量子态中，以便在获得测量结果后，编码的样本表现出更好的可分性——在这种情况下，是通过经典方式来实现的。
- en: One of the main benefits of the QSVM approach is how data points are represented
    in a quantum feature space, due to the use of quantum kernels (visualized in *Figure
    6**.3*). Usually, businesses can face non-linear separable data, and the use of
    classical kernel methods is not enough to properly divide two classes in the case
    of binary classification models. With the usage of quantum kernels, data points
    can be distributed in a Hilbert space so that they can be divided more efficiently
    with the algorithm (SVC). In *Figure 6**.3*, you can see a visual example of a
    workflow that presents both approaches (classical and quantum) and how data could
    be represented in the different feature spaces to gain linear separability ([https://quantum-journal.org/papers/q-2021-08-30-531/](https://quantum-journal.org/papers/q-2021-08-30-531/)).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: QSVM 方法的主要优点之一是数据点如何在量子特征空间中表示，这得益于量子核函数的使用（在*图 6.3*中可视化）。通常，企业会遇到非线性可分的数据，而经典核方法不足以在二分类模型中正确划分两个类别。通过使用量子核函数，数据点可以被分布在一个希尔伯特空间中，从而使得它们能够通过算法（SVC）更高效地进行划分。在*图
    6.3*中，您可以看到展示两种方法（经典和量子）及数据如何在不同特征空间中表示以实现线性可分性的工作流的可视化示例（[https://quantum-journal.org/papers/q-2021-08-30-531/](https://quantum-journal.org/papers/q-2021-08-30-531/)）。
- en: '![Figure 6.3 – A comparison of how classical and quantum kernels embed data
    points](img/B19146_06_003.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.3 – 经典和量子核函数如何嵌入数据点的比较](img/B19146_06_003.jpg)'
- en: Figure 6.3 – A comparison of how classical and quantum kernels embed data points
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 – 经典和量子核函数如何嵌入数据点的比较
- en: Therefore, one of the first steps we will face when attempting a QSVM classifier
    is encoding classical data into a feature map that performs the actual quantum
    encoding for us. There are several options we can choose from, and the gain we
    will obtain will come from arbitrary decisions on the number of repetitions each
    feature map is performed with. This is a common issue we can face in data science
    projects, where some decisions will be based on experience of given datasets or
    scenarios.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们尝试QSVM分类器时，首先需要面对的步骤之一是将经典数据编码成特征图，以便为我们执行实际的量子编码。我们可以选择多个选项，所获得的收益将来自于对每个特征图执行的重复次数的任意决定。这是数据科学项目中常见的问题，一些决策将基于给定数据集或场景的经验。
- en: Simply put, a quantum feature map encodes conventional data into a quantum state
    space by employing a quantum circuit. The number of times a circuit is repeated
    during encoding is called “depth,” and it is a parameter that can be changed.
    QML on classical data requires the encoding of data into quantum states to be
    applied later to the quantum algorithm.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，量子特征图通过使用量子电路将常规数据编码到量子态空间中。在编码过程中，电路重复的次数被称为“深度”，它是一个可以改变的参数。对经典数据进行QML处理要求将数据编码成量子态，之后应用到量子算法中。
- en: 'Qiskit provides a set of candidate feature maps we can use for our task of
    running a classification model. Most of them are based on Pauli operators, rotating
    according to our data features. That is one of the reasons why data needs to be
    preprocessed so that its numerical representation can be introduced as rotation
    angles in our feature map. Using combined Z rotations along the Z axis of each
    qubit is a common case that can be invoked, as seen here:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Qiskit提供了一组候选特征图，我们可以用于运行分类模型的任务。它们中的大多数基于保利算符，按我们的数据特征进行旋转。这也是为什么数据需要预处理的原因，以便将其数值表示作为旋转角度引入到我们的特征图中。使用沿每个量子比特Z轴的组合Z旋转是一个常见的情况，如下所示：
- en: '[PRE8]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: reps makes reference to the number of instances a feature map is repeated and
    is one of those hyperparameters that we might need to play with in order to find
    its best option. *Figure 6**.4* shows the representation of our selected feature
    map composed of a set of rations (P gates in pink) and entangling CNOT gates.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: reps指的是特征图重复的次数，它是我们可能需要调整的超参数之一，以便找到最佳选项。*图6.4*展示了我们选择的特征图的表示形式，它由一组比率（粉色的P门）和纠缠的CNOT门组成。
- en: '![Figure 6.4 – The ZZFeature map with three repetition schemes](img/B19146_06_004.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图6.4 – 带有三种重复方案的ZZ特征图](img/B19146_06_004.jpg)'
- en: Figure 6.4 – The ZZFeature map with three repetition schemes
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 – 带有三种重复方案的ZZ特征图
- en: The *X* variables within the boxes in *Figure 6**.4* represent the features
    of our dataset, which are used as a rotation weight that will drive the initial
    state of the circuit (|00> for the 2-qubit case) toward the one used as input
    in our SVC classifier.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.4*中的*X*变量代表我们的数据集特征，它们作为旋转权重，驱动电路的初始状态（对于2量子比特的情况是|00>）朝向输入到我们SVC分类器中的状态。'
- en: 'Qiskit also provides higher-level abstractions for these QML tasks, so it is
    not required to produce the whole code for known techniques, as is the case with
    QSVM:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Qiskit还为这些QML任务提供了更高层次的抽象，因此不需要为已知的技术编写完整代码，这在QSVM中是常见的情况：
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Even though it may seem like the same result has been obtained, we could check
    the classification report as we did before:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 即使看起来结果相同，我们也可以像之前一样检查分类报告：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We can see some of the decisions have moved between the different classes, losing
    precision and gaining recall in some cases, but we could, by simple encoding,
    improve our detection of defaulters by two percentual points.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到一些决策已经在不同类别之间移动，在某些情况下损失了精度，但通过简单的编码，我们可以将违约检测率提高两个百分点。
- en: It might seem like a small gain, but considering the figure we saw at the beginning
    of this chapter, a 2% increase in detection is a huge improvement in terms of
    revenue. It’s definitely a technique worth trying out, given how simple its adaptation
    from the classical regime is.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来是一个小幅度的提升，但考虑到本章开头看到的图示，2%的检测率提升在收入方面是一个巨大的改进。鉴于从经典领域的适配非常简单，这绝对是值得尝试的技术。
- en: QNNs
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: QNNs
- en: Following the same structure as the previous comparison, we will now process
    our dataset of good customers and defaulters through quantum and classical neural
    networks. Neural networks of all kinds and shapes populate almost every machine
    learning initiative that a corporation may try (*Bishop 1994*). These models are
    versatile for a plethora of tasks, and their general framework allows for all
    kinds of architecture suitable for specific tasks – convolutional neural networks
    for artificial vision (*Khan et al., 2018*), recurrent neural networks for natural
    language understanding (*Yao et al., 2013*), or generative adversarial networks
    for synthetic data generation (*Park et* *al., 2018*).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 按照与前面比较相同的结构，我们将通过量子和经典神经网络处理我们的良好客户和违约者数据集。各种形态的神经网络几乎在所有企业尝试的机器学习项目中都有应用（*Bishop
    1994*）。这些模型适用于各种任务，并且其通用框架允许为特定任务定制各种架构——卷积神经网络用于人工视觉（*Khan等，2018*），递归神经网络用于自然语言理解（*Yao等，2013*），或生成对抗网络用于合成数据生成（*Park等，2018*）。
- en: Risk assessment is not absent from similar exercises (*Khashman 2010*), so given
    these are popular choices, we must try at least. Popular Python frameworks such
    as TensorFlow and its higher order abstraction, thanks to Keras, simplify much
    of the code needed to train a bioinspired trendy model. The code below follows
    an architecture where input data is passed through a series of layers in decreasing
    number of neurons (60, 40, 20 and 1), down to the point where the outcome of the
    last neuron determines the class input sample may belong to. That is why a Sigmoid
    function is defined for that last step.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 风险评估在类似的练习中也有所涉及（*Khashman 2010*），因此，鉴于这些是流行的选择，我们至少需要尝试一下。流行的Python框架，如TensorFlow，以及它的高级抽象（得益于Keras），简化了训练生物启发式时尚模型所需的大部分代码。以下代码遵循一种架构，其中输入数据通过一系列层（神经元数目逐渐减少：60、40、20和1）传递，直到最后一层的输出决定输入样本所属的类别。这就是为什么在最后一步定义了Sigmoid函数。
- en: 'Densely connected layers are our choice for this example and a **Rectified
    Linear Unit** (**ReLU**) is the neuron of choice (*Agarap 2018*), but as previously
    discussed, these decisions are not driven by any specific process, other than
    experience and trials in similar scenarios where this architecture proved successful:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们选择了密集连接的层，**修正线性单元**（**ReLU**）作为神经元的选择（*Agarap 2018*），但如前所述，这些决策并不是由任何特定过程驱动的，而是通过经验和在类似情境中经过试验成功的架构来决定的：
- en: '[PRE11]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Training will yield a high accuracy score (above 90%), but the test dataset
    is the one that provides realistic expectations of the model’s ability to predict:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 训练将产生一个高准确度（超过90%）的评分，但测试数据集才是提供模型预测能力现实预期的关键：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Even though accuracy might seem to have increased, we have sacrificed the ability
    to identify non-defaulters and defaulters, which, even though they give a more
    balanced dataset, are not as efficient as we would like for our business needs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管准确性看起来有所提高，但我们牺牲了识别非违约者和违约者的能力，尽管这样能提供更均衡的数据集，但对于我们的业务需求来说，并不如我们期望的那样高效。
- en: 'Given that we already have an encoding sorted out, based on our previous exercise
    using ZZFeatureMap, it would be good to have a scheme where the whole model gets
    embedded into the quantum device so that once the data is represented in this
    feature map, the ability of quantum devices to disentangle complex relationships
    can be exploited fully. This can be done by QNNs (*Ezhov and Ventura, 2000, and
    Farhi and Neven, 2018*), a data embedding that is followed by a **Parameterized
    Quantum Circuit** (**PQC**) or ansatz, whose measurement sets the class that each
    sample belongs to:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们已经通过之前使用ZZFeatureMap的练习解决了编码问题，最好有一种方案，可以将整个模型嵌入到量子设备中，这样一旦数据以此特征映射表示，量子设备解开复杂关系的能力就能得到充分利用。这可以通过QNNs（*Ezhov和Ventura，2000年，以及Farhi和Neven，2018年*）来实现，这是一种数据嵌入，随后是**参数化量子电路**（**PQC**）或ansatz，其测量结果决定了每个样本所属的类别：
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Figure 6.5 – A QNN obtained by the preceding code](img/B19146_06_005.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 通过前述代码获得的QNN](img/B19146_06_005.jpg)'
- en: Figure 6.5 – A QNN obtained by the preceding code
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 通过前述代码获得的QNN
- en: As can be seen in the obtained circuit, the feature map only has two inputs
    belonging to the features in our dataset, but the PQC has five parameters that
    we need to determine in order to proceed. The way to perform such a task is by
    variationally adapting the output of the QNN model so that it minimizes a cost
    function, the mismatch between our labeled data, and the measured classical bit
    in our case.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如在获得的电路中所见，特征映射只有两个输入，分别来自我们数据集中的特征，但PQC有五个参数，我们需要确定这些参数才能继续进行。执行这一任务的方法是通过变分调整QNN模型的输出，使其最小化成本函数，即我们标注数据与我们案例中的测量经典比特之间的不匹配。
- en: 'Qiskit Machine Learning provides a whole machinery that will do the heavy lifting
    for us so that once the QNN structure is declared by these two steps (the feature
    embedding and the PQC), we just need to invoke a set of routines that will obtain
    the final model for us:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Qiskit Machine Learning提供了完整的工具链，帮助我们完成繁重的工作，因此一旦通过这两步（特征嵌入和PQC）声明了QNN结构，我们只需调用一组程序就能为我们获取最终模型：
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: VQC
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VQC
- en: Finally, we will analyze the benefits of using a VQC, which only exists on the
    quantum side of machine learning; therefore, a comparison can’t be made under
    the same principles. The VQC (*Havlíček et al. 2019*) is nothing more than a generalization
    of previously seen cases of QSVC and QNN. It allows for a broader description
    of the aforementioned concepts on data embedding and circuit parameterization
    but with a less restrictive setup, allowing any architecture to be deployed. The
    only restriction concerns the variational nature of obtaining the parameters for
    our ansatz and the outcome restricted to the task of classification.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将分析使用VQC的好处，VQC只存在于量子机器学习领域，因此无法在相同的原则下进行比较。VQC（*Havlíček et al. 2019*）无非是对先前看到的QSVC和QNN案例的概括。它允许更广泛地描述前述的关于数据嵌入和电路参数化的概念，但设置要求较低，允许任何架构的部署。唯一的限制是获取我们假设参数的变分性质，并且输出仅限于分类任务。
- en: Even though previously Qiskit-based approaches have been used, for this more
    generic setup, PennyLane is our framework of choice. This is mostly because of
    its functionality of differential programming that enables similar mechanisms
    for numerical gradient calculations, such as the ones popularized by TensorFlow
    and PyTorch, but also because of its access to gradient-based trainers such as
    Adam (*Kingma and* *Ba, 2014*).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管先前使用过基于Qiskit的方法，但对于这种更通用的设置，PennyLane是我们的首选框架。这主要是因为它的微分编程功能，使得类似于TensorFlow和PyTorch中推广的数值梯度计算机制成为可能，同时也因为它能访问像Adam（*Kingma和*
    *Ba, 2014*）这样的基于梯度的训练器。
- en: 'Our circuit setup will follow a similar description as the previous example,
    with some differences in embedding and ansatz choices:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的电路设置将遵循与前一个示例类似的描述，但在嵌入和假设选择上有所不同：
- en: '[PRE15]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`Angle` embedding encodes the dataset features into the angles of *Y* rotations
    and `StronglyEntanglingLayers` follows a scheme of single rotations and multiple
    CNOT entangling gate operations, which perform a circular link between all qubits
    (Schuld et al. 2020).'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`Angle`嵌入将数据集特征编码为*Y*旋转的角度，`StronglyEntanglingLayers`遵循单次旋转和多个CNOT纠缠门操作的方案，在所有量子比特之间执行循环连接（Schuld
    et al. 2020）。'
- en: 'Once again, the circuit will be linked to a device that PennyLane calls a `QNode`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，电路将连接到PennyLane称之为`QNode`的设备：
- en: '[PRE16]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'PennyLane allows fine-grained control over the different functions that will
    be used within the training of the model so that we can, for example, decide on
    the level of hybridization between classical and quantum means without much effort.
    In this example below, a classical bias neuron is added to the VQC scheme:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: PennyLane允许对训练模型过程中使用的不同功能进行精细控制，这样我们就可以轻松决定经典方法和量子方法之间的混合程度。例如，在下面的这个示例中，经典偏置神经元被添加到VQC方案中：
- en: '[PRE17]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The bias effect allows for a broader range of approximations when added, so
    it should work in our favor:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置效应在添加后允许更广泛的近似范围，因此它应该对我们有利：
- en: '[PRE18]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once our score loss function is defined, we need to define an accuracy metric
    that will also be used as the criteria for parameter selection within the main
    loop:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的得分损失函数被定义，我们需要定义一个准确度指标，该指标也将作为主循环中参数选择的标准：
- en: '[PRE19]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Our final score shows an increased ability to detect defaulters, but even though
    the number of low-risk individuals has decreased, it still reaches the levels
    of the initial SVM and QSVM approaches.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终得分显示出提高了识别违约者的能力，但即便低风险个体的数量减少，它仍然达到了初始 SVM 和 QSVM 方法的水平。
- en: Classification key performance indicators
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类关键绩效指标
- en: In each one of the algorithms tested so far, you can see that there is a classification
    report that gives us the possibility to understand how good a model is in terms
    of predicting each class correctly. Deciding the **Key Performance Indicator**
    (**KPI**) to evaluate the model’s performance is not a trivial decision. Most
    people assume that accuracy is the most important measure to see whether a model
    is working properly or not, with regard to the objective of predicting a specific
    class. Imagine that your credit scoring dataset is imbalanced, with a proportion
    of 5% defaulters and 95% good customers that pay on time. If the model predicts
    that all the test set is good and there are no defaulters, you will have 95% accuracy,
    which is bad.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在迄今为止测试的每一个算法中，你可以看到有一个分类报告，它让我们有机会理解模型在预测每个类别时的准确性。决定评估模型性能的**关键绩效指标**（**KPI**）并非一个简单的决策。大多数人认为准确率是衡量模型是否正常工作的最重要指标，尤其是当目标是预测某一特定类别时。假设你的信用评分数据集是不平衡的，其中违约者占5%，按时还款的优质客户占95%。如果模型预测测试集中的所有样本都是优质客户，并没有预测出违约者，那么你将得到95%的准确率，这实际上是很糟糕的。
- en: 'As we mentioned before, it is common to face imbalanced datasets in the financial
    sector, so we usually need to look at a classification report to see which metric
    is the best to measure. The classification report shows the precision, recall,
    F1 score, and support per class. Digging deeper, it’s important to see first that
    there are four ways to evaluate whether the predictions are good enough or not.
    These are as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在金融行业中常常会遇到不平衡的数据集，因此我们通常需要查看分类报告，看看哪个度量指标最适合衡量。分类报告展示了每个类别的精度、召回率、F1 分数和支持度。深入分析时，首先需要注意的是，有四种方法来评估预测是否足够好。具体如下：
- en: '**True Negative (TN)**: The case was originally negative and the model predicted
    negative'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正负例（TN）**：该案例原本是负类，且模型预测为负类'
- en: '**True Positive (TP)**: The case was originally positive and the model predicted
    positive'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例（TP）**：该案例原本是正类，且模型预测为正类'
- en: '**False Negative (FN)**: The case was originally positive but the model predicted
    negative'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假负例（FN）**：该案例原本是正类，但模型预测为负类'
- en: '**False Positive (FP)**: The case was originally negative but the model predicted
    positive'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假正例（FP）**：该案例原本是负类，但模型预测为正类'
- en: These four measures are the result of the model, and usually, you can see them
    reflected in a data visualization format called a confusion matrix, as shown in
    *Figure 6**.6*.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个度量指标是模型的结果，通常你可以在一种名为混淆矩阵的数据可视化格式中看到它们的体现，如图*6.6*所示。
- en: '![Figure 6.6 – The confusion matrix](img/B19146_06_006.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.6 – 混淆矩阵](img/B19146_06_006.jpg)'
- en: Figure 6.6 – The confusion matrix
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6 – 混淆矩阵
- en: 'Using these metrics, we can calculate the classification report outcome, which
    are as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些指标，我们可以计算分类报告的结果，具体如下：
- en: '**Precision (TP/(TP + FP))**: This is the capacity of a classifier to avoid
    incorrectly labeling instances as positive when they are truly negative. It considers
    the set of rightfully predicted instances (**TP**) with respect to the number
    of samples defined as a positive class (**TP** + **FP**).'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精度（TP / (TP + FP))**：这是分类器避免错误地将真实负类样本标记为正类样本的能力。它考虑的是正确预测的正类样本集（**TP**）与定义为正类的样本总数（**TP**
    + **FP**）之间的比率。'
- en: '**Recall (TP/(TP+FN))**: This is a classifier’s capacity to locate all positive
    examples. Considering all samples in the positive class of the dataset or population,
    rates the correctly identified positives (**TP**) with respect to the positive
    population (**TP** + **FN**).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率（TP / (TP + FN))**：这是分类器定位所有正类样本的能力。它考虑数据集或总体中所有正类样本，评估正确识别出的正类样本（**TP**）与正类样本总数（**TP**
    + **FN**）之间的比率。'
- en: '**F1-score (2*(Recall * Precision) / (Recall + Precision))**: This is a weighted
    harmonic mean of accuracy and recall, where the highest possible score is 1.0
    and the lowest possible score is 0.0\. F1 scores are lower than accuracy measurements,
    since their computation includes precision and recall. As a general rule, the
    weighted average of F1 should be utilized to compare classifier models rather
    than global accuracy.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F1 得分 (2 * (召回率 * 精确度) / (召回率 + 精确度))**：这是准确率和召回率的加权调和平均数，最高得分为 1.0，最低得分为
    0.0。由于 F1 得分的计算包括精确度和召回率，因此通常低于准确率。作为一般规则，应该使用 F1 的加权平均值来比较分类器模型，而不是使用全局准确率。'
- en: '**Support**: This is the number of real instances of a class in a given dataset.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持度**：这是给定数据集中某类别的真实实例数量。'
- en: All of these numbers are given automatically by libraries such as Scikit-Learn,
    but it is very important to understand them before deciding if the model is working
    well or not.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些数字都会由像 Scikit-Learn 这样的库自动提供，但在决定模型是否表现良好之前，理解这些指标非常重要。
- en: Balanced accuracy, or ROC-AUC score
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平衡准确率或 ROC-AUC 得分
- en: In this exercise, we will add another metric to the classification report that
    is related to the same baseline of the confusion matrix numbers, as can be seen
    in *Figure 6**.7*. To measure the performance of an imbalanced dataset in a test
    set, we cannot rely on accuracy, as it may provide inaccurate estimators, prioritizing
    the class that is predominant and drastically failing to detect the less present
    one.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，我们将添加另一个与混淆矩阵数字基准相关的指标，如 *图 6.7* 所示。要衡量不平衡数据集在测试集上的表现，我们不能仅依赖准确率，因为它可能会提供不准确的估计，偏向于占主导地位的类别，导致难以准确检测到较少出现的类别。
- en: 'The **receiver operating characteristic** (**ROC**) curve is a plot or graph
    representing the performance of the classification at all thresholds (the cut-off
    probability to declare an instance as part of a specific class). Basically, this
    curve is based on two parameters, based on the metrics mentioned previously, which
    are the **True Positive Rate** (**TPR**), equivalent to recall, and the **False
    Positive** **Rate** (**FPR**):'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**接收者操作特性**（**ROC**）曲线是一个表示分类器在所有阈值下性能的图形或图表（阈值是用来确定一个实例是否属于某一特定类别的概率切割点）。基本上，这条曲线基于前面提到的两个参数：**真正例率**（**TPR**），相当于召回率，以及**假正例率**（**FPR**）：'
- en: '| True Positive Rate | False Positive Rate |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 真正例率 | 假正例率 |'
- en: '| TPR =  TP _ TP + FN  | FPR =  FP _ FP + TN  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| TPR =  TP / (TP + FN)  | FPR =  FP / (FP + TN)  |'
- en: Plotting the TPR against the FPR values in opposing axes, we obtain a plot,
    also known as a curve (hence the name).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 将 TPR 与 FPR 的值在对立的坐标轴上绘制，我们得到一条图形，也称为曲线（因此得名）。
- en: '![Figure 6.7 – An ROC curve representation](img/B19146_06_007.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.7 – ROC 曲线表示](img/B19146_06_007.jpg)'
- en: Figure 6.7 – An ROC curve representation
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.7 – ROC 曲线表示
- en: '**AUC** is an acronym for **Area Under Curve**, referring to the ROC curve.
    Thus, AUC measures the full two-dimensional area underneath the complete ROC curve
    (consider integral calculus) and has a score from 0 to 1\. There is no consensus
    about the specific AUC score number to define a model as good enough or not, but
    here are some considerations (assuming that higher is better):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**AUC** 是 **曲线下面积**（**Area Under Curve**）的缩写，指的是 ROC 曲线。因此，AUC 衡量的是完整 ROC 曲线下的二维面积（考虑积分计算），其得分范围从
    0 到 1。关于具体的 AUC 得分数值是否足够好的共识并不存在，但以下是一些考虑因素（假设越高越好）：'
- en: '**AUC score of 0.50**: Not useful'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC 得分 0.50**：无效'
- en: '**AUC score 0.51–0.70**: Not enough discrimination to be a performant model'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC 得分 0.51–0.70**：缺乏足够的区分度，无法成为高效的模型'
- en: '**AUC score 0.71–0.80**: Acceptable as good enough discriminant'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC 得分 0.71–0.80**：可以接受，足够具有区分度'
- en: '**AUC score 0.81–0.90**: Excellent discriminant'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC 得分 0.81–0.90**：优秀的区分度'
- en: '**AUC score >0.90**: An outstanding discriminant or an indicator of model overfitting'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC 得分 >0.90**：卓越的区分度或模型过拟合的指标'
- en: In the case of binary classification models, the AUC score is equal to the balanced
    accuracy score. It represents the arithmetic mean between correctly classified
    samples in each category.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类模型，AUC 得分等于平衡准确率得分。它代表了每个类别中正确分类样本的算术平均值。
- en: Conclusion
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: As mentioned earlier, even if accuracy is a common measure from the classification
    report that most people will look at, the way to treat this kind of imbalanced
    data scenario is to compare the models using a balanced accuracy score, or AUC
    score, which in this case are the same, since it is a binary classification challenge.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，尽管准确度是大多数人会关注的分类报告中的常见度量标准，但处理这种不平衡数据场景的方式是使用平衡准确度得分或AUC得分进行模型比较，在这种情况下它们是相同的，因为这是一个二分类挑战。
- en: '![Figure 6.8 – A comparison of classification results between classical and
    hybrid quantum-classical methods](img/B19146_06_008.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.8 – 经典方法与混合量子-经典方法分类结果的比较](img/B19146_06_008.jpg)'
- en: Figure 6.8 – A comparison of classification results between classical and hybrid
    quantum-classical methods
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.8 – 经典方法与混合量子-经典方法分类结果的比较
- en: At first glance, the results do not appear to be conclusive about the benefits
    of using hybrid quantum-classical for classification problems that the finance
    sector may face. However, the purpose of the exercise in this chapter is to get
    people to think about their own business challenges and do more research, since
    we can see that quantum machine learning could be at least equal or slightly better
    than classical ML methods (e.g., QSVC versus SVC). When any incremental benefit
    is achieved in terms of the model’s capacity to detect each class properly, even
    if it seems a small increase, its impact on a business can actually mean high
    figures of saving or earnings significant in a competitive market.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，结果似乎无法得出关于使用混合量子-经典方法在金融行业面临的分类问题中的优势。然而，本章的目的在于让人们思考自己的业务挑战并进行更多的研究，因为我们可以看到量子机器学习至少可以与经典机器学习方法（例如，QSVC与SVC）相等，甚至稍微更好。当模型在正确识别每个类别方面的能力有所提高时，即使这种增益看似微小，它在商业中的影响实际上可能意味着在竞争激烈的市场中节省或赚取大量资金。
- en: 'On top of the architecture developed for this classification example, there
    are several more adjustments that can be explored to increase the performance
    of the hybrid algorithms. Some of them are as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在为这个分类示例开发的架构基础上，还有多个调整可以探索，以提高混合算法的性能。以下是其中的一些：
- en: Test different preprocessing methods such as normalization or dimensionality
    reductions
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试不同的预处理方法，如标准化或降维
- en: Explore better procedures to apply the division in the dataset for the LDA step
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索更好的程序以应用数据集划分到LDA步骤
- en: Analyze different methods to execute feature selection in terms of the quantum
    enhancement of the architecture
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析不同的方法以执行特征选择，考虑架构的量子增强
- en: Evaluate more feature maps to encode the data in quantum states
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估更多的特征图，以在量子态中编码数据
- en: Customize feature maps manually to measure the best approach for the individual
    problems faced
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动定制特征图，以测量针对个别问题的最佳方法
- en: Increase the qubits used to detect whether there is an advantage or disadvantage
    when a higher number of quantum bits are used
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加用于检测在使用更多量子比特时是否存在优势或劣势的量子比特数
- en: Train a quantum kernel to be optimized
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个量子核进行优化
- en: Change iterations and shots for the sake of finding the best parameters, with
    regard to the model classification result
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了找到最佳参数，调整迭代次数和拍摄次数，考虑模型分类结果
- en: Execute the algorithms in different types of simulators and quantum hardware
    to evaluate the impact of the backends in the final result
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同类型的模拟器和量子硬件上执行算法，以评估后端对最终结果的影响
- en: After deciding to dive into these types of implementations, it’s critical to
    remember that the preprocessing and encoding steps of the quantum algorithms application
    process can be the key to retrieving successful results. We will see in [*Chapter
    7*](B19146_07.xhtml#_idTextAnchor145) how and which cloud provider we can use
    to run this type of project. We will learn how to use different hardware and how
    to access them through the cloud.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定深入研究这些类型的实现时，重要的是记住量子算法应用过程中的预处理和编码步骤可能是成功结果的关键。我们将在[*第7章*](B19146_07.xhtml#_idTextAnchor145)中看到如何以及使用哪个云提供商来运行这种类型的项目。我们将学习如何使用不同的硬件以及如何通过云访问它们。
- en: Further reading
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Agarap, A. F. (2018). Deep learning using rectified linear units (relu). arXiv*
    *preprint arXiv:1803.08375.*'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Agarap, A. F. (2018). 使用修正线性单元（relu）的深度学习。arXiv* *预印本 arXiv:1803.08375.*'
- en: '*Assefa, S. A., Dervovic, D., Mahfouz, M., Tillman, R. E., Reddy, P., & Veloso,
    M. (2020, October). Generating synthetic data in finance: opportunities, challenges
    and pitfalls. In Proceedings of the First ACM International Conference on AI in
    Finance (**pp. 1–8).*'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Assefa, S. A., Dervovic, D., Mahfouz, M., Tillman, R. E., Reddy, P., & Veloso,
    M. (2020, October). 在金融中生成合成数据：机遇、挑战和陷阱. 在第一届ACM国际人工智能金融大会论文集（第1–8页）中.*'
- en: '*Bishop, C. M. (1994). Neural networks and their applications. Review of scientific
    instruments,* *65(6), 1803–1832.*'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Bishop, C. M. (1994). 神经网络及其应用. 科学仪器评论,* *65(6), 1803–1832.*'
- en: '*Bro, R., & Smilde, A. K. (2014). Principal component analysis. Analytical
    methods,* *6(9), 2812–2831.*'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Bro, R., & Smilde, A. K. (2014). 主成分分析. 分析方法,* *6(9), 2812–2831.*'
- en: '*Crook, J. N., Edelman, D. B., & Thomas, L. C. (2007). Recent developments
    in consumer credit risk assessment. European Journal of Operational Research,*
    *183(3), 1447–1465.*'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Crook, J. N., Edelman, D. B., & Thomas, L. C. (2007). 消费者信贷风险评估的最新发展. 欧洲运筹学杂志,*
    *183(3), 1447–1465.*'
- en: '*Crouhy, M., Galai, D., & Mark, R. (2000). A comparative analysis of current
    credit risk models. Journal of Banking & Finance,* *24(1-2), 59–117.*'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Crouhy, M., Galai, D., & Mark, R. (2000). 当前信用风险模型的比较分析. 银行与金融杂志,* *24(1-2),
    59–117.*'
- en: '*Ezhov, A. A., & Ventura, D. (2000). Quantum neural networks. In Future directions
    for intelligent systems and information sciences (pp. 213–235).* *Physica, Heidelberg.*'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Ezhov, A. A., & Ventura, D. (2000). 量子神经网络. 在《智能系统与信息科学的未来方向》一书中（第213–235页）。*
    *Physica, Heidelberg.*'
- en: '*Farhi, E., & Neven, H. (2018). Classification with quantum neural networks
    on near term processors. arXiv* *preprint arXiv:1802.06002.*'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Farhi, E., & Neven, H. (2018). 基于量子神经网络的分类研究：近端处理器的应用. arXiv* *预印本 arXiv:1802.06002.*'
- en: '*Figueira, A., & Vaz, B. (2022). Survey on synthetic data generation, evaluation
    methods and GANs. Mathematics,* *10(15), 2733.*'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Figueira, A., & Vaz, B. (2022). 关于合成数据生成、评估方法和生成对抗网络的调查. 数学,* *10(15), 2733.*'
- en: '*Havlíček, V., Córcoles, A. D., Temme, K., Harrow, A. W., Kandala, A., Chow,
    J. M., & Gambetta, J. M. (2019). Supervised learning with quantum-enhanced feature
    spaces. Nature,* *567(7747), 209–212.*'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Havlíček, V., Córcoles, A. D., Temme, K., Harrow, A. W., Kandala, A., Chow,
    J. M., & Gambetta, J. M. (2019). 使用量子增强特征空间的监督学习. Nature,* *567(7747), 209–212.*'
- en: '*Hearst, M. A., Dumais, S. T., Osuna, E., Platt, J., & Scholkopf, B. (1998).
    Support vector machines. IEEE Intelligent Systems and their applications,* *13(4),
    18–28.*'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Hearst, M. A., Dumais, S. T., Osuna, E., Platt, J., & Scholkopf, B. (1998).
    支持向量机. IEEE Intelligent Systems and their applications,* *13(4), 18–28.*'
- en: '*Izenman, A. J. (2013). Linear discriminant analysis. In Modern multivariate
    statistical techniques (pp. 237–280). Springer, New* *York, NY.*'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Izenman, A. J. (2013). 线性判别分析. 在《现代多元统计技术》一书中（第237–280页）。 Springer, New* *York,
    NY.*'
- en: '*Ji, G., & Zhu, Z. (2020). Knowledge distillation in wide neural networks:
    Risk bound, data efficiency and imperfect teacher. Advances in Neural Information
    Processing Systems,* *33, 20823–20833.*'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Ji, G., & Zhu, Z. (2020). 宽神经网络中的知识蒸馏：风险界限、数据效率和不完美的教师. 神经信息处理系统进展,* *33,
    20823–20833.*'
- en: '*Khan, S., Rahmani, H., Shah, S. A. A., & Bennamoun, M. (2018). A guide to
    convolutional neural networks for computer vision. Synthesis lectures on computer
    vision,* *8(1), 1–207.*'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Khan, S., Rahmani, H., Shah, S. A. A., & Bennamoun, M. (2018). 计算机视觉中的卷积神经网络指南.
    计算机视觉综合讲座,* *8(1), 1–207.*'
- en: '*Khashman, A. (2010). Neural networks for credit risk evaluation: Investigation
    of different neural models and learning schemes. Expert Systems with Applications,*
    *37(9), 6233–6239.*'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Khashman, A. (2010). 用于信用风险评估的神经网络：不同神经模型和学习方案的研究. 专家系统与应用,* *37(9), 6233–6239.*'
- en: '*Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization.
    arXiv* *preprint arXiv:1412.6980.*'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kingma, D. P., & Ba, J. (2014). Adam：一种随机优化方法. arXiv* *预印本 arXiv:1412.6980.*'
- en: '*Mancilla, J., & Pere, C. (2022). A Preprocessing Perspective for Quantum Machine
    Learning Classification Advantage in Finance Using NISQ Algorithms. Entropy,*
    *24(11), 1656.*'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mancilla, J., & Pere, C. (2022). 使用NISQ算法的量子机器学习分类优势：金融中的预处理视角. 熵,* *24(11),
    1656.*'
- en: '*Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., ...
    & Stoica, I. (2018). Ray: A distributed framework for emerging {AI} applications.
    In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    18) (**pp. 561–577).*'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Moritz, P., Nishihara, R., Wang, S., Tumanov, A., Liaw, R., Liang, E., ...
    & Stoica, I. (2018). Ray: A distributed framework for emerging {AI} applications.
    In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI
    18) (**pp. 561–577).*'
- en: '*Park, N., Mohammadi, M., Gorde, K., Jajodia, S., Park, H., & Kim, Y. (2018).
    Data synthesis based on generative adversarial networks. arXiv* *preprint arXiv:1806.03384.*'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Park, N., Mohammadi, M., Gorde, K., Jajodia, S., Park, H., & Kim, Y. (2018).
    基于生成对抗网络的数据合成。arXiv* *预印本 arXiv:1806.03384。*'
- en: '*Rebentrost, P., Mohseni, M., & Lloyd, S. (2014). Quantum support vector machine
    for big data classification. Physical review letters,* *113(13), 130503.*'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Rebentrost, P., Mohseni, M., & Lloyd, S. (2014). 用于大数据分类的量子支持向量机。物理评论快报，*
    *113(13)，130503。*'
- en: '*Schuld, M., Bocharov, A., Svore, K. M., & Wiebe, N. (2020). Circuit-centric
    quantum classifiers. Physical Review A,* *101(3), 032308.*'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Schuld, M., Bocharov, A., Svore, K. M., & Wiebe, N. (2020). 电路中心量子分类器。物理评论A，*
    *101(3)，032308。*'
- en: '*Sergeev, A., & Del Balso, M. (2018). Horovod: fast and easy distributed deep
    learning in TensorFlow. arXiv* *preprint arXiv:1802.05799.*'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Sergeev, A., & Del Balso, M. (2018). Horovod：在TensorFlow中实现快速和简易的分布式深度学习。arXiv*
    *预印本 arXiv:1802.05799。*'
- en: '*Singh, D., & Singh, B. (2020). Investigating the impact of data normalization
    on classification performance. Applied Soft Computing,* *97, 105524.*'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Singh, D., & Singh, B. (2020). 研究数据归一化对分类性能的影响。应用软计算，* *97，105524。*'
- en: '*Tangirala, S. (2020). Evaluating the impact of GINI index and information
    gain on classification using decision tree classifier algorithm. International
    Journal of Advanced Computer Science and Applications,* *11(2), 612–619.*'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Tangirala, S. (2020). 评估GINI指数和信息增益在使用决策树分类算法中的分类影响。国际高级计算机科学与应用杂志，* *11(2)，612–619。*'
- en: '*Yao, K., Zweig, G., Hwang, M. Y., Shi, Y., & Yu, D. (2013, August). Recurrent
    neural networks for language understanding. In Interspeech (**pp. 2524–2528).*'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Yao, K., Zweig, G., Hwang, M. Y., Shi, Y., & Yu, D. (2013年8月). 用于语言理解的递归神经网络。在Interspeech（**第2524–2528页）。*'
